Metadata-Version: 1.1
Name: seq2seq-lstm
Version: 0.1
Summary: Sequence-to-sequence classifier based on LSTM with the simple sklearn-like interface
Home-page: https://github.com/bond005/seq2seq
Author: Ivan Bondarenko
Author-email: bond005@yandex.ru
License: Apache License Version 2.0
Description: # seq2seq-lstm
        
        Seq2Seq-LSTM is a sequence-to-sequence classifier which has the sklearn-like interface and uses the Keras for neural modeling.
        
        Developing of this module was inspired by this tutorial:
        
        _Francois Chollet_, **A ten-minute introduction to sequence-to-sequence learning in Keras**, https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html
        
        Project goal is creating a simple Python package with the sklearn-like interface for solution of different seq2seq tasks:
        machine translation, question answering, decoding phonemes sequence into the word sequence, etc.
        
        ## Getting Started
        
        ### Prerequisites
        
        You should have python installed on your machine (we recommend Anaconda package) and modules listed in requirements.txt. If you do not have them, run in Terminal
        
        ```
        pip install -r requirements.txt
        ```
        
        ### Installing and Usage
        
        To install this project on your local machine, you should run the following commands in Terminal:
        
        ```
        cd YOUR_FOLDER
        git clone https://github.com/bond005/seq2seq.git
        cd seq2seq
        sudo python setup.py
        ```
        
        You can also run the tests
        
        ```
        python setup.py test
        ```
        
        To see the work of the Seq2Seq-LSTM on a large dataset, you can run a demo
        
        ```
        python demo/seq2seq_lstm_demo.py
        ```
        
        or
        
        ```
        python demo/seq2seq_lstm_demo.py some_file.pkl
        ```
        
        In this demo, the Seq2Seq-LSTM learns to translate the sentences from English into Russian. If you specify the neural model file (for example, aforementioned `some_file.pkl`), then the fitted neural model will be saved into this file for its loading instead of re-fitting at the next running.
        
        The Russian-English sentence pairs from the Tatoeba Project have been used as data for unit tests and demo script (see http://www.manythings.org/anki/).
        
        
Keywords: natural language processing,nlp,text processing,sequence-to-sequence,seq2seq,lstm,keras,scikit-learn
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing
Classifier: Topic :: Text Processing :: Linguistic
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 2.6
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
