#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2018 John Devereux <john_devereux@yahoo.com>
# Copyright (C) 2018 Pablo Iranzo Gómez <Pablo.Iranzo@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# description: Provide a summary of a sos report with a storage sbr bias
# long_name: Provide a summary of a sos report with a storage sbr bias
# priority: 500
#
#
# ---------------------------------------------#
# imported classes
# ---------------------------------------------#

from __future__ import print_function

import os
from os import listdir
from os.path import isfile, join
import sys
import stat
import subprocess
import string
import re
import collections
import time
import gzip
try:
    import bz2
except:
    pass

# ------------------------------------------------------------------------------------------
# TODO: need more problem solving options; like:
# Oracle RAC eviction (timeouts? if so why?)
# FS goes READONLY
# Corrupt LVM
# TODO: general multipath problem where cu thinks multipath isn't working but in fact he has only defined a single path
# and thus there can be no failover or multi pathing
# TODO: blacklist EMC gatekeeper luns (small 1/2M devices) in multipath? ->
# TODO: general udev rule issues that cause confusion & problems after reboot
# udev: use SYMLINK+= rather than NAME:= to avoid certain problems(?)
# udev: maintain consistent tape device names:  https://access.redhat.com/solutions/45626
# case  - "my devices names change on reoot"
# see https://access.redhat.com/discussions/1341873
# see https://access.redhat.com/solutions/45626
# TODO: check for valid VG/LV in grub.conf
# TODO: research all 'other ids:' for devices, make sure they make sense and aren't scsi ids, etc. that aren't being id'd properly
# TODO: Consider looking at etc/mdadm.conf for additional md raid info
# TODO: General case of failover not failing over...
#
# KCS reference articles:
#
# https://access.redhat.com/solutions/47894
# How do I setup multipath on a system that already has LVM configured?
#
# https://access.redhat.com/articles/1193803
# FC Discovery: Stage 5 - Quick Check -- SAN LUN Discovery Issues (still private as of 8/28/15 - BB author)
#
# https://access.redhat.com/solutions/1144423
# Why do we see "fcoemon: FC_HOST_EVENT FC_HOST_EVENT X at X secs on hostX:code X=lip_reset datalen X data=X" messages in RHEL 6
#
# https://access.redhat.com/solutions/48886
# Emulex lpfc fails to discover all expected Fibre Channel SCSI device paths
#
# https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/6.6_Technical_Notes/lvm2.html
# 8.132.1. RHBA-2014:1387 — lvm2 bug fix and enhancement update
#
# https://access.redhat.com/articles/17054
# How do I find the FC ID (WWN) of a scsi device/LUN on Red Hat Enterprise Linux?
#
# https://access.redhat.com/solutions/6387
# How to configure the iscsi-initiator in Red Hat Enterprise Linux?
#
# https://access.redhat.com/solutions/60152905727903  (used in case )
# Limiting path failover time for SCSI devices
#
# https://access.redhat.com/solutions/1241173 (used in case )
# 'multipathd' and disk checker recognises failed disks later then Oracle ASM
#
# https://access.redhat.com/solutions/66501
# How do I convert a single path boot from SAN RHEL system to multipath?
#
# https://access.redhat.com/node/3334
# How do I restore a volume group in Red Hat Enterprise Linux if one of the physical volumes that constitutes the volume group has failed?
#
# https://access.redhat.com/solutions/22993
# Why aren't remote filesystems (NFS, SAN) mounted automatically at boot when the netfs service is enabled, the _netdev option is specified and I can mount them manually after boot?
#
# https://access.redhat.com/solutions/433803
# https://access.redhat.com/solutions/2750771 (using bonding on software served FCOE interface...)
# Unable to mount the LVM volumes created over FCoE during boot time
#
# https://access.redhat.com/solutions/78813
# Certain SCSI Sense Keys can cause all paths in a multipath map to fail repeatedly in Red Hat Enterprise Linux
#
# https://access.redhat.com/solutions/504833
# Unable to blacklist a local disk from multipath
#
# https://access.redhat.com/solutions/67778
# How do I change the order of storage devices during boot in RHEL 5 and 6?
#
# https://access.redhat.com/solutions/56351
# Failed paths to scsi devices are deleted from the system
#
# case : ((lvm.conf filters)
# As discussed on call and worked over the remote session the issue was resolved after modifying the lvm filter as below.
# filter="a/.*/"
# filter=["r/sd.*/", "r/disk.*/", "a/.*/"]
#
# ------------------------------------------------------------------------------------------
# Multipath / LVM jmag notes: (from case )
#
# Multipath only supports scsi block devices, so you can't necessarily 'multipath' a VG...only the underlying physical volumes that make up the VG can be under multipath control.
# Now, multipath requires exclusive access to physical device(s), if that physical device is "in-use" by LVM and mounted, that will restrict multipathd from mapping it
# and return "Device or Resource busy" errors and you get no output from multipath user-space commands.
#
# You can map the physical devices that make up VolGroupBin by simply unmounting and deactivating the VG and running 'multipath -r' command.
# However, the issue then lies with VolGroup00, since this is root volume the VG can't be deactivated in runtime.
# So herein lies the challenge, RHEL5 lacks the functionality to convert single path lvm to multipath on a running system(can be done in RHEL6).
# However, can be performed within the rescue environment by passing the 'mpath' boot parameter, ie: linux rescue mpath (this option is not officially supported).
# If this is newly installed system, often times it is easier to reinstall using the mpath boot option vs attempting to convert single path to multipath root volume.
#
# ------------------------------------------------------------------------------------------

# ---------------------------------------------#
# CLASSES:
# ---------------------------------------------#


class Key_data(dict):
    def __missing__(self, key):
        return ""


class Key_data_m1(dict):  # use when 0 is a valid value and there is a need to distinguish between 0 and not set
    def __missing__(self, key):
        return -1


class Key_data_max(dict):  # use for 'max' value fields, if not set returns -1 so that min will be set to compared value the first time
    def __missing__(self, key):
        return -1


class Key_data_min(dict):  # use for 'min' value fields, if not set returns 'big_num' so that min will be set to compared value the first time
    def __missing__(self, key):
        global big_num
        return big_num


class Counter(dict):
    def __missing__(self, key):
        return 0


class mpc_object(object):
    def __init__(self, *arg_list):
        for (name, arg) in zip(multipath_conf_keywords.split(), arg_list):
            setattr(self, name, arg)


class lvm_object(object):
    def __init__(self, *arg_list):
        for (name, arg) in zip(lvm_conf_keywords.split(), arg_list):
            setattr(self, name, arg)


class c:  # no-op use
    pass


# =============================================#
# "language function" extensions
# =============================================#
# ---------------------------------------------#
# function: is_hex(str)
# ---------------------------------------------#
def is_hex(s):
    try:
        int(s, 16)
        return True
    except ValueError:
        return False

# ---------------------------------------------#
# function: is_float(str)
# ---------------------------------------------#


def is_float(s):
    try:
        float(s)
        return True
    except ValueError:
        return False

# ---------------------------------------------#
# function: is_printable(str)
# ---------------------------------------------#


def is_printable(s):
    global printset
    return(set(s).issubset(printset))


# ---------------------------------------------#
# function adjust_for_dbcs()
# ---------------------------------------------#
def adjust_for_dbcs(line, i, mpc_file):

    if '“' in line:
        line = line.replace('“', '"')  # left sided double quote: e2 80 9c (case )
    if '”' in line:
        line = line.replace('”', '"')  # right sided double quote: e2 80 9d (case )
    if '–' in line:
        line = line.replace('–', '-')  # dbcs dash: e2 80 93 (case )
    if ' ' in line:
        line = line.replace(' ', ' ')  # dbcs space: c2 a0  (case  etc/multipath.conf)
    if '-­' in line:
        line = line.replace('-­', '-')  # more dbcs dash wierdness 2d c2 ad [note 2d is an ascii dash]: (case  etc/multipath.conf)

    return(line)


# ---------------------------------------------#
# function: wordcount(list)
# return count of blank separated words in list
# ---------------------------------------------#
def wordcount(list):
    return(wordcount_sep(list, ''))

# ---------------------------------------------#
# function: wordscount_sep(list,sep)
# where:
# list is word of 'sep' separated words to count (default is blank-separated)
# return count of words in list
# ---------------------------------------------#


def wordcount_sep(list, sep):
    if list == "":
        return 0
    if sep == '' or sep == ' ':
        tmp = list.split()
    else:
        tmp = list.split(sep)
    return len(tmp)


# ---------------------------------------------#
# function: update_counted_list()
# word: AA
# list: AA(2) DD(9) BB(3) [passed in]
# list: AA(3) DD(9) BB(3) [returned]
# look up word in list and increment count
# ---------------------------------------------#
def update_counted_list(list, word):
    if not regex_word_in_list(word + "\(" + n6_re + "\)", list):
        if list == "":
            return(word + "(1)")
        else:
            return(list + " " + word + "(1)")

    tmp = list.split()
    for tmp_word in tmp:
        if re.match(word + "\(" + n6_re + "\)", tmp_word):
            n = tmp_word.strip(word + "(")
            n = n.rstrip(")")
            n = int(n)
            n += 1
            new_word = "{0}({1})".format(word, n)
            list = list.replace(tmp_word, new_word)
            return(list)
        # end: if rematch(word+"\("+n6_re+"\)",tmp_word):
    # end: for tmp_word in tmp:

    return('?')  # should never get here


# ---------------------------------------------#
# function: unique_list(list,item)
# if item is not in list, add it and return new list
# else return original list
# ---------------------------------------------#
def unique_list(list, item):
    return(unique_list_sep(list, item, ' ', False))

# ---------------------------------------------#
# function: unique_list_sep(list,item,sep)
# if item is not in list, add it and return new list
# else return original list
# list,word,sep, and ci are as in word_in_list_sep
# ---------------------------------------------#


def unique_list_sep(list, item, sep, ci):
    if item == '':
        return(list)
    if list == '':
        return(item)
    if word_in_list_sep(item, list, sep, ci, False):
        return(list)
    return(list + sep + item)


# ---------------------------------------------#
# function: word_in_list(word,list)
# basic word in list check
# ---------------------------------------------#
def word_in_list(word, list):
    return(word_in_list_sep(word, list, '', False, False))

# ---------------------------------------------#
# function: ci_word_in_list(word,list)
# case insensitive word in list check
# ---------------------------------------------#


def ci_word_in_list(word, list):
    return(word_in_list_sep(word, list, '', True, False))

# ---------------------------------------------#
# function: regex_word_in_list(word,list)
# reg_exp word in list check
# ---------------------------------------------#


def regex_word_in_list(regex_word, list):
    return(word_in_list_sep(regex_word, list, '', False, True))

# ---------------------------------------------#
# function: word_in_list_sep(word,list,sep)
# where word is word to serch for in list
# list is word of 'sep' separated words to search (default is blank-separated)
# ci is True/False and indicates whether or not the word comparission is case insensitive
# regex is True/False and indicates whether or not the word comparission is via re.match()
# return True or False on whether word is in list or not
# ---------------------------------------------#


def word_in_list_sep(word, list, sep, ci, regex):
    if word == "" or list == "":
        return False
    if sep == '' or sep == ' ':
        tmp = list.split()
    else:
        tmp = list.split(sep)
    for tmp_word in tmp:
        if ci:
            if regex:
                if re.match(word.lower(), tmp_word.lower()):
                    return True
            else:
                if word.lower() == tmp_word.lower():
                    return True
        else:
            if regex:
                if re.match(word, tmp_word):
                    return True
            else:
                if word == tmp_word:
                    return True
    # end: for tmp_word in tmp:
    return False


# ---------------------------------------------#
# function: dedup_(list)
# remove an duplicate items in list and return updated list
# ---------------------------------------------#
def dedup_list(list):
    return(dedup_list_sep(list, ' ', False))

# ---------------------------------------------#
# function: dedup_list_sep()
# list,sep, and ci are as in word_in_list_sep
# ---------------------------------------------#


def dedup_list_sep(list, sep, ci):
    if list == "":
        return list
    if sep == '' or sep == ' ':
        tmp = list.split()
    else:
        tmp = list.split(sep)
    deduped_list = ''
    for tmp_word in tmp:
        deduped_list = unique_list_sep(deduped_list, tmp_word, sep, ci)
    # end: for tmp_word in tmp:
    return deduped_list


# ---------------------------------------------#
# function: sort_numeric_list()
# list,and sep are as in word_in_list_sep
# ---------------------------------------------#
def sort_numeric_list(list):
    return(sort_list_sep(list, '', 'n'))

# ---------------------------------------------#
# function: sort_list()
# list,and sep are as in word_in_list_sep
# ---------------------------------------------#


def sort_list(list):
    return(sort_list_sep(list, '', ''))

# ---------------------------------------------#
# function: sort_list_sep()
# list,and sep are as in word_in_list_sep
# ---------------------------------------------#


def sort_list_sep(list, sep, stype):
    if list == "":
        return list

    if sep == '' or sep == ' ':
        tmp = list.split()
    else:
        tmp = list.split(sep)

    if stype == 'n':
        tmp.sort(key=int)
    else:
        tmp.sort()

    new_list = sep
    if new_list == '':
        new_list = ' '

    new_list = new_list.join(tmp[0:])

    return new_list


# ---------------------------------------------#
# function: word_in_re_list(word,re_list)
# ---------------------------------------------#
def word_in_re_list(word, re_list):
    return(word_in_re_list_sep(word, re_list, ' '))

# ---------------------------------------------#
# function: word_in_re_list_sep(word,re_list,sep)
# list can contain regex patterns
# ---------------------------------------------#


def word_in_re_list_sep(word, re_list, sep):
    if word == "" or re_list == "":
        return False
    tmp = re_list.split(sep)
    for tmp_re_word in tmp:
        if re.match(tmp_re_word, word):
            return True
    # end: for tmp_re_word in tmp:
    return False


# ---------------------------------------------#
# function: word_count(list)
# return count blank separated words in list
# ---------------------------------------------#
def word_count(list):
    return(word_count_sep(list, ''))

# ---------------------------------------------#
# function: word_count_sep(list,sep)
# return count of 'sep' separated words in list
# ---------------------------------------------#


def word_count_sep(list, sep):
    if list == '':
        return(0)
    if sep == '':
        words = list.split()
    else:
        words = list.split(sep[0:1])
    return(len(words))


# ---------------------------------------------#
# function: squeeze(string)
# return a string with all excess whitespace squeezed out
# e.g.: squeeze('aa  bb    c') -> 'aa bb c'
# ---------------------------------------------#
def squeeze(string):
    if string == '':
        return('')
    return(" ".join(string.split()))

# ---------------------------------------------#
# function: count_leading()
# ---------------------------------------------#


def count_leading(char, line):
    if line == '' or char == '':
        return(0)
    lc = char[0:1]
    leading_char_count = 0

    for i in range(0, len(line)):
        if line[i:i + 1] != lc:
            break
        leading_char_count += 1

    return(leading_char_count)

# ---------------------------------------------#
# function: plural(count)
# ---------------------------------------------#


def plural(count):
    if count > 1:
        return "s"
    return ""
# ---------------------------------------------#
# function: plurale(count)
# ---------------------------------------------#


def plurale(count):
    if count > 1:
        return "es"
    return ""
# ---------------------------------------------#
# function: was_were(count)
# ---------------------------------------------#


def was_were(count):
    if count > 1:
        return "were"
    return "was"
# ---------------------------------------------#
# function: has_have(count)
# ---------------------------------------------#


def has_have(count):
    if count > 1:
        return "have"
    return "has"

# ---------------------------------------------#
# function: csp(phrase,fragment)
# combine phrase and fragment,
# separate with comma (',') if necessary.
# ---------------------------------------------#


def csp(phrase, fragment):

    if phrase == '' and fragment == '':
        return('')
    if phrase == '':
        return(fragment)
    if fragment == '':
        return(phrase)
    return(phrase + ", " + fragment)

# =============================================#
# OS and file related functions:
# =============================================#

# ---------------------------------------------#
# function: subproc(cmd)
# ---------------------------------------------#


def subproc(cmd):
    global sw_cmd_fail
    debug_print(3, "about to run cmd: {0}".format(cmd))

    sw_cmd_fail = False
    cmd_stdout = ""
    try:
        cmd_stdout = subprocess.check_output(cmd, shell=True)
    except:
        # exit_print("cmd {0} failed, exiting...".format(cmd),0)
        print_stderr("cmd {0} failed, exiting...".format(cmd))
        sw_cmd_fail = True

    return cmd_stdout

# ---------------------------------------------#
# function: dir_exists(dir)
# return true or false; directory exists
# (no error message)
# ---------------------------------------------#


def dir_exists(dir):
    stat_ = stat_dir("", dir, 0)
    if stat_ is None:
        return False
    return True

# ---------------------------------------------#
# function: file_exists(fn)
# return true or false; files exists
# (no error message)
# ---------------------------------------------#


def file_exists(fn):
    stat = stat_file("", fn, 0)
    if stat is None:
        return False
    return True

# ---------------------------------------------#
# function: file_exists_with_data(fn)
# return true or false; files exists and size > 0
# (no error message)
# ---------------------------------------------#


def file_exists_with_data(fn):
    stat = stat_file("", fn, 0)
    if stat is None:
        return False
    if stat.st_size == 0:
        return False
    return True

# ---------------------------------------------#
# function: file_size(fn)
# return file size in bytes
# return -1 if file does not exist
# ---------------------------------------------#


def file_size(fn):
    stat = stat_file("", fn, 0)
    if stat is None:
        return(-1)
    return(stat.st_size)

# ---------------------------------------------#
# function: stat_file(dir,fn,bMsg)
# ---------------------------------------------#


def stat_file(dir, fn, bMsg):  # file exist?
    global callback_level  # 0

    sb = stat_fs_obj(dir, fn, bMsg, 2 + callback_level)
    if sb is None:
        return(sb)

    if not stat.S_ISREG(sb.st_mode):
        error_print('s', "{0} is not a file".format(dir + fn))
        errorprint(4 / 0)
        return(None)

    if not os.access(dir + fn, os.R_OK):
        error_print('a', "Unable to access file {0}".format(dir + fn))
        return(None)

    return(sb)

# ---------------------------------------------#
# function: stat_dir(dir,sub_dir,bMsg)
# ---------------------------------------------#


def stat_dir(dir, sub_dir, bMsg):  # dir exist?
    global callback_level  # 0

    sb = stat_fs_obj(dir, sub_dir, bMsg, 2 + callback_level)
    if sb is None:
        return(sb)

    if not stat.S_ISDIR(sb.st_mode):
        error_print('s', "{0} is not a directory".format(dir + sub_dir))
        return(None)

    if not os.access(dir + sub_dir, os.R_OK + os.X_OK):
        error_print('a', "Unable to access directory {0}".format(dir + sub_dir))
        return(None)

    return(sb)

# ---------------------------------------------#
# function: stat_fs_obj()
# ---------------------------------------------#


def stat_fs_obj(dir, fn, bMsg, level):  # return stat buf if object exists
    try:
        fid = dir + fn
        stat_obj = os.stat(fid)
# errorprint("size of {0} is {1}".format(fid,stat_obj.st_size))
        return(stat_obj)
    except OSError as e:
        if bMsg == 1:
            error_print("f", "[{0}.{1}] stat error({2}): {3} on object {4}".format(FUNC(level), LINE(level), e.errno, e.strerror, fid))
        return(None)


# ---------------------------------------------#
# function: readline1(fn)
#
# read what is usually a one, or sometimes two, line file.
#
# Note: Found that on older RHEL 4 sys/sos reports (not sure if it was an early sos report or not)
# where files like hostname and uname contained 2 lines, the first was the command used to
# create it and the second was the data (normally the first/only line).
# i.e. the uname file was:
#
# /bin/uname -a -or- /usr/bin/uname -a
# 'uname data....'
#
# Code added here to account for that.
# ---------------------------------------------#
def readline1(fn):
    global sw_debug_level
    debug_print(3, "attempting to open({0})".format(fn))

    fh = openfile(fn)
    if fh is None:
        return('')

    data = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if (line.startswith("/bin/") or line.startswith("/usr/bin/")) and fn in line:
            continue  # skip command echo
        if data == '':
            data = line
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return(data)


# ---------------------------------------------#
# function: writefile_nomsg(fn)
# ---------------------------------------------#
def writefile_nomsg(fn, data):
    return(writefile_msgctl(fn, data, 0))  # suppress open error msg

# ---------------------------------------------#
# function: writefile(fn)
# ---------------------------------------------#


def writefile(fn, data):
    return(writefile_msgctl(fn, data, 1))  # issue msg on open error

# ---------------------------------------------#
# function: writefile_msgctl(fn,Bmsg)
# ---------------------------------------------#


def writefile_msgctl(fn, data, Bmsg):
    debug_print(3, "attempting to open({0})".format(fn))

    try:
        fh = open(fn, 'w')
    except:
        # Use FUNC(2)/LINE(2) to get actual caller as writefile_msgctl is called from writefile_nomsg() or writefile()
        if Bmsg != 0:
            error_print("f", "[{0}.{1}] failed to open({2})".format(FUNC(2), LINE(2), fn))
        return ""

    debug_print(3, "file({0}) opened".format(fn))
    fh.write(data)
    debug_print(3, "file({0}) write".format(fn))
    fh.close()
    return ""


# ---------------------------------------------#
# function: openfile_nomsg(fn)
# ---------------------------------------------#
def openfile_nomsg(fn):
    return(openfile_msgctl(fn, False))  # suppress open error msg

# ---------------------------------------------#
# function: openfile(fn)
# ---------------------------------------------#


def openfile(fn):
    return(openfile_msgctl(fn, True))  # issue msg on open error

# ---------------------------------------------#
# function: openfile_msgctl(fn,Bmsg)
# fn = file name to open and read
# Bmsg = 0/1: issue msg on open error (or not)
# ---------------------------------------------#


def openfile_msgctl(fn, Bmsg):
    global sw_debug_level
    global total_sos_files_opened
    global callback_level  # 0

    debug_print(3, "attempting to open({0})".format(fn))

    sBmsg = 0
    if sw_debug_level > 0:
        sBmsg = 1
    callback_level += 1
    if stat_file('', fn, sBmsg) is None:
        callback_level -= 1
        return None  # out now of no file
    callback_level -= 1

    file_open = False
    open_verb = ""

    if fn.endswith(".gz"):
        if valid_gz_file(fn):
            fh = gzip.open(fn, 'r')
            file_open = True
        else:
            open_verb = "gzip.open"
    elif bz2 and fn.endswith(".bz2"):
        if valid_bz2_file(fn):
            fh = bz2.BZ2File(fn, 'r')
            file_open = True
        else:
            open_verb = "bz2.BZ2File"
    else:
        try:
            fh = open(fn, 'r')
            file_open = True
        except:
            open_verb = "open"
            # Use FUNC(2)/LINE(2) to get actual caller as openfile_msgctl is called from openfile_nomsg() or openfile()
            # if Bmsg != 0: debug_print(1,"[{0}.{1}] failed to open({2})".format(FUNC(2),LINE(2),fn))
            # return ""

    if file_open:
        debug_print(3, "file({0}) opened".format(fn))
        total_sos_files_opened += 1
    else:
        # Use FUNC(2)/LINE(2) to get actual caller as openfile_msgctl() is called from openfile_nomsg() or openfile()
        error_print('f', "[{0}.{1}] failed to {2}({3})".format(FUNC(2), LINE(2), open_verb, fn))
        fh = None

    return fh


# ---------------------------------------------#
# function: valid_gz_file()
# True/False - fn is valid gzip file
# ---------------------------------------------#
def valid_gz_file(fn):
    try:
        fh = gzip.open(fn, 'r')
    except:
        return(False)

    try:
        line = fh.readline()
    except:
        fh.close()
        return(False)

    fh.close()
    return(True)

# ---------------------------------------------#
# function: valid_bz2_file()
# True/False - fn is valid bz2 file
# ---------------------------------------------#


def valid_bz2_file(fn):
    try:
        fh = bz2.BZ2File(fn, 'r')
    except:
        return(False)

    try:
        line = fh.readline()
    except:
        fh.close()
        return(False)

    fh.close()
    return(True)

# ---------------------------------------------#
# function: closefile()
# ---------------------------------------------#


def closefile(fh, lines_read):
    global total_sos_files_closed
    global total_sos_lines_read

    try:
        fh.close()
        total_sos_files_closed += 1
        total_sos_lines_read += lines_read
        debug_print(3, "file() closed")
    except:
        error_print('f', "[{0}.{1}] failed to close file ({2})".format(FUNC(1), LINE(1), fh))

    return

# =============================================#
# Debugging / utility extensions
# =============================================#


def LINE(back=0):
    return sys._getframe(back + 1).f_lineno


def FILE(back=0):
    return sys._getframe(back + 1).f_code.co_filename


def FUNC(back=0):
    return sys._getframe(back + 1).f_code.co_name


def WHERE(back=0):
    frame = sys._getframe(back + 1)
    return "%s/%s %s()" % (os.path.basename(frame.f_code.co_filename),
                           frame.f_lineno, frame.f_code.co_name)

# ---------------------------------------------#
# function: debug_print(txt)
# ---------------------------------------------#


def debug_print(level, db_txt):
    global sw_debug
    global sw_debug_level
    global sw_t
    global last_time  # = time.time()

    if sw_debug is False:
        return

    if level > sw_debug_level:
        return

    curr_time = time.time()
    elapsed_time = round((curr_time - last_time), 4)
    last_time = curr_time
    # if elapsed_time < 0.000100000: elapsed_time = 0.0001000000
    if sw_t:
        et = "{0}".format(elapsed_time)
    else:
        et = "-.-"
    errorprint("debug{0}:({1})[{2}.{3}] {4}".format(level, et, FUNC(1), LINE(1), db_txt))
    return

# ---------------------------------------------#
# function: error_print()
# prints to stdout unless ":stderr" is appended to severity
# severity:
# a: unable to access an object due to permission settings
# i: informational
# l: logic error in the code
# t: table search failed where it should not occur
# d: data found that was unexpected, may require code update
# f: file input/output error
# s: unexpected system condition
# ---------------------------------------------#


def error_print(severity, error_txt):

    line = "@error[{0}]:[{1}.{2}] {3}".format(severity, FUNC(1), LINE(1), error_txt)

    if severity.endswith(":stderr"):
        print_stderr(line)
    else:
        errorprint(line)
    return


# ---------------------------------------------#
# function: print_stderr(txt)
# print to stderr
# ---------------------------------------------#
def print_stderr(txt):
    os.write(2, "{0}\n".format(txt))
    return

# =============================================#
# ---------------------------------------------#
# function: usage()
# ---------------------------------------------#
# =============================================#


def usage():
    errorprint("NAME")
    errorprint("        {0} - summarize a sosreport".format(this_script_name))
    errorprint("")
    errorprint("SYNOPSIS")
    errorprint("        {0} [OPTION] sosreport_fn".format(this_script_name))
    errorprint("            - or -")
    errorprint("        {0} [OPTION] base directory of extracted sosreport".format(this_script_name))
    errorprint("")
    errorprint("DESCRIPTION")
    errorprint("        Summarize a sosreport from a storage perspective")
    errorprint("")
    errorprint("        -a 'all', same as -pcdgftx")
    errorprint("        -b[=d|h|m|s] timeline, presents anomaly summary in chronological order, =increment: d(ay), h(our), m(inute), s(econd)(default)")
    errorprint("        -l leave the extracted sosreport in /tmp/{tmpname}_sumsos")
    errorprint("        -lvmdev='/dev/name' or -lvmdev='/dev/name1, /dev/name2, ...' name(s) of device(s) to test against either")
    errorprint("           the lvm.conf file in the sos report or a standalone rule specified in -lvmrule='rule'")
    errorprint("        -lvmrule='a -or r|/dev/...', requires -lvmdev= to have been specified, enclose multiple rules in brackets")
    errorprint("           lvmrule='[ a|/dev/sda, r|/dev/sdb ]'")
    errorprint("        -mpcdev='/dev/name' or -mpcdev='/dev/name1, /dev/name2, ...' name(s) of device(s) to test against either")
    errorprint("           the multipath.conf file in the sos report or a standalone rule specified in -mpcrule='rule'")
    errorprint("        -mpcrule='devnode \"^(md|dm-)\", requires -mpcdev= to have been specified, enclose multiple rules in braces")
    errorprint("           mpcrule='{ devnode \"^(md|dm-)\" devnode \"^hd[a-z]\"")
    errorprint("        -p analyze performance related data")
    errorprint("        -sga=n[G|M] size of Oracle sga, optional Gig or Meg modifiers, default {0}".format(mg_disp(oracle_sga, 1)))
    errorprint("        -c analyze configuration related data")
    errorprint("        -d print device mapper data")
    errorprint("        -g print volume group data")
    errorprint("        -f print filesystem data")
    errorprint("        -simulate=string where string can be Oracle or VMware, evaluate performance data as if present")
    errorprint("        -m[n] - read the last 'n' var/log/messages.n[.gz] file(s) prior to reading the current var/log/messages")
    errorprint("                file as if they were a single concatenated file. (also provides '-m' skeleton support)")
    errorprint("        -n if present, logically append sos_commands/general/dmesg_now and/or sos_commands/kernel_dmesg, to var/log/dmesg,")
    errorprint("           in certain cases this reveals additional errors and/or data, however normally these lines are in var/log/dmesg.")
    errorprint("        -r start from the most recent reboot line rather than starting at line 1 in var/log/messages")
    errorprint("        -o create '[overridden]' anomalies when newer data overrides older. These are bypassed by default.")
    errorprint("        -i create '[ignored]' anomalies when older data is ignored due to newer. These are bypassed by default.")
    errorprint("        -s[n] - print scsi map data where 'n' is detail level:")
    errorprint("                0 - print only device types and counts (minimimal)")
    errorprint("                1 - print summary map; luns coalesced on target line (default)")
    errorprint("                2 - print map with luns broken out")
    errorprint("                3 - print flat map with one line per host and lun in 'h:b:t:l description' format")
    errorprint("                4 - print map with luns broken out, partition data (if any) and all associated lun detail lines")
    errorprint("        -t provide overall elapsed time as well as interim timings if debug is on")
    errorprint("        -u analyze lvm backup data even if no LVM issues are found")
    errorprint("        -w [deprecated] scan and report on words and phrases in var/log/dmesg and var/log/messages")
    errorprint("        -x[n] - print pci bus map data where 'n' is detail level:")
    errorprint("                0 - print only pci types and counts (minimimal)")
    errorprint("                1 - print pci detail only if associated with a scsi host or errors found (default)")
    errorprint("                2 - print all pci entries")
    errorprint("        -maxanom=n maximum number of anomalies (per type) to track, default {0}".format(max_anomaly_count))
    errorprint("        -maxdanom=n maximum number of anomalies (per type) to display, default {0}".format(max_disp_anomaly_count))
    errorprint("        -dup display information about duplicate anomalies")
    errorprint("        -debug=n - print debug information")
    errorprint("               1 - print file i/o information")
    errorprint("               2 - print unexpected data encountered by {0}".format(this_script_name))
    errorprint("               3 - print processing flow data")
    errorprint("               4 - print processing loop flow data (potentially many lines)")
    errorprint("")
    errorprint("        Note: options in -optname=value format must appear as separate strings")


# =============================================#
# utility extensions specific to sumsos
# =============================================#

# ---------------------------------------------#
# function: is_wwn_id(w)
# is the passed parameter a world-wide-name id?
# Typically it is a 32 character hex string,
# but sometimes an 8 or 16 character hex string, see cases 01713084 and 01762927.
# e.g.:
#
# +--(8)
# 1---5---
# 48005001
#
# 1     +--(16)
# 1---5----0----5-
# 5000cca242d4116a
# 5000cca242d5cf57
#
# 1         2         3 +--(32)
# 1---5----0----5----0----5----0--
# 60000970000292603608533030413534
# 600508b1001037354d4b313133300008-part3
#
# as seen in case  sos_commands/devicemapper/ls_-laR_.dev:
#
# lrwxrwxrwx  1 root root   10 Jan 26 09:53 wwn-0x60000970000292603608533031313034 -> ../../sdbz
# lrwxrwxrwx  1 root root   10 Jan 26 09:53 wwn-0x60000970000292603608533031363137 -> ../../sdbv
# lrwxrwxrwx  1 root root   16 Jan 26 10:02 wwn-0x600508b1001037354d4b313133300008 -> ../../cciss/c0d0
# lrwxrwxrwx  1 root root   18 Jan 26 10:02 wwn-0x600508b1001037354d4b313133300008-part1 -> ../../cciss/c0d0p1
#
# lrwxrwxrwx 1 0 0  12 Mar 22 19:09 wwn-0x600605b00cfe3cd021416b2f33552a6b-part127 -> ../../sdb127
#
# ---------------------------------------------#
def is_wwn_id(w):
    if w == '':
        return(False)
    # if len(w) < 30:
    #     return(False)
    _w = w
    if is_partition_id(_w, ''):
        _w = get_dev_from_part_id(_w, '')
        # debug_print(0,_w)

    return(is_wwid(_w))

    # if not is_hex(_w): return(False)
    # if len(_w) == 32 or len(_w) == 16 or len(_w) == 8: return(True)
    # return(False)

# ---------------------------------------------#
# function: is_fc_id(f)
# is the passed parameter a fibre channel id?
# e.g.:
# 1     +--(16)
# 1---5----0----5-
# 5001738062930192
#
# lrwxrwxrwx. 1 0 0   10 Mar  1 16:43 pci-0000:08:00.0-fc-0x5001738062930192-lun-9 -> ../../sdax
# lrwxrwxrwx. 1 0 0   11 Mar  1 16:43 pci-0000:08:00.0-fc-0x5001738062930192-lun-9-part1 -> ../../sdax1
#
# ---------------------------------------------#


def is_fc_id(f):
    global hex16_re, n3_re

    if f == '':
        return(False)
    if len(f) < 16:
        return(False)

    if re.match(hex16_re, f):
        pass
    elif re.match("0x" + hex16_re, f):
        pass
    elif re.match("0x" + hex16_re + "-lun-" + n3_re, f):
        pass
    elif re.match("0x" + hex16_re + "-lun-" + n3_re + "-part" + n3_re, f):
        pass
    else:
        return(False)
    _f = f
    if is_partition_id(_f, ''):
        _f = get_dev_from_part_id(_f, '')
    # if not is_hex(_f): return(False)
    return(True)

# ---------------------------------------------#
# function: is_scsi_id(s)
# is the passed parameter a scsi id?
#
# e.g.:
# 1      +--(17)
# 1---5----0----5--
# 2001738006293120c
# 2001738006293120c-part1
#
# 20017380062933172
# 20017380062933172-part1
#
# 1         2         3  +--(33) -- standard length
# 1---5----0----5----0----5----0---
# 360000970000192605744533039363541
# 360060e8006d1e1000000d1e100000034
#
# 1         2         3   +--(34) -- partition id '1' appended
# 1---5----0----5----0----5----0-----
# 360002ac0000000000000051800019fbb1
#
#
# 1         2         3  +--(33) -- standard length plus 2 extra characters (D0) - why? no idea
# 1---5----0----5----0----5----0---
# 360060e8006d1e1000000d1e10000010cD0
#
# 1         2         3    +--(35) -- partition id 'p1' appended
# 1---5----0----5----0----5----0-----
# 360050768018186cc600000000000025fp1
# 360002ac000000000000004ed00019fbb-part3
#
# ---------------------------------------------#


def is_scsi_id(s):
    global len_std_scsi_id  # 33
    global n3_re

    s = s.strip()
    if s.startswith("0x"):
        s = s[len("0x"):]
    if s == '':
        return(False)

    p = s.find("-part")
    if p != -1:
        part_id = s[p:]
        s = s[0:p]

    if len(s) == 35 and s.endswith("D0") and is_hex(s) and s.startswith("3"):
        return(True)

    if len(s) > len_std_scsi_id:
        part_id = s[len_std_scsi_id:]
        if re.match(n3_re, part_id) or re.match("p" + n3_re, part_id):
            s = s[0:len_std_scsi_id]
        else:
            # debug_print(z,"bad scsi id? '{0}'".format(s))
            return(False)

    # if is_partition_id(s,''):
        # s = get_dev_from_part_id(s,'')

    lid = len(s)
    if lid == 17 and (s.startswith("3") or s.startswith("2")):
        pass
    elif lid < len_std_scsi_id:
        return(False)

    if not is_hex(s):
        # debug_print(z,s)
        return(False)

    # debug_print(z,"{0} true".format(s))
    return(True)

# ---------------------------------------------#
# function: is_iscsi_id(s)
# is the passed parameter a iscsi id?
# e.g.:
# 1IET_00010001
# 1IET_00010002
#
# ---------------------------------------------#


def is_iscsi_id(s):
    global len_std_iscsi_id  # 13

    if s == '':
        return(False)
    if len(s) < len_std_iscsi_id:
        return(False)
    _s = s
    if is_partition_id(_s, ''):
        _s = get_dev_from_part_id(_s, '')
    if not re.match("1IET_[0-9]{8}", _s):
        return(False)

    return(True)

# ---------------------------------------------#
# function: is_sata_id(s)
# e.g.:
# SATA_TSATA2R2_WD-WMAYUU584803
# ---------------------------------------------#


def is_sata_id(s):
    global len_std_sata_id  # 13

    if s == '':
        return(False)
    if len(s) < len_std_sata_id:
        return(False)
    _s = s
    if is_partition_id(_s, ''):
        _s = get_dev_from_part_id(_s, '')
    if not re.match("SATA_.*", _s):
        return(False)

    return(True)

# ---------------------------------------------#
# function: is_ata_id(s)
# TODO: research ata id standards
# anecdotally is seems free-form
# ---------------------------------------------#


def is_ata_id(s):
    global len_std_ata_id  # 13

    if s == '':
        return(False)
    # if len(s) < len_std_ata_id: return(False)
    _s = s
    if is_partition_id(_s, ''):
        _s = get_dev_from_part_id(_s, '')
    # if not re.match("SATA_.*",_s): return(False)

    return(True)

# ---------------------------------------------#
# function: is_wwid(w)
#
# from https://en.wikipedia.org/wiki/World_Wide_Name:
# A World Wide Name (WWN) or World Wide Identifier (WWID) is a unique identifier used in storage technologies including Fibre Channel,
# Advanced Technology Attachment (ATA) or Serial Attached SCSI (SAS).
#
# Each WWN is an 8 or 16 byte number, the length and format of which is determined by the most significant four bits,
# which are referred to as an NAA (Network Address Authority.) The remainder of the value is derived from an IEEE OUI
# (often the term "Company Identifier" is used as a synonym for OUI) and vendor-supplied information.
# Each format defines a different way to arrange and/or interpret these components.
# OUIs are used with the U/L and multicast bits zeroed, or sometimes even omitted (and assumed zero.)
#
# Note 1: we see wwn that are 4 bytes long too. See is_wwn_id() function prolog.
# Note 2: wwids are presented as hex display so a 4 byte number has a length of 8,
# an 8 byte number has a length of 16,
# and a 16 byte number has a length of 32.
#
# Note 3: we periodically see 15 byte wwns so 15 is added as a valid length. see case
# ---------------------------------------------#


def is_wwid(w):
    wl = len(w)
    if wl == 0:
        return(False)  # w == ''

    if wl == 8 or wl == 16 or wl == 32 or wl == 15:
        pass
    else:
        # debug_print(0,wl)
        return(False)

    if not is_hex(w):
        return(False)

    return(True)


# ---------------------------------------------#
# function: is_uuid(u)
#
# from https://en.wikipedia.org/wiki/World_Wide_Name:
# A universally unique identifier (UUID) is a 128-bit number used to identify information in computer systems.
# The term globally unique identifier (GUID) is also used.
# ---------------------------------------------#
def is_uuid(u):
    if u == '':
        return(False)
    if len(u) < 32:
        return(False)
    _u = u
    # if is_partition_id(_u,''):
    # _u = get_dev_from_part_id(_u,'')

    tmp = _u.split("-")
    _u = ""
    _u = _u.join(tmp[0:])
    if len(_u) != 32:
        return(False)
    # if not is_hex(_u): # Sometimes, but not all the time
    #     return(False)

    return(True)

# ---------------------------------------------#
# function: uuids_equal()
# allow equality when two uuids are the same
# but one or both has additional text appended to it:
# e.g.:  FTx68rB61ZZKOUfBDVR3XmsZ8zfeu2mM-real
# msZMCEyd0F0elQ9hZoG6AcM0dvChb4eY-cow
# 2oARmjsRgUaTK6H3Xe2Jb4T0QNjSQFCF-tpool
# NAURTimqRfnHlVeVCyqTG3Q6J0PVUesk-pool
# ---------------------------------------------#


def uuids_equal(uuid1, uuid2):
    len_std_uuid = 32

    if uuid1 == uuid2:
        return(True)

    l1 = len(uuid1)
    l2 = len(uuid2)
    if l1 == l2 == len_std_uuid:
        return(False)

    if (l1 < len_std_uuid) or (l2 < len_std_uuid):
        return(False)

    if uuid1[0:len_std_uuid] != uuid2[0:len_std_uuid]:
        return(False)

    extra1 = ''
    extra2 = ''

    if l1 > len_std_uuid:
        extra1 = uuid1[len_std_uuid:]
    if l2 > len_std_uuid:
        extra2 = uuid2[len_std_uuid:]

    if extra1 != '' and not re.match("-.*", extra1):
        return(False)
    if extra2 != '' and not re.match("-.*", extra2):
        return(False)
    return(True)


# ---------------------------------------------#
# function: clean_uuid(uuid)
# 123456-1234-1234-1234-1234-1234-123456
# len = 32 -> (6 * 2) + (4 * 5)
# -or-
# 12345678 1234 1234 1234 123456789012
# len = 32 -> 8 + (4 * 3) + 12
# d0f60ab1-4eda-4f68-9f3d-ffd364df8379
# ---------------------------------------------#
def clean_uuid(uuid):
    if not is_uuid(uuid):
        return(uuid)
    tmp = uuid.split("-")  # remove any "-"s
    uuid = ""
    uuid = uuid.join(tmp[0:])
    return(uuid)

# ---------------------------------------------#
# function clean_vg_lv()
# made necessary because of double dash rules...
# ---------------------------------------------#


def clean_vg_lv(vg_lv, source):
    # debug_print(z,"'{0}' ({1})".format(vg_lv,source))
    vg = split_valid_vg_name(vg_lv, source)
    if vg == '':
        return('')

    lv = split_valid_lv_name(vg_lv, source)
    if lv == '':
        return('')

    clean_vg_lv = build_vg_lv(vg, lv, source)
    return(clean_vg_lv)

# ---------------------------------------------#
# function create_vg_lv()
# like build_vg_lv() but validate vg and lv?
# ---------------------------------------------#
# def create_vg_lv(vg,lv,source):

# ---------------------------------------------#
# ---------------------------------------------#


def build_vg_lv(vg, lv, source):
    if vg == "" or lv == "":
        return('')
    return(dash_conv(vg) + "-" + dash_conv(lv))

# ---------------------------------------------#
# ---------------------------------------------#


def dash_conv(ele):
    d = ele.find("-", i)
    dd = ele.find("--", i)
    if d != -1 and d != dd:
        ele = ele.replace("-", "--")
    return(ele)

# ---------------------------------------------#
# function: format_uuid(uuid)
# 123456-1234-1234-1234-1234-1234-123456
# ---------------------------------------------#


def format_uuid(_uuid):
    uuid = _uuid
    if uuid == "":
        return(uuid)

    std_uuid_len = (6 + (4 * 5) + 6)

    if len(uuid) != std_uuid_len:
        extra = ''
        if len(uuid) > std_uuid_len:
            extra = uuid[std_uuid_len:]
        if not extra.startswith('-'):
            errorprint("format_uuid({0}) length not 32 ({1})".format(uuid, len(uuid)))

    f_uuid = "{0}-{1}-{2}-{3}-{4}-{5}-{6}".\
              format(uuid[0:6],\
                     uuid[0o6:0o6+4],\
                     uuid[10:10+4],\
                     uuid[14:14+4],\
                     uuid[18:18+4],\
                     uuid[22:22+4],\
                     uuid[26:])


    return(f_uuid)


# ---------------------------------------------#
# function: get_info_from_sos_fn(sos_report_fn,f_size)
#
# format of sos fn: 'sosreport-'name'.'caseno'-'date_n_time'-'md5'.tar.bz2/.xz
#
# ---------------------------------------------#
def get_info_from_sos_fn(sos_fn, f_size):

    # suffix_list = { ".tar.bz2", ".tar.xz" } # this ok in python 2.7.5 but not in 2.6.6
    suffix_list = ".tar.bz2 .tar.xz"         # so use this method instead

    sos_info = os.path.basename(sos_fn)
    debug_print(3, "sos_info after basename: {0}".format(sos_info))
    pfx_l = len("sosreport-")

    if len(sos_info) <= pfx_l:
        errorprint("warning: sosreport name is shorter than standard prefix ['sosreport-']")
        return

    # debug_print(3,"sos_info prefix length: {0}".format(pfx_l))
    # debug_print(3,"sos_info prefix: {0}".format(sos_info[0:pfx_l]))
    if sos_info[0:pfx_l] != "sosreport-":
        errorprint("warning: sosreport name does not have the standard prefix ['sosreport-']")
        return

    sos_info = sos_info[pfx_l:]  # remove prefix
    debug_print(3, "sos_info w/o prefix: {0}".format(sos_info))
    li = len(sos_info)

    suffix_list = suffix_list.split()  # see above python comment
    for suffix in suffix_list:
        sfx_beg = li - len(suffix)
        if sos_info[sfx_beg:] == suffix:
            debug_print(3, "sfx_beg {0}".format(sfx_beg))
            sos_info = sos_info[0:sfx_beg]  # remove suffix
            debug_print(3, "sos_info w/o suffix: {0}".format(sos_info))
            break

    if li == len(sos_info):  # did we fail to find & remove a suffix?
        errorprint("warning: sosreport name does not have a recognized suffix [{0}]".format(suffix_list))

    sos_id = "????"
    sos_case_no = "nnnnnnn"
    sos_datetime = "yyyymmddhhmmss"
    sos_info = sos_info.replace(".", "-")
    words = sos_info.split('-')
    i = 0

    for word in words:
        i = i + 1
        debug_print(3, "word[{0}]".format(word))
        lw = len(word)
        if lw == 8 and word.isdigit() is True:
            sos_case_no = word
            continue
        if lw == 14 and word.isdigit() is True:
            sos_datetime = word
            continue
        if i == 1:
            sos_id = word
    errorprint("{0} size({1})".format(os.path.basename(sos_fn), mg_disp(f_size, 1)))
    errorprint("sosreport fn report id: {0}".format(sos_id))
    errorprint("sosreport fn case number: {0}".format(sos_case_no))
    errorprint("sosreport fn date & time: {0}/{1}/{2} {3}:{4}:{5}".
               format(sos_datetime[0:4], sos_datetime[4:6], sos_datetime[6:8], sos_datetime[8:10], sos_datetime[10:12], sos_datetime[12:14]))

    return
# ---------------------------------------------#
# function: mem_disp(line)
#
# RHEL 6:
# total       used       free     shared    buffers     cached
# Mem:     529153744  515299528   13854216     991576     128852  323908868
# -/+ buffers/cache:  191261808  337891936
# Swap:     56619000        644   56618356
#
# RHEL 7:
# total        used        free      shared  buff/cache   available
# Mem:        1884512      233852     1147660       17044      503000     1477116
# Swap:       2097148           0     2097148
# ---------------------------------------------#


def mem_disp(ml, bDisplay):
    global total_mem
    global pct_mem_buff_cache  # ''
    global ATTN

    mem_word = ml.split()
    wc = len(mem_word)
    mem_type = mem_word[0]
    mem_total = int(mem_word[1])
    mem_used = int(mem_word[2])
    mem_free = int(mem_word[3])
    bc_blurb = ''

    if mem_word[0] == "Mem:":
        if rhel_is("GE", "7.0"):
            mem_buff_cache = int(mem_word[5])
            pct_mem_buff_cache = pct_disp(mem_buff_cache, mem_total)
            bc_blurb = " buff/cache: {0} ({1}%)".format(mg_disp(mem_buff_cache, 1024), pct_mem_buff_cache)
        elif wc == 7:
            mem_buff_cache = int(mem_word[5]) + int(mem_word[6])
            pct_mem_buff_cache = pct_disp(mem_buff_cache, mem_total)
            bc_blurb = " buff/cache: {0} ({1}%)".format(mg_disp(mem_buff_cache, 1024), pct_mem_buff_cache)

    pct_mem_used = pct_disp(mem_used, mem_total)
    pct_mem_free = pct_disp(mem_free, mem_total)

    if is_float(pct_mem_used):
        pmu = float(pct_mem_used)
    else:
        pmu = 0

    if mem_type == "Mem:" and pmu > 95.0:
        mem_blurb = ATTN + "used exceeds 95%"
    else:
        mem_blurb = ''

    if bDisplay:
        errorprint("{0} total: {1}  used: {2} ({3}%) free: {4} ({5}%){6} {7}".format(mem_type,
                                                                                     mg_disp(mem_total, 1024),
                                                                                     mg_disp(mem_used, 1024), pct_mem_used,
                                                                                     mg_disp(mem_free, 1024), pct_mem_free,
                                                                                     bc_blurb,
                                                                                     mem_blurb
                                                                                     ))

    if mem_type == "Mem:":
        total_mem = mem_total

    return


# ---------------------------------------------#
# function: devsize_disp()
# return the display version of the device size
# ---------------------------------------------#
def devsize_disp(dev_id):
    global dev_2_size  # Counter()

    dev_size = dev_2_size[dev_id]
    # dev_size = ((dev_size + (kb-1)) / kb) * kb
    dev_size_disp = mg_disp(dev_size, 1)
    # debug_print(0,dev_2_size_origin[dev_id])
    return(dev_size_disp)

# ---------------------------------------------#
# function: mg_disp(numstr,units)
# display an amount in Tb, Gb, Mb, Kb, b
# as appropriate.
# ---------------------------------------------#


def mg_disp(amount, units):
    global pb, tb, gb, mb, kb
    mga = amount * units
    if mga >= pb:
        return "{0}Pb".format(round((float(mga) / pb), 1))
    if mga >= tb:
        return "{0}Tb".format(round((float(mga) / tb), 1))
    if mga >= gb:
        return "{0}Gb".format(round((float(mga) / gb), 1))
    if mga >= mb:
        return "{0}Mb".format(round((float(mga) / mb), 1))
    if mga >= kb:
        return "{0}Kb".format(round((float(mga) / kb), 1))
    else:
        return "{0}b".format(mga)

# ---------------------------------------------#
# function: mg_conv(numstr)
# convert an amount in P, Tb, Gb, Mb, Kb, b
# as appropriate.
# ---------------------------------------------#


def mg_conv(numstr, bExit, ss):
    global tb, gb, mb, kb
    debug_print(3, "mg_conv({0})".format(numstr))

    # no g/m/k/b suffix, just return the number
    if numstr.isdigit() is True:
        return int(numstr)

    if numstr.find(",") != -1:
        numstr = numstr.replace(",", ".")
        debug_print(3, numstr)

    amt = numstr[0:len(numstr) - 1]
    mgk = numstr[len(numstr) - 1:].upper()

    if mgk == "B":
        last_char = amt[len(amt) - 1:].upper()
        # nnnTB/GB/MB, etc.. ??
        if word_in_list(last_char, "P T G M K"):
            amt = amt[0:len(amt) - 1]
            mgk = last_char
        elif last_char.isdigit():
            pass
        else:
            return int(-1)

    unit = 0
    if mgk == "P":
        unit = pb
    elif mgk == "T":
        unit = tb
    elif mgk == "G":
        unit = gb
    elif mgk == "M":
        unit = mb
    elif mgk == "K":
        unit = kb
    elif mgk == "B":
        unit = 1
    elif mgk == "S" and ss:
        unit = ss
    else:
        if bExit == 1:
            err_line = "invalid option value: {0}".format(numstr)
            exit_print(err_line, RC_FAILED)
        else:
            return int(-1)

    if numstr.find(".") != -1:
        amt = float(amt) * float(unit)
        return float(amt)
    else:
        amt = int(amt) * int(unit)
        return int(amt)

# ---------------------------------------------#
# function: pct_disp(nstr_partial,nstr_total)
# ---------------------------------------------#


def pct_disp(nstr_partial, nstr_total):

    np = int(nstr_partial)
    nt = int(nstr_total)

    np = np * 1024
    nt = nt * 1024

    if nt == 0:
        if np == 0:
            return "0"
        else:
            return "~"
    else:
        return "{0}".format((np * 100) / nt)


# ---------------------------------------------#
# function: chk_options(option)
# ---------------------------------------------#
def chk_options(opt):
    global sw_configuration
    global sw_performance
    global sw_debug
    global sw_debug_level
    global sw_help
    global sw_leave
    global sw_sm
    global sw_sm_level
    global sw_vg
    global sw_fs
    global sw_dm
    global sw_w
    global sw_r
    global sw_m
    global sw_msg_level  # 0
    global sw_n
    global sw_o
    global sw_i
    global sw_t
    global sw_u
    global sw_pci
    global sw_pci_level
    global sw_dup
    global oracle_sga
    global sw_sim_oracle
    global sw_sim_vmware
    global sw_timeline
    global timeline_increment
    global max_anomaly_count
    global max_disp_anomaly_count
    global lvm_device_to_test
    global lvm_rule_to_eval
    global mpc_device_to_test
    global mpc_rule_to_eval

    debug_print(3, "chk_options({0})".format(opt))

    if opt == "-":
        exit_print("incomplete option", RC_FAILED)

    l = len(opt)
    for i in range(1, l):
        opt_switch = opt[i:i + 1]
        debug_print(3, "opt sw '{0}' {1}".format(opt_switch, i))
        if opt_switch == "-" or opt_switch == "":
            continue
        if opt_switch == "a":
            sw_performance = True
            sw_configuration = True
            sw_dm = True
            sw_vg = True
            sw_fs = True
            sw_sm = True
            sw_t = True
            sw_sm_level = 1
            sw_pci = True
            sw_pci_level = 1
            debug_print(3, "sw_all")
            continue
        if opt_switch == "b":
            sw_timeline = True
            debug_print(3, "sw_timeline {0}".format(sw_timeline))
            if opt.startswith("-b="):
                timeline_increment = opt[3:4]
                if timeline_increment == '':
                    timeline_increment = 's'
                if word_in_list(timeline_increment, "d h m s"):
                    return
            continue
        if opt_switch == "c":
            sw_configuration = True
            debug_print(3, "sw_configuration {0}".format(sw_configuration))
            continue
        if opt_switch == "g":
            sw_vg = True
            debug_print(3, "sw_vg {0}".format(sw_vg))
            continue
        if opt_switch == "f":
            sw_fs = True
            debug_print(3, "sw_fs {0}".format(sw_fs))
            continue
        if opt_switch == "p":
            sw_performance = True
            debug_print(3, "sw_performance {0}".format(sw_performance))
            continue
        if opt_switch == "d":
            if opt.startswith("-debug="):
                sw_debug = True
                sw_debug_level = mg_conv(opt[7:], 1, 0)
                debug_print(3, "sw_debug {0} sw_debug_level {1}".format(sw_debug, sw_debug_level))
                return
            if opt.startswith("-dup"):
                sw_dup = True
                return
            sw_dm = True
            debug_print(3, "sw_dm {0}".format(sw_dm))
            continue
        if opt_switch == "h":
            sw_help = True
            debug_print(3, "sw_help {0}".format(sw_help))
            continue
        if opt_switch == "l":
            if opt.startswith("-lvmdev="):
                lvm_device_to_test = opt[len("-lvmdev="):]
                debug_print(3, "lvm_device_to_test {0}".format(lvm_device_to_test))
                return
            if opt.startswith("-lvmrule="):
                lvm_rule_to_eval = opt[len("-lvmrule="):]
                debug_print(3, "lvm_rule_to_eval {0}".format(lvm_rule_to_eval))
                return
            sw_leave = True
            debug_print(3, "sw_leave {0}".format(sw_leave))
            continue
        if opt_switch == "r":
            sw_r = True
            debug_print(3, "sw_r {0}".format(sw_r))
            continue
        if opt_switch == "s":
            if opt.startswith("-sga="):
                oracle_sga = mg_conv(opt[5:], 1, 0)
                debug_print(3, "oracle_sga {0}".format(oracle_sga))
                return
            if opt.startswith("-simulate="):
                sim_env = opt[10:]
                if sim_env.lower() == "oracle":
                    sw_sim_oracle = 1
                    return
                if sim_env.lower() == "vmware":
                    sw_sim_vmware = 1
                    return
                err_line = "invalid value '{0}' for simulate=".format(sim_env)
                exit_print(err_line, RC_FAILED)
            sw_sm = True
            tmp_level = opt[i + 1:i + 2]
            if tmp_level.isdigit():
                sw_sm_level = int(tmp_level)
                opt = "{0}{1}".format(opt[0:i + 1], opt[i + 2:])  # take digit out and resume parsing (any) rem-aining opt switches
            else:
                sw_sm_level = 1
            debug_print(3, "sw_sm {0} sw_sm_level {1}".format(sw_sm, sw_sm_level))
            continue
        if opt_switch == "m":
            if opt[0:9] == "-maxanom=":
                max_anomaly_count = mg_conv(opt[9:], 1, 0)
                debug_print(3, "max_anomaly_count {0}".format(max_anomaly_count))
                return
            if opt[0:10] == "-maxdanom=":
                max_disp_anomaly_count = mg_conv(opt[10:], 1, 0)
                debug_print(3, "max_disp_anomaly_count {0}".format(max_disp_anomaly_count))
                return
            if opt.startswith("-mpcdev="):
                mpc_device_to_test = opt[8:]
                debug_print(3, "mpc_device_to_test {0}".format(mpc_device_to_test))
                return
            if opt.startswith("-mpcrule="):
                mpc_rule_to_eval = opt[9:]
                debug_print(3, "mpc_rule_to_eval {0}".format(mpc_rule_to_eval))
                return
            sw_m = True
            tmp_level1 = opt[i + 1:i + 2]
            tmp_level2 = opt[i + 2:i + 3]
            if tmp_level1.isdigit():
                sw_msg_level = int(tmp_level1)
                end_m_opt = 2
                if tmp_level2.isdigit():
                    sw_msg_level = (sw_msg_level * 10) + int(tmp_level2)
                    end_m_opt = 3
                opt = "{0}{1}".format(opt[0:i + 1], opt[i + end_m_opt:])  # take digit(s) out and resume parsing (any) rem-aining opt switches
            debug_print(1, "sw_m {0} sw_msg_level {1}".format(sw_m, sw_msg_level))
            continue
        if opt_switch == "n":
            sw_n = True
            debug_print(3, "sw_n {0}".format(sw_n))
            continue
        if opt_switch == "o":
            sw_o = True
            debug_print(3, "sw_o {0}".format(sw_o))
            continue
        if opt_switch == "i":
            sw_i = True
            debug_print(3, "sw_i {0}".format(sw_i))
            continue
        if opt_switch == "w":
            sw_w = True
            debug_print(3, "sw_w {0}".format(sw_w))
            continue
        if opt_switch == "t":
            sw_t = True
            debug_print(3, "sw_t {0}".format(sw_t))
            continue
        if opt_switch == "u":
            sw_u = True
            debug_print(3, "sw_u {0}".format(sw_u))
            continue
        if opt_switch == "x":
            sw_pci = True
            tmp_level = opt[i + 1:i + 2]
            if tmp_level.isdigit():
                sw_pci_level = int(tmp_level)
                opt = "{0}{1}".format(opt[0:i + 1], opt[i + 2:])  # take digit out and resume parsing (any) rem-aining opt switches
            else:
                sw_pci_level = 1
            debug_print(3, "sw_pci {0} sw_pci_level {1}".format(sw_pci, sw_pci_level))
            continue

        err_line = "invalid option: {0}".format(opt_switch)
        exit_print(err_line, RC_FAILED)


# ---------------------------------------------#
# function: exit_print(text,rc) # print processing error
# ---------------------------------------------#
def exit_print(error_text, exit_code):

    exitcitellus(code=exit_code, msg=error_text)

# ---------------------------------------------#
# function: cleanup(code)
# ---------------------------------------------#


def cleanup(cleanup_code):
    global sw_leave
    global sw_t
    global tmp_dir
    global first_time
    global last_time
    global messages_file_count
    global messages_line_count
    global messages_skipped
    global messages_start_line_ref
    global first_message_timestamp
    global last_message_timestamp
    global last_reboot_timestamp
    global syslog_nodename_status  # '' # status line indicating outcome of nodename analysis in messages file
    # global messages_fn # "messages"
    global first_message_file_read  # ''
    global skip_same_last_non_match  # 0
    global total_sos_files_opened
    global total_sos_files_closed
    global total_sos_lines_read

    if sw_leave is False and tmp_dir != "":
        rmcmd = "rm -rf {0}".format(tmp_dir)
        subproc(rmcmd)

    last_time = time.time()
    elapsed_time = last_time - first_time
    if sw_t:
        et = "{0}".format(round(elapsed_time, 2))
    else:
        et = "-.-"

    debug_print(1, "syslog skip breakdown: mark|repeatd:{0}, inv hdr:{1}, not this nodename:{2}, matched skip prefix:{3}".
                format(messages_skipped_mark_or_repeat, messages_skipped_inv_hdr, messages_skipped_not_this_nodename, messages_skipped_skip_prefix))
    debug_print(1, "skipped {0} check_log_msg() calls based on last_non_match_line".format(skip_same_last_non_match))

    if messages_line_count > 0:
        skip_pct = (100 * messages_skipped) / messages_line_count
    else:
        skip_pct = 0
    errorprint("{0} '{1}' file{2} read, {3} lines, {4} skipped [{5}%], oldest msg:'{6}' newest msg:'{7}' last reboot:'{8}'".
               format(messages_file_count, first_message_file_read, plural(messages_file_count),
                      messages_line_count, messages_skipped, skip_pct,
                      first_message_timestamp.rstrip(), last_message_timestamp.rstrip(), last_reboot_timestamp.rstrip()))

    # if no current messages file or no messages evaluated (messages_line_count eq 0) , but older messages.xxx(.gz) files exist,
    # messages_start_line_ref could be set. However, unless sw_r is set they were not evaluated (just scanned).
    # Note: abitrarily checking for at least 100 messages skipped as otherwise the chance of any mis-leading messages is low.
    if not sw_r and (messages_line_count > 0 and messages_start_line_ref > 100):
        blurb = " This can cause invalid device correlation failure messages. Use the -r option if needed."
        # if messages_start_line_ref <= 100: blurb = '' # un comment if check above changes
        errorprint("Note: {0} messages were evaluated which occured prior to most recent reboot.{1}".
                   format(messages_start_line_ref, blurb))

    errorprint("{0}".format(syslog_nodename_status))

    if total_sos_files_opened != total_sos_files_closed:
        error_print('l', "total_sos_files_opened={0} total_sos_files_closed={1} ?".
                    format(total_sos_files_opened, total_sos_files_closed))

    errorprint("exiting from {0} with rc={1}, elapsed time={2}, files read={3}, lines read={4}".
               format(this_script_name, cleanup_code, et, total_sos_files_opened, total_sos_lines_read))

    exitcitellus(code=RC_FAILED, msg='Cleanup exit')


# ---------------------------------------------#
# function: rhel_is()
# if rhel_is("GT","6.5")
# return True/False
# ---------------------------------------------#
def rhel_is(op, rhel_compare):
    global rh_major
    global rh_minor
    t_maj = 0
    t_min = 0
    debug_print(3, "rhel_is({0}.{1},{2},{3})".format(rh_major, rh_minor, op, rhel_compare))
    valid_ops = "EQ GT GE LT LE"

    if op == '' or rhel_compare == '' or not word_in_list(op, valid_ops):
        return False

    tmp = rhel_compare.split('.')
    tc = len(tmp)
    if tc > 2:
        return False
    if not tmp[0].isdigit():
        return False
    t_maj = tmp[0]
    if tc > 1:
        if not tmp[1].isdigit():
            return False
        t_min = tmp[1]
    rhel_expanded = kernel_normalize(rh_major, rh_minor, '0', '0')

    comp_expanded = kernel_normalize(t_maj, t_min, '0', '0')
    debug_print(3, "rhel_is({0},{1},{2})".format(rhel_expanded, op, comp_expanded))

    true_false = False
    if op == "EQ":
        true_false = (rhel_expanded == comp_expanded)
    elif op == "GE":
        true_false = (rhel_expanded >= comp_expanded)
    elif op == "GT":
        true_false = (rhel_expanded > comp_expanded)
    elif op == "LE":
        true_false = (rhel_expanded <= comp_expanded)
    elif op == "LT":
        true_false = (rhel_expanded < comp_expanded)
    else:
        true_false = (False)

    debug_print(3, "rhel_is: returns {0}".format(true_false))
    return(true_false)


# ---------------------------------------------#
# function: kernel_is()
# if kernel_is("GT","2.6.32-220.el6")
# return True/False
# ---------------------------------------------#
def kernel_is(op, k_compare):
    global kernelStr  # Key_data()
    t_maj = 0
    t_min = 0
    t_rel1 = 0
    t_rel2 = 0
    debug_print(3, "kernel_is({0},{1},{2})".format(kernelStr['level'], op, k_compare))
    valid_ops = "EQ GT GE LT LE"

    if op == '' or k_compare == '' or not word_in_list(op, valid_ops):
        return False

    tmp = k_compare.split('.')
    tc = len(tmp)

    if tc >= 1:
        if tmp[0].isdigit():
            t_maj = int(tmp[0])
        else:
            return False

    if tc >= 2:
        if tmp[1].isdigit():
            t_min = int(tmp[1])
        else:
            return False

    if tc >= 3:
        if tmp[2].isdigit():
            t_rel1 = int(tmp[2])
        else:
            if '-' in tmp[2]:
                rtmp = tmp[2].split('-')
                if rtmp[0].isdigit():
                    t_rel1 = int(rtmp[0])
                else:
                    return False
                if rtmp[1].isdigit():
                    t_rel2 = int(rtmp[1])
                else:
                    return False
            else:
                return False
    compare_expanded = kernel_normalize(t_maj, t_min, t_rel1, t_rel2)
    debug_print(3, "kernel_is({0},{1},{2})".format(kernelStr['expanded'], op, compare_expanded))

    true_false = False
    if op == "EQ":
        true_false = (kernelStr['expanded'] == compare_expanded)
    elif op == "GE":
        true_false = (kernelStr['expanded'] >= compare_expanded)
    elif op == "GT":
        true_false = (kernelStr['expanded'] > compare_expanded)
    elif op == "LE":
        true_false = (kernelStr['expanded'] <= compare_expanded)
    elif op == "LT":
        true_false = (kernelStr['expanded'] < compare_expanded)
    else:
        true_false = (False)

    debug_print(3, "kernel_is: returns {0}".format(true_false))
    return(true_false)


# ---------------------------------------------#
# function: kernel_normalize()
# return nn.nnn.nnnn.nnnn
# |  |   |    |
# |  |   |    +-- rel2
# |  |   +------- rel1
# |  +----------- minor
# +-------------- major
# e.g.: 02.006.0032.0504 (RHEL 6.6)
# ---------------------------------------------#
def kernel_normalize(maj, min, rel1, rel2):

    ch_maj = "{0}".format(maj)
    ch_min = "{0}".format(min)
    ch_rel1 = "{0}".format(rel1)
    ch_rel2 = "{0}".format(rel2)

    kernel_norm = "{0}.{1}.{2}.{3}".\
        format(ch_maj.rjust(2, '0'),
               ch_min.rjust(3, '0'),
               ch_rel1.rjust(4, '0'),
               ch_rel2.rjust(4, '0'))

    return(kernel_norm)

# ---------------------------------------------#
# function: kernel_string_normalize()
# ---------------------------------------------#


def kernel_string_normalize(kernel_level):

    kernel_level = kernel_level.replace(".", ' ')
    kernel_level = kernel_level.replace("-", ' ')
    tmp = kernel_level.split()
    wc = len(tmp)

    if wc < 4:
        debug_print(1, "invalid kernel string? '{0}'".format(kernel_level))
        return('')

    if not tmp[0].isdigit():
        return('')
    if not tmp[1].isdigit():
        return('')
    if not tmp[2].isdigit():
        return('')
    if not tmp[3].isdigit():
        return('')

    return(kernel_normalize(tmp[0], tmp[1], tmp[2], tmp[3]))


# =============================================#
#
# see: https://access.redhat.com/solutions/164103 for SCSI address notes
#
# SCSI Addressing:
# '1:0:2:1'
# | | | |
# | | | |
# | | | +-----Lun (logical unit number)
# | | +-------Target (target id number)
# | +---------Bus  (channel bus number)
# +-----------Host (SCSI host adapter number)
# =============================================#


# ---------------------------------------------#
# function: add_scsi_host()
# scsi adapter lines looks like:
# kernel: scsi0: ahci'
# kernel: scsi1: qla2xx'
# kernel: scsi2: on PCI bus 0b device 00 irq 98'
# kernel: scsi3: pata_atiixp'
# kernel: scsi4: hpsa'
# kernel: scsi5: qla2xxx'
# kernel: scsi6: Emulex 10Gbe open-iscsi Iniator Driver'
# kernel: scsi7: VMware PVSCSI storage adaptor rev 2, ...'
# kernel: scsi8: ata_piix'
# kernel: scsi9: LSI SAS based MegaRAID driver'
# kernel: scsi10: fnic'
# kernel: scsi11: ioc0: LSI53C1020A A1, FwRev=1032700h, Ports=1, MaxQ=255, IRQ=28'
# kernel: scsi12: iscsi'
# kernel: scsi13: cciss'
# kernel: scsi14: cxgb4i'
# kernel: scsi15: IBM 57D7 Storage Adapter'
#
# From a virtual RHEL image running under MS HyperV: (dmesg)
# scsi0: ata_piix
# scsi1: ata_piix
# scsi2: storvsc_host_t
# scsi3: storvsc_host_t
#
# alternate form 1:
# kernel: scsi host0: LSI SAS based MegaRAID driver'
# kernel: scsi host1: Emulex OneConnect OCe14000, FCoE Initiator  on PCI bus 06 device 02 irq 37'
# kernel: scsi host2: Emulex OneConnect OCe14000, FCoE Initiator  on PCI bus 06 device 03 irq 38'
#
# alternate form 2:
# kernel: host0: ...
# kernel: host1: ...
#
# Ignore host lines that are describing things going on with that hba:
# kernel: host1: libfc: Link up on port (000000)
# kernel: host1: Assigned Port ID 010ab6
# kernel: host1: rport fffffc: callback ev 1
# kernel: host1: lport 010ab6: Received a 1 event for port (fffffc)
# kernel: host1: xid 1001: Exchange timer armed
# kernel: scsi host1: bnx2fc: xid:0x40 scsi_done. err_code = 0x7
#
# kernel: scsi host5: scsi_eh_5: waking up 0/1/1
# kernel: scsi host5: Total of 1 commands on 1 devices require eh work
# kernel: scsi host5: scsi_eh_5: sleeping
# etc.,
#
# ---------------------------------------------#
def add_scsi_host(line, source):
    global scsi_host
    global Virtual_guest, Virtual_type
    global max_host
    global prev_scan_msg

    ignore_host_phrase_list = "hdr status = FCP\n"\
                              "Link UP on Port\n"\
                              "Link Down on Port\n"\
                              "No boot session\n"\
                              "No Boot Session\n"\
                              "reset called portid\n"\
                              "received on CID\n"\
                              "mgmt_open_connection Failed\n"\
                              "Failed in beiscsi_open_conn\n"\
                              "firmware supports FIP\n"\
                              ": waking up\n"\
                              "devices require eh work\n"\
                              "sleeping\n"\
                              "skip scsi_eh_stu,\n"\
                              "past eh deadline\n"\
                              "INQUIRY result too short\n"\
                              "uevent: unsupported action-string\n"\
                              ""

    # ignore_host_word_list = "bnx2fc: lport rport xid libfc: Assigned storvsc_host_t disc: FLOGI PLOGI vNIC flog Issued reset"
    ignore_host_word_list = "bnx2fc: lport rport xid libfc: Assigned disc: FLOGI PLOGI vNIC flog Issued reset"

    debug_print(2, "'{0}' {1}".format(line, source))

    phrases = ignore_host_phrase_list.split('\n')
    for phrase in phrases:
        if phrase == '' or phrase.startswith('# '):
            continue
        if phrase in line:
            return

    words = line.split()
    wcnt = len(words)
    # "kernel:" = words[0]

    if words[1] == "scsi":
        scsi_host_number = words[2]
        starting_desc_word = 3
    else:
        scsi_host_number = words[1]
        starting_desc_word = 2
    scsi_host_number = scsi_host_number.rstrip(":")  # take off trailing ':' if present
    scsi_host_number = scsi_host_number[4:]  # remove 'scsi' or 'host' and now left with just the number

    max_host = max(int(scsi_host_number), max_host)

    if words[starting_desc_word] == ":":
        starting_desc_word += 1

    host_desc = " "
    host_desc = host_desc.join(words[starting_desc_word:])
    host_desc = host_desc.strip()

    words = host_desc.split()
    if word_in_list(words[0], ignore_host_word_list):  # ignore means no mfg / description info
        track_hba(scsi_host_number, '', source)
    else:
        track_hba(scsi_host_number, host_desc, source)
        #
        # check for any vitual info
        if "VMware" in line:
            check_virtual_status(line, source)
        if "QEMU" in line:
            check_virtual_status(line, source)
        if "VBOX" in line:
            check_virtual_status(line, source)

    # often the msgs prior to scsi host identifying message will be describing pci attributes
    # this bit of code will attempt to capture  the pci adr so we can keep it correlated to its scsi host
    # in case we can't make the correlation anywhere else:
    # e.g.g;
    # kernel: ACPI: PCI Interrupt 0000:05:00.0[A] -> GSI 50 (level, low) -> IRQ 190
    # kernel: qla2xxx 0000:05:00.0: Found an ISP2031, irq 190, iobase 0xffffc20010326000
    # kernel: qla2xxx 0000:05:00.0: Configuring PCI space...
    # kernel: qla2xxx 0000:05:00.0: Configure NVRAM parameters...
    # kernel: qla2xxx 0000:05:00.0: ZIO mode 6 enabled; timer delay (200 us).
    # kernel: qla2xxx 0000:05:00.0: Verifying loaded RISC code...
    # kernel: qla2xxx 0000:05:00.0: Allocated (64 KB) for EFT...
    # kernel: qla2xxx 0000:05:00.0: Allocated (1426 KB) for firmware dump...
    # kernel: scsi10: qla2xxx
    #
    tmp = prev_scan_msg.split()
    twc = len(tmp)
    if twc >= 3 and tmp[0] == "kernel:":
        pci_type_prefix_words = "qla lpfc ahci bfa"
        tmp2 = pci_type_prefix_words.split()
        valid_pci_pref = False
        pci_type = tmp[1]
        pci_adr = tmp[2]
        for pci_pref in tmp2:
            if pci_type.startswith(pci_pref):
                valid_pci_pref = True
                break
        # end: for pci_pref in tmp2:
        if valid_pci_pref:
            check_pci = False
            if host_desc == "":
                check_pci = True
            else:
                if host_desc[0:3] == pci_type[0:3]:
                    check_pci = True
                else:
                    check_pci = False
            if check_pci and len(pci_adr) >= len("xxxx:xx:xx.x"):
                pci_adr = pci_adr.strip("[")
                pci_adr = pci_adr[0:len("xxxx:xx:xx.x")]
                if re.match(pci_long_re, pci_adr):
                    track_pci_address_and_host(pci_adr, '', scsi_host_number, source)
                    # debug_print(0,prev_scan_msg)
                    # debug_print(0,line)
                    # debug_print(0,'-------')
    return

# ---------------------------------------------#
# Function get_host_desc():
# return host description for the host represented by the passed scsi address
# scsi_adr can either be full scsi address (h:b:t:l) or simply a host number (h)
# ---------------------------------------------#


def get_host_desc(scsi_adr):
    global scsi_host
    global scsi_host_2_pci
    global pci_address

    if ":" in scsi_adr:
        scsi_adr = normalize_scsi_adr(scsi_adr)

    tmp = scsi_adr.split(":")
    host = tmp[0]
    scsi_host_desc = scsi_host[host]

    pci_adr = scsi_host_2_pci[host]
    if pci_adr != '':
        pci_host_desc = pci_address[pci_adr]
        scsi_host_desc = "{0} / {1} {2}".format(scsi_host_desc, pci_adr, pci_host_desc)
    return(scsi_host_desc)

# ---------------------------------------------#
# Function track_qla_aborts():
# track high qla hba for aborts
# two varieties:
# 'kernel: qla2xxx [0000:15:00.1]-801c:6: Abort command issued nexus=6:1:15 -- 1 2002.'
# 'kernel: qla2xxx 0000:09:00.0: scsi(0:0:3): Abort command issued -- 1 15bd1f1c 2002.'
# ---------------------------------------------#


def track_qla_aborts(line, words, line_no, source):
    global pci_short_re, pci_long_re
    global high_host_qla_abort_count
    global high_host_qla_abort_host

    found = False
    host = ''
    pci_adr = ''

    debug_print(4, line)
    tmp = words[2].split("-")
    wc = len(tmp)
    pci_adr = tmp[0]              # both varieties
    pci_adr = pci_adr.strip("[]")  # first variety
    pci_adr = pci_adr.rstrip(":")  # second variety
    if not re.match(pci_long_re, pci_adr):
        error_print("d", line)
        return  # should not occur
    if wc == 2:
        # first variety
        host = tmp[1]          # "801c:n:"
        tmp = host.split(":")  # "801c:n:" where 'n' is host number
        host = tmp[1]
    else:  # second variety, no '-' in words[2]
        host = words[3]  # 'scsi(0:0:3):'
        if host.startswith("scsi("):  # it should...
            host = host[len("scsi("):]  # remove 'scsi('
            tmp = host.split(":")
            host = tmp[0]  # first colon delimited value

    # if pci_adr[4:5] != ':':
        # error_print("d",line)
        # return

    # pci_adr = pci_adr[5:] # 0000:15:00.1 --> 15:00.1
    # if not re.match(pci_short_re,pci_adr):
        # error_print("d",line)
        # return

    if host == '' or not host.isdigit():
        error_print("d", line)
        return

    track_pci_address_and_host(pci_adr, '', host, source)

    host_qla_abort_count[host] += 1
    error_count = host_qla_abort_count[host]
    if error_count > high_host_qla_abort_count:
        high_host_qla_abort_count = error_count
        high_host_qla_abort_host = "{0}".format(host)
    debug_print(4, "qla abort host {0} count {1}, high qla host {2} count {3}".
                   format(host, host_qla_abort_count[host], high_host_qla_abort_host, high_host_qla_abort_count))
    return
# ---------------------------------------------#
# Function high_qla_aborts():
# summarize qla hba aborts
# ---------------------------------------------#


def high_qla_aborts(scan_block, source):
    global high_host_qla_abort_count
    global high_host_qla_abort_host

    return("High qla abort host {0}: count {1}".format(high_host_qla_abort_host, high_host_qla_abort_count))

# ---------------------------------------------#
# function is_scsi_adr():
# return True/False for scsi address passed in
# ---------------------------------------------#


def is_scsi_adr(scsi_adr):
    if normalize_scsi_adr(scsi_adr) == '':
        return(False)
    return(True)
# ---------------------------------------------#
# function normalize_scsi_adr():
# clean up and return scsi address
# handles two formats:
# a) 0:1:2:3     (wc is 4)
# a) 0:1:2:3:    (wc is 5)
# ---------------------------------------------#


def normalize_scsi_adr(scsi_adr):

    words = scsi_adr.split(':')
    wc = len(words)
    if wc != 4 and wc != 5:
        return ''

    host = words[0]
    if not host.isdigit():
        return ''
    host = int(host)  # use int() to strip any leading zeroes

    bus = words[1]
    if not bus.isdigit():
        return ''
    bus = int(bus)

    target = words[2]
    if not target.isdigit():
        return ''
    target = int(target)

    lun = words[3]
    if not lun.isdigit():
        return ''
    lun = int(lun)
    return "{0}:{1}:{2}:{3}".format(host, bus, target, lun)

# ---------------------------------------------#
# check and build (if necessary) intermediate  data areas
# ---------------------------------------------#


def bld_ha_bus_tgt_lun(_scsi_adr, source):
    global scsi_host
    global scsi_bus
    global scsi_target
    global scsi_lun
    global max_host
    global max_bus
    global max_target
    global lo_lun
    global max_lun

    debug_print(3, "{0} {1}".format(_scsi_adr, source))
    words = _scsi_adr.split(':')

    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]

    if lun == "49409":
        return  # see comment in crunch_scsi_scsi

    if lun.isdigit() and len(lun) > 5:
        if int(lun) > 999999:
            anomaly_line = "Ignoring scsi address {0}, lun portion greater than 999,999 ({1})".format(_scsi_adr, source)
            handle_anomaly("SCSI", anomaly_line)
            #
            # see case  (HP raid device)
            #
            # head sos_commands/scsi/lsscsi
            # [0:0:0:0]    storage HP       P440ar           4.58  -
            # [0:0:0:4194240]storage HP       P440ar           4.58  -   <-------------
            # [0:1:0:0]    disk    HP       LOGICAL VOLUME   4.58  /dev/sda
            #
            return

    scsi_adr = "{0}".format(host)
    if scsi_host[scsi_adr] == '':
        track_hba(host, '', source)

    max_host = max(max_host, int(host))

    scsi_adr = "{0}:{1}".format(host, bus)
    if scsi_bus[scsi_adr] == "":
        scsi_bus[scsi_adr] = "bus{0}".format(bus)

    max_bus = max(max_bus, int(bus))

    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    if scsi_target[scsi_adr] == "":
        scsi_target[scsi_adr] = "target{0}".format(target)

    max_target = max(max_target, int(target))

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    if scsi_lun[scsi_adr] == "":
        scsi_lun[scsi_adr] = "lun{0}".format(lun)
        scsi_lun_origin[scsi_adr] = source

    lo_lun = min(lo_lun, int(lun))
    max_lun = max(max_lun, int(lun))
    # debug_print(z,'lo lun: {0}  max lun:{1}   {2}'.format(lo_lun,max_lun,scsi_adr)) # REMOVE
    if max_lun == 49409:
        print(49409 / 0)

    return

# ---------------------------------------------#
# count reservation conflicts
# ---------------------------------------------#


def reservation_conflict_ha_bus_tgt_lun(dev_type, _scsi_adr, source):
    global scsi_host_reservation_conflicts  # Counter()
    global scsi_bus_reservation_conflicts  # Counter()
    global scsi_target_reservation_conflicts  # Counter()
    global scsi_lun_reservation_conflicts  # Counter()
    global total_reservation_conflicts  # 0
    global reservation_conflicts  # Counter()
    global lun_2_type  # Key_data()             # key: scsi address,        data: device type;      e.g. 0:0:0:0, sd
    global high_lun_sd_rc_count  # 0
    global high_lun_sd_rc_lun   # ''
    global high_lun_st_rc_count  # 0
    global high_lun_st_rc_lun   # ''
    global high_lun_mi_rc_count  # 0
    global high_lun_mi_rc_lun   # ''

    scsi_adr = normalize_scsi_adr(_scsi_adr)
    words = scsi_adr.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]

    dt = lun_2_type[scsi_adr]
    # assuming that 'source' is var/log/messages (likely), any discrepancy is handeled in add_dev_type() [see -i/-o options]
    # if dt != dev_type and dt != '':
    # error_print('d',"{0},{1},{2} ({3},{4})".format(dev_type,scsi_adr,dt,lun_2_type_origin[scsi_adr],source))
    total_reservation_conflicts += 1
    reservation_conflicts[dev_type] += 1

    scsi_adr = "{0}".format(host)
    scsi_host_reservation_conflicts[scsi_adr] += 1

    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_reservation_conflicts[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_reservation_conflicts[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_reservation_conflicts[scsi_adr] += 1

    if dt == "sd":
        rc_count = scsi_lun_reservation_conflicts[scsi_adr]
        if rc_count > high_lun_sd_rc_count:
            high_lun_sd_rc_count = rc_count
            high_lun_sd_rc_lun = scsi_adr
    elif dt == "st":
        rc_count = scsi_lun_reservation_conflicts[scsi_adr]
        if rc_count > high_lun_st_rc_count:
            high_lun_st_rc_count = rc_count
            high_lun_st_rc_lun = scsi_adr
    else:
        rc_count = scsi_lun_reservation_conflicts[scsi_adr]
        if rc_count > high_lun_mi_rc_count:
            high_lun_mi_rc_count = rc_count
            high_lun_mi_rc_lun = scsi_adr

    return

# ---------------------------------------------#
# count scsi tape I/O errors.
# kernel: st74: Error e0000 (driver bt 0x0, host bt 0xe).
# ---------------------------------------------#


def st_io_error(line, source):
    global dev_2_lun

    words = line.split()
    dev = words[1].rstrip(':')
    scsi_adr = dev_2_lun[dev]

    # debug_print(z,line)
    io_err_ha_bus_tgt_lun(scsi_adr, dev, line, source)
    return

# ---------------------------------------------#
# count dev and lun I/O errors.
# bubble up counters to target, bus and host
# ---------------------------------------------#


def io_err_ha_bus_tgt_lun(_scsi_adr, dev_name, line, source):
    global scsi_host_io_errs
    global scsi_bus_io_errs
    global scsi_target_io_errs
    global scsi_lun_io_errs
    global total_io_errors
    global all_detached_devices
    global high_lun_io_error_count
    global high_lun_io_error_lun
    global high_host_io_error_count
    global high_host_io_error_host

    global lun_2_dev  # Key_data()
    global dev_2_dms  # Key_data()
    global dev_2_errs  # Counter()
    global lun_2_dev  # Key_data()

    if _scsi_adr == "":
        if not word_in_list(dev_name, all_detached_devices):
            anomaly_line = "no scsi address for {0} '{1}' ({2})".format(dev_name, line, source)
            handle_anomaly("SCSI", anomaly_line)
        return

    debug_print(4, "'{0}' {1} {2} {3}".format(line, _scsi_adr, dev_name, source))
    scsi_adr = normalize_scsi_adr(_scsi_adr)

    if dev_name == "":
        dev_name = lun_2_dev[scsi_adr]
    if dev_name != "":
        dev_2_errs[dev_name] += 1

    words = scsi_adr.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_io_errors += 1

    scsi_adr = "{0}".format(host)
    scsi_host_io_errs[scsi_adr] += 1
    error_count = scsi_host_io_errs[scsi_adr]
    if error_count > high_host_io_error_count:
        high_host_io_error_count = error_count
        high_host_io_error_host = scsi_adr
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_io_errs[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_io_errs[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_io_errs[scsi_adr] += 1
    error_count = scsi_lun_io_errs[scsi_adr]
    if error_count > high_lun_io_error_count:
        high_lun_io_error_count = error_count
        high_lun_io_error_lun = scsi_adr
    dev_id = lun_2_dev[scsi_adr]
    if dev_id != '':
        dm_devs = dev_2_dms[dev_id]
        tmp = dm_devs.split()
        for dm_dev in tmp:
            if dm_dev != dev_name:
                dev_2_errs[dm_dev] += 1
        # end: for dm_dev in tmp:

    return
# ---------------------------------------------#
# count lun path errors and bubble up
# ---------------------------------------------#


def io_path_ha_bus_tgt_lun(_scsi_adr, line, source):
    global scsi_host_path_errs
    global scsi_bus_path_errs
    global scsi_target_path_errs
    global scsi_lun_path_errs
    global total_path_errors
    global high_lun_path_error_count
    global high_lun_path_error_lun
    global high_host_path_error_count
    global high_host_path_error_host

    global lun_2_dev  # Key_data()
    global dev_2_dms  # Key_data()
    # global dm_2_path_errs # Counter()
    global mm_2_path_errs  # Counter()

    scsi_adr = normalize_scsi_adr(_scsi_adr)
    words = scsi_adr.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_path_errors += 1
    # debug_print(z,"tpe: {0} '{1}' ({2}) [{3}]".format(_scsi_adr,line,source,total_path_errors))

    scsi_adr = "{0}".format(host)
    scsi_host_path_errs[scsi_adr] += 1
    error_count = scsi_host_path_errs[scsi_adr]
    if error_count > high_host_path_error_count:
        high_host_path_error_count = error_count
        high_host_path_error_host = scsi_adr
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_path_errs[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_path_errs[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_path_errs[scsi_adr] += 1
    error_count = scsi_lun_path_errs[scsi_adr]
    if error_count > high_lun_path_error_count:
        high_lun_path_error_count = error_count
        high_lun_path_error_lun = scsi_adr

    dev_id = lun_2_dev[scsi_adr]
    if dev_id != '':
        mm = conv_id_2_mm(dev_id, '')
        if mm != '':
            mm_2_path_errs[mm] += 1
        dm_devs = dev_2_dms[dev_id]
        tmp = dm_devs.split()
        for dm_dev in tmp:
            # dm_2_path_errs[dm_dev]+=1
            dm_mm = conv_id_2_mm(dm_dev, '')
            if dm_mm != '' and dm_mm != mm:
                mm_2_path_errs[dm_mm] += 1
        # end: for dm_dev in tmp:

    return

# ---------------------------------------------#
# function track_failing_paths()
# ---------------------------------------------#


def track_failing_paths(line, words, source):
    global all_failing_path_mm  # ''
    mm = words[5].rstrip('.')
    all_failing_path_mm = unique_list(all_failing_path_mm, mm)

    sd_dev = conv_mm_2_bd(mm)
    # debug_print(z,"conv_mm_2_bd({0}):'{1}'".format(mm,sd_dev))
    if sd_dev == "":
        return
    scsi_adr = dev_2_lun[sd_dev]
    if scsi_adr == "":
        return
    io_path_ha_bus_tgt_lun(scsi_adr, line, source)  # count path errors

    return

# ---------------------------------------------#
# count lun detaches
# ---------------------------------------------#


def detach_ha_bus_tgt_lun(_scsi_adr):
    global scsi_host_detaches
    global scsi_bus_detaches
    global scsi_target_detaches
    global scsi_lun_detaches
    global total_detaches
    global high_lun_detach_count
    global high_lun_detach_lun

    scsi_adr = normalize_scsi_adr(_scsi_adr)
    words = scsi_adr.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_detaches += 1

    scsi_adr = "{0}".format(host)
    scsi_host_detaches[scsi_adr] += 1
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_detaches[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_detaches[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_detaches[scsi_adr] += 1
    detach_count = scsi_lun_detaches[scsi_adr]
    if detach_count > high_lun_detach_count:
        high_lun_detach_count = detach_count
        high_lun_detach_lun = scsi_adr

    return

# ---------------------------------------------#
# count lun timeouts
# ---------------------------------------------#


def timeout_ha_bus_tgt_lun(_scsi_adr):
    global scsi_host_timeouts
    global scsi_bus_timeouts
    global scsi_target_timeouts
    global scsi_lun_timeouts

    global total_timeouts
    global high_host_timeout_count
    global high_host_timeout_lun
    global high_lun_timeout_count
    global high_lun_timeout_lun

    scsi_adr = normalize_scsi_adr(_scsi_adr)
    if scsi_adr == '':
        return  # should only happen if orig msg was corrupt
    words = scsi_adr.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_timeouts += 1

    scsi_adr = "{0}".format(host)
    scsi_host_timeouts[scsi_adr] += 1
    timeout_count = scsi_host_timeouts[scsi_adr]
    if timeout_count > high_host_timeout_count:
        high_host_timeout_count = timeout_count
        high_host_timeout_host = scsi_adr
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_timeouts[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_timeouts[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_timeouts[scsi_adr] += 1
    timeout_count = scsi_lun_timeouts[scsi_adr]
    if timeout_count > high_lun_timeout_count:
        high_lun_timeout_count = timeout_count
        high_lun_timeout_lun = scsi_adr

    return

# ---------------------------------------------#
# count lun offlined
# ---------------------------------------------#


def offlined_ha_bus_tgt_lun(_scsi_adr):
    global scsi_host_offlined_devices  # Key_data()       # key: host number, list of unique devices offlined
    global scsi_host_offlined
    global scsi_bus_offlined
    global scsi_target_offlined
    global scsi_lun_offlcsaned

    global total_offlined
    global high_host_offlined_count
    global high_host_offlined_host
    global high_lun_offlined_count
    global high_lun_offlined_lun

    scsi_adr_n = normalize_scsi_adr(_scsi_adr)
    if scsi_adr_n == '':
        return  # should only happen if orig msg was corrupt
    words = scsi_adr_n.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_offlined += 1

    scsi_adr = "{0}".format(host)
    scsi_host_offlined_devices[scsi_adr] = unique_list(scsi_host_offlined_devices[scsi_adr], scsi_adr_n)
    scsi_host_offlined[scsi_adr] += 1
    offlined_count = scsi_host_offlined[scsi_adr]
    if offlined_count > high_host_offlined_count:
        high_host_offlined_count = offlined_count
        high_host_offlined_host = scsi_adr
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_offlined[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_offlined[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_offlined[scsi_adr] += 1
    offlined_count = scsi_lun_offlined[scsi_adr]
    if offlined_count > high_lun_offlined_count:
        high_lun_offlined_count = offlined_count
        high_lun_offlined_lun = scsi_adr_n

    return

# ---------------------------------------------#
# count luns not added
# ---------------------------------------------#


def not_added_ha_bus_tgt_lun(_scsi_adr):
    # global scsi_host_not_added_luns # Key_data()        # key: host number, list of unique luns not added
    global scsi_host_not_added  # Counter()               # as above w/scsi_..._path_errs and scsi_..._io_errs
    global scsi_bus_not_added  # Counter()                # .
    global scsi_target_not_added  # Counter()             # .
    global scsi_lun_not_added  # Counter()                # .
    global total_not_added  # 0

    scsi_adr_n = normalize_scsi_adr(_scsi_adr)
    if scsi_adr_n == '':
        return  # should only happen if orig msg was corrupt
    words = scsi_adr_n.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    total_not_added += 1

    scsi_adr = "{0}".format(host)
    scsi_host_not_added_luns[scsi_adr] = unique_list(scsi_host_not_added_luns[scsi_adr], scsi_adr_n)
    scsi_host_not_added[scsi_adr] += 1
    # not_added_count = scsi_host_not_added[scsi_adr]
    # if not_added_count > high_host_not_added_count:
    # high_host_not_added_count = not_added_count
    # high_host_not_added_host  = scsi_adr
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_not_added[scsi_adr] += 1
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_not_added[scsi_adr] += 1

    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    scsi_lun_not_added[scsi_adr] += 1
    # not_added_count = scsi_lun_not_added[scsi_adr]
    # if not_added_count > high_lun_added_count:
    # high_lun_not_added_count = not_added_count
    # high_lun_not_added_lun   = scsi_adr_n

    return

# ---------------------------------------------#
# track write protect status of luns
# ---------------------------------------------#


def write_protected_ha_bus_tgt_lun(_scsi_adr, bump):
    global scsi_host_write_protected_luns  # Key_data()         # key: host number, list of unique luns with write protect on
    global scsi_host_write_protected  # Counter()               # as above w/scsi_..._path_errs and scsi_..._io_errs
    global scsi_bus_write_protected  # Counter()                # .
    global scsi_target_write_protected  # Counter()             # .
    global scsi_lun_write_protected  # Counter()                # .
    global total_write_protected  # 0

    scsi_adr_n = normalize_scsi_adr(_scsi_adr)
    if scsi_adr_n == '':
        return  # should only happen if orig msg was corrupt
    words = scsi_adr_n.split(':')
    host = words[0]
    bus = words[1]
    target = words[2]
    lun = words[3]
    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
    lun_wp = scsi_lun_write_protected[scsi_adr]
    if lun_wp == 0 and bump == -1:
        return  # write protect off and not seen as on before

    scsi_lun_write_protected[scsi_adr] += bump

    total_write_protected += bump

    scsi_adr = "{0}".format(host)
    if bump == 1:
        scsi_host_write_protected_luns[scsi_adr] = unique_list(scsi_host_not_added_luns[scsi_adr], scsi_adr_n)
    # if bump == -1: scsi_host_write_protected_luns[scsi_adr] = delete_word_from_list(scsi_adr_n,scsi_host_not_added_luns[scsi_adr])
    scsi_host_write_protected[scsi_adr] += 1
    scsi_adr = "{0}:{1}".format(host, bus)
    scsi_bus_write_protected[scsi_adr] += bump
    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
    scsi_target_write_protected[scsi_adr] += bump

    return

# ---------------------------------------------#
# deal with anomalous situations
# ---------------------------------------------#


def handle_anomaly(anomaly_type, line):
    return(handle_anomaly_with_points(anomaly_type, line, '', 0))  # no type or points

# ---------------------------------------------#
# deal with anomalous situations
# ---------------------------------------------#


def handle_anomaly_with_points(anomaly_type, line, anomaly_reference_type, anomaly_reference_points):
    global this_script_name
    global total_anomaly_count
    global anomaly_list
    global anomaly_types
    global anomaly_counts  # = Counter()  # Key: Anomaly type Data: count
    global duplicate_anomaly_counts  # = Counter()  # Key: Anomaly type Data: count
    global max_anomaly_count
    global last_anomaly_type
    global last_anomaly_line
    global duplicate_anomalies_skipped
    global anomaly_points  # Counter()  # Key: Anomaly point type (one of all_anomaly_point_types)  Data: point value

    if anomaly_type not in anomaly_types:
        error_print("t", "error in handle_anomaly, anomaly type '{0}' not defined".format(anomaly_type))
        return "err"

    # if anomaly_type == "SSSS": debug_print(# ,'not err')
    if anomaly_reference_type != '':
        anomaly_points[anomaly_reference_type] += anomaly_reference_points

    track_anomaly_timeline(anomaly_type)
    if last_anomaly_type == anomaly_type and last_anomaly_line == line:
        duplicate_anomalies_skipped += 1
        duplicate_anomaly_counts[anomaly_type] += 1
        return "dup"

    # if anomaly_type == "SSSS": debug_print(# ,'not dup 1')
    words = anomaly_types.split()

    if total_anomaly_count == 0:  # only done the first time thru to init the lead elements
        for i in range(0, len(words)):
            anomaly_list[i][0] = ""
    i = 0

    for word in words:  # assign anomaly type to its ordinal value
        if word == anomaly_type:
            break
        i += 1

    # if anomaly_type == "SSSS": debug_print(# ,'{0} -> {1}'.format(anomaly_type,i))
    last_anomaly_type = anomaly_type
    last_anomaly_line = line

    ac = anomaly_counts[anomaly_type]

    # if anomaly_type == "SSSS": debug_print(# ,'{0} cnt: {1}'.format(anomaly_type,ac))
    end_range = min(ac, max_anomaly_count)
    for j in range(0, end_range + 1):
        if anomaly_list[i][j] == line:
            duplicate_anomalies_skipped += 1
            duplicate_anomaly_counts[anomaly_type] += 1
            return "dup"

    # if anomaly_type == "SSSS": debug_print(# ,'not dup 2')
    total_anomaly_count += 1  # total unique anomalies
    ac += 1
    anomaly_counts[anomaly_type] = ac

    debug_print(3, "{0} anomaly[{1}][{2}]: {3}".format(this_script_name, i, ac, line))

    if ac <= max_anomaly_count:
        anomaly_list[i][ac] = line
        if ac == 1:
            return "new"
        else:
            return "added"
    else:
        return "over"

    # return "new"

# ---------------------------------------------#
# function: track_anomaly_timeline()
# if tracking anomaly timeline then create entries
# ---------------------------------------------#


def track_anomaly_timeline(anomaly_type):
    global curr_anom_timestamp  # ''
    global prev_anom_timestamp  # '' # prev timestamp added to variable all_timetamps
    global all_anom_timestamps  # '' # seperated with '~' characters (due to timestamps having spaces)
    global timestamp_anomalies  # Key_data()  # key: timestamp data: list of anomalies occurring for this timestamp

    if curr_anom_timestamp == '':
        return  # (can not be set unless sw_timeline is True)

    # debug_print(0,'{0}: {1}'.format(curr_anom_timestamp,anomaly_type))
    if word_in_list(anomaly_type, 'KCS BZ SFDC NOTE'):
        return  # non specific

    if curr_anom_timestamp != prev_anom_timestamp:
        prev_anom_timestamp = curr_anom_timestamp
        if all_anom_timestamps == '':
            all_anom_timestamps = curr_anom_timestamp
        else:
            all_anom_timestamps = all_anom_timestamps + '~' + curr_anom_timestamp

    # timestamp_anomalies[curr_anom_timestamp] = unique_list(timestamp_anomalies[curr_anom_timestamp],anomaly_type)
    timestamp_anomalies[curr_anom_timestamp] = update_counted_list(timestamp_anomalies[curr_anom_timestamp], anomaly_type)
    return

# ---------------------------------------------#
# display anomalies
# ---------------------------------------------#


def display_anomalies():
    global this_script_name
    global total_anomaly_count
    global anomaly_list
    global anomaly_types
    global anomaly_counts  # = Counter()  # Key: Anomaly type Data: count
    global duplicate_anomaly_counts  # = Counter()  # Key: Anomaly type Data: count
    global max_anomaly_count
    global max_disp_anomaly_count
    global all_anomaly_point_types  # 'hardware configuration performance'
    global anomaly_points  # Counter()  # Key: Anomaly point type (one of all_anomaly_point_types)  Data: point value
    global sw_dup

    if total_anomaly_count == 0:
        errorprint("no anomalies found")
        return

    errorprint("total anomalies: {0},  total duplicate anomalies skipped: {1}".format(total_anomaly_count, duplicate_anomalies_skipped))

    words = anomaly_types.split()
    wc = len(words)
    i = 0

    for i in range(0, wc):
        anom = words[i]
        ac = anomaly_counts[anom]

        # Skip DATA-n messages unless debug is on - most users will not find it useful / helpful
        if anom.startswith("DATA-") and sw_debug_level == 0:
            continue

        max_blurb = ""
        if ac > max_anomaly_count:
            max_blurb = "(max anomaly count exceeded, {0} anomaly lines discarded)".format(ac - max_anomaly_count)

        tc = min(ac, max_anomaly_count)
        if tc > max_disp_anomaly_count:
            max_blurb2 = "(max disp anomaly count exceeded, {0} anomaly lines hidden)".format(tc - max_disp_anomaly_count)
            if max_blurb == "":
                max_blurb = max_blurb2
            else:
                max_blurb = max_blurb + " " + max_blurb2
        debug_print(4, "anomaly {0}({1}) count({2}) {3}".format(i, anom, ac, max_blurb))

        if ac > 0:
            dac = duplicate_anomaly_counts[anom]
            if dac == 0:
                dup_blurb = ""
            else:
                dup_blurb = "({0} duplicate{1} skipped)".format(dac, plural(dac))
            errorprint('')  # blank line between each type of anomaly
            errorprint("{0} unique instance{1} of anomaly type {2} found: {3} {4}".format(ac, plural(ac), anom, max_blurb, dup_blurb))
            for j in range(1, min(min(ac + 1, max_anomaly_count + 1), max_disp_anomaly_count)):
                errorprint("  [{0}] {1}".format(j, regex_string_cleanup(anomaly_list[i][j])))

    # end: for i in range(0,len(words)):

    if sw_dup and duplicate_anomalies_skipped > 0:
        errorprint("")
        errorprint("{0} duplicate anomalies skipped...".format(duplicate_anomalies_skipped))
        for i in range(0, wc):
            anom = words[i]
            dac = duplicate_anomaly_counts[anom]
            if dac > 0:
                errorprint("    {0} duplicates skipped for type {1}".format(dac, anom))
        errorprint("")
        # end; for i in range(0,len(words)):

    words = all_anomaly_point_types.split()  # 'hardware configuration performance, etc.'
    total_arp_points = 0
    for point_type in words:
        total_arp_points += anomaly_points[point_type]
    if total_arp_points > 0:
        errorprint("")
        errorprint("Anomaly reference points:")
        wm = 0  # word length max
        for point_type in words:
            wm = max(len(point_type), wm)
        for point_type in words:
            # next check is primarily for qla2xxx/lpfc point accumulation which occasionally goes neg.
            if anomaly_points[point_type] < 0:
                anomaly_points[point_type] = 0
            errorprint("  {0} related points: {1}".format(point_type.ljust(wm, '.'), anomaly_points[point_type]))
        # end: for point_type in words:
        errorprint("  {0} related points: {1}".format("Total ARP".ljust(wm, '.'), total_arp_points))
    else:
        errorprint("No anomaly reference points assigned.")

    return

# ---------------------------------------------#
# regex_string_cleanup()
# replace the regex notation in a string with more user friendly strings
# ---------------------------------------------#


def regex_string_cleanup(string):
    global re_search_words
    global re_replace_words
    global var_spaces
    global zero_or_more_spaces

    i = 0

    for ss in re_search_words:
        if string.find(ss) != -1:
            rs = re_replace_words[i]
            string = string.replace(ss, rs)
        i += 1

    if string.find("\\(") != -1:
        string = string.replace("\\(", "(")
    if string.find("\\)") != -1:
        string = string.replace("\\)", ")")
    if string.find("\\[") != -1:
        string = string.replace("\\[", "[")
    if string.find("\\]") != -1:
        string = string.replace("\\]", "]")
    if string.find("\\?") != -1:
        string = string.replace("\\?", "?")
    if string.find("\\*") != -1:
        string = string.replace("\\*", "*")
    if string.find("\\+") != -1:
        string = string.replace("\\+", "+")
    if string.find(var_spaces) != -1:
        string = string.replace(var_spaces, " ")
    if string.find(zero_or_more_spaces) != -1:
        string = string.replace(zero_or_more_spaces, "")

    return(string)


# ---------------------------------------------#
# function: display_anomaly_timeline()
# ---------------------------------------------#
def display_anomaly_timeline():
    global sw_timeline
    global all_anom_timestamps  # '' # seperated with '~' characters (due to timestamps having spaces)
    global timestamp_anomalies  # Key_data()  # key: timestamp data: list of anomalies occurring for this timestamp

    if not sw_timeline:
        return

    if all_anom_timestamps == '':
        errorprint("")
        errorprint("no timeline anomalies to report")
        return

    tmp = all_anom_timestamps.split('~')
    errorprint("")
    errorprint("Start of anomaly timeline:")
    for timestamp in tmp:
        errorprint("{0}: {1}".format(timestamp, timestamp_anomalies[timestamp]))
    errorprint("End of anomaly timeline:")

    return

# ============================================================================================#
#
# from https://en.wikipedia.org/wiki/SCSI_Peripheral_Device_Type
#
# Value  Device type; Command set; Specification
# 00h      Direct-access block device (e.g., magnetic disk); SBC Direct Access Commands; SCSI Block Commands (SBC)
# 01h      Sequential-access device (e.g., magnetic tape); SSC Sequential Access Commands; SCSI Stream Commands (SSC)
# 02h      Printer device; SSC Printer Commands; SCSI Stream Commands (SSC)
# 03h      Processor device; SPC Processor Commands; SCSI Primary Commands (SPC)
# 04h      Write-once device; SBC Write Once Commands; SCSI Block Commands (SBC)
# 05h      CD/DVD-ROM device; MMC CD-ROM Commands; SCSI Multimedia Commands (MMC)
# 06h      Scanner device; SGC Scanner Commands; SCSI Graphics Commands (SGC)
# 07h      Optical memory device (e.g., some optical disks); SBC Optical Media Commands; SCSI Block Commands (SBC)
# 08h      Medium changer (e.g. jukeboxes); SMC Medium Changer Commands; SCSI Medium Changer Commands (SMC)
# 09h      Communications device; SSC Communications Commands; SCSI Stream Commands (SSC)
# 0A-0Bh Defined by ASC ITS (Graphic arts pre-press devices); ASC ITS Prepress Commands
# 0Ch      Storage array controller device (e.g., RAID); SCC Array Controller Commands; SCSI Controller Commands (SCC)
# 0Dh      Enclosure services device; SES Enclosure Services Commands; SCSI Enclosure Services (SES)
# 0Eh      Simplified direct-access device (e.g., magnetic disk); RBC Reduced Block Commands; Reduced Block Commands (RBC)
# 0Fh      Optical card reader/writer device; OCRW Optical Card Commands; SCSI Specification for Optical Card Reader/Writer (OCRW)
# 10h      Reserved for bridging expanders
# 11h      Object-based Storage Device; OSD Object-based Storage Commands; Object-based Storage Commands (OSD)
# 12h      Automation/Drive Interface
# 13h      Security manager device
# 14h      Reserved
# 15h     RMC Simplified Multimedia Commands; Reduced Multimedia Commands (RMC)
# 15-1Dh Reserved
# 1Eh      Well known logical unit
# 1Fh      Unknown or no device type
#
#
# ============================================================================================#

# ---------------------------------------------#
# function: add_scsi_info()
#
# process the following types of various scsi lines: (not necessarily a complete list)
#
# scsi 2:0:0:1: Direct-Access     VMware   Virtual disk     1.0  PQ: 0 ANSI: 2
# scsi 0:0:1:0: Direct-Access     IBM      2145             0000 PQ: 0 ANSI: 6
# scsi 0:0:0:0: Direct-Access     HP       LOGICAL VOLUME   6.60 PQ: 0 ANSI: 5
# scsi 10:0:1:0: Direct-Access     LSI      MR9361-8i        4.26 PQ: 0 ANSI: 5
# scsi 5:0:0:0: Direct-Access     DGC      VRAID            0533 PQ: 0 ANSI: 4
# scsi 5:0:4:0: Direct-Access     XtremIO  XtremApp         3020 PQ: 0 ANSI: 6
# scsi 0:0:0:0: Direct-Access     EMC      SYMMETRIX        5874 PQ: 0 ANSI: 4
# scsi 4:2:0:0: Direct-Access     DELL     PERC H710        3.13 PQ: 0 ANSI: 5
# scsi 3:0:0:12: Direct-Access     HP       OPEN-V           6007 PQ: 0 ANSI: 3
# scsi 1:0:0:16: Direct-Access     HITACHI  OPEN-V           7006 PQ: 0 ANSI: 3
# scsi 0:0:0:0: Direct-Access     SEAGATE  ST300MM0006      LS0A PQ: 0 ANSI: 6
# scsi 0:0:0:0: Direct-Access     FUJITSU  MBD2300RC        D80A PQ: 0 ANSI: 5
# scsi 2:0:0:0: Direct-Access     ATA      ST91000640NS     BE2A PQ: 0 ANSI: 6
# scsi 4:0:0:0: Direct-Access     3PARdata VV               3212 PQ: 0 ANSI: 6
#
# scsi 4:0:9:1: Medium Changer    IBM      03584L22         C450 PQ: 0 ANSI: 3
#
# scsi 6:0:8:0: Sequential-Access IBM      03592E05         1F1F PQ: 0 ANSI: 3
# scsi 7:0:1:0: Sequential-Access QUANTUM  SDLT320          5E5E PQ: 0 ANSI: 2
# scsi 0:0:5:0: Sequential-Access HP       Ultrium 4-SCSI   R500 PQ: 0 ANSI: 3
#
# scsi 9:0:0:0: CD-ROM            PLDS     DVD+-RW DS-8A9SH ED51 PQ: 0 ANSI: 5
# scsi 0:0:0:1: CD-ROM            NECVMWar VMware IDE CDR00 1.00 PQ: 0 ANSI: 5
# scsi 3:0:0:0: CD-ROM            hp       DVDROM DH40N     IS01 PQ: 0 ANSI: 5
# scsi 5:0:0:0: CD-ROM            PLDS     DVD-ROM DS-8DBSH CD51 PQ: 0 ANSI: 5
# scsi 0:0:0:0: CD-ROM            TEAC     DV-28S-W         C.2D PQ: 0 ANSI: 5
#
# scsi 0:3:0:0: RAID              HP       P410i            6.60 PQ: 0 ANSI: 5
# scsi 3:3:0:0: RAID              HP       P410i            5.14 PQ: 0 ANSI: 5
#
# scsi 10:0:0:0: Enclosure         LSI      SAS3x40          0601 PQ: 0 ANSI: 5
#
# scsi 10:0:0:0: SSP: handle(0x000b), sas_addr(0x5000c5007f79c6a1), phy(5), device_name(0x5000c5007f79c6a0)
# scsi 10:0:0:0: SSP: enclosure logical id(0x50050cc10f276a75), slot(255)
# scsi 10:0:0:0: SSP: enclosure level(0x0000), connector name(     )
# scsi 10:0:0:0: serial_number(S7K00N2X0000J449Y6AH)
# scsi 10:0:0:0: qdepth(254), tagged(1), simple(1), ordered(0), scsi_level(7), cmd_que(1)
#
# scsi 12:0:0:0: Enclosure         IBM      VSBPD12M1 6GSAS    03 PQ: 0 ANSI: 2
# scsi 12:0:0:0: Resource path: 12/00-16
# scsi 12:0:0:0: Attached scsi generic sg6 type 13
#
# scsi 13:0:0:0: Enclosure         IBM      VSBPD12M1 6GSAS    03 PQ: 0 ANSI: 2
# scsi 13:0:0:0: Resource path: 13/00-15
# scsi 13:3:0:0: No Device         IBM      57D7001SISIOA    0150 PQ: 0 ANSI: 0
# scsi 13:3:0:0: Resource path: 13/FE
#
# scsi 0:0:0:254: Enclosure         3PARdata SES              3210 PQ: 0 ANSI: 6
# scsi 0:0:0:254: Attached scsi generic sg19 type 13
# scsi 0:0:0:254: Failed to get diagnostic page 0x8000002
# scsi 0:0:0:254: Failed to bind enclosure -19
#
# scsi 2:0:1:110: Direct-Access     DGC      RAID 5           0326 PQ: 0 ANSI: 4
# scsi 2:0:1:110: emc: detected Clariion CX3-80, flags 0
# scsi 2:0:1:110: emc: connected to SP A Port 1 (bound, default SP B)
#
# scsi 1:0:2:0: Sequential-Access HP       Ultrium 6-SCSI   22GS PQ: 0 ANSI: 6
# scsi 1:0:2:0: alua: supports implicit TPGS
# scsi 1:0:2:0: alua: port group 00 rel port 01
# scsi 1:0:2:0: alua: transition timeout set to 60 seconds
# scsi 1:0:2:0: alua: port group 00 state A preferred supports tolusnA
# scsi 1:0:2:0: alua: Attached
#
# scsi 11:0:3:2: rejecting I/O to offline device
# scsi 11:0:3:2: killing request
# scsi 11:0:3:2: rejecting I/O to offline device
# scsi 6:0:3:0: timing out command, waited 24s
# scsi 1:0:0:0: [sda] Unhandled error code
# scsi 1:0:0:0: [sda] Result: hostbyte=DID_REQUEUE driverbyte=DRIVER_OK
#
# scsi 2:0:0:0: Direct-Access     ATA      ST91000640NS     BE2A PQ: 0 ANSI: 6
# scsi 2:0:0:0: SATA: handle(0x0005), sas_addr(0x4433221100000000), phy(0), device_name(0x5000c500670d62d9)
# scsi 2:0:0:0: SATA: enclosure_logical_id(0x50050760478087c4), slot(0)
# scsi 2:0:0:0: atapi(n), ncq(y), asyn_notify(n), smart(y), fua(y), sw_preserve(y)
# scsi 2:0:0:0: qdepth(32), tagged(1), simple(1), ordered(0), scsi_level(7), cmd_que(1)
# scsi 0:0:0:0: Warning! Received an indication that the LUN assignments on this target have changed. The Linux SCSI layer does not automatically remap LUN assignments.
#
#
# scsi 0:3:0:0: Attached scsi generic sg1 type 0
# scsi 0:3:0:0: Attached scsi generic sg0 type 12
# sd 4:0:0:1: Attached scsi generic sg7 type 0
#
# sd 5:0:3:0: scsi scan: REPORT LUN scan
#
# sd 4:0:0:1: rdac: AVT mode detected
# sd 4:0:0:1: rdac: LUN 1 (owned (AVT mode))
# scsi 3:0:0:0: rdac: AVT mode detected
# scsi 3:0:0:0: rdac: LUN 0 (owned (AVT mode))
# scsi 3:0:0:0: rdac: Detached
#
# sd 5:0:0:31: SCSI error: return code = 0x80000002
#
# sd 2:0:1:0: Attached scsi generic sg19 type 0'
# sd 8:0:0:0: Attached scsi generic sg141 type 0'
# sd 0:0:0:0: Attached scsi removable disk sda'
# sd 8:0:0:0: Attached scsi disk sdc'
#
# st 1:0:2:5: Attached scsi tape st4'
# st 1:0:3:4: Attached scsi tape st11'
#
# sr 0:0:0:0: Attached scsi CD-ROM sr0'
# ses 2:0:3:254: Attached Enclosure device
#
# sd 2:0:1:0: Attached scsi generic sg19 type 0'
# sd 8:0:0:0: Attached scsi generic sg141 type 0'
# sd 0:0:0:0: Attached scsi removable disk sda'
# sd 8:0:0:0: Attached scsi disk sdc'
#
# st 1:0:2:5: Attached scsi tape st4'
# st 1:0:3:4: Attached scsi tape st11'
#
# sr 0:0:0:0: Attached scsi CD-ROM sr0'
# ses 2:0:3:254: Attached Enclosure device
#
# sd 3:0:0:0: [sdb] Attached SCSI disk
# sd 8:0:0:1: [sdek] 142264800 512-byte logical blocks: (72.8 GB/67.8 GiB)
#
# sd 4:0:0:0: emc: detected Clariion VNX7600, flags 0
# sd 4:0:0:0: emc: ALUA failover mode detected
# sd 4:0:0:0: emc: connected to SP A Port 3 (owned, default SP A)
# sd 4:0:0:0: emc: ALUA failover mode detected
# sd 4:0:0:0: emc: at SP A Port 3 (owned, default SP A)
# sd 4:0:0:0: emc: ALUA failover mode detected
# sd 4:0:0:0: emc: at SP A Port 3 (owned, default SP A)
#
# st 1:0:3:4: reservation conflict
# sd 2:0:5:6: reservation conflict
#
# sd 5:0:3:0: scsi scan: REPORT LUN scan
# scsi 5:0:1:172: scsi scan: INQUIRY pass 1 length 36
# scsi 5:0:1:172: scsi scan: INQUIRY pass 2 length 193
#
# (n/a)
# scsi scan: Sending REPORT LUNS to host 6 channel 0 id 0 (try 0)
# scsi scan: REPORT LUNS successful (try 0) result 0x0
# scsi scan: INQUIRY successful with code 0x0
#
# sd 2:0:0:1: Device offlined - not ready after error recovery
#
# scsi 2:0:0:0: Direct-Access     DGC      LUNZ             0326 PQ: 0 ANSI: 4
#
# ---------------------------------------------#


def add_scsi_info(line, source):
    global sd_br_re, sd_re, st_br_re, st_re, dm_re
    global valid_device_types  # "sd st sr ch ac esd ses"
    global num_2_dev_type  # Key_data()
    global count_of_times_add_scsi_info_called  # 0 # (per calling routine)
    global LUNZ_count  # 0
    global iscsi_LUNZ_count  # 0
    global very_big_device_list  # ''

    count_of_times_add_scsi_info_called += 1

    if ">" in line or "<" in line:
        return  # potentially corrupt line? e.g.: <6>

    mfg_indicator = "Direct-Access Sequential-Access Enclosure RAID CD-ROM Medium-Changer"
    if line.find("Medium Changer") != -1:
        line = line.replace("Medium Changer", "Medium-Changer")

    if line.startswith("kernel: "):
        line = line[8:]  # <<--- strip 'kernel:' word from from start of line

    if "Well-known LUN" in line:
        return  # see comment in crunch_scsi_scsi

    io_error_line = False

    words = line.split()
    word_cnt = len(words)

    word0 = words[0]
    word1 = words[1]
    word2 = ''
    word3 = ''
    word4 = ''
    word5 = ''
    word6 = ''
    word7 = ''
    word8 = ''
    word9 = ''
    if word_cnt > 2:
        word2 = words[2]
    if word_cnt > 3:
        word3 = words[3]
    if word_cnt > 4:
        word4 = words[4]
    if word_cnt > 5:
        word5 = words[5]
    if word_cnt > 6:
        word6 = words[6]
    if word_cnt > 7:
        word7 = words[7]
    if word_cnt > 8:
        word8 = words[8]
    if word_cnt > 9:
        word9 = words[9]

    dev_type = word0
    if dev_type == "SCSI":
        dev_type = "scsi"
    scsi_adr = normalize_scsi_adr(word1)
    dev_id = ""
    dev_sgn = ""
    dev_mfg = ""

    if word_in_list(word2, mfg_indicator):
        if word2 == "Direct-Access":
            dev_type = "sd"
            if not source.endswith("/scsi"):
                track_scsi_rev_level(scsi_adr, words[word_cnt - 1], source)
        elif word2 == "Sequential-Access":
            dev_type = "st"
            if not source.endswith("/scsi"):
                track_scsi_rev_level(scsi_adr, words[word_cnt - 1], source)
        elif word2 == "CD-ROM":
            dev_type = "sr"
        elif word2 == "Medium-Changer":
            dev_type = "ch"
        elif word2 == "RAID":
            dev_type = "ac"
        elif word2 == "Enclosure":
            dev_type = "esd"
        elif word2 == "SPP:":
            dev_type = "esd"

        if word_cnt >= 6:
            dev_mfg = word3 + "," + word4 + " " + word5
        elif word_cnt == 5:
            dev_mfg = word3 + "," + word4
        elif word_cnt == 4:
            dev_mfg = word3

    if dev_type == "ses":
        dev_type = "esd"

    if dev_type == "scsi":
        if re.match(sd_br_re, word2):
            dev_type = "sd"
        elif re.match(st_br_re, word2):
            dev_type = "st"
        elif word2 == "Failed" and "Failed to bind enclosure" in line:
            dev_type = "esd"

    # Sep  1 06:51:29 nahas05364 kernel: sd 5:0:0:0: alua: Detached
    if word3 == "Detached" and word_in_list(word2, "emc: alua: rdac:"):
        clear_out_scsi_info(scsi_adr, source)
    elif word2 == "rejecting" and word3 == "I/O":
        io_error_line = True
    elif word2 == "reservation" and word3 == "conflict":
        if dev_type == "scsi":
            dev_type = lun_2_type[scsi_adr]
        if dev_type != "":
            reservation_conflict_ha_bus_tgt_lun(dev_type, scsi_adr, source)
    elif word2 == "emc:" and word3 == "detected":
        dev_mfg = "DGC" + "," + word4 + " " + word5
    else:
        pass

    # sd 3:0:0:31: SCSI error: return code = 0x08000002
    if re.match("(sd|sr|ses) " + scsi_adr_re + ": SCSI error: return code = 0x", line) or \
       re.match("(sd|sr|ses) " + scsi_adr_re + ": (" + sd_br_re + "|" + sr_br_re + ") SCSI device reset on scsi.*", line):
        # debug_print(z,line)
        track_scsi_error(line, source)  # calls io_err_ha_bus_tgt_lun()

    # sd 0:0:0:8 [sdo] CDB: Write(10) 2a 00 00 9f 1a 40 00 00 10 00
    if "CDB:" in line:
        if re.match("(sd|sr) " + scsi_adr_re + ": (" + sd_br_re + "|" + sr_br_re + ") CDB: (Read|Write)", line) or \
           re.match("(sd|sr) " + scsi_adr_re + ": (" + sd_br_re + "|" + sr_br_re + ") tag# " + n1_re + " CDB: (Read|Write)", line):
            dev_id = word2.strip("[]")
            io_error_line = True
            # debug_print(z,"{0} '{1}'".format(dev_id,line))

    # kernel: sr 2:0:0:0: Send: scmd 0xffff883fd7314fc0
    if "Send: scmd" in line:
        if re.match("(sd|sr|st) " + scsi_adr_re + ": .*", line):
            io_error_line = True
            # debug_print(z,"{0} '{1}'".format(dev_id,line))

    if "abort" in line:
        if "task abort on host" in line:
            dev_id = word2.strip("[]")
            io_error_line = True
        #
        # kernel: sd 0:2:0:0: task abort: FAILED scmd(ffff883ff58742c0)
        elif "task abort: FAILED scmd" in line:
            io_error_line = True
        elif "task abort: SUCCESS scmd" in line:
            io_error_line = True

    if "failed" in line:
        if "Read Capacity" in line or "READ CAPACITY" in line:
            dev_id = word2.strip("[]")
            io_error_line = True
        #

    if dev_mfg != "":
        track_dev_mfgs(scsi_adr, dev_mfg, 1, source)

    if word_cnt == 6 and word2 == "Attached" and dev_id == "":
        dev_id = word5

    if word_cnt == 8 and word2 == "Attached" and word4 == "generic" and word6 == "type":
        dev_sgn = word5
        dt = num_2_dev_type[word7]
        if dev_type == "" or dev_type == "scsi":
            dev_type = dt
        else:
            if not dev_type_match(dt, dev_type):
                anomaly_line = "Device type mismatch: {0}/{1} '{2}' ({3})".format(dt, dev_type, line, source)
                handle_anomaly("DT", anomaly_line)
    if word_cnt == 7 and word4 == "removable" and word5 == "disk":
        if dev_type == "":
            dev_type = "sd"
        dev_id = word6

    if word_cnt == 6 and word4 == "disk":
        dev_id = word5

    if word_cnt == 6 and dev_type == "sr" and word4 == "CD-ROM":
        dev_id = word5

    if word_cnt == 6 and dev_type == "st" and word4 == "tape":
        dev_id = word5

    if dev_type == "scsi":
        dev_type = ""
    if dev_id == "":
        if re.match(sd_br_re, word2) or re.match(st_br_re, word2):
            dev_id = word2.strip("[]")

    if "512-byte logical blocks:" in line:
        blocks = word3
        if blocks.startswith("0x"):
            blocks = int(blocks, 16)
        else:
            blocks = int(blocks)
        # block = (int(word3) # size in bytes
        size = (int(word3) * 512)  # size in bytes
        set_device_size(dev_id, size, source)
        max_32_bit_val = int("0xffffffff", 16)
        if "(2.19 TB" in line and blocks == max_32_bit_val and word_in_list(scsi_adr, very_big_device_list):
            anomaly_line = "{0} {1} has a size of 2.19 TB but is in the 'VERY BIG DEVICE' list and may not be sized correctly, see {2}".\
                           format(scsi_adr, words[2], kcs_url("59606"))
            handle_anomaly("SD", anomaly_line)

    if dev_type == "sd" and "Very big device. Trying to use READ CAPACITY(16)" in line:
        very_big_device_list = unique_list(very_big_device_list, scsi_adr)

    if dev_type == "sr":
        check_virtual_status(line, source)

    if dev_type == "sd" and "LUNZ" in line:
        LUNZ_count += 1
        if 'iscsi' in get_host_desc(scsi_adr):
            iscsi_LUNZ_count += 1

    debug_print(4, "scsi_adr={0} dev_type={1} dev_id={2} sgn={3} line={4} ({5})".
                format(scsi_adr, dev_type, dev_id, dev_sgn, line, source))

    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, dev_sgn, line, source)

    if io_error_line:
        io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)

    return

# ---------------------------------------------#
# Function add_sd_partition_info()
# kernel:  sda: sda1 sda2 ...
#
# but sometimes we see data that doesn't make sense:
#
# kernel: sdaz: sday1  (case )
# kernel: sdao: sdbt1        "
# ---------------------------------------------#


def add_sd_partition_info(line, source):
    if line.startswith("kernel: "):
        line = line[8:]  # it should...

    words = line.split()
    wc = len(words)

    if wc < 2:
        return  # should not occur
    sd_dev = words[0].strip(":")

    for p in range(1, wc):
        sd_dev_partition = words[p]
        if sd_dev_partition.startswith(sd_dev):
            if is_partition_id(sd_dev_partition, source):
                add_partition_2_dev(sd_dev, sd_dev_partition, source)

    return


# ---------------------------------------------#
# Function dev_type_match()
# check for the logical equivalence of two device types
# ---------------------------------------------#
def dev_type_match(dt1, dt2):

    if dt1 == dt2:
        return True
    if dt1 == "sd" and dt2 == "mpdt":
        return True
    if dt1 == "mpdt" and dt2 == "sd":
        return True
    return False

# ---------------------------------------------#
# Function clear_out_scsi_info()
# clear out all info regarding a scsi adr
# when a detach message comes in
# ---------------------------------------------#


def clear_out_scsi_info(scsi_adr, source):
    global scsi_lun  # Key_data()              # key: host:bus:target:lun, data: lun id;           e.g. 0:0:0:0, lun0
    global scsi_lun_origin  # Key_data()       # key: host:bus:target:lun, data: file origin       e.g. 0:0:0:0, var/log/dmesg
    global scsi_lun_detail  # Key_data()       # key: host:bus:target:lun, data: lun data line(s); e.g. 0:0:0:0, sd 0:2:0:0: Attached scsi generic sg1 type 0
    global scsi_lun_mfg  # Key_data()          # key: host:bus:target:lun, data: mfg;              e.g. 0:0:0:0, HITACHI
    global scsi_lun_mfg_origin  # Key_data()   # key: host:bus:target:lun, data: file origin       e.g. 0:0:0:0, var/log/dmesg
    global scsi_lun_mfg_model  # Key_data()     # key: host:bus:target:lun, data: model;            e.g. 0:0:0:0, HITACHI
    # global scsi_2_path_errs # Counter()        # key: scsi id,             data: path error count  e.g. 0:0:1:2, 1

    global sgn_2_lun  # Key_data()              # key: sgn,                 data: scsi address;     e.g. sg1,     0:0:0:0
    global sgn_2_lun_origin  # Key_data()       # key: sgn,                 data: file origin       e.g. sg1,     var/log/dmesg
    global lun_2_sgn  # Key_data()              # key: scsi address,        data: sgn;              e.g. 0:0:0:0, sg1
    global lun_2_sgn_origin  # Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg

    global dev_2_lun  # Key_data()              # key: device id,           data: scsi address;     e.g. sda,     0:0:0:0
    global dev_2_lun_origin  # Key_data()       # key: device id,           data: file origin       e.g. sda,     var/log/dmesg
    global dev_2_parts  # Key_data()            # key: device id,           data: partion id(s)     e.g. sda,     sda1, sda2, ...
    global lun_2_dev  # Key_data()              # key: scsi address,        data: device id;        e.g. 0:0:0:0, sda
    global lun_2_dev_origin  # Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg
    global lun_2_type  # Key_data()             # key: scsi address,        data: device type;      e.g. 0:0:0:0, sd
    global lun_2_type_origin  # Key_data()      # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg
    global detached_device_count  # 0
    global all_detached_devices  # ""
    detached_device_count += 1
    detach_ha_bus_tgt_lun(scsi_adr)

    dev_id = lun_2_dev[scsi_adr]
    sgn_id = lun_2_sgn[scsi_adr]
    mfg = scsi_lun_mfg[scsi_adr]

    action_scsi1 = file_check(source, scsi_lun_origin[scsi_adr])
    if action_scsi1 == "overridden":
        scsi_lun[scsi_adr] = ''
        scsi_lun_origin[scsi_adr] = ''
        scsi_lun_detail[scsi_adr] = ''

    action_scsi2 = file_check(source, scsi_lun_mfg_origin[scsi_adr])
    if action_scsi2 == "overridden":
        scsi_lun_mfg[scsi_adr] = ''
        scsi_lun_mfg_model[scsi_adr] = ''
        scsi_lun_mfg_origin[scsi_adr] = ''
        if mfg != '':
            mfg_lun_count[mfg] = mfg_lun_count[mfg] - 1

    action_scsi3 = file_check(source, lun_2_type_origin[scsi_adr])
    if action_scsi3 == "overridden":
        lun_2_type[scsi_adr] = ''
        lun_2_type_origin[scsi_adr] = ''

    action_scsi4 = file_check(source, lun_2_dev_origin[scsi_adr])
    if action_scsi4 == "overridden":
        lun_2_dev[scsi_adr] = ''
        lun_2_dev_origin[scsi_adr] = ''

    action_dev1 = file_check(source, dev_2_lun_origin[dev_id])
    if action_dev1 == "overridden":
        dev_2_lun[dev_id] = ''
        dev_2_lun_origin[dev_id] = ''
        dev_2_parts[dev_id] = ''
        all_detached_devices = unique_list(all_detached_devices, dev_id)

    action_sgn1 = file_check(source, lun_2_sgn_origin[scsi_adr])
    if action_sgn1 == "overridden":
        lun_2_sgn[scsi_adr] = ''
        lun_2_sgn_origin[scsi_adr] = ''

    action_sgn2 = file_check(source, sgn_2_lun_origin[sgn_id])
    if action_sgn2 == "overridden":
        sgn_2_lun[sgn_id] = ''
        sgn_2_lun_origin[sgn_id] = ''

    debug_print(4, "detaching {0} dev_id:{1} sgn_id:{2} ({3})".format(scsi_adr, dev_id, sgn_id, source))
    return

# ---------------------------------------------#
# Function track_sd_timeouts()
# kernel: sd h:b:t:l: timing out command, waited nns
#
# ---------------------------------------------#


def track_sd_timeouts(line, words, source):
    global scsi_timeout_count  # Counter()
    timeout_ha_bus_tgt_lun(words[2])
    return

# ---------------------------------------------#
# Function track_scsi_error()
# sd h:b:t:l: SCSI error: return code = 0xXXXXXXXX
# sd 3:0:0:31: SCSI error: return code = 0x08000002
#
# sd h:b:t:l: [sdcc] SCSI device reset on scsi.*
# ---------------------------------------------#


def track_scsi_error(line, source):
    global scsi_err_count  # Counter()
    global scsi_err_dev_ids  # Key_data()
    global scsi_err_scsi_adrs  # Key_data()
    global all_scsi_err_codes  # ""
    global corrupt_scsi_error_lines  # 0
    global messages_file_list

    # sd 3:0:0:31: SCSI error: return code = 0x08000002
    words = line.split()
    wc = len(words)
    if wc < 8:
        errorprint(line)
        errorprint(87 / 0)

    dev_type = words[0]
    scsi_adr = normalize_scsi_adr(words[1])
    dev_id = lun_2_dev[scsi_adr]

    if "SCSI error: return code" in line:
        err_code = words[7]
        # check error code for validity (avoid bad data due to <n> corruption)
        if not err_code.startswith("0x") or len(err_code) != 10:
            if word_in_list(source, messages_file_list):
                corrupt_scsi_error_lines += 1
            return
        if not is_hex(err_code):
            if word_in_list(source, messages_file_list):
                corrupt_scsi_error_lines += 1
            return

        all_scsi_err_codes = unique_list(all_scsi_err_codes, err_code)

        scsi_err_count[err_code] += 1

        scsi_err_scsi_adrs[err_code] = unique_list(scsi_err_scsi_adrs[err_code], scsi_adr)
        if dev_id != "":
            scsi_err_dev_ids[err_code] = unique_list(scsi_err_dev_ids[err_code], dev_id)
    # end: if "SCSI error: return code" in line:

    io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)
    return


# ---------------------------------------------#
# Function track_dev_mfgs()
# ---------------------------------------------#
def track_dev_mfgs(scsi_adr, _mfg, count, source):
    global all_dev_mfgs
    global all_dev_mfgs_orig
    global mfg_lun_count
    global scsi_lun_mfg
    global scsi_lun_mfg_origin
    global max_mfg
    if "handle(" in _mfg or "enclosure" in _mfg or "serial_number(" in _mfg:
        return

    mfg = _mfg
    model = ""
    words = mfg.split(",")
    if len(words) > 1:
        mfg = words[0]
        model = words[1]

    debug_print(4, "scsiadr[{0}],mfg[{1}],count[{2}]) model[{3}] ({4})".format(scsi_adr, mfg, count, model, source))

    mfg = mfg.rstrip(".")  # take off trailing '.' (if any)
    all_dev_mfgs_orig = unique_list(all_dev_mfgs_orig, mfg)  # maintain list of mfg names as originally seen

    mfg = mfg.upper()  # conv to UC for consistency

    debug_print(4, "scsiadr[{0}],mfg[{1}],count[{2}]) model[{3}] ({4})".format(scsi_adr, mfg, count, model, source))

    all_dev_mfgs = unique_list(all_dev_mfgs, mfg)

    max_mfg = max(max_mfg, len(mfg))
    if model != "":
        if mfg_models[mfg] == "":
            mfg_models[mfg] = model
        else:
            if model not in mfg_models[mfg]:  # use softer 'in' vs word_in_list() to allow mulit-word, fuzzier match
                mfg_models[mfg] = mfg_models[mfg] + ", " + model

    if scsi_adr != "":
        if scsi_lun_mfg[scsi_adr] == "":
            scsi_lun_mfg[scsi_adr] = mfg
            scsi_lun_mfg_origin[scsi_adr] = source
            mfg_lun_count[mfg] += count
        else:
            if scsi_lun_mfg[scsi_adr] != mfg:  # if not the normal case, check it out
                check_scsi_lun_mfg(scsi_adr, mfg, count, source)

        track_dev_models(scsi_adr, model, source)

    return

# ---------------------------------------------#
# Function track_dev_models()
# ---------------------------------------------#


def track_dev_models(scsi_adr, model, source):
    global scsi_lun_mfg_model
    global scsi_lun_mfg_model_origin
    global max_model

    if model == "":
        return

    if scsi_lun_mfg_model[scsi_adr] == "":
        scsi_lun_mfg_model[scsi_adr] = model
        scsi_lun_mfg_model_origin[scsi_adr] = source
        max_model = max(max_model, len(model))
    else:
        if scsi_lun_mfg_model[scsi_adr] != model:  # if not the normal case, check it out
            check_scsi_lun_mfg_model(scsi_adr, model, source)

    return

# ---------------------------------------------#
# Function check_scsi_lun_mfg()
# track scsi manufacturers, check for anomalies.
# ---------------------------------------------#


def check_scsi_lun_mfg(scsi_adr, mfg, count, source):
    global scsi_lun_mfg
    global scsi_lun_mfg_origin
    global scsi_lun_mfg_model

    # Allow EMC and DGC to be aliases
    if scsi_lun_mfg[scsi_adr] == "DGC" and mfg == "EMC":
        return
    if scsi_lun_mfg[scsi_adr] == "EMC" and mfg == "DGC":
        return

    if scsi_lun_mfg[scsi_adr] != mfg:
        action = file_check(scsi_lun_mfg_origin[scsi_adr], source)
        if do_anomaly(action):
            anomaly_line = "scsi lun {0} already has mfg set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                format(scsi_adr, scsi_lun_mfg[scsi_adr], scsi_lun_mfg_origin[scsi_adr], mfg, action, source)
            handle_anomaly("DUP-3", anomaly_line)
        if action == "overridden":
            mfg_lun_count[scsi_lun_mfg[scsi_adr]] -= count
            scsi_lun_mfg[scsi_adr] = mfg
            scsi_lun_mfg_origin[scsi_adr] = source
            mfg_lun_count[mfg] += count

    return

# ---------------------------------------------#
# Function do_anomaly()
# return True/False wrt cteating an anomaly
# may or may not be an '[overridden]' one.
# ---------------------------------------------#


def do_anomaly(action):
    global sw_o
    global sw_i
    # if sw_o: return(True)                      # aked to provide overridden anomalies
    # if action == "overridden": return(False)   # not asked and an override
    if action == "overridden":
        if sw_o:
            return(True)
        else:
            return(False)
    if action == "ignored":
        if sw_i:
            return(True)
        else:
            return(False)
    return(True)                                # not an override

# ---------------------------------------------#
# Function check_scsi_lun_mfg_model()
# track scsi manufacturers device models, check for anomalies.
# ---------------------------------------------#


def check_scsi_lun_mfg_model(scsi_adr, model, source):
    global scsi_lun_mfg
    global scsi_lun_mfg_origin
    global scsi_lun_mfg_model
    global max_model

    # allow for the situation where we may see model as 'xx' one time and 'xx nnnn' the next
    # take the longer of the two when initially equal
    a = model
    b = scsi_lun_mfg_model[scsi_adr]

    if a == b:
        return

    l = min(len(a), len(b))
    if a[0:l] == b[0:l]:
        if len(a) < len(b):
            return
        scsi_lun_mfg_model[scsi_adr] = model
        return

    if a == "EMS Virtual":
        return
    if b == "EMS Virtual":
        # model typically "Virtual CD/HD/FD" (better choice thatn EMS Virtual and no need for anom DUP)
        scsi_lun_mfg_model[scsi_adr] = model
        return

    if ("RAID" in a or "RAID" in b) and ("Clariion" in a or "Clariion" in b):
        model = clean_up_clariion_model(a, b, scsi_adr)
        debug_print(3, "'{0}' '{1}' '{2}' {3} {4}".format(a, b, model, scsi_adr, source))
        scsi_lun_mfg_model[scsi_adr] = model
        max_model = max(max_model, model)
        return
    action = file_check(scsi_lun_mfg_model_origin[scsi_adr], source)
    if do_anomaly(action):
        anomaly_line = "scsi lun {0} already has mfg model set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
            format(scsi_adr, scsi_lun_mfg_model[scsi_adr], scsi_lun_mfg_origin[scsi_adr], model, action, source)
        handle_anomaly("DUP-3", anomaly_line)
    if action == "overridden":
        scsi_lun_mfg_model[scsi_adr] = model
        scsi_lun_mfg_model_origin[scsi_adr] = source
        max_model = max(max_model, len(model))

    return

# ---------------------------------------------#
# function clean_up_clariion_model():
# return a model w/Clariion first followed by whatever (V)RAID details are found
# ---------------------------------------------#


def clean_up_clariion_model(a, b, scsi_adr):
    # raid can be: "VRAID" "VRAID 0532" "RAID 10" "RAID 5"
    # model can be: "Clariion VNX7600, VNX5500, VNX5300, AX4-5F8, CX4-960, CX3-80"

    model = b  # "Clariion xxx"
    if a.startswith("Clariion"):
        model = a

    raid = a  # (V)RAID (5|10)
    if b.startswith("RAID") or b.startswith("VRAID"):
        raid = b

    if model.find(raid) != -1:
        return(model)  # raid already completely in model, done

    tmp = raid.split()
    wc = len(tmp)
    if wc == 1:
        model = model + " " + raid
        return(model)

    if wc == 2:
        if model.find(tmp[0]) == -1:
            model = model + " " + raid
            return(model)
        else:
            model = model + " " + tmp[1]
            return(model)

    return("?")

# ---------------------------------------------#
# check_dev_id_tgt_node()
# ---------------------------------------------#


def check_dev_id_tgt_node(dev_id, tgt_node, source):
    global dev_id_2_tgt_node  # Key_data()
    global dev_id_2_tgt_node_origin  # Key_data()
    global tgt_node_2_dev_ids  # Key_data()

    if dev_id_2_tgt_node[dev_id] == "":
        dev_id_2_tgt_node[dev_id] = tgt_node
        dev_id_2_tgt_node_origin[dev_id] = source
    else:
        if dev_id_2_tgt_node[dev_id] != tgt_node:
            anomaly_line = "dev id {0} already has tgt node set to {1}({2}), attempting to set to {3} ({4})".\
                format(dev_id, dev_id_2_tgt_node[dev_id], dev_id_2_tgt_node_origin[dev_id], tgt_node, source)
            handle_anomaly("DUP-1", anomaly_line)

    tgt_node_2_dev_ids[tgt_node] = unique_list(tgt_node_2_dev_ids[tgt_node], dev_id)

# ---------------------------------------------#
# add_scsi_info_from_mpo()
# From multipath command output:
# ---------------------------------------------#


def add_scsi_info_from_mpo(dev_id, scsi_adr, mfg, model, mm, tgt, source):

    dev_type = dev_id[0:2]  # 'sd'

    debug_print(3, "{0} {1} {2} {3} {4} {5}".format(dev_id, scsi_adr, mfg, model, tgt, source))

    if dev_type != "sd":
        return

    scsi_adr = normalize_scsi_adr(scsi_adr)
    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, "", "", source)

    if mm != "":
        add_mm_bd(dev_id, mm, source)
    if mfg != "":
        track_dev_mfgs(scsi_adr, mfg, 1, source)
    if model != "":
        track_dev_models(scsi_adr, model, source)
    if tgt != "":
        check_dev_id_tgt_node(dev_id, tgt, source)
    return

# ---------------------------------------------#
# add_scsi_info_from_mp_map_detail(mpl,dm_dev)
# From multipath command output:
# ' \_ 5:0:0:8  sdd 8:48   [active][ghost]'
# ' \_ 5:0:0:15 sdk 8:160  [active][ready]'
#
# '  |- 6:0:0:0 sdc 8:32 active ready running'
# '  `- 9:0:0:0 sdf 8:80 active ready running'
#
# ---------------------------------------------#


def add_scsi_info_from_mp_map_detail(mpl, dm_dev, source):

    words = mpl.split()
    scsi_adr = normalize_scsi_adr(words[1])
    dev_id = words[2]
    dev_type = "sd"
    dev_major_minor = words[3]

    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, "", mpl, source)

    add_normalized_mm_data(scsi_adr, dev_id, dm_dev, dev_major_minor, mpl, "", source)
    return


# ---------------------------------------------#
# add_scsi_info_from_mp_map_detail2(mpl,dm_dev)
# From multipath command output:
# '| |- 7:0:0:0 sdd 8:48 active ready running'
# '| `- 8:0:0:0 sde 8:64 active ready running'
#
# ---------------------------------------------#
def add_scsi_info_from_mp_map_detail2(mpl, dm_dev, source):

    words = mpl.split()
    scsi_adr = normalize_scsi_adr(words[2])
    dev_id = words[3]
    dev_type = "sd"
    dev_major_minor = words[4]

    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, "", mpl, source)

    add_normalized_mm_data(scsi_adr, dev_id, dm_dev, dev_major_minor, mpl, "", source)
    return


# ---------------------------------------------#
# function: add_normalized_mm_data(...)
# ---------------------------------------------#
def add_normalized_mm_data(scsi_adr, dev_id, dm_dev, dev_major_minor, line, hint, source):
    global dev_2_dms             # key: device id,           data: dm id(s);         e.g. sdc,     dm-30,dm-31,..
    global dm_2_devs             # key: dm id,               data: device id(s);     e.g. dm-307,  sdcpc
    global dm_re

    # if dev_major_minor == "xxx:yyyy":
    # if dev_major_minor.startswith("9:") or dev_id.startswith("md"):
    # debug_print(0,"(scsi({0}),dev_id({1}),dm_dev({2}),dev_major_minor({3}),hint({4}),source({5})".\
    # format(scsi_adr,dev_id,dm_dev,dev_major_minor,hint,source))  #

    debug_print(3, "(scsi({0}),dev_id({1}),dm_dev({2}),dev_major_minor({3}),hint({4}),source({5})".
                format(scsi_adr, dev_id, dm_dev, dev_major_minor, hint, source))
    char_or_block = ''

    if line != '':
        if line.startswith("crw"):
            char_or_block = "char"
        elif line.startswith("brw"):
            char_or_block = "block"
        elif line.startswith("b--"):
            char_or_block = "block"
        elif "failed" in line or "faulty" in line:
            io_path_ha_bus_tgt_lun(scsi_adr, line, source)

    if dm_dev != "" and not re.match(dm_re, dm_dev):
        dm_dev = ""

    if dev_id != "" and dm_dev != "":
        dm_mm = conv_id_2_mm(dm_dev, 'dm')
        dev_2_dms[dev_id] = unique_list(dev_2_dms[dev_id], dm_dev)
        dm_2_devs[dm_mm] = unique_list(dm_2_devs[dm_mm], dev_id)

    if dm_dev != "":
        add_dm_info(dm_dev, '', source)

    if dev_major_minor != "":
        if dev_id != "":
            if char_or_block == "char":
                add_mm_cd(dev_id, dev_major_minor, source)
            else:
                add_mm_bd(dev_id, dev_major_minor, source)
        elif dm_dev != "":
            add_mm_bd(dm_dev, dev_major_minor, source)

    return

# ---------------------------------------------#
# function: add_dm_info()
# ---------------------------------------------#


def add_dm_info(dm_dev, ufn_dev, source):
    global max_dm  # 0 max len of "dm-nnn" names
    global max_dm_nn  # 0 max value of nnn portion of "dm-nnn"
    global dm_array  # Counter()                # key dm id                 data: number of times seen e.g. dm-12, 2
    global dm_re

    debug_print(3, "{0} '{1}' {2}".format(dm_dev, ufn_dev, source))
    if not dm_dev.startswith("dm-"):
        return
    # if dm_dev.startswith(".asm_"): return
    # if dm_dev.startswith("asm_"): return
    # if dm_dev.startswith("ora_"): return

    nn = dm_dev.lstrip("dm-")
    # case: dm-nnnp1
    if not nn.isdigit():
        error_print('l', "{0} '{1}' {2}".format(dm_dev, ufn_dev, source))
        return

    max_dm = max(max_dm, len(dm_dev))

    max_dm_nn = max(max_dm_nn, int(nn))
    dm_array[dm_dev] += 1

    major = get_device_mapper_major()
    mm = "{0}:{1}".format(major, nn)

    if ufn_dev != '' and ufn_dev != dm_dev:
        track_ufn(ufn_dev, mm, dm_dev, source)

    debug_print(3, "{0} '{1}' {2}".format(dm_dev, ufn_dev, source))
    return


# ---------------------------------------------#
# function: track_ufn()
# ufn=user friendly name
# ---------------------------------------------#
def track_ufn(ufn, mm, dm_nn, source):
    global Oracle
    global all_vg_names

    debug_print(3, "'{0}' '{1}' '{2}' ({3})'".format(ufn, mm, dm_nn, source))

    # if this ufn is vg-lv name, track in that way
    vg_name = split_valid_vg_name(ufn, source)
    debug_print(3, "'{0}' '{1}'".format(vg_name, all_vg_names))
    if vg_name != '':
        lv_name = split_valid_lv_name(ufn, source)
        # if dm_nn == "dm-2": debug_print(z,"{0} {1}".format(ufn,lv_name))
        if lv_name != '':
            if '-' in vg_name or '-' in lv_name:
                tufn = ufn
            else:
                tufn = vg_name + "-" + lv_name
            add_mm_bd(tufn, mm, source)
            return
    # if this ufn is a mpath* name or scsi id (36xxxx..), track in that way
    if ufn.startswith("mpath") or is_scsi_id(ufn):
        add_mm_bd(ufn, mm, source)
        return

    tmp = mm.split(':')
    major = int(tmp[0])
    # debug_print(3,"{0} {1}".format(mm,get_device_mapper_major()))
    if major == get_device_mapper_major():
        add_mm_bd(ufn, mm, source)
        return

    # should not get here
    debug_print(0, "'{0}' '{1}' '{2}' ({3})'".format(ufn, mm, dm_nn, source))
    errorprint(88803 / 0)

    return
# ---------------------------------------------#
# function: add_partition_2_dev()
# ---------------------------------------------#


def add_partition_2_dev(dev_id, part_id, source):
    global dev_2_parts  # Key_data()
    global max_dev_id

    debug_print(3, "'{0}' '{1}' ({2})".format(dev_id, part_id, source))

    if dev_id == '' or part_id == '':
        return

    dev_2_parts[dev_id] = unique_list(dev_2_parts[dev_id], part_id)

    max_dev_id = max(max_dev_id, len(part_id))

    return


# ---------------------------------------------#
# gather major number device info
#
# Character devices:
# 1 mem
# 4 /dev/vc/0
# .
# .
# .
# 251 bsg
# 252 pcmcia
# 253 watchdog
# 254 rtc
#
# Block devices:
# 1 ramdisk
# 259 blkext
# 7 loop
# 8 sd
# 9 md
# 65 sd
# .
# .
# .
# 134 sd
# 135 sd
# 251 ofsctl
# 252 .asm_ctl_spec
# 253 device-mapper
# 254 mdp
#
# 254 device-mapper <<---- CentOS system (see case )
#
# ---------------------------------------------#
def crunch_proc_devices():
    global major_block_type  # Key_data() # key major number, data block type description
    global major_char_type  # Key_data() # key major number, data character type description
    global proc_device_dm_major  # -1

    fn = 'proc/devices'
    fh = openfile(fn)
    if fh is None:
        return

    block_type = False
    char_type = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove ending \n
        i += 1
        line = line.strip()
        if line == '':
            continue
        words = line.split()
        wc = len(words)

        if line == "Character devices:":
            char_type = True
            block_type = False
            continue
        if line == "Block devices:":
            char_type = False
            block_type = True
            continue

        if wc != 2:
            error_print('d', line)
            continue

        major_number = words[0]
        major_type = words[1]

        if not major_number.isdigit():
            error_print('d', line)
            continue

        maj = int(major_number)

        if block_type:
            if major_type == "device-mapper":
                major_type = "dm"
                proc_device_dm_major = maj
            else:
                pass
            major_block_type[maj] = major_type

        if char_type:
            major_char_type[maj] = major_type

    # end: for line in fh:

    for j in range(0, 1000):
        if major_char_type[j] == '':
            continue
        debug_print(4, "char maj[{0}] -> '{1}'".format(j, major_char_type[j]))

    for j in range(0, 1000):
        if major_block_type[j] == '':
            continue
        debug_print(4, "block maj[{0}] -> '{1}'".format(j, major_block_type[j]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ===============================================================================================#
# This data comes from: http://www.lanana.org/docs/device-list/devices-2.6+.txt
#
# See also: http://lxr.free-electrons.com/source/Documentation/devices.txt
# (not clear where the definitive list is the free-electrons list says lanana.or is but yet seems to have later info)
#
# Note 1:
# Char and block major numbers marked with (note 1) indicate that their (brief) description came
# from the file {sos_command_dir}/proc/devices
#
# Major no.   Description
# ---------   --------------------
# 1 char      memory devices
# 1 block     RAM disk
#
# 2 char      pseudo tty
# 2 block     floppy disks, fd0, etc.
#
# 3 char      pseudo tty slaves
# 3 block     IDE disk/CD-ROM
# 4 char      tty
# 4 block     aliases for dynamically allocated major devcies to be used when it's not possible
# to create the real device nodes becuase the root filesystem is mounted read-only.
# 5 char      alt tty devices
# 5 block     parallel printer devices
# 6 block
# 7 char      virtual console capture devices
# 7 block     loop back devices; loop0, loop1, etc. (filesystem within a file)
# 8 char
# 8 block     scsi disk devices (0-15)
# 9 char      scsi tape devices
# 9 block     Metadisk (RAID) devices
#
# 10 char     non-serial mice
# 10 block
# 11 char     raw keyboard devices
# 11 block    SCSI CD-ROM devices
# 12 char     QIC-02 tape
# 12 block    MSCDEX CD-ROM call back support
# 13 char
# 13 block    8-bit MFM/RLL/IDE controller
# 14 char     Open Sound System (OSS)
# 14 block    BIOS harddrive callback support {2.6}
#
# 15 char     Joystick
# 15 block    Sony CDU-31A/CDU-33A CD-ROM
# 16 char     non-SCSI scanners
# 16 block    GoldStart CD-ROM
# 17 char     Chase serial card
# 17 block    Optics Storage CD-ROM
# 18 char     Chase serial card - alt devices
# 18 block    Sanyo CD-ROM
# 19 char     Cyclades serial card
# 19 block    "Double" compressed disk
#
# 20 char     Cyclades serial card - alt devices
# 20 block    Hitachi CD-ROM
# 21 char     Generic SCSI access
# 21 block    Acorn MFM hard drive interface
# ...
# 27 char     QIC-117 tape
# 27 block    Third Matsushita CD-ROM
# ...
# 37 char     IDE tape
# 37 block    Zorro II ramdisk
# ...
# 65 char     obsolete board (unused)
# 65 block    SCSI disk devices (16-31)
# 66 char     YARC PowerPC coprocessor card
# 66 block    SCSI disk devices (32-47)
# 67 block    SCSI disk devices (48-63)
# 68 block    SCSI disk devices (64-79)
# 69 block    SCSI disk devices (80-95)
#
# 70 char
# 70 block    SCSI disk devices (96-111)
# 71 char
# 71 block    SCSI disk devices (112-127)
# ...
# 94 char     miroVIDEO DC10/30 capture/playback device
# 94 block    IBM S/390 DASD block storage
# ...
# 96 char     Parallel port ATAPI tape devices
# 97 block    block Inverse NAND Flash Translation Layer
# ========
# 100 char
# 100 block
# ...
# 104 char
# 104 block   Compaq Next Generation Drive Array, first controller
# 105 char
# 105 block   Compaq Next Generation Drive Array, second controller
# 106 char
# 106 block   Compaq Next Generation Drive Array, third controller
# 107 char
# 107 block   Compaq Next Generation Drive Array, fourth controller
# 108 char
# 108 block   Compaq Next Generation Drive Array, fifth controller
# 109 char    reserved for LVM
# 109 block   Compaq Next Generation Drive Array, sixth controller
# 110 char
# 110 block   Compaq Next Generation Drive Array, seventh controller
# 111 char
# 111 block   Compaq Next Generation Drive Array, eigth controller
#
# 112 char
# 112 block   IBM iSeries vritual disk
# 113 char
# 113 block   IBM iSeries vritual CD-ROM
# 114 char
# 114 block   IDE BIOS powered software RAID interfaces
# 115 char
# 115 block   NetWare (NWFS) Devices
# ...
# ...
# 120-127 char    officially: LOCAL/EXERIMENTAL USE
# 120-127 block   officially: LOCAL/EXERIMENTAL USE
# 120 block   in reality: EMC PowerPath
# ...
# 128-135     block SCSI disk devices (128-255)
# ...
# 199 char    Veritas volume manager (VxVM) volumes (/dev/vx/rdsk/*/*)
# 199 block   Veritas volume manager (VxVM) volumes (dev/vx/dsk/*/*)
# 200 char    Veritas VxVM configuration interface
# 200 block
# 201 char    Veritas VxVM dynamic multipathing driver (/dev/vx/rdmp/*)
# 201 block   Veritas VxVM dynamic multipathing driver (/dev/vx/dmp/*)
# ...
# 202 char    CPU model-specific registers
# 202 block   XVD virtual disk (xvd)
#
# 203 char    CPU CPUID information
# 203 block
#
# 204 char    Low-density serial ports
# 204 block
#
# 205 char    Low-density serial ports (alternate device)
# 205 block
#
# 206 char    OnStream SC-x0 tape devices
# 206 block
#
# 207 char    Compaq ProLiant health feature indicate
# ...
#
# 230 char    IBM iSeries virtual tape
# 230 block
#
# 240-254 char    LOCAL/EXPERIMENTAL USE
# 240-254 block    LOCAL/EXPERIMENTAL USE
# Allocated for local/experimental use.  For devices not
# assigned official numbers, these ranges should be
# used in order to avoid conflicting with future assignments.
#
# 246 char
# 246 block   (oracle asm_ctl?)
#
# 247 char    IBM tape & changer (from case  sos_commands/devicemapper/ls_-laR_.dev)
# 247 block   Oracle use
#
# 248 char    IBM tape (from case  sos_commands/devicemapper/ls_-laR_.dev)
# 248 char    'megaraid_sas_ioctl' (note 1)
# 248 char    nvme control
# 248 block   Oracle use
#
# 249 char    'hidraw' (note 1)
# 249 block   Oracle use
#
# 250 char    'usbmon' (note 1)
# 250 block
#
# 251 char    'bsg' (note 1)
# 251 block   vd[a-z][1-9]
#
# 252 char    'watchdog' (note 1)
# 252 block   Multipath use; dm-n devices, also dfa, fio, etc.
#
# 253 char    'rtc' (note 1)
# 253 block   Multipath use; dm-n devices
# 253 block   vd[a-z] (RHEV virtblk)
#
# 254 char    'tpc' (note 1)
# 254 block   'mdp' (note 1)
#
# 255 char    RESERVED
# 255 block   RESERVED
# This major is reserved to assist the expansion to a
# larger number space.  No device nodes with this major
# should ever be created on the filesystem.
#
# 256 char    RESERVED
# 256 block   RESERVED
# -thru-
# 259 char    ?
# 255 block   nvme devices
# 260 char
# 260 block -- now apparently defined, see free-electrons page
# ===============================================================================================#

# ---------------------------------------------#
# function: set_default_device_type_names()
# set default major number info
# ---------------------------------------------#
def set_default_device_type_names():  # set default major number info
    global major_block_type_default  # Key_data() # key major number, data block type description
    global major_char_type_default  # Key_data() # key major number, data character type description

    major_char_type_default[1] = "mem"
    major_char_type_default[4] = "tty"
    major_char_type_default[5] = "/dev/console"
    major_char_type_default[7] = "vcs"
    # major_char_type_default[9] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[10] = "misc"
    # major_char_type_default[12] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[13] = "input"
    major_char_type_default[21] = "sg"
    # major_char_type_default[27] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[29] = "fb"
    # major_char_type_default[37] = "st" --- needs verification or presence in proc/devices
    # major_char_type_default[96] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[126] = "dtrep"
    major_char_type_default[128] = "ptm"
    major_char_type_default[136] = "pts"
    major_char_type_default[162] = "raw"
    major_char_type_default[180] = "usb"
    major_char_type_default[188] = "ttyUSB"
    major_char_type_default[189] = "usb_device"
    major_char_type_default[202] = "cpu/msr"
    major_char_type_default[203] = "cpu/cpuid"
    # major_char_type_default[206] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[226] = "drm"
    # major_char_type_default[230] = "st" --- needs verification or presence in proc/devices
    major_char_type_default[246] = "ql2xapidev"
    major_char_type_default[247] = "ptp"
    major_char_type_default[248] = "megraid_sas_ioctl"
    major_char_type_default[249] = "pps"
    major_char_type_default[250] = "hidraw"
    major_char_type_default[253] = "usbmon"
    major_char_type_default[254] = "rtc"

    # /\/\/\/\/\/\  C H A R   M A J O R  T Y P E S /\/\/\/\/\/

    # \/\/\/\/\/\/  B L O C K   M A J O R  T Y P E S \/\/\/\/\/\/

    major_block_type_default[1] = "ramdisk"
    major_block_type_default[2] = "fd"
    major_block_type_default[3] = "hd"  # may need to be reconsidered
    major_block_type_default[7] = "sd"
    major_block_type_default[8] = "sd"
    major_block_type_default[9] = "md"
    major_block_type_default[11] = "sr"
    major_block_type_default[22] = "hd"  # may need to be reconsidered
    major_block_type_default[33] = "hd"  # may need to be reconsidered (md too?)
    major_block_type_default[34] = "hd"  # may need to be reconsidered
    major_block_type_default[43] = "md"  # may need to be reconsidered
    major_block_type_default[65] = "sd"
    major_block_type_default[66] = "sd"
    major_block_type_default[67] = "sd"
    major_block_type_default[68] = "sd"
    major_block_type_default[69] = "sd"
    major_block_type_default[70] = "sd"
    major_block_type_default[71] = "sd"
    # major_block_type_default[94]  = "dasd" -- IBM system 390 dasd (set in proc/devices)
    # major_block_type_default[104] = "cciss" / "ccissn" -- HP builtin harddrives (set in proc/devices)
    # (cciss 104:111)
    # major_block_type_default[111] = "cciss" / "ccissn" -- HP builtin harddrives (set in proc/devices)
    # TODO: verify dasd type
    # major_block_type_default[120] = "pp" -- EMC powerpath (should be set in proc/devices??)
    major_block_type_default[128] = "sd"
    major_block_type_default[129] = "sd"
    major_block_type_default[130] = "sd"
    major_block_type_default[131] = "sd"
    major_block_type_default[132] = "sd"
    major_block_type_default[133] = "sd"
    major_block_type_default[134] = "sd"
    major_block_type_default[135] = "sd"
    # major_block_type_default[200] = "vm" -- veritas mapper dev (should be set in proc/devices)
    # major_block_type_default[201] = "vx" -- veritas mapper dev (should be set in proc/devices)
    # major_block_type_default[253] = "device-mapper" -- don't set this in case overridden from ls_-laR.dev
    major_block_type_default[254] = "mdp"
    major_block_type_default[259] = "blkext"

    return


# ---------------------------------------------#
# function: get_major_type()
# return 'string' representing major type
# ---------------------------------------------#
def get_major_type(major, char_or_block):

    if char_or_block.startswith("b"):
        return(get_block_major_name(major))
    elif char_or_block.startswith("c"):
        return(get_char_major_name(major))
    else:
        errorprint(88 / 0)  # die for now -- SNO


# ---------------------------------------------#
# function: is_sd(major)
# True/False - major number is a scsi disk
# ---------------------------------------------#
def is_sd(major):
    if (major == 8) or \
       (major >= 65 and major <= 71) or \
       (major >= 128 and major <= 135):
        return(True)
    return(False)


# ---------------------------------------------#
# function: is_tape(major)
# True/False - major number is a tape device
# ---------------------------------------------#
def is_tape(major):
    global LIN_TAPED
    global service_procs  # Counter()
    if major == 9 or \
       major == 12 or major == 27 or \
       major == 37 or major == 96 or \
       major == 206 or major == 230:
        return(True)

    if (major >= 246 and major <= 248) and service_procs[LIN_TAPED]:
        return(True)

    return(False)

# ---------------------------------------------#
# function: is_tape_id(dev_id)
# True/False - dev_id is a tape device name
# ---------------------------------------------#


def is_tape_id(dev_id):
    global st_re, nst_re, rmt_re, tsm_re, lt_re

    if dev_id == '' or dev_id.startswith("sd"):
        return(False)

    if re.match(st_re, dev_id) or re.match(nst_re, dev_id) or re.match(rmt_re, dev_id) or re.match(tsm_re, dev_id) or re.match(lt_re, dev_id):
        return(True)

    return(False)

# ---------------------------------------------#
# function: get_device_mapper_major()
# Priority:
# 1. based on finding dm-nn device(s) in sos_commands/.../ls_-laR.dev
# 2. based on what is found as the device_mapper major in proc/devices
# 3. the default value of 253
# ---------------------------------------------#


def get_device_mapper_major():
    global ls_dev_dm_major  # -1
    global proc_device_dm_major  # -1

    if ls_dev_dm_major != -1:
        return(ls_dev_dm_major)
    if proc_device_dm_major != -1:
        return(proc_device_dm_major)

    return(253)

# ---------------------------------------------#
# function: get_first_block_minor_no()
# ---------------------------------------------#


def get_first_block_minor_no(major):
    global lo_block_minor  # Key_data_min()
    global hi_block_minor  # Key_data_max()
    global big_num

    lbm = lo_block_minor[major]
    hbm = hi_block_minor[major]

    if lbm == big_num and hbm == -1:
        return(-1)  # no minor devices numbers for this major

    if lbm == big_num or hbm == -1:
        error_print("l", "major[{0}] lo_minor[{1}] hi_minor[{2}] - should not occur".format(major, lbm, hbm))
        return(-1)

    return(lbm)

# ---------------------------------------------#
# function: get_next_block_minor_no()
#
# Previously device minor numbers were iterated over using this type of for loop:
#
# for i in range(lo_dm_minor,hi_dm_minor+1):
#
# Unfortuneately some third party drivers created widely sparse ranges which meant
# many iterations which returned nothing and caused sumsos run for ~30 minutes in some cases:
#
# VxDMP block major type: ----> see case
# 201:16      VxDMP2 -> vx/dmp/emc0_3ca7    ---> lo_dm_minor[201] = 16
# 201:17      vx/dmp/emc0_3ca7s1
# 201:18      vx/dmp/emc0_3ca7s2
# .           .
# .           .
# .           .
# 201:990     vx/dmp/emc0_46acs14
# 201:991     vx/dmp/emc0_46acs15
# \
# \ huge sparse gap
# /
# /
# 201:1048575 vx/dmpconfig    ---> hi_dm_minor[201] = 1,048,575
#
# In the vx case above the for loop would iterate well over a million times to return less than 1000 elements.
#
# ---------------------------------------------#


def get_next_block_minor_no(major, ordinal):
    global lo_block_minor  # Key_data_min()
    global hi_block_minor  # Key_data_max()
    global block_minor_cnt  # Counter()         # key: block major device number, data: count of minor device numbers
    global block_minor_devs  # Key_data()       # key: block major device number, data: unique list of minor device numbers
    global last_major_used  # -1                #
    global last_block_minor_cnt  # -1
    global last_block_minor_array  # ''.split() # will be set to block_minor_devs[major].split()

    if ordinal >= block_minor_cnt[major]:
        return(-1)

    if major != last_major_used:
        last_block_minor_cnt = -1
        last_major_used = major

    if block_minor_cnt[major] != last_block_minor_cnt:
        last_block_minor_cnt = block_minor_cnt[major]
        last_block_minor_array = block_minor_devs[major].split()

    return(last_block_minor_array[ordinal])


# minor = get_first_block_minor_no(major)
# ordinal = 0
# while minor != -1:
# mm = "{0}:{1}".format(major,minor)
# .... do stuff
# ordinal+=1
# minor = get_next_block_minor_no(major,ordinal)


# ---------------------------------------------#
# function: add_mm_bd()
# track the major/minor data for a block device
# ---------------------------------------------#
def add_mm_bd(id, mm, source):
    add_mm_bd_w_dir(id, mm, '', source)
    return

# ---------------------------------------------#
# function: add_mm_bd_w_dir()
# track the major/minor data for a block device
# ---------------------------------------------#


def add_mm_bd_w_dir(id, mm, _dir, source):
    global bd_2_mm  # Key_data()
    global bd_2_mm_origin  # Key_data()
    global mm_2_bd  # Key_data()
    global mm_2_bd_origin  # Key_data()
    global max_major
    global max_minor
    global lo_block_major  # big_num
    global hi_block_major  # -1
    global lo_block_minor  # Key_data_min()
    global hi_block_minor  # Key_data_max()
    global block_minor_cnt  # Counter()         # key: block major device number, data: count of minor device numbers
    global block_minor_devs  # Key_data()       # key: block major device number, data: unique list of minor device numbers
    global messages_fn  # "messages"
    global messages_file_list

    global mm_2_bd_aliases  # Key_data() # key: major:minor no.      data: block device name alias(es) e.g. 253:0,    mpatha, vg-lv
    global dm_re

    # debug_print(z,"{0},{1},({2})".format(id,mm,source)) # REMOVE
    if id.startswith("disk/by-id"):
        debug_print(0, "{0},{1},({2})".format(id, mm, source))  # REMOVE
        errorprint(232 / 0)

    accept_aliases = True
    if source.endswith("dmesg") or source.endswith(messages_fn) or messages_fn + "." in source or \
       messages_fn + "-" in source or word_in_list(source, messages_file_list):
        accept_aliases = False

    if not valid_major_minor(mm, True, source):
        return
    tmp = mm.split(":")
    major = int(tmp[0])
    minor = int(tmp[1])

    max_major = max(max_major, major)  # used for display purposes
    max_minor = max(max_minor, minor)  # used for display purposes

    hi_block_major = max(hi_block_major, major)
    lo_block_major = min(lo_block_major, major)

    hi_block_minor[major] = max(hi_block_minor[major], minor)
    lo_block_minor[major] = min(lo_block_minor[major], minor)

    # track all minor numbers for this major in sequential order
    block_minor_devs[major] = sort_numeric_list(unique_list(block_minor_devs[major], "{0}".format(minor)))
    block_minor_cnt[major] = wordcount(block_minor_devs[major])

    if bd_2_mm[id] == "":
        bd_2_mm[id] = mm
        bd_2_mm_origin[id] = source
    else:
        check_xx_2_major_minor(id, "bd", bd_2_mm[id], mm, source, bd_2_mm_origin[id])

    if major == get_device_mapper_major():
        pattern = dm_re
    else:
        pattern = '.*'

    if mm_2_bd[mm] == "" and re.match(pattern, id):  # for device-mapper major, only set id if its dm-nn (put the reset in the alises)
        mm_2_bd[mm] = id
        mm_2_bd_origin[mm] = source
    else:
        # if   id == mm_2_bd[mm]: pass # ok, just a subsequent reference to the same info
        if id_match(id, mm_2_bd[mm], _dir):
            pass  # ok, just a subsequent reference to the same info
        else:
            if accept_aliases:
                if dev_in_list(id, mm_2_bd_aliases[mm], _dir):
                    pass
                else:
                    mm_2_bd_aliases[mm] = unique_list(mm_2_bd_aliases[mm], id)
                    # debug_print(z,"{0} '{1}' {2}".format(mm,mm_2_bd[mm],id))
            else:
                check_major_minor_2_xx(mm, "bd", mm_2_bd[mm], id, source, mm_2_bd_origin[mm])

    return

# ---------------------------------------------#
# function: dev_in_list()
# ---------------------------------------------#


def dev_in_list(dev, _list, _dir):

    if dev == "" or _list == "":
        return(False)

    tmp = _list.split()
    for d in tmp:
        if id_match(dev, d, _dir):
            return(True)
    # end: for d in tmp:

    return(False)

# ---------------------------------------------#
# function: id_match()
# ---------------------------------------------#


def id_match(id, id_set, _dir):
    if id == id_set:
        return(True)

    # debug_print(z,"{0},{1}".format(id,id_set))

    if _dir != "asm":
        if equal_vg_lvs(id, id_set, ''):
            return(True)

    if id.startswith("mapper/") or id_set.startswith("mapper/"):
        tid = id.replace("mapper/", '')
        tid_set = id_set.replace("mapper/", '')
        if equal_vg_lvs(tid, tid_set, ''):
            return(True)

    if "/" in id_set:
        tmp = id_set.split('/')
        wc = len(tmp)
        last_seg_id_set = tmp[wc - 1]
    else:
        last_seg_id_set = id_set

    if "/" in id:
        tmp = id.split('/')
        wc = len(tmp)
        last_seg_id = tmp[wc - 1]
    else:
        last_seg_id = id

    # debug_print(z,"{0} '{1}'".format(id,tmp[wc-1]))
    if last_seg_id == last_seg_id_set:
        return(True)  # equal, but id_set starts with subdirectory
    return(False)

# ---------------------------------------------#
# function: conv_mm_to_vg_lv()
# return the vg_lv associated w/the passed major/minor (if there is one)
# ---------------------------------------------#


def conv_mm_2_vg_lv(mm, source):
    global mm_2_bd_aliases  # Key_data()
    if not valid_major_minor(mm, True, ''):
        return ''
    aliases = mm_2_bd_aliases[mm]

    tmp = aliases.split()
    for alias in tmp:
        vg = split_valid_vg_name(alias, source)
        if vg == '':
            continue
        return(alias)
    # end: for alias in tmp
    return ''

# ---------------------------------------------#
# function: add_mm_cd()
# track the major/minor data for a char device
# ---------------------------------------------#


def add_mm_cd(id, mm, source):
    global cd_2_mm  # Key_data()
    global cd_2_mm_origin  # Key_data()
    global mm_2_cd  # Key_data()
    global mm_2_cd_origin  # Key_data()
    global max_major
    global max_minor
    global lo_char_minor  # Key_data_min()
    global hi_char_minor  # Key_data_max()
    global lo_char_major  # big_num
    global hi_char_major  # -1

    if not valid_major_minor(mm, True, source):
        return

    tmp = mm.split(":")
    major = int(tmp[0])
    minor = int(tmp[1])

    max_major = max(max_major, major)  # for display purposes
    max_minor = max(max_minor, minor)  # for display purposes

    hi_char_major = max(hi_char_major, major)
    lo_char_major = min(lo_char_major, major)

    hi_char_minor[major] = max(hi_char_minor[major], minor)
    lo_char_minor[major] = min(lo_char_minor[major], minor)

    # track all minor numbers for this major in sequential order
    char_minor_devs[major] = sort_numeric_list(unique_list(char_minor_devs[major], "{0}".format(minor)))
    char_minor_cnt[major] = wordcount(char_minor_devs[major])

    # debug_print(z,"@cdmm {0} {1} {2}".format(id,mm,source))
    if cd_2_mm[id] == "":
        cd_2_mm[id] = mm
        cd_2_mm_origin[id] = source
    else:
        check_xx_2_major_minor(id, "cd", cd_2_mm[id], mm, source, cd_2_mm_origin[id])

    if mm_2_cd[mm] == "":
        mm_2_cd[mm] = id
        mm_2_cd_origin[mm] = source
    else:
        check_major_minor_2_xx(mm, "cd", mm_2_cd[mm], id, source, mm_2_cd_origin[mm])

    return


# ---------------------------------------------#
# function: check_xx_2_major_minor()
# check the value to be set, if not equal, create anomaly
# ---------------------------------------------#
def check_xx_2_major_minor(id, xx, majmin_set, majmin, source, origin):
    if majmin_set == majmin:
        return
    anomaly_line = "{0} device id[{1}] already has major:minor set to {2} ({3}), trying to set to {4} ({5})".\
        format(xx, id, majmin_set, origin, majmin, source)
    handle_anomaly("DUP-1", anomaly_line)
    return

# ---------------------------------------------#
# function: check_major_minor_2_xx()
# check the value to be set, if not equal, create anomaly
# ---------------------------------------------#


def check_major_minor_2_xx(majmin, xx, id_set, id, source, origin):
    global dev_2_scsi_id  # Key_data()
    global scsi_id_2_devs  # Key_data()
    global all_filesystems
    global fs_2_mountpoint  # Key_data()
    global dm_re

    if id_set == id:
        return

    # check and allow for 'nw_4' to match 'nw_4p1' or vice-versa
    l1 = len(id_set)
    l2 = len(id)
    ld = max(l1, l2) - min(l1, l2)
    if ld > 0:
        p_suffix = ''
        if l1 > l2 and id_set.startswith(id):
            p_suffix = id_set[l1 - ld:]
        elif l2 > l1 and id.startswith(id_set):
            p_suffix = id[l2 - ld:]
        if p_suffix != '' and re.match("p[1-9]{1,2}", p_suffix):
            return

    scsi_id = dev_2_scsi_id[id_set]
    if scsi_id != "":
        if word_in_list(id, scsi_id_2_devs[scsi_id]):
            return

    fc_id = dev_2_fc_id[id_set]
    if fc_id != "":
        if word_in_list(id, fc_id_2_devs[fc_id]):
            return

    # label alias ?
    if id == dev_2_label[id_set] or id_set == dev_2_label[id]:
        return

    if id == "root":
        fss = all_filesystems.split()
        for fs in fss:
            if fs.endswith(id_set) and fs_2_mountpoint[fs] == '/':
                return

    dm_devs = dev_2_dms[id_set]
    if dm_devs != "":
        dm_devs = dm_devs.split()
        for dm_dev in dm_devs:
            if dev_2_label[dm_dev] == id:
                return  # e.g.: dev_2_label[dm-2] -> "VOL012"

    if tape_name(id) and tape_name(id_set):
        return

    anomaly_line = "major:minor[{0}] already has {1} device id set to {2} ({3}), trying to set to {4} ({5})".\
                   format(majmin, xx, id_set, origin, id, source)
    handle_anomaly("DUP-2", anomaly_line)

    if xx != "lv":
        # print anomaly_line # REMOVE
        # print 10 / 0 # REMOVE
        pass

    return

# ---------------------------------------------#
# function: tape_name()
# is passed device id a tape name?
# ---------------------------------------------#


def tape_name(id):
    global st_re, nst_re, tsm_re, rmt_re
    global lt_re, lt_ch_re

    if re.match(st_re, id) or re.match(nst_re, id) or re.match(tsm_re, id) or re.match(rmt_re, id):
        return(True)
    return(False)

# ---------------------------------------------#
# function: conv_id_2_mm()
# because there are two major:minor arrays (block and character)
# tracking device ids, this helper routine exists
# to guide the return of data.
# ---------------------------------------------#


def conv_id_2_mm(id, hint):
    global st_re, nst_re, lt_re, lt_ch_re, dm_re, tsm_re, sg_re, lo_re

    if id.startswith("/dev/"):
        id = id[len("/dev/"):]

    mm = ""

    if hint == "" and re.match(sg_re, id):
        hint = "sg"
    if hint == "" and re.match(lo_re, id):
        hint = "loop"

    if hint == "" and re.match(st_re, id):
        hint = "tp"
    if hint == "" and re.match(nst_re, id):
        hint = "tp"
    if hint == "" and re.match(lt_re, id):
        hint = "tp"
    if hint == "" and re.match(lt_ch_re, id):
        hint = "tp"
    if hint == "" and re.match(tsm_re, id):
        hint = "tp"
    if hint == "" and re.match(sr_re, id):
        hint = "sr"
    if hint == "" and id.startswith("IBMtape"):
        debug_print(0, id)
        hint = "tp"

    if hint == "sg" or hint == "tp" or hint == "st" or hint == "cd":
        mm = cd_2_mm[id]  # get char major:minor
        return(mm)  # return char major:minor
    else:
        mm = bd_2_mm[id]  # return block major:minor
        if mm != '':
            return(mm)
        mm = get_dm_mm_from_alias(id)
        if mm != '':
            return(mm)
        return(mm)  # REMOVE
        errorprint(9999 / 0)
    return


# ---------------------------------------------#
# function: valid_major_minor()
# ensure that a string is in valid major:minor format.
# optionally issue a @error msg
# ---------------------------------------------#
def valid_major_minor(majmin, IssMsg, source):

    if is_major_minor(majmin):
        return(True)

    if IssMsg:
        error_print('d', "invalid mm: {0} ({1})".format(majmin, source))
        errorprint(99 / 0)  # REMOVE

    return(False)

# ---------------------------------------------#
# function: is_major_minor()
# ---------------------------------------------#


def is_major_minor(mm):
    if ":" not in mm:
        return False

    tmp = mm.split(":")
    wc = len(tmp)
    if wc != 2:
        return False

    if tmp[0].isdigit() and tmp[1].isdigit():
        major = int(tmp[0])
        minor = int(tmp[1])
    else:
        return False

    # if major > 259 or minor > 65535: return False
    # if major > 259 or minor > 999999: return False
    if major > 259 or minor > 1999999:
        return False

    return True

# ---------------------------------------------#
# function: def get_dm_mm_from_alias():
# ---------------------------------------------#


def get_dm_mm_from_alias(id):
    global sd_re, dm_re

    if re.match(sd_re, id) or re.match(dm_re, id):
        return('')

    # try device-mapper major
    dm_major = get_device_mapper_major()
    mm = get_dm_mm_from_alias_and_major(id, dm_major)
    if mm != '':
        return(mm)

    # try VxDMP major
    if "VxDMP" == get_block_major_name(201):
        mm = get_dm_mm_from_alias_and_major(id, 201)
        if mm != '':
            return(mm)

    # try VxVM major
    if "VxVM" == get_block_major_name(199):
        mm = get_dm_mm_from_alias_and_major(id, 199)
        if mm != '':
            return(mm)

    return('')

# ---------------------------------------------#
# function: def get_dm_mm_from_alias_and_major():
# ---------------------------------------------#


def get_dm_mm_from_alias_and_major(id, major):
    global mm_2_bd_aliases  # Key_data()

    minor = get_first_block_minor_no(major)
    i = 0
    while minor != -1:
        mm = "{0}:{1}".format(major, minor)
        alias_list = mm_2_bd_aliases[mm]
        if word_in_list(id, alias_list):
            return(mm)
        i += 1
        minor = get_next_block_minor_no(major, i)
    # end: while minor != -1:

    return('')


# ---------------------------------------------#
# function: conv_mm_2_bd()
# ---------------------------------------------#
def conv_mm_2_bd(mm):
    global mm_2_bd  # Key_data()

    id = mm_2_bd[mm]
    return(id)

# ---------------------------------------------#
# function: conv_mm_2_bd_alias_list()
# return a list of aliases that correspond to this mm
# ---------------------------------------------#


def conv_mm_2_bd_alias_list(mm):
    global mm_2_bd_aliases  # Key_data()

    aliases = mm_2_bd_aliases[mm]
    aliases = dedup_list(aliases)
    aliases = sort_list(aliases)
    return(aliases)

# ---------------------------------------------#
# function: conv_mm_2_cd()
# ---------------------------------------------#


def conv_mm_2_cd(mm):
    global mm_2_cd  # Key_data()

    id = mm_2_cd[mm]
    return(id)


# ---------------------------------------------#
# function: add_normalized_scsi_data(scsi_id,dev_type,dev_id,dev_sgn,detail_line,source)
# ---------------------------------------------#
def add_normalized_scsi_data(scsi_adr, dev_type, dev_id, dev_sgn, detail_line, source):
    global scsi_lun_detail
    global sw_sm_level
    global total_esc_messages_count  # 0
    global scsi_host
    global lun_2_dev

    debug_print(4, "sa({0}) dt({1}) di({2}) dl[{3}] ({4})".format(scsi_adr, dev_type, dev_id, detail_line, source))

    if scsi_adr == "":
        # if this syslog file has junk in it, skip next error_print()
        # or if it is a "(kernel:) SCSI device sdcc: nnnnn 512-byte hdwr sectors (nnnn MB)
        if total_esc_messages_count == 0 and "SCSI" not in detail_line:
            error_print("l", "error in call to add_normalized_scsi_data({0},{1},{2},{3},{4},{5}), scsi_adr is null".
                        format(scsi_adr, dev_type, dev_id, dev_sgn, detail_line, source))
        return

    if scsi_adr.endswith(":49409"):
        return  # see comment in crunch_scsi_scsi

    bld_ha_bus_tgt_lun(scsi_adr, source)

    if dev_id != "":
        add_dev_id(scsi_adr, dev_id, source)

    if dev_sgn != "":
        add_dev_sgn(scsi_adr, dev_sgn, source)

    if dev_type != "":
        add_dev_type(scsi_adr, dev_type, source)

    if detail_line != "" and sw_sm_level >= 4:
        if scsi_lun_detail[scsi_adr] == "":
            scsi_lun_detail[scsi_adr] = detail_line
        else:
            scsi_lun_detail[scsi_adr] = "{0}\n{1}".format(scsi_lun_detail[scsi_adr], detail_line)

    return

# ---------------------------------------------#
# function: add_dev_id(scsi_adr,dev_id)
# update the dev_2_lun and lun_2_dev arrays
# ---------------------------------------------#


def add_dev_id(scsi_adr, dev_id, source):
    global dev_2_lun
    global dev_2_lun_origin
    global lun_2_dev
    global lun_2_dev_origin
    global max_dev_id
    global lun_2_dev_aliases  # Key_data()      # key: scsi address,        data: device id(s);     e.g. 0:0:0:0, nst120

    debug_print(4, "({0},{1} ({2}))".format(scsi_adr, dev_id, source))

    if dev_2_lun[dev_id] == "":
        dev_2_lun[dev_id] = scsi_adr
        dev_2_lun_origin[dev_id] = source
        debug_print(4, "dev_2_lun[{0}] now = {1}".format(dev_id, dev_2_lun[dev_id]))
    else:
        if dev_2_lun[dev_id] != scsi_adr:
            action = file_check(dev_2_lun_origin[dev_id], source)
            if do_anomaly(action):
                anomaly_line = "device id {0} already set to scsi adr {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(dev_id, dev_2_lun[dev_id], dev_2_lun_origin[dev_id], scsi_adr, action, source)
                handle_anomaly("DUP-1", anomaly_line)
                add_normalized_scsi_data(scsi_adr, "", "", "", anomaly_line, source)  # add to scsi_lun_details
            if action == "overridden":
                dev_2_lun[dev_id] = scsi_adr
                dev_2_lun_origin[dev_id] = source
                debug_print(4, "dev_2_lun[{0}] now = {1}".format(dev_id, dev_2_lun[dev_id]))

    if lun_2_dev[scsi_adr] == "":
        lun_2_dev[scsi_adr] = dev_id
        lun_2_dev_origin[scsi_adr] = source
        debug_print(4, "lun_2_dev[{0}] now = {1}".format(scsi_adr, lun_2_dev[scsi_adr]))
    else:
        # if lun_2_dev[scsi_adr] != dev_id:
        if dev_ids_equivalent(lun_2_dev[scsi_adr], dev_id):
            if is_tape_id(dev_id) and lun_2_dev[scsi_adr] != dev_id:
                lun_2_dev_aliases[scsi_adr] = unique_list(lun_2_dev_aliases[scsi_adr], dev_id)
                # debug_print(z,"{0} '{1}'".format(scsi_adr,lun_2_dev_aliases[scsi_adr]))
        else:
            action = file_check(lun_2_dev_origin[scsi_adr], source)
            if do_anomaly(action):
                anomaly_line = "scsi adr {0} already set to device {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(scsi_adr, lun_2_dev[scsi_adr], lun_2_dev_origin[scsi_adr], dev_id, action, source)
                handle_anomaly("DUP-2", anomaly_line)
                add_normalized_scsi_data(scsi_adr, "", "", "", anomaly_line, source)  # add to scsi_lun_details
            if action == "overridden":
                lun_2_dev[scsi_adr] = dev_id
                lun_2_dev_origin[scsi_adr] = source
                debug_print(4, "lun_2_dev[{0}] now = {1}".format(scsi_adr, lun_2_dev[scsi_adr]))

    max_dev_id = max(max_dev_id, len(dev_id))

    return

# ---------------------------------------------#
# function: dev_ids_equivalent()
# ---------------------------------------------#


def dev_ids_equivalent(dev_id1, dev_id2):
    if dev_id1 == dev_id2:
        return(True)

    if dev_id1.startswith("nst") and dev_id2.startswith("st"):
        if dev_id1.replace("nst", "st") == dev_id2:
            return(True)
        else:
            return(False)

    if dev_id1.startswith("st") and dev_id2.startswith("nst"):
        if dev_id1 == dev_id2.replace("nst", "st"):
            return(True)
        else:
            return(False)

    if dev_id1.startswith("sch") and dev_id2.startswith("ch"):
        if dev_id1.replace("sch", "ch") == dev_id2:
            return(True)
        else:
            return(False)

    if dev_id1.startswith("ch") and dev_id2.startswith("sch"):
        if dev_id1 == dev_id2.replace("sch", "ch"):
            return(True)
        else:
            return(False)

    return(False)

# ---------------------------------------------#
# function: add_dev_sgn(scsi_adr,dev_sgn)
# update the dev_2_lun and lun_2_dev arrays
# ---------------------------------------------#


def add_dev_sgn(scsi_adr, dev_sgn, source):
    global sgn_2_lun
    global sgn_2_lun_origin
    global lun_2_sgn
    global lun_2_sgn_origin
    global max_dev_sgn

    debug_print(4, "({0},{1})".format(scsi_adr, dev_sgn))

    if sgn_2_lun[dev_sgn] == "":
        sgn_2_lun[dev_sgn] = scsi_adr
        sgn_2_lun_origin[dev_sgn] = source
        debug_print(4, "sgn_2_lun[{0}] now = {1}".format(dev_sgn, sgn_2_lun[dev_sgn]))
    else:
        if sgn_2_lun[dev_sgn] != scsi_adr:
            action = file_check(sgn_2_lun_origin[dev_sgn], source)
            if do_anomaly(action):
                anomaly_line = "device sgn {0} already set to scsi adr {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(dev_sgn, sgn_2_lun[dev_sgn], sgn_2_lun_origin[dev_sgn], scsi_adr, action, source)
                handle_anomaly("DUP-1", anomaly_line)
                add_normalized_scsi_data(scsi_adr, "", "", "", anomaly_line, source)  # add to scsi_lun_details
            if action == "overridden":
                sgn_2_lun[dev_sgn] = scsi_adr
                sgn_2_lun_origin[dev_sgn] = source
                debug_print(4, "sgn_2_lun[{0}] now = {1}".format(dev_sgn, sgn_2_lun[dev_sgn]))

    if lun_2_sgn[scsi_adr] == "":
        lun_2_sgn[scsi_adr] = dev_sgn
        lun_2_sgn_origin[scsi_adr] = source
        debug_print(4, "lun_2_sgn[{0}] now = {1}".format(scsi_adr, lun_2_sgn[scsi_adr]))
    else:
        if lun_2_sgn[scsi_adr] != dev_sgn:
            action = file_check(lun_2_sgn_origin[scsi_adr], source)
            if do_anomaly(action):
                anomaly_line = "scsi adr {0} already set to device sgn {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(scsi_adr, lun_2_sgn[scsi_adr], lun_2_sgn_origin[scsi_adr], dev_sgn, action, source)
                handle_anomaly("DUP-2", anomaly_line)
                add_normalized_scsi_data(scsi_adr, "", "", "", anomaly_line, source)  # add to scsi_lun_details
            if action == "overridden":
                lun_2_sgn[scsi_adr] = dev_sgn
                lun_2_sgn_origin[scsi_adr] = source
                debug_print(4, "lun_2_sgn[{0}] now = {1}".format(scsi_adr, lun_2_sgn[scsi_adr]))

    max_dev_sgn = max(max_dev_sgn, len(dev_sgn))

    return


# ---------------------------------------------#
# function: file_check(prev_fn,new_fn)
# determine if the new source of information (new_fn) should override
# the previous source (prev_fn)
# ---------------------------------------------#
def file_check(prev_fn, new_fn):
    action = "ignored"  # default
    # if the file rankings are equal, we will override with the assumption that later data in the
    # file is more up to date and therefore should override previous data.
    if file_rank(new_fn) >= file_rank(prev_fn):
        action = "overridden"
    return(action)


# ---------------------------------------------#
# function: file_rank(fn)
# assign a numeric rank to a file name so it can be
# used above in file_check()
# ---------------------------------------------#
def file_rank(fn):
    global messages_fn  # "messages"

    if fn == '':
        return(0)

    if fn.startswith("./"):
        fn = fn[len("./"):]
    # lowest rank to highest: (after var/log/messages (tail_messages), the list is somewhat arbitrary)
    rank_list = "var/log/dmesg "\
                "sos_commands/general/dmesg_now "\
                "sos_commands/kernel/dmesg "\
                "var/log/" + messages_fn + "[-,\\.].* "\
                "var/log/" + messages_fn + " "\
                "sos_commands/general/tail_" + messages_fn + " "\
                "sos_commands/logs/journalctl_--no-pager_--boot "\
                "sos_commands/logs/journalctl_--all_--this-boot_--no-pager "\
                "sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0 "\
                "sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0_2 "\
                "sos_commands/devicemapper/vgscan_-vvv "\
                "proc/scsi/scsi "\
                "sos_commands/scsi/lsscsi "\
                "sos_commands/hardware/lshal "\
                "sos_commands/hardware/systool_-v_-c_scsi_.* "\
                "proc/scsi/sg/devices "\
                "sos_commands/scsi/sg_map "\
                "sos_commands/devicemapper/ls_-laR_.dev "\
                "sos_commands/block/ls_-lanR_.dev "\
                "sos_commands/devicemapper/systool_-v_-c_scsi_.* "\
                "sos_commands/devicemapper/ls_-laR_.sys.block "\
                "sos_commands/block/ls_-lanR_.sys.block "\
                "sos_commands/cluster/fdisk_-l "\
                "sos_commands/block/lsblk "\
                "sos_commands/block/fdisk_-l_\.dev\..* "\
                "sos_commands/block/parted_-s_\.dev\..* "\
                "sos_commands/filesys/lsblk "\
                "sos_commands/filesys/fdisk_-l_\.dev\..* "\
                "sos_commands/filesys/parted_-s_\.dev\..* "\
                "sos_commands/devicemapper/multipath_-v4_-ll "\
                "sos_commands/multipath/multipath_-v4_-ll "\
                "sos_commands/multipath/multipath_-l "\
                "proc/partitions "\
                "sos_commands/devices/udevadm_info_--export-db "\
                "sos_commands/s390/lsdasd "\
                "sos_commands/s390/lstape "\
                "sos_commands/s390/dasdview_-x_-i_-j_-l_-f_.dev.dasda "\
                "sos_commands/hardware/dmidecode "\
                ""
    words = rank_list.split()
    rank = 1
    for ranked_file in words:
        if re.match(ranked_file, fn):
            return rank
        rank += 1

    error_print('d', "{0} not found in rank file list".format(fn))
    return(0)

# ---------------------------------------------#
# function: add_dev_type(scsi_adr,dev_type)
# update the lun_2_type array
# ---------------------------------------------#


def add_dev_type(scsi_adr, dev_type, source):
    global lun_2_type
    global host_devtypes
    global all_scsi_dev_types

    debug_print(4, "({0},{1})".format(scsi_adr, dev_type))

    all_scsi_dev_types = unique_list(all_scsi_dev_types, dev_type)

    if lun_2_type[scsi_adr] == "":
        lun_2_type[scsi_adr] = dev_type
        lun_2_type_origin[scsi_adr] = source
        debug_print(4, "lun_2_type[{0}] now = {1}".format(scsi_adr, lun_2_type[scsi_adr]))
    else:
        if lun_2_type[scsi_adr] != dev_type:
            action = file_check(lun_2_type_origin[scsi_adr], source)
            if do_anomaly(action):
                anom_line = "scsi adr {0} already set to dev type {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(scsi_adr, lun_2_type[scsi_adr], lun_2_type_origin[scsi_adr], dev_type, action, source)
                handle_anomaly("DUP-1", anom_line)
                add_normalized_scsi_data(scsi_adr, "", "", "", anom_line, source)  # add to scsi_lun_details
            if action == "overridden":
                lun_2_type[scsi_adr] = dev_type
                lun_2_type_origin[scsi_adr] = source
                debug_print(4, "lun_2_type[{0}] now = {1}".format(scsi_adr, lun_2_type[scsi_adr]))

    host = scsi_adr.split(':')
    host = host[0]
    # track all unique device types on this host for disk/tape host sharing anomaly check
    host_devtypes[host] = unique_list(host_devtypes[host], dev_type)

    return


# =============================================#
# locate sos report
# could be already unwrapped and given to
# us via a directory name (or defaulted to cwd)
# or it could be a tar file we need to unbundle.
# =============================================#
def locate_sos_report():
    global sos_report_fn
    global sw_m
    global this_script_name  # os.path.basename(sys.argv[0])

    required_dirs = "sos_commands/ sos_commands/kernel sos_commands/general/ etc/ proc/ var/log/"
    req_err_cnt = 0

    global CITELLUS_ROOT
    sos_report_fn = os.getenv('CITELLUS_ROOT', '')

    if sos_report_fn == "":
        try:
            cwd = os.getcwd()
        except OSError as e:
            errno = e.errno
            errstr = e.strerror
            error_print('f', "os.getcwd() failed with errno {0}[{1}], mostly likely directory removed from underneath {2}".
                        format(errno, errstr, this_script_name))
        exit_print("exiting due to above error", RC_FAILED)

        errorprint("sosreport_fn or directory omitted, using cwd: {0}".format(os.getcwd()))

    bMsg = True
    level = 2
    # stb = stat_file("",sos_report_fn,1)
    stb = stat_fs_obj("", sos_report_fn, bMsg, level)
    if stb is None:
        exit(2)

    if stat.S_ISDIR(stb.st_mode) is True:
        if stat_dir("", sos_report_fn, bMsg) is None:
            exit(13)  # must be EACCES
        tmp_dir = sos_report_fn
        os.chdir(tmp_dir)
        debug_print(3, "now in tmp_dir {0}".format(tmp_dir))
        sw_leave = True
    else:
        if stat_file("", sos_report_fn, bMsg) is None:
            exit(13)  # must be EACCES
        unwrap_sosreport_tarfile(sos_report_fn, stb.st_size)

    words = required_dirs.split()
    wc = len(words)
    for dir in words:
        if stat_dir("", os.path.join(sos_report_fn, dir), 0) is None:
            errorprint("sos report directory {0} not found, not a directory, or not accessible".format(os.path.join(sos_report_fn, dir)))
            req_err_cnt += 1

    # end: for dir in words:

    if req_err_cnt > 0:
        exit_print("exiting due to all sos report directories in minimum set, not found (or not valid)", RC_SKIPPED)

    return


# =============================================#
# unwrap sosreport tar file
# =============================================#
def unwrap_sosreport_tarfile(sos_fn, sos_size):
    global tmp_dir
    global sw_cmd_fail

    get_info_from_sos_fn(sos_fn, sos_size)

    tmp_dir = subproc("mktemp -d --suffix=_sumsos")
    tmp_dir = tmp_dir[0:(len(tmp_dir) - 1)]
    if sw_cmd_fail is True:
        cleanup(3)

    # validate the tar file...and get the root directory
    tar_cmd = "tar -tvf {0}".format(sos_fn)
    tar_stdout = subproc(tar_cmd)
    if sw_cmd_fail is True:
        cleanup(3)

    tar_stdout = tar_stdout.split('\n')
    i = 0

    for line in tar_stdout:
        i = i + 1
        if i == 1:
            cus_dir = line

    del tar_stdout

    debug_print(3, "cus_dir {0}".format(cus_dir))
    if cus_dir == "":
        exit_print("cmd {0} failed, exiting...".format(tar_cmd), RC_FAILED)

    words = cus_dir.split()
    # tar -tvf output:
    # drwx------ root/root        0 yyyy-mm-dd hh:mm directory_name_is_nodename
    cus_dir = words[5]
    debug_print(3, "cus_dir {0}".format(cus_dir))

    # temp while running against multiple sosreports
    errorprint("cus_dir {0}".format(cus_dir))

    extract_dirs = ""

    if sos_fn[0:1] != '/':
        sos_fn = "{0}/{1}".format(os.getcwd(), sos_fn)

    ext_dirs = ""
    extract_dirs = sorted(extract_dirs.split())
    for d in extract_dirs:
        if d == "":
            continue
        ext_dirs = "{0} {1}{2}".format(ext_dirs, cus_dir, d)

    os.chdir(tmp_dir)
    debug_print(3, "now in tmp_dir {0}".format(tmp_dir))

    tar_cmd = "tar -xf {0} {1}".format(sos_fn, ext_dirs)
    tar_stdout = subproc(tar_cmd)
    tar_sw_cmd_fail = sw_cmd_fail

    # adjust directories so we can rm -rf at the end
    # do this regardless of whether prev tar -xf work in case of partial extract.
    # chmod will allow cleanup
    find_chmod_cmd = "find . -type d -exec chmod u+wx {} \;"
    find_chmod_stdout = subproc(find_chmod_cmd)
    if tar_sw_cmd_fail is True:
        cleanup(3)

    # change so that we are now at the etc/ and sos_commands/ level
    os.chdir(cus_dir)
    debug_print(3, "now in cus_dir {0}".format(cus_dir))


# =============================================#
# do_watch_words(fn,verboseB)
#
# << this is a deprecated function >>
# << it will probably be removed in the future >>
#
# process watch words for a file
# ** all matching is done in a case insensitive manner **
# This can be an expensive call when there are ~> 20k lines in the target file
# and there is a medium to high match ratio.
#
# This routine is *not* called by default and may be deprecated in the future.
# =============================================#
def do_watch_words(ww_fn, ww_verboseB):
    global ww_file_count
    global syslog_hdr_length  # 0

    watch_words = \
        ""\
        "Device offlined - not ready after error recovery~"\
        ""\
        "attempt to access beyond end of device~"\
        "iscsid: Login failed to authenticate with target~"\
        "lun assignments on this target have changed~"\
        "Medium access timeout failure. Offlining disk!~"\
        "Sense: Logical block address out of range~"\
        "SCSI error: return code = 0x~"\
        ""\
        "blocked FC remote port time out~"\
        "blocked for more than 120 seconds~"\
        "Buffer I/O error on device dm~"\
        "Buffer I/O error on device sd~"\
        "Host adapter reset request. SCSI hang~"\
        "tur checker reports path is down~"\
        "unrecoverable I/O read error for block~"\
        "unrecoverable I/O write error for block~"\
        ""\
        "couldn't get asymmetric access state~"\
        "Current: sense key: Aborted Command~"\
        "Current: sense key: Data Protect~"\
        "Current: sense key: Illegal Request~"\
        "Current: sense key: Not Ready~"\
        "emc_clariion_checker: sending query command failed~"\
        "Failed to load firmware image~"\
        "rejecting i/o to offline device~"\
        "removing target and saving binding~"\
        "SCSI layer issued Device Reset~"\
        "unable to get inquiry page~"\
        ""\
        "Adapter Hardware Error Data:~"\
        "alua: rtpg failed with~"\
        "alua: transition timeout set~"\
        "audit: backlog limit exceeded~"\
        "Devloss timeout on WWPN~"\
        "device-mapper: multipath: Failing path~"\
        "failed to resume link~"\
        "failed while handling '/dev~"\
        "Host adapter abort request~"\
        "Illegal state transition offline->created-blocked~"\
        "Illegal state transition offline->blocked~"\
        "multipath: error getting device~"\
        "multipathd: checker failed path~"\
        "remaining active paths: 0~"\
        "Too many open files~"\
        "Trying to join cluster~"\
        "unexpectedly returned with status~"\
        ""\
        "Abort command issued~"\
        "BUG: soft lockup~"\
        "Cable is unplugged~"\
        "deleting unreferenced inode~"\
        "detected conn error~"\
        "device not ready~"\
        "failed to mount~"\
        "Fimware image unavailable~"\
        "Found duplicate PV~"\
        "hard resetting link~"\
        "Illegal state transition~"\
        "Link Down Event~"\
        "Link Up Event~"\
        "LIP reset occurred~"\
        "LOOP DOWN detected~"\
        "LOOP UP detected~"\
        "mark as failed~"\
        "metadata not found~"\
        "multipath: failing path~"\
        "page allocation failure~"\
        "path is down~"\
        "port time out~"\
        "timing out command~"\
        "trying to unmount~"\
        "unhandled error code~"\
        "unknown partition table~"\
        ""\
        "CDB: Write(~"\
        "CDB: Read(~"\
        "EXT3-fs error~"\
        "ext4-fs warning~"\
        "failed mbx~"\
        "firmware bug~"\
        "FLOGI failure~"\
        "FLOGI timeout~"\
        "HARD ERROR~"\
        "is dead~"\
        "Medium Error~"\
        "readonly filesystem~"\
        "readonly fs~"\
        "remove path~"\
        "reservation conflict~"\
        "timing out~"\
        "i/o error~"\
        "scsi error~"\
        "time out~"\
        "unhandled exception~"\
        ""\
        "abort~"\
        "abrt~"\
        "blocked~"\
        "debug~"\
        "bug~"\
        "duplicate~"\
        "emulex~"\
        "error~"\
        "exiting~"\
        "failover~"\
        "failure~"\
        "failed~"\
        "fail~"\
        "firmware~"\
        "kref_get~"\
        "lip_reset~"\
        "multipathd~"\
        "qla2xxx~"\
        "reject~"\
        "reset~"\
        "rxiting~"\
        "segfault~"\
        "signal~"\
        "taint~"\
        "timeout~"\
        "udevd~"\
        "udev~"\
        "unexpected~"\
        "unknown~"\
        "[<ffff~"\
        ""

    if ww_file_count == 0:
        errorprint("Watch word summary includes partial matches; 'error' matches 'terror', only one tally per line):")
        errorprint("Longer matches are counted over shorter; if 'i/o error' is tallied, 'error' will not be.")

    ww_file_count += 1
    wwc = Counter()    # key: watch word    data: count of watch words
    fh = openfile(ww_fn)
    if fh is None:
        return

    max_wws = 0
    wws = watch_words.split("~")

    for ww in wws:  # find longest multi-word phrase in watch words list
        ww_tmp = ww.split(" ")
        max_wws = max(max_wws, len(ww_tmp))
    line_count = 0
    ww_total = 0
    dmesg_file = False
    if ww_fn == "var/log/dmesg":
        dmesg_file = True

    for wl in fh:
        wl = wl[0:len(wl) - 1]  # remove trailing \n
        line_count += 1

        if not dmesg_file:
            if line_count < messages_start_line:
                continue
            # TODO - fix this ala crunch_messages
            wl = wl[syslog_hdr_length:]  # remove header
            if " info: " in wl:
                continue

        # Do multiword checks first
        # skip shorter word/phrase checks if we
        # already found a longer version.
        # i.e., don't match 'failed' if we already matched 'failed mbx'
        # also avoid matching 'fail' and failed' (failed must appear before fail above)
        ww_matches = ""  # watch words matched on this line
        line = wl.lower()
        j = max_wws
        while j > 0:
            for ww in wws:  # do from hightest multi-word phrases to lowest
                ww_tmp = ww.split(" ")  # ww_tmp is the count of words in the current watch word/phrase
                prev_match = False

                if ww != "" and len(ww_tmp) == j:
                    wwl = ww.lower()
                    if ww_matches != "":
                        # pmws = ww_matches.split("~") # do below now as to not waste cylces if ww_matches hasn't changed
                        for pmw in pmws:
                            if wwl in pmw:
                                prev_match = True

                    if prev_match is False and wwl in line:  # wl.lower():
                        wwc[ww] += 1
                        ww_total += 1
                        if ww_matches == "":   # collection of all watchword matches for this file line
                            ww_matches = wwl
                        else:
                            ww_matches = ww_matches + "~" + wwl
                        pmws = ww_matches.split("~")  # split now for prev match check above

            j = j - 1   # end of for ww in wws loop

    closefile(fh, line_count)
    debug_print(1, "read {0} lines from {1}".format(line_count, ww_fn))

    if ww_total > 0:
        errorprint("")
        errorprint("Summary of watch words found in {0} ({1} lines)".format(ww_fn, line_count))
        if not dmesg_file:
            if messages_start_line > 0:
                errorprint("Scanning started at line {0} for {1} lines.".format(messages_start_line, (line_count - messages_start_line)))
        if ww_verboseB == 1:
            for ww in wws:
                _wwc = wwc[ww]
                if _wwc == 0:
                    continue
                if _wwc > 9999:
                    ast = "***"
                elif _wwc > 999:
                    ast = "**"
                elif _wwc > 99:
                    ast = "*"
                else:
                    ast = ""
                errorprint("    watch word[{0}] appears {1} time{2}    {3}".format(ww, _wwc, plural(_wwc), ast))
        errorprint("    total matches {0}".format(ww_total))
    else:
        errorprint("")
        errorprint("No watch words matches found in {0} ({1} lines)".format(ww_fn, line_count))

    del wwc
    return


# ---------------------------------------------#
# function: info_sfdc(case_number)
# build a 'check for applicability of SFDC ...' string
# ---------------------------------------------#
def info_sfdc(case_number):
    global info_text  # "information in"
    return("{0} SFDC {1}".format(info_text, sfdc_url(case_number)))

# ---------------------------------------------#
# function: cfa_sfdc(case_number)
# build a 'check for applicability of SFDC ...' string
# ---------------------------------------------#


def cfa_sfdc(case_number):
    global cfa_text  # "check for applicability of"
    return("{0} SFDC {1}".format(cfa_text, sfdc_url(case_number)))

# ---------------------------------------------#
# function: sfdc_url(case_number)
# build a sfdc "case# " url for a SalesForceDotCom case number
# ---------------------------------------------#


def sfdc_url(case_number):
    return "https://access.redhat.com/support/cases/# /case/{0}".format(case_number)

# ---------------------------------------------#
# function: info_kcs(kcs_number)
# build a 'information in KCS ...' string
# ---------------------------------------------#


def info_kcs(kcs_number):
    global info_text  # "information in"
    return("{0} KCS {1}".format(info_text, kcs_url(kcs_number)))

# ---------------------------------------------#
# function: info_kca(kca_number)
# build a 'information in KCA ...' string
# ---------------------------------------------#


def info_kca(kca_number):
    global info_text  # "information in"
    return("{0} KCA {1}".format(info_text, kca_url(kca_number)))

# ---------------------------------------------#
# function: cfa_kcs(kcs_number)
# build a 'check for applicability of KCS ...' string
# ---------------------------------------------#


def cfa_kcs(kcs_number):
    global cfa_text  # "check for applicability of"
    return("{0} KCS {1}".format(cfa_text, kcs_url(kcs_number)))

# ---------------------------------------------#
# function: kcs_url(kcs_number)
# build a kcs "solutions" url
# ---------------------------------------------#


def kcs_url(kcs_number):
    if not kcs_number.isdigit():
        return "https://access.redhat.com/{0}".format(kcs_number)
    return "https://access.redhat.com/solutions/{0}".format(kcs_number)

# ---------------------------------------------#
# function: kca_url(kcs_number)
# build a kcs "articles" url
# ---------------------------------------------#


def kca_url(kcs_number):
    return "https://access.redhat.com/articles/{0}".format(kcs_number)


# ---------------------------------------------#
# function: cfa_bz(kcs_number)
# build a 'check for applicability of bz ...' string
# ---------------------------------------------#
def cfa_bz(bz_number):
    global cfa_text  # "check for applicability of"
    return("{0} BZ {1}".format(cfa_text, bz_url(bz_number)))

# ---------------------------------------------#
# function: bz_url(bz_number)
# build a bz url
# ---------------------------------------------#


def bz_url(bz_number):
    return "https://bugzilla.redhat.com/show_bug.cgi?id={0}".format(bz_number)


# ---------------------------------------------#
# function: do_fs_check()
# check fs data in relation to other system data for anomalies
# ---------------------------------------------n
def do_fs_checks():
    global all_filesystems  # ""
    global all_fs_types  # ""
    global fs_2_mountpoint  # Key_data()
    global fs_2_mountpoint_origin  # Key_data()
    global fs_2_type  # Key_data()
    global fs_2_type_origin  # Key_data()
    # global fs_2_pctused # Key_data()
    global fs_2_opts  # Key_data()
    # global fs_2_blocks # Counter()
    # global fs_2_block_size # Counter()

    global LVMConf  # Key_data()
    global service_procs  # Counter()          # key: service name         data: count of daemon procs from ps info

    global vg_lv_fs_but_no_vgs_list
    global fs_full_anom_lines  # ''

    netdev_fs_cnt = 0
    gfs_cnt = 0
    ext4_cnt = 0
    ext4_nodealloc_cnt = 0
    xfs_discard_cnt = 0

    words = all_filesystems.split()
    wc = len(words)

    var_count = 0
    lld = LVMConf["locking_dir"]
    netfs_status = service_status("netfs")

    fs_without_size = ''    # list of local fs systems without size
    fs_without_device = ''  # list of local fs systems without device

    for fs in words:

        if fs_2_type[fs].startswith("gfs"):
            gfs_cnt += 1

        if fs_2_type[fs] == "ext4":
            ext4_cnt += 1
            if word_in_list_sep("nodealloc", fs_2_opts[fs], ",", False, False):
                ext4_nodealloc_cnt += 1

        if fs_2_type[fs] == "xfs":
            if word_in_list_sep("discard", fs_2_opts[fs], ",", False, False):
                xfs_discard_cnt += 1

        if 'nfs' not in fs_2_type[fs] and word_in_list_sep("_netdev", fs_2_opts[fs], ",", False, False):
            netdev_fs_cnt += 1
            if netfs_status != "on":
                anomaly_line = "Filesystem {0} mounted on {1} has the _netdev option specified but the netfs service is not configured 'on' [{2}]".\
                    format(fs, fs_2_mountpoint[fs], netfs_status)
                handle_anomaly_with_points("FS", anomaly_line, 'configuration', 1)

        if fs_2_mountpoint[fs] == "/var":
            var_count += 1
            if var_count == 1:  # can be more than one
                if lld.startswith("/var/"):
                    check_lvm_version(fs, lld)
                    # anomaly_line="LVM locking_dir is {0} and /var is a standalone filesystem mounted on device {1}, see BZ {2}".\
                    # format(lld,fs,bz_url("1337977"))
                    # handle_anomaly_with_points("BZ",anomaly_line,'configuration',1)
            debug_print(4, "/var is a standalone filesystem mounted on device {0}".format(fs))

        if fs.startswith("/dev/sd"):
            check_for_multiple_luns(fs)

        if local_fs(fs, ''):

            rc = check_fs_size(fs)
            if rc > 0:
                pass  # filesize available
            elif rc == 0:
                fs_without_size = unique_list(fs_without_size, fs)  # fs_no_size+=1
            else:
                pass  # fs_no_size_allowed+=1
            # debug_print(0,"{0}:'{1}'".format(fs,fs_2_type[fs])) # REMOVE
            if not check_fs_dev(fs, fs_2_type[fs]):
                fs_without_device = unique_list(fs_without_device, fs)  # fs_no_fs_dev+=1
        # end: if local_fs(fs,''):

    # end: for fs in words:

    if fs_full_anom_lines != '':
        tmp = fs_full_anom_lines.split("\n")
        lc = len(tmp)
        if lc > 5:
            anomaly_line = "Caution: {0} filesystems are close to being 100% full".format(lc)
            handle_anomaly("FS", anomaly_line)
        else:
            for anomaly_line in tmp:
                handle_anomaly("FS", anomaly_line)

    tmp = fs_without_size.split()
    wc = len(tmp)
    if wc > 0:
        if wc > 5:
            anomaly_line = "Unable to determine filesystem size for {0} filesystems".format(wc)
            handle_anomaly("FS", anomaly_line)
        else:
            for fs in tmp:
                anomaly_line = "Unable to determine filesystem size for {0} mounted on {1}".format(fs_2_mountpoint[fs], fs)
                handle_anomaly("FS", anomaly_line)
            # end: for fs in tmp:
        # end: else:
    # end: if wc > 0:

    tmp = fs_without_device.split()
    wc = len(tmp)
    if wc > 0:
        if wc > 5:
            anomaly_line = "Unable to find filesystem device file for {0} filesystems".format(wc)
            handle_anomaly("FS", anomaly_line)
        else:
            for fs in tmp:
                anomaly_line = "Unable to find filesystem device file {0}".format(fs)
                handle_anomaly("FS", anomaly_line)
            # end: for fs in tmp:
        # end: else:
    # end: if wc > 0:

    tmp = vg_lv_fs_but_no_vgs_list.split()
    wc = len(tmp)
    if wc > 0:
        if wc > 5:
            anomaly_line = "Found {0} instances of apparent vg/lv name in fs data, but no volume groups found - check lvm archive data".format(wc)
            handle_anomaly("FS", anomaly_line)
        else:
            for tmp_word in tmp:
                tmp2 = tmp_word.split('~')
                name = tmp2[0]
                source = tmp2[1]
                anomaly_line = "Apparent vg/lv name [{0}] in fs data, but no volume groups found - check lvm archive data ({1})".\
                               format(name, source)
                handle_anomaly("FS", anomaly_line)
            # end: for tmp_word in tmp:
    # end: if wc > 0:

    if gfs_cnt:
        # TODO: add code when looking at ps_auxwww for "infomatica" if found add additional kcsref for 69415
        # see case
        anomaly_line = "Found {0} gfs filesystem{1}, for performance information see {2}".\
            format(gfs_cnt, plural(gfs_cnt), kcs_url("216483"))
        handle_anomaly_with_points("FS", anomaly_line, 'configuration', 1)

    if ext4_cnt > 0 and (ext4_cnt > ext4_nodealloc_cnt):
        # see case
        if ext4_nodealloc_cnt == 0:
            blurb = "none of them have"
        elif ext4_nodealloc_cnt == 1:
            blurb = "only 1 of them has"
        else:
            blurb = "only {0} of them have"
        anomaly_line = "Found {0} ext4 filesystem{1}, but {2} specified the 'nodealloc' option, if ext4 performance is an issue see {3}".\
            format(ext4_cnt, plural(ext4_cnt), blurb, kcs_url("472273"))
        handle_anomaly_with_points("FS", anomaly_line, 'configuration', 1)
    if xfs_discard_cnt > 0:
        anomaly_line = "Found {0} xfs filesystem{1} with the 'discard' option specified, {2}".\
            format(xfs_discard_cnt, plural(xfs_discard_cnt), cfa_sfdc("01983888"))
        handle_anomaly_with_points("XFS", anomaly_line, 'configuration', xfs_discard_cnt * 2)

    return


# ---------------------------------------------#
# function: check_for_multiple_luns()
# ensure that this /dev/scX device does not have
# multiple luns assocatiated via its scsi id
# (if so, the fs should be mounted via /dev/mapper/xxx name)
# ---------------------------------------------#
def check_for_multiple_luns(fs):
    global dev_2_scsi_id
    global scsi_id_2_devs
    global sdc_re
    global fs_2_mountpoint_origin  # Key_data()

    scsi_id_err = False
    dev_id = fs[len("/dev/"):]
    sd_cnt = 0
    sd_list = ''
    tmp_dev_id = ''

    scsi_id = dev_2_scsi_id[dev_id]
    if scsi_id == '':
        return

    dev_list = scsi_id_2_devs[scsi_id]
    if not word_in_list(dev_id, dev_list):
        lc = dev_id[len(dev_id) - 1:]
        if lc.isdigit():
            tmp_dev_id = dev_id[0:len(dev_id) - 1]
            if not word_in_list(tmp_dev_id, dev_list):
                scsi_id_err = True
        else:
            scsi_id_err = True

    if scsi_id_err:
        error_print('l', "dev {0} with scsi id {1} is not in scsi id list '{2}'".format(dev_id, scsi_id, dev_list))
        return

    tmp = dev_list.split()
    for dev in tmp:
        if dev == dev_id:
            continue
        if dev == tmp_dev_id:
            continue
        if re.match(sd_re, dev):
            sd_cnt += 1
            sd_list = unique_list(sd_list, dev)
    # end: for dev in tmp:

    if sd_cnt > 0:
        s = plural(sd_cnt)
        verb = ''                 # 2 devices share
        if s == '':
            verb = 's'   # 1 device shares
        anomaly_line = "FS device {0} is mounted on {1} and has scsi id {2} however {3} device{4} share{5} that scsi id [{6}], see {7}".\
            format(fs, fs_2_mountpoint[fs], scsi_id, sd_cnt, s, verb, sd_list, sfdc_url("01946863"))
        handle_anomaly_with_points("FS", anomaly_line, 'configuration', 10)

    return

# ---------------------------------------------#
# function: check_lvm_version()
# check lvm2 version if rhel 6 and issue LVM / RPM anomalies if appropriate
# ---------------------------------------------#


def check_lvm_version(fs, lld):
    global rh_major  # 0
    global rpm_pkg  # Key_data()                # key: pkg name             data: pkg version

    if rh_major != 6:
        return

    if rpm_pkg["lvm2"] == '':
        return

    rpm_pkg_min['6_lvm2'] = '2.02.143-9'

    # debug_print(z,"'{0}' '{1}'".format(normalize_rpm_version(rpm_pkg["lvm2"]) , normalize_rpm_version(rpm_pkg_min["6_lvm2"])))

    if normalize_rpm_version(rpm_pkg["lvm2"]) < normalize_rpm_version(rpm_pkg_min["6_lvm2"]):
        # TODO: add and lvm service is configed on

        anomaly_line = "LVM locking_dir is {0} and /var is a standalone filesystem mounted on device {1}, see BZ {2}".\
            format(lld, fs, bz_url("1337977"))
        handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 1)

        blurb = "[see LVM]"
        anomaly_line = "RPM package '{0}' is at version {1} which is below the recommended level of {2}, {3} ({4})".\
            format("lvm2", rpm_pkg["lvm2"], rpm_pkg_min["6_lvm2"], blurb, "installed-rpms")
        handle_anomaly("RPM", anomaly_line)

    return

# ---------------------------------------------#
# function: do_scsi_stats()
# ---------------------------------------------#


def do_scsi_stats():
    global scsi_host
    global scsi_bus
    global scsi_target
    global scsi_lun
    global scsi_lun_mfg
    global scsi_lun_mfg_model
    global scsi_lun_io_errs
    global scsi_lun_path_status  # Key_data()   # key: scsi_adr             data: "active"/"passive"
    global lun_2_type  # Key_data()             # key: scsi address,        data: device type;      e.g. 0:0:0:0, sd

    global service_procs  # Key_data()
    global max_host
    global max_bus
    global max_target
    global lo_lun
    global max_lun

    global max_mfg
    global max_model

    global total_hosts
    global total_buses
    global total_targets
    global total_luns
    global total_iscsi_luns
    global total_io_errors
    global total_path_errors
    global total_detaches
    global total_reservation_conflicts
    global reservation_conflicts  # Key_data()
    #
    global high_host_io_error_count  # 0
    global high_host_io_error_host  # ''
    global high_host_path_error_count  # 0
    global high_host_path_error_host  # ''
    #
    global high_lun_io_error_count  # 0
    global high_lun_io_error_lun  # ''
    global high_lun_path_error_count  # 0
    global high_lun_path_error_lun  # ''
    #
    global high_lun_detach_count  # 0
    global high_lun_detach_lun  # ''
    global high_lun_sd_rc_count  # 0
    global high_lun_sd_rc_lun   # ''
    global high_lun_st_rc_count  # 0
    global high_lun_st_rc_lun   # ''
    global high_lun_mi_rc_count  # 0
    global high_lun_mi_rc_lun   # ''
    global dm_re
    global scsi_mod_parameters  # Key_data()    # key: parm name        data: parm value   e.g. max_luns, 1024
    global scsi_luns_w_rsrv_conflicts_rev_level_2  # ''
    global total_illegal_requests  # 0

    max_mfg = 0
    max_model = 0
    sr_dev_type_error_count = 0
    total_iscsi_luns = 0
    total_iscsi_hosts = 0
    total_fcoe_luns = 0
    total_fcoe_hosts = 0

    total_lunz_devs_with_io_errors = 0
    total_lunz_dev_io_errors = 0
    # total_msft_vd_devs_with_io_errors = 0
    # total_msft_vd_dev_io_errors = 0
    total_passive_devices_with_io_errors = 0
    total_passive_io_errors = 0

    for host in range(0, max_host + 1):
        iscsi_host = False
        fcoe_host = False
        scsi_adr = "{0}".format(host)

        host_desc = get_host_desc(scsi_adr)
        if host_desc == "":
            continue

        total_hosts += 1
        if word_in_list("iscsi", host_desc.lower()):
            iscsi_host = True
        if word_in_list("fcoe", host_desc.lower()):
            fcoe_host = True
        if word_in_list("(fcoe)", host_desc.lower()):
            fcoe_host = True
        host_luns = 0

        hba_mfg = get_hba_mfg(host_desc)
        # debug_print(3,"mfg({0}) desc='{1}'".format(hba_mfg,host_desc))
        if hba_mfg != '':
            mfg_hba_count[hba_mfg] += 1

        for bus in range(0, max_bus + 1):
            scsi_adr = "{0}:{1}".format(host, bus)
            if scsi_bus[scsi_adr] == "":
                continue
            total_buses += 1

            for target in range(0, max_target + 1):
                scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
                if scsi_target[scsi_adr] == "":
                    continue
                total_targets += 1

                for lun in range(lo_lun, max_lun + 1):
                    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
                    if scsi_lun[scsi_adr] == "":
                        continue

                    total_luns += 1
                    host_luns += 1

                    # device detaches can cause the max to be different than actual
                    max_mfg = max(max_mfg, len(scsi_lun_mfg[scsi_adr]))
                    max_model = max(max_model, len(scsi_lun_mfg_model[scsi_adr]))

                    if scsi_lun_reservation_conflicts[scsi_adr] > 0 and scsi_lun_rev_level[scsi_adr] == "2":
                        scsi_luns_w_rsrv_conflicts_rev_level_2 = unique_list(scsi_luns_w_rsrv_conflicts_rev_level_2, scsi_adr)

                    # count the various types of scsi devices that have been found
                    if lun_2_type[scsi_adr] != "":
                        scsi_dev_type_count[lun_2_type[scsi_adr]] += 1
                    io_errors = scsi_lun_io_errs[scsi_adr]

                    if io_errors:

                        if scsi_lun_path_status[scsi_adr] == "passive":
                            dev_id = lun_2_dev[scsi_adr]
                            # in certain cases we end up with lots of these anomalies. changed to issue summary
                            # anomaly and label passive luns in the scsi map.
                            # anomaly_line = "{0} [{1}] had {2} io error{3} but its path status is {4}, {5}".\
                            # format(scsi_adr,dev_id,io_errors,plural(io_errors),scsi_lun_path_status[scsi_adr],cfa_kcs("18746"))
                            # handle_anomaly_with_points("SCSI",anomaly_line,'hardware',1)
                            total_passive_devices_with_io_errors += 1
                            total_passive_io_errors += io_errors

                        if lun_2_type[scsi_adr] == "sr" and lvm_filter_accepts_all():
                            sr_dev_type_error_count += 1

                        if scsi_lun_mfg_model[scsi_adr].startswith("LUNZ") and word_in_list(scsi_lun_mfg[scsi_adr], "DGC EMC"):
                            total_lunz_devs_with_io_errors += 1
                            total_lunz_dev_io_errors += io_errors

                    # end: if io_errors:

                # end: for lun in range(lo_lun,max_lun+1):

            # end: for target in range(0,max_target+1):

        # end: for bus in range(0,max_bus+1):

        if iscsi_host and host_luns:
            total_iscsi_luns += host_luns
            total_iscsi_hosts += 1

        # debug_print(z,"host[{0}] host_luns[{1}]".format(host,host_luns))
        if fcoe_host and host_luns:
            total_fcoe_luns += host_luns
            total_fcoe_hosts += 1

    # end: for host in range(0,max_host+1):  # --------------------------------------------

    if total_passive_devices_with_io_errors > 0:
        anomaly_line = "Found {0} passive lun{1} which had {2} io error{3}, {4}".\
            format(total_passive_devices_with_io_errors, plural(total_passive_devices_with_io_errors),
                   total_passive_io_errors, plural(total_passive_io_errors),
                   cfa_kcs("18746"))
        handle_anomaly_with_points("SCSI", anomaly_line, 'hardware', total_passive_devices_with_io_errors)

    if total_illegal_requests > 0 and Virtual_guest and Virtual_type == "HyperV":
        anomaly_line = "Found {0} Illegal scsi request{1} in a {2} VM, {3}".\
            format(total_illegal_requests, plural(total_illegal_requests),
                   Virtual_type, cfa_sfdc("01360293"))
        handle_anomaly("SD", anomaly_line)

    if total_lunz_devs_with_io_errors > 0:
        anomaly_line = "Found {0} LUNZ device{1} with {2} io error{3}, {4}".\
            format(total_lunz_devs_with_io_errors, plural(total_lunz_devs_with_io_errors),
                   total_lunz_dev_io_errors, plural(total_lunz_dev_io_errors), cfa_kcs("24527"))
        handle_anomaly("SD", anomaly_line)

    if total_fcoe_luns > 0:
        anomaly_line = "Found {0} fcoe device{1} on {2} fcoe host{3}, for LVM errors {4} & {5}".\
            format(total_fcoe_luns, plural(total_fcoe_luns), total_fcoe_hosts, plural(total_fcoe_hosts), cfa_kcs("2042963"), kcs_url("433803"))
        handle_anomaly("FCOE", anomaly_line)

        anomaly_line = "Found {0} fcoe device{1} on {2} fcoe host{3}, general FCoE {4}".\
            format(total_fcoe_luns, plural(total_fcoe_luns), total_fcoe_hosts, plural(total_fcoe_hosts), info_kca("2144731"))
        handle_anomaly("FCOE", anomaly_line)

    if total_iscsi_luns > 0 and service_procs["iscsid"] == 0:
        anomaly_line = "Found {0} iscsi device{1} on {2} host{3} but no iscsid processes running".\
            format(total_iscsi_luns, plural(total_iscsi_luns), total_iscsi_hosts, plural(total_iscsi_hosts))
        handle_anomaly_with_points("ISCSI", anomaly_line, 'configuration', 1)

    if total_iscsi_hosts > 0 or service_procs["iscsid"] > 0:
        check_iscsi_settings()

    if sr_dev_type_error_count > 0:
        blurb = high_lun_blurb(high_lun_io_error_lun, high_lun_io_error_count, high_host_io_error_host, high_host_io_error_count)
        anomaly_line = "Encountered {0} sr device{1} with io errors and the lvm filter accepts all devices, consider adjusting.".\
                       format(sr_dev_type_error_count, plural(sr_dev_type_error_count))
        handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 100)

    if total_io_errors > 0:
        blurb = high_lun_blurb(high_lun_io_error_lun, high_lun_io_error_count, high_host_io_error_host, high_host_io_error_count)
        anomaly_line = "Encountered {0} total io error{1}. {2}".\
                       format(total_io_errors, plural(total_io_errors), blurb)
        handle_anomaly_with_points("IOERR", anomaly_line, 'hardware', (total_io_errors * 2))

    if total_path_errors > 0:
        blurb = high_lun_blurb(high_lun_path_error_lun, high_lun_path_error_count, high_host_path_error_host, high_host_path_error_count)
        anomaly_line = "Encountered {0} total path error{1}. {2}".\
                       format(total_path_errors, plural(total_path_errors), blurb)
        handle_anomaly("MULTIPATH", anomaly_line)

    if total_timeouts > 0:
        blurb = high_lun_blurb(high_lun_timeout_lun, high_lun_timeout_count, high_host_timeout_host, high_host_timeout_count)
        anomaly_line = "Encountered {0} total scsi timeout{1}. {2}".\
                       format(total_timeouts, plural(total_timeouts), blurb)
        handle_anomaly("SCSI", anomaly_line)

    if total_dm_io_errors > 0:
        high_err_dm_mm = "{0}:{1}".format(get_device_mapper_major(), high_dm_io_error_dev.replace("dm-", ''))
        dm_dev_ids = dm_2_devs[high_err_dm_mm]
        # dm_dev_ids = dm_2_devs[high_dm_io_error_dev]
        if dm_dev_ids != '':
            dm_dev_ids = "[" + dm_dev_ids + "]"
        blurb = "High device {0} count {1} {2}".format(high_dm_io_error_dev, high_dm_io_error_count, dm_dev_ids, '', '')
        anomaly_line = "Encountered {0} total dm io error{1}. {2}".\
                       format(total_dm_io_errors, plural(total_dm_io_errors), blurb)
        handle_anomaly("MULTIPATH", anomaly_line)

    # end: if total_dm_io_errors > 0:

    if total_reservation_conflicts > 0:

        kcs_info_blurb = ", {0} & {1} & {2}".format(info_kcs("40655"), kcs_url("43402"), kcs_url("20119"))
        rc_st = reservation_conflicts["st"]
        if rc_st > 0:
            blurb = high_lun_blurb(high_lun_st_rc_lun, high_lun_st_rc_count, '', '')
            anomaly_line = "Encountered {0} st reservation conflict{1}. Often caused by 3rd party software. {2}{3}".\
                           format(rc_st, plural(rc_st), blurb, kcs_info_blurb)
            handle_anomaly_with_points("RSRV", anomaly_line, 'configuration', (rc_st / 2) + 1)
            st_rsrv_3()  # issue any additional RSRV st reserve conflict anoms that are apropos

        rc_sd = reservation_conflicts["sd"]
        if rc_sd > 0:
            blurb = high_lun_blurb(high_lun_sd_rc_lun, high_lun_sd_rc_count, '', '')
            anomaly_line = "Encountered {0} sd reservation conflict{1}. Usually caused by 3rd party software. {2}{3}".\
                           format(rc_sd, plural(rc_sd), blurb, kcs_info_blurb)
            handle_anomaly_with_points("RSRV", anomaly_line, 'configuration', (rc_sd / 2) + 1)
            sd_rsrv_2()  # issue any additional RSRV sd reserve conflict anoms that are apropos
        misc_reservation_conflicts = total_reservation_conflicts - (rc_st + rc_sd)
        if misc_reservation_conflicts > 0:  # (unlikely)
            blurb = high_lun_blurb(high_lun_mi_rc_lun, high_lun_mi_rc_count, '', '')
            misc_dt = lun_2_type[high_lun_mi_rc_lun]
            if misc_dt == '':
                misc_dt = "non-st/sd"
            if misc_dt == "ch":
                st_rsrv_3()  # issue any additional RSRV st reserve conflict anoms that are apropos
                anom_points = (misc_reservation_conflicts / 2) + 1
            else:
                anom_points = 0
            anomaly_line = "Encountered {0} {1} reservation conflict{2}. Often caused by 3rd party software. {3}{4}".\
                           format(misc_reservation_conflicts, misc_dt, plural(misc_reservation_conflicts), blurb, kcs_info_blurb)
            handle_anomaly_with_points("RSRV", anomaly_line, 'configuration', anom_points)

    # end: if total_reservation_conflicts > 0:

    if total_detaches > 0:
        blurb = high_lun_blurb(high_lun_detach_lun, high_lun_detach_count, '', '')
        anomaly_line = "Encountered {0} total device detache{1}. {2}".\
                       format(total_detaches, plural(total_detaches), blurb)
        handle_anomaly("DETACH", anomaly_line)
    # end: if total_detaches > 0:

    if scsi_mod_parameters["max_luns"] != '':
        max_luns = scsi_mod_parameters["max_luns"]
        if max_luns.isdigit():
            max_luns = int(max_luns)
            if total_luns > max_luns:
                anomaly_line = "Found {0} total luns but max_luns is set to {1}, some luns may not be recognized, max_luns and/or max_report_luns may need to be increased, {2}".\
                               format(total_luns, max_luns, info_kcs("3292"))
                handle_anomaly("SCSI", anomaly_line)
            else:
                pct_of_max = (100 * total_luns) / max_luns
                if pct_of_max > 90:
                    anomaly_line = "Found {0} total luns and max_luns is set to {1}, which exceeds 90% [{2}], max_luns and/or max_report_luns may need to be increased if new devices are added, {3}".\
                                   format(total_luns, max_luns, pct_of_max, info_kcs("3292"))
                    handle_anomaly("SCSI", anomaly_line)
    # end: if scsi_mod_parameters["max_luns"] != '':

    return


# ---------------------------------------------#
# function: check_iscsi_settings()
# ---------------------------------------------#
def check_iscsi_settings():
    global iscsidConf_data  # Key_data()

    # iscis parm name  op_code  recommended value
    iscsi_parm_list = ""\
                      "node.session.timeo.replacement_timeout LE 5~"\
                      "node.conn[0].timeo.noop_out_timeout LE 5~"\
                      "node.conn[0].timeo.noop_out_interval LE 5~"\
                      ""

    fn = "etc/iscsi/iscsid.conf"
    if not file_exists_with_data(fn):
        return

    tmp = iscsi_parm_list.split("~")
    for tmp1 in tmp:

        if tmp1 == '' or tmp1.startswith("#"):
            continue

        gen_anom = False
        tmp2 = tmp1.split()

        iscsi_parm = tmp2[0]
        op_code = tmp2[1]
        iscsi_recommended_value = tmp2[2]

        iscsi_current_value = iscsidConf_data[iscsi_parm]

        if iscsi_current_value == '':
            anomaly_line = "{0} is not set, the recommended value is {1} (etc/iscsi/iscsid.conf), see {2}".\
                           format(iscsi_parm, iscsi_recommended_value, kcs_url("1171203"))
            handle_anomaly("ISCSI", anomaly_line)
            continue

        if word_in_list(op_code, "LE GE") and not iscsi_current_value.isdigit():
            anomaly_line = "{0} is not numeric [{1}], the recommended value is {2} (etc/iscsi/iscsid.conf), see {3}".\
                           format(iscsi_parm, iscsi_current_value, iscsi_recommended_value, kcs_url("1171203"))
            handle_anomaly("ISCSI", anomaly_line)
            continue

        err_blurb = "not {0} than".format(op_code)
        gen_anom = True  # assume an anomaly will be generated

        if op_code == "LE":
            # debug_print(z,"{0} {1} {2}".format(iscsi_current_value,op_code,iscsi_recommended_value))
            if int(iscsi_current_value) <= int(iscsi_recommended_value):
                gen_anom = False  # good value
        elif op_code == "GE":
            if int(iscsi_current_value) >= int(iscsi_recommended_value):
                gen_anom = False  # good value
        elif op_code == "EQ":
            if iscsi_current_value == iscsi_recommended_value:
                gen_anom = False
            err_blurb = "not EQ to"
        else:
            error_print("l", "error in iscsi_parm_list, opcode missing or invalid {0}".format(op_code))

        if gen_anom:
            anomaly_line = "{0} set to {1} which is {2} the recommended value of {3} ({4}), see {5}".\
                           format(iscsi_parm, iscsi_current_value, err_blurb, iscsi_recommended_value, fn, kcs_url("1171203"))
            handle_anomaly("ISCSI", anomaly_line)

    # end: for tmp1 in tmp:

    return


# ---------------------------------------------#
# function: high_lun_blurb()
# ---------------------------------------------#
def high_lun_blurb(high_lun, high_lun_count, high_host, high_host_count):
    global lun_2_dev
    high_dev = lun_2_dev[high_lun]
    if high_host != '':
        blurb = "High host {0}: count {1}, High LUN {2} [{3}] count {4}".\
                format(high_host, high_host_count, high_lun, high_dev, high_lun_count)
    else:
        blurb = "High LUN {0} [{1}] count {2}".\
                format(high_lun, high_dev, high_lun_count)
    return blurb


# ---------------------------------------------#
# function: st_rsrv_3()
# ---------------------------------------------#
def st_rsrv_3():
    global LIN_TAPED

    third_party_tape_apps = "amidxtape dsmrecall dsmrecalld " + LIN_TAPED + " ltfs nbcssc netbackup omni uma "
    st_sd_rsrv_3(third_party_tape_apps, "st")

    return

# ---------------------------------------------#
# function: st_sd_rsrv_3()
# ---------------------------------------------#


def st_sd_rsrv_3(apps, sd_st):
    global config_service  # Key_data() # "on/off/''"
    global service_procs  # Counter()

    tmpapps = apps.split()

    tmp_list = ''
    for tmpapp in tmpapps:
        if config_service[tmpapp] != "":  # <<<---- loop thru installed services
            tmp_list = unique_list(tmp_list, tmpapp)

    tmp = tmp_list.split()
    tmp_app_count = len(tmp)
    if tmp_app_count:
        anomaly_line = "found {0} installed service{1} that can reserve {2} devices: {3}, {4} and {5}".\
                       format(tmp_app_count, plural(tmp_app_count), sd_st, tmp_list, info_kcs("55885"), kcs_url("43402"))
        handle_anomaly("RSRV", anomaly_line)

    tmp_list = ''
    for tmpapp in tmpapps:
        if service_procs[tmpapp] > 0:  # <<<---- loop thru running procs
            tmp_list = unique_list(tmp_list, tmpapp)

    tmp = tmp_list.split()
    tmp_app_count = len(tmp)
    if tmp_app_count:
        anomaly_line = "found {0} running process{1} that can reserve {2} devices: {3}, {4}".\
                       format(tmp_app_count, plurale(tmp_app_count), sd_st, tmp_list, info_kcs("55885"), kcs_url("43402"))
        handle_anomaly("RSRV", anomaly_line)

    return

# ---------------------------------------------#
# function: sd_rsrv_2()
# ---------------------------------------------#


def sd_rsrv_2():
    global all_dev_mfgs
    global config_service  # Key_data() # "on/off/''"
    global all_fs_types  # ""
    global service_procs  # Counter()
    global Virtual_guest, Virtual_type
    global all_scsi_err_codes  # ""
    global service_procs  # Counter()
    global rpm_pkg  # Key_data()
    global scsi_luns_w_rsrv_conflicts_rev_level_2  # ''

    ulcnt = word_count(scsi_luns_w_rsrv_conflicts_rev_level_2)
    if ulcnt > 0:
        if ulcnt < 10:
            blurb = "[{0}] ".format(scsi_luns_w_rsrv_conflicts_rev_level_2)
        else:
            blurb = ''
        anomaly_line = "Found {0} unique scsi rev level 2 lun{1} {2}with reservation conflicts, scsi rev level 2 allows only reserve primitives, {3}".\
                       format(ulcnt, plural(ulcnt), blurb, cfa_sfdc('02020400'))
        handle_anomaly("RSRV", anomaly_line)

    if word_in_list('HP', all_dev_mfgs) or word_in_list('HITACHI', all_dev_mfgs):
        anomaly_line = "sd reservation conflicts can occur with HP/HITACHI OPEN-V SAN devices depending on TUR multipath settings, {0}".\
                       format(cfa_kcs('2686631'))
        handle_anomaly("RSRV", anomaly_line)

    if word_in_list('EMC', all_dev_mfgs) or word_in_list('DGC', all_dev_mfgs):
        anomaly_line = "sd reservation conflicts can be caused by non-blacklisted EMC gatekeeper devices, {0}".\
                       format(cfa_kcs('357753'))
        handle_anomaly("RSRV", anomaly_line)

    if config_service["vcs"] == "on" or service_procs["CVMClusterAgent"] > 0:
        anomaly_line = "sd reservation conflicts can be caused by VCS configuration issues, {0}".\
                       format(cfa_kcs('738223'))
        handle_anomaly("RSRV", anomaly_line)

    if word_in_list("gfs", all_fs_types) or word_in_list("gfs2", all_fs_types) or service_procs["fenced"] > 0:
        anomaly_line = "sd reservation conflicts can occur in a clustered gfs environment, {0}".\
                       format(cfa_kcs('304023'))
        handle_anomaly("RSRV", anomaly_line)

    if file_exists_with_data("./etc/cluster/cluster.conf"):
        anomaly_line = "sd reservation conflicts can occur in a clustered environment, see etc/cluster/cluster.conf and {0}".\
                       format(cfa_kcs('316073'))
        handle_anomaly("RSRV", anomaly_line)

    # TODO: how do we determine this
    if rpm_pkg["tuned-profiles-sap-hana"] != '':
        anomaly_line = "sd reservation conflicts can occur in a sap/hana clustered environment, please contact vendor"
        handle_anomaly("RSRV", anomaly_line)

    if word_in_list('NETAPP', all_dev_mfgs):
        anomaly_line = "sd reservation conflicts can occur in a NETAPP env. using alua, {0}".\
                       format(cfa_kcs('539553'))
        handle_anomaly("RSRV", anomaly_line)

    if Virtual_guest and Virtual_type == "VMware":
        if service_procs["clvmd"] > 0:
            # had used cfa_kcs('338173') but this is retired now
            anomaly_line = "sd reservation conflicts can occur in a clustered {0} env., {1} & {2}".\
                           format(Virtual_type, cfa_kcs('3131271'), kcs_url("158873"))
            handle_anomaly("RSRV", anomaly_line)
        else:
            anomaly_line = "sd reservation conflicts can occur in a shared disk {0} env., {1} & {2}".\
                           format(Virtual_type, cfa_kcs('3131271'), kcs_url("158873"))
            handle_anomaly("RSRV", anomaly_line)

    scsi_err = "0x00110018"
    if word_in_list(scsi_err, all_scsi_err_codes) and Virtual_guest and Virtual_type == "VMware":
        anomaly_line = "sd reservation conflicts can occur in a {0} env. when scsi error '{1}' is present, {1}".\
                       format(Virtual_type, scsi_err, cfa_kcs('134653'))
        handle_anomaly("RSRV", anomaly_line)

    third_party_backup_apps = "bpbkar bpbkarv nbcssc netbackup "
    st_sd_rsrv_3(third_party_backup_apps, "sd")

    return

# ---------------------------------------------#
# function: check_offlined_msg():
# call for each occurence of:
# kernel: (sd|st|ch) 0:0:0:0: Device offlined - not ready after error recovery
# kernel: (sd|st|ch) 0:0:0:0: scsi: Device offlined - not ready after error recovery
# ---------------------------------------------#


def check_offlined_msg(line, source):
    global lun_2_type

    # debug_print(z,line)
    words = line.split()
    dev_type = words[1]
    scsi_adr = words[2].rstrip(":")

    offlined_ha_bus_tgt_lun(scsi_adr)

    return
    # if dev_type == "scsi":
    # dt = lun_2_type[scsi_adr]
    # else: dt = ''
    # debug_print(z,dt)
    # tmp = scsi_adr.split(':')
    # host_desc = get_host_desc(tmp[0])
    # debug_print(z,host_desc)
    # if   "Emulex"  in host_desc: cfa = cfa_kcs("356243")  # aka lpfc
    # elif "qla2xxx" in host_desc: cfa = cfa_kcs("45099")
    # elif "hpsa"    in host_desc: cfa = cfa_kcs("2854741")
    # elif word_in_list(dev_type,"sd st") or word_in_list(dt,"sd st"): cfa = cfa_kcs("60605")
    # else: cfa = "check with vendor of hba {0}".format(tmp[0])

    # if dt != '': cfa = '({0}) {1}'.format(dt,cfa)
    # return(cfa)

# ---------------------------------------------#
# function: check_not_added_msg():
# call for each occurence of:
# kernel: scsi: 0:0:0:0: scsi scan: peripheral qualifier of n, device not added
# ---------------------------------------------#


def check_not_added_msg(line, source):
    global lun_2_type

    # debug_print(z,line)
    words = line.split()
    dev_type = words[1]
    scsi_adr = words[2].rstrip(":")

    not_added_ha_bus_tgt_lun(scsi_adr)

    return


# ---------------------------------------------#
# function: check_write_protected_msg():
# call for each occurence of:
# kernel: sd 0:0:0:0: [sdcc] Write Protect is on
# kernel: sd 0:0:0:0: [sdcc] Write Protect is off
# ---------------------------------------------#
def check_write_protected_msg(line, source):
    global lun_2_type

    # debug_print(z,line)
    words = line.split()
    wc = len(words)
    dev_type = words[1]
    scsi_adr = words[2].rstrip(":")
    dev = words[3].strip("[]")

    on_off = words[wc - 1]  # last word
    if on_off == "on":
        bump = 1
    elif on_off == "off":
        bump = -1
    else:
        error_print('d', "'{0}' not on or off ({1})".format(line, source))
        return

    write_protected_ha_bus_tgt_lun(scsi_adr, bump)

    return


# ---------------------------------------------#
# function: track_hba()
# ---------------------------------------------#
def track_hba(scsi_host_number, desc, source):
    global scsi_host
    global max_host
    global all_hba_mfgs

    debug_print(3, "{0} '{1}'".format(scsi_host_number, desc))
    scsi_adr = "{0}".format(scsi_host_number)
    scsi_host_desc_prefix = "host{0}:".format(scsi_host_number)

    if scsi_host[scsi_adr] == '':
        scsi_host[scsi_adr] = scsi_host_desc_prefix

    desc = desc.strip()

    if desc != '':
        if scsi_host[scsi_adr] == scsi_host_desc_prefix:
            scsi_host[scsi_adr] = "{0} {1}".format(scsi_host_desc_prefix, desc).strip()
        else:
            if desc not in scsi_host[scsi_adr]:
                scsi_host[scsi_adr] = "{0}, {1}".format(scsi_host[scsi_adr], desc)

    max_host = max(max_host, int(scsi_host_number))

    scsi_host_pci_desc = get_host_desc(scsi_host_number)

    if scsi_host_pci_desc == scsi_host_desc_prefix:  # i.e. null
        hba_mfg = ''
    else:
        hba_mfg = get_hba_mfg(scsi_host_pci_desc)

    if hba_mfg == "HP" and "cciss" in scsi_host_pci_desc:
        track_cciss_devs(scsi_host_number, '', source)

    if hba_mfg != '':
        all_hba_mfgs = unique_list(all_hba_mfgs, hba_mfg)
    debug_print(3, "{0} {1} {2} ({3})".format(scsi_host_number, scsi_host_pci_desc, all_hba_mfgs, source))

    return
# ---------------------------------------------#
# function: get_hba_mfg()
# ---------------------------------------------#


def get_hba_mfg(host_desc):

    if "QLogic" in host_desc or "qla2xxx" in host_desc or "qla4xx" in host_desc:
        return("QLogic")
    elif "Emulex" in host_desc or "lpfc" in host_desc or "be2iscsi" in host_desc:  # be2iscsi(ServerEngines) bought by Emulex
        return("Emulex")
    elif "Hewlett-Packard" in host_desc or "hpsa" in host_desc or "cciss" in host_desc:
        return("HP")
    # LSI/Avago/Broadcom are now the same company, see: https://en.wikipedia.org/wiki/Broadcom_Limited
    elif "LSI" in host_desc or "MegaRaid" in host_desc or "Fusion" in host_desc or "MPT" in host_desc:
        return("LSI")
    elif "VMware" in host_desc:
        return("VMware")
    elif "Intel" in host_desc:
        return("Intel")
    elif "Advanced Micro Devices" in host_desc or "AMD" in host_desc:
        return("AMD")
    elif "Cisco" in host_desc:
        return("Cisco")
    elif "Adaptec" in host_desc or "aacraid" in host_desc:
        return("Adaptec")
    elif "Avago" in host_desc:
        return("Avago")
    elif "Broadcom" in host_desc or "pata_serverworks" in host_desc:
        return("Broadcom")
    elif "Brocade" in host_desc:
        return("Brocade")
    elif "IBM" in host_desc:
        return("IBM")
    elif "Chelsio" in host_desc or "cxgb4" in host_desc or "cxgb3" in host_desc:
        return("Chelsio")
    # elif "NetApp" in host_desc or "fnic" in host_desc or "enic" in host_desc: # was getting false positives for Cisco fnic
    elif "NetApp" in host_desc:
        return("NetApp")
    elif "Silicon Image" in host_desc or 'pata_sil680' in host_desc:
        return("Lattice")
    return ''

# ---------------------------------------------#
# function: display_s390_devs()
# ---------------------------------------------#


def display_s390_devs():
    global cuuu_2_class  # Key_data()
    global cuuu_2_type  # Key_data()
    global cuuu_2_status  # Key_data()
    global cuuu_2_vol1  # Key_data()
    global class_2_cuuus  # Key_data()
    global type_2_cuuus  # Key_data()
    global max_hlq1  # 0
    global max_hlq2  # 0
    global high_cuuu  # 0
    global low_cuuu  # big_num
    global s390_device_count  # 0
    global dasd_2_parts  # Key_data()
    global dev_2_parts  # Key_data()

    errorprint("")
    errorprint("s390 devices")
    errorprint("")

    hdr_written = False
    for cuuu in range(low_cuuu, high_cuuu + 1):
        xcuuu = "{0}".format(hex(cuuu))
        xcuuu = xcuuu[2:]
        xcuuu = xcuuu.rjust(4, "0")
        cuuu_disp = "{0}.{1}.{2}".format(max_hlq1, max_hlq2, xcuuu)
        # if cuuu_2_class[xcuuu] == '':
        # continue
        status = cuuu_2_status[xcuuu]
        s390_class = cuuu_2_class[xcuuu]
        s390_type = cuuu_2_type[xcuuu]

        if word_in_list(s390_class, "dasd fba"):
            dasdid = cuuu_2_dasd[xcuuu]
            mm = bd_2_mm[dasdid]
            vol1 = cuuu_2_vol1[xcuuu]
        else:
            dasdid = ''
            mm = ''
            vol1 = ''

        if status == '' and s390_class == '' and s390_type == '':
            continue

        if not hdr_written:
            errorprint("{0} {1} {2} {3} {4} {5} {6}".
                       format('cuuu'.rjust(8),
                              'status'.ljust(10),
                              'dev class'.ljust(9),
                              'dev type'.ljust(9),
                              'maj:min'.ljust(8),
                              'dasdid'.ljust(8),
                              'vol1'.ljust(8)))
            hdr_written = True

        errorprint("{0} {1} {2} {3} {4} {5} {6}".
                   format(cuuu_disp.ljust(8),
                          status.ljust(10),
                          s390_class.ljust(9),
                          s390_type.ljust(9),
                          mm.ljust(8),
                          dasdid.ljust(8),
                          vol1.ljust(8)))

        partitions = dev_2_parts[dasdid] + " " + dasd_2_parts[dasdid]
        partitions = sort_list(dedup_list(squeeze(partitions)))
        if partitions != '':
            parts = partitions.split()
            for part in parts:
                part_cuuu = ''  # same as parent
                part_status = ''
                part_class = ''
                part_type = ''
                part_mm = bd_2_mm[part]
                errorprint("{0} {1} {2} {3} {4} {5}".
                           format(part_cuuu.ljust(8),
                                  part_status.ljust(10),
                                  part_class.ljust(9),
                                  part_type.ljust(9),
                                  part_mm.ljust(8),
                                  part.ljust(8)))

    errorprint("")
    errorprint("s390 device count: {0}".format(s390_device_count))
    errorprint("")
    errorprint("end s390 device display")
    errorprint("")
    debug_print(1, "complete")
    return


# =============================================#
# function display_pci_map()
# display pci imap from global data
# =============================================#
def display_pci_map():
    global sw_pci
    global sw_pci_level
    global all_pci_addresses  # ""
    global pci_errors  # Counter()

    if all_pci_addresses == '':
        return

    all_pci_addresses = sort_list(all_pci_addresses)
    tmp = all_pci_addresses.split()

    errorprint("")
    errorprint("pci bus map:")
    errorprint("")

    # debug_print(z,"{0} {1}".format(sw_pci,sw_pci_level))

    for pci_adr in tmp:

        scsi_host = pci_address_2_host(pci_adr)
        if scsi_host == '':
            scsi_blurb = ""
        else:
            scsi_blurb = "scsi host {0}".format(scsi_host.rjust(3))

        pci_errs = pci_errors[pci_adr]
        # debug_print(z,"{0} {1}".format(pci_adr,pci_errs))
        if pci_errs > 999999:
            error_print('d', "pci err count > 999999 [{0}] for pci_adr {1}".format(pci_errs, pci_adr))

        if pci_errs == 0:
            err_blurb = ''
        else:
            err_disp = "{0}".format(pci_errs)
            err_blurb = "errors[{0}]".format(err_disp.rjust(5, '0'))

        if sw_pci_level == 0:
            continue

        if (scsi_blurb == '' and err_blurb == '') and sw_pci_level <= 1:
            continue

        errorprint("{0} {1} {2} {3}".format(pci_adr, scsi_blurb.ljust(13), err_blurb.ljust(13), pci_address[pci_adr]))
    # end: for pci_adr in tmp:

    errorprint("")
    errorprint("Total pci buses: {0}".format(len(tmp)))
    errorprint("")
    errorprint("end pci bus map")
    errorprint("")

    return

# =============================================#
# function display_scsi_map()
# display scsi map from global arrays
# =============================================#


def display_scsi_map():
    global sw_sm
    global sw_sm_level
    global scsi_host
    global scsi_bus
    global scsi_target
    global scsi_lun
    global scsi_lun_detail
    global scsi_host_path_errs
    global dev_2_lun
    global dev_2_parts  # Key_data()
    global lun_2_dev
    global lun_2_dev_aliases  # Key_data()      # key: scsi address,        data: device id(s);     e.g. 0:0:0:0, nst120
    global lun_2_sgn
    global lun_2_type
    global total_luns
    global max_host
    global max_bus
    global max_target
    global lo_lun
    global max_lun
    global max_dev_id
    global max_lintape
    global max_dev_sgn
    global max_dm
    global max_mfg
    global max_model
    global max_major
    global max_minor
    global max_label
    global max_scsi_id
    global all_scsi_dev_types
    global scsi_dev_type_count  # Counter()
    global dev_2_label  # Key_data()
    global dev_2_scsi_id  # Key_data()
    global dev_2_parts  # Key_data()
    global dev_2_dms  # Key_data()
    global dev_2_errs  # Counter()

    global dev_2_size  # Counter() # device size in bytes

    global scsi_host_io_errs
    global scsi_bus_io_errs
    global scsi_target_io_errs
    global scsi_lun_io_errs

    global scsi_host_path_errs
    global scsi_bus_path_errs
    global scsi_target_path_errs
    global scsi_lun_path_errs

    global scsi_host_reservation_conflicts
    global scsi_bus_reservation_conflicts
    global scsi_target_reservation_conflicts
    global scsi_lun_reservation_conflicts

    global scsi_host_detaches
    global scsi_bus_detaches
    global scsi_target_detaches
    global scsi_lun_detaches

    global scsi_host_offlined
    global scsi_bus_offlined
    global scsi_target_offlined
    global scsi_lun_offlined

    # global scsi_host_not_added_luns # Key_data()        # key: host number, list of luns devices not added
    global scsi_host_not_added  # Counter()               # as above w/scsi_..._path_errs and scsi_..._io_errs
    global scsi_bus_not_added  # Counter()                # .
    global scsi_target_not_added  # Counter()             # .
    global scsi_lun_not_added  # Counter()                # .
    # global total_not_added # 0

    global scsi_host_write_protected_luns  # Key_data()         # key: host number, list of unique luns with write protect on
    global scsi_host_write_protected  # Counter()               # as above w/scsi_..._path_errs and scsi_..._io_errs
    global scsi_bus_write_protected  # Counter()                # .
    global scsi_target_write_protected  # Counter()             # .
    global scsi_lun_write_protected  # Counter()                # .
    global total_write_protected  # 0

    global scsi_2_lintape  # Key_data()
    global scsi_mod_parameters  # Key_data()    # key: parm name        data: parm value   e.g. max_luns, 1024

    global all_write_cache_disabled_devs  # ''
    global all_read_cache_disabled_devs  # ''

    max_dev = max(max_dev_id, max_dm)
    max_dev = max(max_dev, max_lintape)
    max_mm = len("{0}:{1}".format(max_major, max_minor))  # may be wider than any that are displayed
    flat_display = (sw_sm_level == 3)
    if flat_display:
        len_host = len("{0}".format(max_host))
        len_bus = len("{0}".format(max_bus))
        len_target = len("{0}".format(max_target))
        len_lun = len("{0}".format(max_lun))
        for host in range(0, max_host + 1):  # host loop <====================================================|
            scsi_adr = "{0}".format(host)
            if get_host_desc(scsi_adr) == '':
                continue
            for bus in range(0, max_bus + 1):  # bus loop <===================================================|
                scsi_adr = "{0}:{1}".format(host, bus)
                if scsi_bus[scsi_adr] == "":
                    continue
                for target in range(0, max_target + 1):  # target loop <======================================|
                    scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
                    if scsi_target[scsi_adr] == "":
                        continue
                    for lun in range(lo_lun, max_lun + 1):  # lun loop <======================================|
                        scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
                        if scsi_lun[scsi_adr] == "":
                            continue
                        dev_id = lun_2_dev[scsi_adr]
                        max_dev = max(max_dev, len(dev_id))
                        if is_tape_id(dev_id):
                            tape_id_suffixes = "a l m"
                            tmp = tape_id_suffixes.split()
                            for suffix in tmp:
                                tmp_tape_id = dev_id + suffix
                                p_mm = conv_id_2_mm(tmp_tape_id, "")
                                if p_mm != "":
                                    max_dev = max(max_dev, len(tmp_tape_id))
                        if dev_id != "" and lun_2_dev_aliases[scsi_adr] != "":
                            aliases = lun_2_dev_aliases[scsi_adr].split()
                            for alias in aliases:
                                max_dev = max(max_dev, len(alias))
                        if dev_id != "" and dev_2_parts[dev_id] != "":
                            parts = dev_2_parts[dev_id].split()
                            for part in parts:
                                max_dev = max(max_dev, len(part))
                        if dev_id != "" and dev_2_dms[dev_id] != "":
                            dms = dev_2_dms[dev_id].split()
                            for dm in dms:
                                max_dev = max(max_dev, len(dm))
                                p_mm = conv_id_2_mm(dm, "dm")
                                p_aliases = conv_mm_2_bd_alias_list(p_mm)
                                aliases = p_aliases.split()
                                for alias in aliases:
                                    max_dev = max(max_dev, len(alias))
                                    parts = dev_2_parts[alias].split()
                                    for part in parts:
                                        max_dev = max(max_dev, len(part))
                    # end: for lun in range(lo_lun,max_lun+1): # lun loop <======================================|
                # end: for target in range(0,max_target+1): # target loop <======================================|
            # end: for bus in range(0,max_bus+1): # bus loop <===================================================|
        # end: for host in range(0,max_host+1): # host loop <====================================================|

    errorprint("")
    errorprint("scsi map:")
    errorprint("")

    for host in range(0, max_host + 1):  # host loop <====================================================|
        scsi_adr = "{0}".format(host)
        combined_desc = get_host_desc(scsi_adr)
        if combined_desc == "":
            continue
        host_blurb = fmt_misc('',
                              scsi_host_io_errs[scsi_adr],
                              scsi_host_path_errs[scsi_adr],
                              scsi_host_reservation_conflicts[scsi_adr],
                              scsi_host_detaches[scsi_adr],
                              scsi_host_timeouts[scsi_adr],
                              scsi_host_offlined[scsi_adr],
                              scsi_host_not_added[scsi_adr],
                              scsi_host_write_protected[scsi_adr],
                              False,
                              False)
        if flat_display:
            errorprint("{0} {1}".format(fmt_scsi_adr(host, len_host, -1, len_bus, -1, len_target, -1, len_lun), combined_desc))
        elif sw_sm_level >= 1:
            errorprint("{0} {1}".format(combined_desc, host_blurb))
        for bus in range(0, max_bus + 1):  # bus loop <===================================================|
            scsi_adr = "{0}:{1}".format(host, bus)
            if scsi_bus[scsi_adr] == "":
                continue

            bumper = "    "
            bus_blurb = fmt_misc('',
                                 scsi_bus_io_errs[scsi_adr],
                                 scsi_bus_path_errs[scsi_adr],
                                 scsi_bus_reservation_conflicts[scsi_adr],
                                 scsi_bus_detaches[scsi_adr],
                                 scsi_bus_timeouts[scsi_adr],
                                 scsi_bus_offlined[scsi_adr],
                                 scsi_bus_not_added[scsi_adr],
                                 scsi_bus_write_protected[scsi_adr],
                                 False,
                                 False)
            if sw_sm_level >= 1 and not flat_display:
                errorprint("{0}{1} {2}".format(bumper, scsi_bus[scsi_adr], bus_blurb))
            for target in range(0, max_target + 1):  # target loop <======================================|
                scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
                if scsi_target[scsi_adr] == "":
                    continue

                bumper = "        "
                target_blurb = fmt_misc('',
                                        scsi_target_io_errs[scsi_adr],
                                        scsi_target_path_errs[scsi_adr],
                                        scsi_target_reservation_conflicts[scsi_adr],
                                        scsi_target_detaches[scsi_adr],
                                        scsi_target_timeouts[scsi_adr],
                                        scsi_target_offlined[scsi_adr],
                                        scsi_target_not_added[scsi_adr],
                                        scsi_target_write_protected[scsi_adr],
                                        False,
                                        False)

                lun_count = 0
                low_lun = ""
                low_lun_type = ""
                low_lun_id = ""
                low_lun_sgn = ""
                high_lun = ""
                high_lun_type = ""
                high_lun_id = ""
                high_lun_sgn = ""

                target_line = "{0}{1}".format(bumper, scsi_target[scsi_adr])
                if sw_sm_level >= 2 and not flat_display:
                    errorprint("{0} {1}".format(target_line, target_blurb))
                for lun in range(lo_lun, max_lun + 1):  # lun loop <======================================|
                    scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
                    if scsi_lun[scsi_adr] == "":
                        continue

                    lun_count += 1

                    # count the various types of scsi devices that have been found # # (now done in do_scsi_stats())
                    # if lun_2_type[scsi_adr] != "":
                    # scsi_dev_type_count[lun_2_type[scsi_adr]]+=1

                    if lun_2_type[scsi_adr] == "":  # scsi address found but not type, possible max_luns reached
                        lun_2_type[scsi_adr] = "??"
                        all_scsi_dev_types = unique_list(all_scsi_dev_types, "??")
                        scsi_dev_type_count[lun_2_type[scsi_adr]] += 1

                    if low_lun == "":
                        low_lun = lun
                        low_lun_type = lun_2_type[scsi_adr]
                        low_lun_id = lun_2_dev[scsi_adr]
                        low_lun_sgn = lun_2_sgn[scsi_adr]
                        low_lun_mfg = scsi_lun_mfg[scsi_adr]
                    high_lun = lun
                    high_lun_type = lun_2_type[scsi_adr]
                    high_lun_id = lun_2_dev[scsi_adr]
                    high_lun_sgn = lun_2_sgn[scsi_adr]
                    high_lun_mfg = scsi_lun_mfg[scsi_adr]

                    if sw_sm_level >= 2:
                        bumper = "            "
                        dev_id = lun_2_dev[scsi_adr]
                        lun_or_dev_errs = max(scsi_lun_io_errs[scsi_adr], dev_2_errs[dev_id])

                        wdc_status = word_in_list(dev_id, all_write_cache_disabled_devs)
                        # debug_print(z,"{0} -> '{1}' in'{2}'".format(wdc_status,dev_id,all_write_cache_disabled_devs))
                        rdc_status = word_in_list(dev_id, all_read_cache_disabled_devs)

                        lun_blurb = fmt_misc(scsi_lun_path_status[scsi_adr],
                                             lun_or_dev_errs,
                                             scsi_lun_path_errs[scsi_adr],
                                             scsi_lun_reservation_conflicts[scsi_adr],
                                             scsi_lun_detaches[scsi_adr],
                                             scsi_lun_timeouts[scsi_adr],
                                             scsi_lun_offlined[scsi_adr],
                                             scsi_lun_not_added[scsi_adr],
                                             scsi_lun_write_protected[scsi_adr],
                                             wdc_status,
                                             rdc_status)
                        major_minor = ""
                        major_minor2 = ""
                        label_id_blurb = ""
                        tmp_s_label = ""
                        tmp_s_id = ""
                        if dev_id != "":
                            major_minor = conv_id_2_mm(dev_id, "")
                            if flat_display:
                                tmp_s_label = dev_2_label[dev_id]
                                tmp_s_id = dev_2_scsi_id[dev_id]
                            else:
                                label_id_blurb = "label:'{0}' scsi_id:'{1}'".format(dev_2_label[dev_id], dev_2_scsi_id[dev_id])
                                if label_id_blurb == "label:'' scsi_id:''":
                                    label_id_blurb = ""
                        if major_minor == "":
                            major_minor = "?:?"
                        if lun_2_sgn[scsi_adr] != '':
                            major_minor2 = conv_id_2_mm(lun_2_sgn[scsi_adr], "sg")
                        if major_minor2 == "":
                            major_minor2 = "?:?"
                        # sc_size = dev_2_size[dev_id]
                        # sc_disp_size = mg_disp(sc_size,1024)
                        sc_disp_size = devsize_disp(dev_id)
                        if flat_display:  # flat_display aka -s3
                            errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8} {9}".
                                       format(fmt_scsi_adr(host, len_host, bus, len_bus, target, len_target, lun, len_lun),
                                              lun_2_type[scsi_adr].ljust(5),
                                              dev_id.ljust(max_dev),
                                              major_minor.ljust(max_mm),
                                              sc_disp_size.rjust(8),
                                              scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                              scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                              tmp_s_label.ljust(max_label),
                                              tmp_s_id.ljust(max_scsi_id),
                                              lun_blurb,
                                              ))
                        else:
                            errorprint("{0}{1} - {2}[{3}/{4}] {5}/{6} {7} {8} {9} {10}".
                                       format(bumper,
                                              scsi_lun[scsi_adr],
                                              lun_2_type[scsi_adr],
                                              dev_id,
                                              lun_2_sgn[scsi_adr],
                                              major_minor,
                                              major_minor2,
                                              scsi_lun_mfg[scsi_adr],
                                              scsi_lun_mfg_model[scsi_adr],
                                              label_id_blurb,
                                              lun_blurb))
                        if is_tape_id(dev_id):
                            bumper = "                  "
                            tape_id_suffixes = "a l m"
                            tmp = tape_id_suffixes.split()
                            for suffix in tmp:
                                tmp_tape_id = dev_id + suffix
                                p_mm = conv_id_2_mm(tmp_tape_id, "")
                                if p_mm != "":
                                    p_sgn = ""
                                    # p_size = dev_2_size[tmp_tape_id]
                                    # p_disp_size = mg_disp(p_size,1024)
                                    p_disp_size = devsize_disp(tmp_tape_id)
                                    p_blurb = ''
                                    if flat_display:
                                        # format(fmt_scsi_adr(host,len_host,bus,len_bus,target,len_target,lun,len_lun)
                                        errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8} {9}".
                                                   format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                          lun_2_type[scsi_adr].ljust(5),
                                                          tmp_tape_id.ljust(max_dev),
                                                          p_mm.ljust(max_mm),
                                                          p_disp_size.rjust(8),
                                                          scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                          scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                          dev_2_label[tmp_tape_id].ljust(max_label),
                                                          dev_2_scsi_id[tmp_tape_id].ljust(max_scsi_id),
                                                          p_blurb
                                                          ))
                                    else:
                                        label_id_blurb = "label:{0} scsi_id:{1}".format(dev_2_label[tmp_tape_id], dev_2_scsi_id[tmp_tape_id])
                                        if label_id_blurb == "label: scsi_id:":
                                            label_id_blurb = ""
                                        errorprint("{0}{1} {2} {3} {4}".
                                                   format(bumper, tmp_tape_id, p_mm, label_id_blurb, p_blurb))
                                # end: if p_mm != "":
                            # end: for suffix in tmp:
                            bumper = "            "
                        if dev_id != "" and lun_2_dev_aliases[scsi_adr] != "":
                            aliases = lun_2_dev_aliases[scsi_adr].split()
                            bumper = "                  "
                            for alias in aliases:
                                p_mm = conv_id_2_mm(alias, "")
                                p_sgn = ""
                                p_disp_size = devsize_disp(alias)
                                p_blurb = ''
                                if flat_display:
                                    # format(fmt_scsi_adr(host,len_host,bus,len_bus,target,len_target,lun,len_lun)
                                    errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8} {9}".
                                               format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                      lun_2_type[scsi_adr].ljust(5),
                                                      alias.ljust(max_dev),
                                                      p_mm.ljust(max_mm),
                                                      p_disp_size.rjust(8),
                                                      scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                      scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                      dev_2_label[alias].ljust(max_label),
                                                      dev_2_scsi_id[alias].ljust(max_scsi_id),
                                                      p_blurb
                                                      ))
                                else:
                                    label_id_blurb = "label:{0} scsi_id:{1}".format(dev_2_label[alias], dev_2_scsi_id[alias])
                                    if label_id_blurb == "label: scsi_id:":
                                        label_id_blurb = ""
                                    errorprint("{0}{1} {2} {3} {4}".
                                               format(bumper, alias, p_mm, label_id_blurb, p_blurb))
                            bumper = "            "
                        if dev_id != "" and dev_2_parts[dev_id] != "":
                            parts = dev_2_parts[dev_id].split()
                            # debug_print(z,"{0} ({1}) - {2}".format(scsi_adr,dev_id,parts)) # REMOVE
                            bumper = "                  "
                            for part in parts:
                                p_mm = conv_id_2_mm(part, "bd")
                                p_sgn = ""
                                # p_size = dev_2_size[part]
                                # p_disp_size = mg_disp(p_size,1024)
                                p_disp_size = devsize_disp(part)
                                p_blurb = ''
                                if dev_2_errs[part]:
                                    p_blurb = "(I/O errors {0})".format(dev_2_errs[part])
                                if flat_display:
                                    # format(fmt_scsi_adr(host,len_host,bus,len_bus,target,len_target,lun,len_lun)
                                    errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8} {9}".
                                               format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                      lun_2_type[scsi_adr].ljust(5),
                                                      part.ljust(max_dev),
                                                      p_mm.ljust(max_mm),
                                                      p_disp_size.rjust(8),
                                                      scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                      scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                      dev_2_label[part].ljust(max_label),
                                                      dev_2_scsi_id[part].ljust(max_scsi_id),
                                                      p_blurb
                                                      ))
                                else:
                                    label_id_blurb = "label:{0} scsi_id:{1}".format(dev_2_label[part], dev_2_scsi_id[part])
                                    if label_id_blurb == "label: scsi_id:":
                                        label_id_blurb = ""
                                    errorprint("{0}{1} {2} {3} {4}".
                                               format(bumper, part, p_mm, label_id_blurb, p_blurb))
                            bumper = "            "
                        if dev_id != "" and dev_2_dms[dev_id] != "":
                            dms = dev_2_dms[dev_id].split()
                            dwc = len(dms)
                            # if dwc > 1: errorprint("# $# $ WTF {0} ({1}) - {2}".format(scsi_adr,dev_id,dms))
                            # debug_print(z,"{0} ({1}) - {2}".format(scsi_adr,dev_id,dms)) # REMOVE
                            bumper = "                  "
                            for dm in dms:
                                p_mm = conv_id_2_mm(dm, "dm")
                                p_sgn = ""
                                # p_size = dev_2_size[dm]
                                # p_disp_size = mg_disp(p_size,1024)
                                p_disp_size = devsize_disp(dm)
                                p_aliases = conv_mm_2_bd_alias_list(p_mm)
                                if flat_display:
                                    # format(fmt_scsi_adr(host,len_host,bus,len_bus,target,len_target,lun,len_lun),
                                    errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8}".
                                               format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                      lun_2_type[scsi_adr].ljust(5),
                                                      dm.ljust(max_dev),
                                                      p_mm.ljust(max_mm),
                                                      p_disp_size.rjust(8),
                                                      scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                      scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                      dev_2_label[dm].ljust(max_label),
                                                      dev_2_scsi_id[dm].ljust(40)
                                                      ))
                                    aliases = p_aliases.split()
                                    for alias in aliases:
                                        # p_size = dev_2_size[alias]
                                        # p_disp_size = mg_disp(p_size,1024)
                                        p_disp_size = devsize_disp(alias)
                                        errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8}".
                                                   format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                          lun_2_type[scsi_adr].ljust(5),
                                                          alias.ljust(max_dev),
                                                          p_mm.ljust(max_mm),
                                                          p_disp_size.rjust(8),
                                                          scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                          scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                          dev_2_label[alias].ljust(max_label),
                                                          dev_2_scsi_id[alias].ljust(40)
                                                          ))
                                        parts = dev_2_parts[alias].split()
                                        for part in parts:
                                            # p_size = dev_2_size[part]
                                            # p_disp_size = mg_disp(p_size,1024)
                                            p_disp_size = devsize_disp(part)
                                            errorprint("{0} {1} {2} {3} {4} {5} {6} {7} {8}".
                                                       format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                              lun_2_type[scsi_adr].ljust(5),
                                                              part.ljust(max_dev),
                                                              conv_id_2_mm(part, "bd").ljust(max_mm),
                                                              p_disp_size.rjust(8),
                                                              scsi_lun_mfg[scsi_adr].ljust(max_mfg),
                                                              scsi_lun_mfg_model[scsi_adr].ljust(max_model),
                                                              dev_2_label[part].ljust(max_label),
                                                              dev_2_scsi_id[part].ljust(40)
                                                              ))
                                else:
                                    label_id_blurb = "label:{0} scsi_id:{1}".format(dev_2_label[dm], dev_2_scsi_id[dm])
                                    if label_id_blurb == "label: scsi_id:":
                                        label_id_blurb = ""
                                    errorprint("{0}{1} {2} {3}".
                                               format(bumper, dm, p_mm, label_id_blurb))
                        if scsi_2_lintape[scsi_adr] != "":
                            bumper = "                  "
                            lt_id = scsi_2_lintape[scsi_adr]
                            lt_mm = conv_id_2_mm(lt_id, '')
                            if lt_mm == "":
                                lt_mm = "?:?"
                            if flat_display:
                                # format(fmt_scsi_adr(host,len_host,bus,len_bus,target,len_target,lun,len_lun),
                                errorprint("{0} {1} {2} {3}".
                                           format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                  lun_2_type[scsi_adr].ljust(5),
                                                  lt_id.ljust(max_dev),
                                                  lt_mm.ljust(max_mm)
                                                  ))
                            else:
                                lintape_blurb = "lintape:{0}".format(scsi_2_lintape[scsi_adr])
                                errorprint("{0}{1}".
                                           format(bumper, lt_mm, lintape_blurb))
                            # if sgn != ''
                        if lun_2_sgn[scsi_adr] != "":
                            if flat_display:
                                errorprint("{0} {1} {2} {3}".
                                           format(fmt_scsi_adr(-2, len_host, -2, len_bus, -2, len_target, -2, len_lun),
                                                  lun_2_type[scsi_adr].ljust(5),
                                                  lun_2_sgn[scsi_adr].ljust(max_dev),
                                                  major_minor2.ljust(max_mm)
                                                  ))
                        if sw_sm_level >= 4:
                            lines = scsi_lun_detail[scsi_adr]
                            lines = lines.split('\n')
                            bumper = "              "
                            for line in lines:
                                errorprint("{0}{1}".format(bumper, line))

                if sw_sm_level == 1:
                    if lun_count > 1:
                        errorprint("{0} - {1} luns (lun{2}.{3}[{4}/{5}({6})] to lun{7}.{8}[{9}/{10}({11})]) {12}".
                                   format(target_line, lun_count,
                                          low_lun, low_lun_type, low_lun_id, low_lun_sgn, low_lun_mfg,
                                          high_lun, high_lun_type, high_lun_id, high_lun_sgn, high_lun_mfg,
                                          target_blurb))
                    else:
                        errorprint("{0} - {1} lun (lun{2}.{3}[{4}/{5}({6})]) {7}".
                                   format(target_line,
                                          lun_count,
                                          low_lun,
                                          low_lun_type,
                                          low_lun_id,
                                          low_lun_sgn,
                                          low_lun_mfg,
                                          target_blurb))

                # end: for lun in range(lo_lun,max_lun+1): # lun loop <======================================|
            # end: for target in range(0,max_target+1): # target loop <======================================|
        # end: for bus in range(0,max_bus+1): # bus loop <===================================================|
    # end: for host in range(0,max_host+1): # host loop <====================================================|

    errorprint("")
    # if detached_device_count > 0:
    # print("Detached device count: {0}".format(detached_device_count))
    # print("")

    words = all_scsi_dev_types.split()
    errorprint("all scsi device types: {0}".format(all_scsi_dev_types))
    for dev_type in words:
        errorprint("count of {0} devtype: {1}".format(dev_type, scsi_dev_type_count[dev_type]))

    errorprint("")
    errorprint("Total hosts/buses/targets/luns: {0}/{1}/{2}/{3} [max luns: {4}]".
               format(total_hosts, total_buses, total_targets, total_luns, scsi_mod_parameters["max_luns"]))
    errorprint("")
    errorprint("end scsi map")
    errorprint("")
    debug_print(1, "complete")

    return


# ---------------------------------------------#
# function: track_cciss_devs()
# ---------------------------------------------#
def track_cciss_devs(dev, mm, source):
    # global cciss_devs_present # False
    global all_cciss_devs  # ''

    if '>' in dev or '<' in dev:
        return  # broken syslog lines?

    if mm != '':
        tmp = mm.split(':')
        major = int(tmp[0])
        minor = int(tmp[1])
        if major < 104 or major > 111:
            error_print('d', '{0} {1} ?? ({2})'.format(dev, mm, source))
            return

    if dev.startswith("cciss/"):
        dev = dev.rstrip(':')
        dev = dev[len("cciss/"):]  # everything after cciss/

    # cciss_devs_present = True
    # if not cciss_devs_present(): error_print("l","cciss_devs_present false: {0} ({1})".format(item,source))

    if re.match(ccd_re, dev) or re.match(ccd_re_p, dev):
        all_cciss_devs = unique_list(all_cciss_devs, dev)

    return

# ---------------------------------------------#
# function cciss_devs_present()
# return true/false based on presence or absence of cciss devices [Compaq(HP) smart array devices]
# ---------------------------------------------#


def cciss_devs_present():
    # global hi_block_minor # Key_data_max()

    cciss_devices_present = False

    for j in range(104, 111 + 1):
        # debug_print(z,"{0}:{1}".format(j,hi_block_minor[j]))
        hbm = get_first_block_minor_no(j)
        if hbm != -1:
            cciss_devices_present = True
    # end: for j in range(104,111):

    return(cciss_devices_present)

# ---------------------------------------------#
# function vdx_devs_present()
# return true/false based on presence or absence of vdx devices
# ---------------------------------------------#


def vdx_devs_present():
    # global hi_block_minor # Key_data_max()

    vdx_devices_present = False

    vdx_maj = 251  # typical
    if get_major_type(253, "b") == "vd":
        vdx_maj = 253

    for j in range(vdx_maj, vdx_maj + 1):
        # debug_print(z,"{0}:{1}".format(j,hi_block_minor[j]))
        # if hi_block_minor[j] != -1: vdx_devices_present = True
        hbm = get_first_block_minor_no(j)
        if hbm != -1:
            vdx_devices_present = True
    # end: for j in range(vdx_maj,vdx_maj+1):

    return(vdx_devices_present)

# ---------------------------------------------#
# function dfa_devs_present()
# return true/false based on presence or absence of dfa devices
# ---------------------------------------------#


def dfa_devs_present():
    # global hi_block_minor # Key_data_max()

    dfa_devices_present = False

    for j in range(251, 251 + 1):
        # debug_print(z,"{0}:{1}".format(j,hi_block_minor[j]))
        # if hi_block_minor[j] != -1: dfa_devices_present = True
        hbm = get_first_block_minor_no(j)
        if hbm != -1:
            dfa_devices_present = True
    # end: for j in range(251,251+1):

    return(dfa_devices_present)

# ---------------------------------------------#
# function def do_cciss_dev()
# track the names of all cciss devices (and partitions) found in var/log/messages|dmesg
#
# kernel:  cciss/c0d0: p1 p2
# ---------------------------------------------#


def do_cciss_dev(line, words, source):

    # debug_print(z,line)
    wc = len(words)
    dev_id = words[1].rstrip(':')
    if not dev_id.startswith("cciss/"):
        return  # should not happen

    dev_id = dev_id[len("cciss/"):]  # everything after cciss/
    track_cciss_devs(dev_id, '', source)
    if wc > 2 and "unknown partition table" not in line:
        for i in range(2, wc):
            dev_id_with_p = dev_id + words[i]
            track_cciss_devs(dev_id_with_p, '', source)
        # end: for i in range(2,wc):

    return

# ---------------------------------------------#
# function fmt_misc()
# formatting helper function
# ---------------------------------------------#


def fmt_misc(lun_status, io_errs, path_errs, rsrvtn_conflicts, detaches, timeouts, offlined, not_added, write_protected, wdc_status, rdc_status):

    status_blurb = "" if lun_status == '' else "({0} lun)".format(lun_status)

    io_err_blurb = "" if io_errs == 0 else "(I/O errors {0})".format(io_errs)

    path_err_blurb = "" if path_errs == 0 else "(path errors {0})".format(path_errs)

    rsrvtn_cnflct_blurb = "" if rsrvtn_conflicts == 0 else "(reservation conflicts {0})".format(rsrvtn_conflicts)

    detach_blurb = "" if detaches == 0 else "(detaches {0})".format(detaches)

    timeout_blurb = "" if timeouts == 0 else "(timeouts {0})".format(timeouts)

    offlined_blurb = "" if offlined == 0 else "(offlined {0})".format(offlined)

    not_added_blurb = "" if not_added == 0 else "(not added {0})".format(not_added)

    write_protected_blurb = "" if write_protected == 0 else "(write protected {0})".format(write_protected)

    wdc_blurb = "" if wdc_status is False else "(write cache disabled)"

    rdc_blurb = "" if rdc_status is False else "(read cache disabled)"

    blurb = "{0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}".\
            format(status_blurb,
                   io_err_blurb,
                   path_err_blurb,
                   rsrvtn_cnflct_blurb,
                   detach_blurb,
                   timeout_blurb,
                   offlined_blurb,
                   not_added_blurb,
                   write_protected_blurb,
                   wdc_blurb,
                   rdc_blurb)
    return(squeeze(blurb.strip()))
# ---------------------------------------------#
# function: fmt_scsi_adr()
# return a h:b:t:l string in a right justified, zero filled format.
# (unless an element is -1, in which case '*' will be supplied.)
# ---------------------------------------------#


def fmt_scsi_adr(host, len_host, bus, len_bus, target, len_target, lun, len_lun):
    return("{0}:{1}:{2}:{3}".format(fmt_scsi_ele(host, len_host),
                                    fmt_scsi_ele(bus, len_bus),
                                    fmt_scsi_ele(target, len_target),
                                    fmt_scsi_ele(lun, len_lun)))

# ---------------------------------------------#
# function: fmt_scsi_ele()
# return a scsi address element as per fmt_scsi_adr()
# ---------------------------------------------#


def fmt_scsi_ele(ele, len_ele):

    s = ''
    if ele == -1:
        s = s.ljust(len_ele, '*')
    elif ele == -2:
        s = s.ljust(len_ele, '-')
    else:
        s = "{0}".format(ele)
        s = s.zfill(len_ele)

    return(s)

# ---------------------------------------------#
# function: check_scsi_anomalies()
# ---------------------------------------------#


def check_scsi_anomalies():
    global rh_major
    global all_dev_mfgs  # ""
    global host_devtypes  # Key_data()          # key: host,                date: device types(s);  e.g. 0,       sd
    global max_host
    global cmdline  # Key_data()
    global mfg_models  # Key_data()            # key: mfg                  data: model(s)          e.g. EMC,     SYMMETRIX
    global scsi_dev_type_count  # Counter()     # key: device type          data: count             e.g. st,      7
    global all_modprobe_alias_entries  # ''
    global modprobe_alias_data  # Key_data()     # key: alias name          data: alias data e.g.: scsi_adapter cciss
    global all_lsmods  # ''
    global lsmod_data  # Key_data()     # key: module name          data: size & used by data e.g. lockd  73662 nfs
    global Virtual_guest
    global Virtual_type
    global scsi_dev_type_count  # Counter()
    global LUNZ_count  # 0
    global iscsi_LUNZ_count  # 0
    global all_pci_addresses  # ""
    global all_scsi_ids  # ""
    global pci_address  # Key_data()             # key: pci address         data: pci line
    global scsi_host
    global scsi_lun

    global total_offlined
    global scsi_host_offlined
    global scsi_host_offlined_devices  # Key_data()       # key: host number, list of unique devices offlined
    global high_host_offlined_count
    global high_host_offlined_lun
    global high_lun_offlined_count
    global high_lun_offlined_lun

    global total_not_added
    global scsi_host_not_added
    global scsi_host_not_added_luns  # Key_data()       # key: host number, list of unique luns not added
    global total_end_requests  # 0

    cisco_host_cnt = 0
    cisco_pci_cnt = 0
    words = all_pci_addresses.split()
    for pci_adr in words:
        tmp_pci_desc = pci_address[pci_adr].lower()
        if "cisco" in tmp_pci_desc:
            cisco_pci_cnt += 1

    total_unique_offlined_devices = 0
    total_hosts_with_offlined_devices = 0

    total_unique_not_added_devices = 0
    total_hosts_with_not_added_devices = 0

    low_host = -1
    # 1. check for mix of sd & st on same host, if so, raise anomaly
    # 2. check for cisco fnic hosts, if found check against pci=nomsi
    for host in range(0, max_host + 1):
        scsi_adr = "{0}".format(host)

        tmp_host = scsi_host[scsi_adr].lower()
        if "cisco" in tmp_host and "nomsi" in cmdline['pci']:
            # see cases 01500740 and 01472583
            anomaly_line = "Cisco host{0} has 'pci=nomsi' present in proc/cmdline: this can lead to time outs, {1}, {2}".\
                           format(host, cfa_kcs("1524433"), sfdc_url("01500740"))
            handle_anomaly_with_points("SCSI", anomaly_line, 'configuration', 10)
            cisco_host_cnt += 1

        if "storvsc_host_t" in tmp_host:  # check for LUN0 on MS Hyperv virtual hba
            lun0 = ''
            for tgt in range(0, 255 + 1):
                lun0_index = "{0}:0:{1}:0".format(host, tgt)
                lun0 = unique_list(lun0, scsi_lun[lun0_index])
            # Issue with LUN0 not defined to HyperV vHBA causing problems - see case  and MS url:
            # https://technet.microsoft.com/en-us/windows-server-docs/compute/hyper-v/supported-centos-and-red-hat-enterprise-linux-virtual-machines-on-hyper-v
            if lun0 == "":
                anomaly_line = "host{0} is a MS Hyperv vitural HBA, but has no lun 0, {1}".\
                               format(host, sfdc_url("01693993"))
                handle_anomaly("SCSI", anomaly_line)

        offlined_instance_cnt = scsi_host_offlined[scsi_adr]
        if offlined_instance_cnt > 0:
            # total_offlined_instance_cnt+=offlined_instance_cnt = total_offlined
            total_hosts_with_offlined_devices += 1
            unique_offlined_devices = word_count(scsi_host_offlined_devices[scsi_adr])
            total_unique_offlined_devices += unique_offlined_devices
            host_desc = get_host_desc(scsi_adr)
            if "Emulex" in host_desc:
                cfa = cfa_kcs("356243")  # aka lpfc
            elif "qla2xxx" in host_desc:
                cfa = cfa_kcs("45099")
            elif "hpsa" in host_desc:
                cfa = cfa_kcs("2854741")
            # elif word_in_list(dev_type,"sd st") or word_in_list(dt,"sd st"): cfa = cfa_kcs("60605")
            else:
                cfa = "check with vendor of host{0} ({1})".format(host, host_desc)
            anomaly_line = "scsi host{0} had {1} unique device{2} offlined {3} time{4}, {5}".\
                           format(host,
                                  unique_offlined_devices, plural(unique_offlined_devices),
                                  offlined_instance_cnt, plural(offlined_instance_cnt),
                                  cfa)
            handle_anomaly("SCSI", anomaly_line)
        # end: if offlined_instance_cnt > 0:

        not_added_instance_cnt = scsi_host_not_added[scsi_adr]
        if not_added_instance_cnt > 0:
            # total_not_added_instance_cnt+=not_added_instance_cnt = total_not_added_
            total_hosts_with_not_added_devices += 1
            unique_not_added_luns = word_count(scsi_host_not_added_luns[scsi_adr])
            # total_unique_not_added_devices+=unique_not_added_devices
            total_unique_not_added_devices += 1
            anomaly_line = "scsi host{0} had {1} unique device{2} not added, consider passing flags".\
                           format(host,
                                  unique_not_added_luns, plural(unique_not_added_luns))
            handle_anomaly("SCSI", anomaly_line)
        # end: if not_added_instance_cnt > 0:

        dev_types = host_devtypes[scsi_adr]
        if dev_types == "":
            continue

        if low_host == -1:
            low_host = host

        if word_in_list("sd", dev_types) and (word_in_list("st", dev_types) or word_in_list("ch", dev_types)):
            anomaly_line = "host{0} has both disk and tape devices attached - longer tape io response could impact disk performance - best practice is to separate disk and tape io traffic".format(host)
            handle_anomaly("SCSI", anomaly_line)

    # end: for host in range(0,max_host+1):

    if total_unique_offlined_devices > 0:
        anomaly_line = "encountered {0} host{1} which had {2} unique device{3} offlined {4} time{5}, high host {6}: count {7}, high lun {8}: count {9}".\
                       format(total_hosts_with_offlined_devices, plural(total_hosts_with_offlined_devices),
                              total_unique_offlined_devices, plural(total_unique_offlined_devices),
                              total_offlined, plural(total_offlined),
                              high_host_offlined_host, high_host_offlined_count,
                              high_lun_offlined_lun, high_lun_offlined_count)
        handle_anomaly("SCSI", anomaly_line)

    #
    # Cisco url to check hw/fw/sf interoperability: http://www.cisco.com/web/techdoc/ucs/interoperability/matrix/matrix.html
    #
    if "nomsi" in cmdline['pci'] and (cisco_host_cnt == 0 and cisco_pci_cnt > 0):
        # see case  (no host info, only pci info)
        anomaly_line = "Cisco pci{0} [{1}] found and 'pci=nomsi' present in proc/cmdline: this can lead to time outs, {2}, {3}".\
                       format(plural(cisco_pci_cnt), cisco_pci_cnt, cfa_kcs("1524433"), sfdc_url("01500740"))
        handle_anomaly_with_points("SCSI", anomaly_line, 'configuration', 10)

    if low_host == max_host and Virtual_guest:
        sd_dev_cnt = scsi_dev_type_count["sd"]
        if sd_dev_cnt > 1:
            anomaly_line = "Virtual guest and all {0} sd device{1} are on the same virtual HBA ({2}), possible performance bottleneck, {3}".\
                           format(sd_dev_cnt, plural(sd_dev_cnt), low_host, cfa_sfdc("01635940"))
            handle_anomaly_with_points("VM", anomaly_line, 'performance', 2)

    if LUNZ_count > 0:
        anomaly_line = "Found {0} LUNZ device{1}, {2}".\
                       format(LUNZ_count, plural(LUNZ_count), cfa_kcs("328493"))
        handle_anomaly_with_points("SCSI", anomaly_line, 'hardware', LUNZ_count)
        if iscsi_LUNZ_count > 0:
            anomaly_line = "Found {0} iscsi LUNZ device{1}, see {2}".\
                           format(LUNZ_count, plural(LUNZ_count), "https://community.emc.com/docs/DOC-17644")
            handle_anomaly_with_points("SCSI", anomaly_line, 'hardware', LUNZ_count)
    if word_in_list("NETAPP", all_dev_mfgs) and "VTL" in mfg_models["NETAPP"] and scsi_dev_type_count["st"] == 7:
        anomaly_line = "NETAPP VTL found and only 7 tape luns reporting, see KCS: {0}".format(kcs_url("342913"))
        handle_anomaly_with_points("ST", anomaly_line, 'hardware', 5)

    if cciss_devs_present():
        cciss_adapter_count = 0
        words = all_modprobe_alias_entries.split()
        for alias in words:
            # debug_print(z,"modprobe_alias_data[{0}]: {1}".format(alias,modprobe_alias_data[alias]))
            if alias.startswith("scsi_hostadapter") and "cciss" in modprobe_alias_data[alias]:
                cciss_adapter_count += 1
        if cciss_adapter_count == 0:
            anomaly_line = "cciss devices present, but no cciss scsi_hostadapter alias entry found in modprobe.conf, {0}".format(cfa_sfdc("01620074"))
            handle_anomaly_with_points("SCSI", anomaly_line, 'configuration', 5)

        if not word_in_list("cciss", all_lsmods) or lsmod_data["cciss"] == '':
            # not sure if this is possible
            anomaly_line = "cciss devices present, but no cciss kernel module loaded (lsmod)"
            handle_anomaly_with_points("SCSI", anomaly_line, 'configuration', 5)

    if scsi_dev_type_count['st'] > 0 and mfg_lun_count['IBM'] > 0 and service_procs[LIN_TAPED] > 0:
        # mod_name = 'lintape.ko' # saw a reference to this but never seen in cases
        mod_name = 'lin_tape'
        if not word_in_list(mod_name, all_lsmods):
            anomaly_line = "module {0} not loaded, but IBM tape devices and {1} appear to be present, {2}".\
                           format(mod_name, LIN_TAPED, cfa_sfdc("01675402"))
            handle_anomaly_with_points("ST", anomaly_line, 'configuration', 10)

    if (Virtual_guest and Virtual_type == "VMware") and scsi_dev_type_count["sd"] > 0 and all_scsi_ids == "":
        anomaly_line = "VMware guest has no scsi ids, if needed, enable 'disk.EnableUUID' config parameter within VMware, {0}".\
                       format(info_kcs("93943"))
        handle_anomaly_with_points("VMWARE", anomaly_line, 'configuration', 2)
        # should all_wwn_ids and/or all_iscsi_ids be checked too?

    summarize_session_recovery_timeout()  # (if any..)

    if total_end_requests > 0:
        anomaly_line = "Found a total of {0} 'end_request' messsage{1}, {2}".\
                       format(total_end_requests, plural(total_end_requests), cfa_kcs("2260951"))
        handle_anomaly("IOERR", anomaly_line)

    if rh_major == 5:
        lpfc_kcs_29128_check_events = scan_count[get_scan_block("ID:lpfc_kcs_29128_check")]
        lpfc_use_msi = lpfc_parameters["lpfc_use_msi"]
        if lpfc_use_msi == '':
            lpfc_use_msi = '?'
        if lpfc_kcs_29128_check_events > 0 and lpfc_use_msi != '2':
            anomaly_line = "With the combination of previous lpfc messages, RHEL 5 and lpfc_use_msi={0}, {1}".\
                           format(lpfc_use_msi, cfa_kcs("29128"))
            handle_anomaly("LPFC", anomaly_line)

    lun_nr_events = scan_count[get_scan_block("ID:lun_nr_1")]
    lun_nr_events += scan_count[get_scan_block("ID:lun_nr_2")]
    lun_nr_events += scan_count[get_scan_block("ID:lun_nr_3")]
    if lun_nr_events > 99:
        anomaly_line = "Found {0} 'LUN not ready' messages, possible udev flapping, {1}".\
                       format(lun_nr_events, cfa_sfdc("02044279"))
        handle_anomaly("SD", anomaly_line)
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: crunch_lspci()
# gather all pci data
# ---------------------------------------------#
def crunch_lspci():
    global all_pci_addresses  # ""
    global pci_address  # Key_data()             # key: pci address         data: pci line

    # TODO: not recognizing some fcoe hba / pci adapters? see hosts 5-10 in case
    files = "lspci "\
            "sos_commands/pci/lspci " \
            "sos_commands/hardware/lspci "\
            ""
    tmp = files.split()
    found_files = ''

    for lspci_file in tmp:
        if not file_exists_with_data(lspci_file):
            continue
        if found_files == '':
            found_files = lspci_file
        else:
            found_files = found_files + lspci_file

        lspci_cmd_cnt = crunch_lspci_file(lspci_file, 1)
        # debug_print(z,"{0} ({1})".format(lspci_cmd_cnt,lspci_file))

        # if lspci_cmd_cnt == 0 and all_pci_addresses == '':
        if lspci_cmd_cnt == 0:  # all_pci_addresses can be added to from other routines
            crunch_lspci_file(lspci_file, 0)

    # end: for lspci_file in tmp:

    tmp = all_pci_addresses.split()
    wc = len(tmp)
    debug_print(1, "found {0} pci addresses in ({1})".format(wc, found_files))

    for pci_adr in tmp:
        debug_print(2, "{0} {1}".format(pci_adr, pci_address[pci_adr]))
    return

# ---------------------------------------------#
# function: crunch_lspci_file()
# read an lspci file
#
# lspci:
# .
# 1f:00.0 Fibre Channel: Emulex Corporation Saturn-X: LightPulse Fibre Channel Host Adapter (rev 03)
# 1f:00.1 Fibre Channel: Emulex Corporation Saturn-X: LightPulse Fibre Channel Host Adapter (rev 03)
# .
# lspci -nvv:
# .
# .
# lspci -tv:
# .
# .
# <eof>
# ---------------------------------------------#


def crunch_lspci_file(lspci_file, bCheckCmds):
    global all_pci_addresses  # ""
    global pci_address  # Key_data()             # key: pci address         data: pci line
    global pci_short_re
    global pci_long_re

    fh = openfile(lspci_file)
    if fh is None:
        return

    if bCheckCmds == 1:
        search_active = False  # need to find 'lspci:'
    else:
        search_active = True
    skip_next_line = False
    lspci_cmd_cnt = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        if line == "" or \
           "Cannot find" in line or \
           "Cannot open" in line or \
           "Unable to load" in line or \
           "Unable to read" in line or \
           "timeout:" in line or \
           "warning:" in line:
                continue

        # libkmod: kmod_config_parse: /etc/modprobe.d/ixgbe.conf line 1: ignoring bad line starting with 'allow_unsupported_sfp=1'
        if line.startswith("libkmod: "):
            continue
        if bCheckCmds == 1 and (line == "lspci:" or line == "lspci"):
            search_active = True
            lspci_cmd_cnt += 1
            continue

        if bCheckCmds == 1 and (line == "lspci -nvv:" or line == "lspci -nvv"):
            search_active = False
            lspci_cmd_cnt += 1
            continue

        if bCheckCmds == 1 and (line == "lspci -n:" or line == "lspci -n"):
            search_active = False
            lspci_cmd_cnt += 1
            continue

        if bCheckCmds == 1 and (line == "lspci -tv:" or line == "lspci -tv"):
            search_active = False
            lspci_cmd_cnt += 1
            continue

        if search_active is False:
            continue

        if "sysfs_read_vpd: read failed:" in line:
            skip_next_line = True
            continue

        if skip_next_line:
            skip_next_line = False
            continue

        if not bCheckCmds and line.startswith("\t"):
            continue

        words = line.split()
        pci_adr = words[0]
        wc = len(words)
        valid_pci_adr = False

        if len(pci_adr) == len("xx:xx.x") and re.match(pci_short_re, pci_adr):
            pci_desc = line[len("xx:xx.x") + 1:]  # remainder of line minus pci address
            pci_adr = "0000:" + pci_adr  # build out pci_adr to long format
            valid_pci_adr = True
        elif len(pci_adr) == len("xxxx:xx:xx.x") and re.match(pci_long_re, pci_adr):
            pci_desc = line[len("xxxx:xx:xx.x") + 1:]  # remainder of line minus pci address
            valid_pci_adr = True

        if valid_pci_adr:
            # debug_print(z,"{0} '{1}'".format(pci_adr,line))
            track_pci_address_and_host(pci_adr, pci_desc, '', lspci_file)
        else:
            error_print('d', "{0} '{1}' ({2},{3})".format(pci_adr, line, i, lspci_file))
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lspci_file))

    return(lspci_cmd_cnt)

# ---------------------------------------------#
# function: crunch_udevadm_info()
# extract data from udevadm info file
# ---------------------------------------------#


def crunch_udevadm_info():

    udevadm_files = "sos_commands/devices/udevadm_info_--export-db"
    tmp = udevadm_files.split()

    for udevadm_file in tmp:
        if file_exists_with_data(udevadm_file):
            crunch_udevadm_file(udevadm_file)
    # end: for udevadm_file in tmp:

    return

# ---------------------------------------------#
# function: crunch_udevadm_file()
# read an udevadm_info file
#
# P: /devices/pci0000:00/0000:00:03.2/0000:0e:00.0/host11/rport-11:0-3/target11:0:1/11:0:1:9/block/sdch
# E: ...
# E: ..
#
#
# ---------------------------------------------#


def crunch_udevadm_file(udevadm_file):

    fh = openfile(udevadm_file)
    if fh is None:
        return

    udevadm_section = ''
    i = 0
    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        if line == "":
            continue

        if line.startswith("P: "):
            if udevadm_section != '':
                crunch_udevadm_section(udevadm_section, udevadm_file)
            udevadm_section = ''

        if udevadm_section == '':
            udevadm_section = line
        else:
            udevadm_section = udevadm_section + '\n' + line

    # end: for line fh udevadm_lines:

    if udevadm_section != '':
        crunch_udevadm_section(udevadm_section, udevadm_file)
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, udevadm_file))
    return

# ---------------------------------------------#
# function: crunch_udevadm_section()
# ---------------------------------------------#


def crunch_udevadm_section(udevadm_section, udevadm_file):
    if udevadm_section.startswith("P: /devices/pci"):
        crunch_udevadm_pci_section(udevadm_section, udevadm_file)
    elif udevadm_section.startswith("P: /devices/virtual/block/md"):
        crunch_udevadm_md_section(udevadm_section, udevadm_file)
    return

# ---------------------------------------------#
# function: crunch_udevadm_pci_section()
# process pci data section from the udevadm file
#
# P: /devices/pci0000:00/0000:00:03.2/0000:0e:00.0/host11/rport-11:0-3/target11:0:1/11:0:1:9/block/sdch
# E: ...
# E: ..
#
# ---------------------------------------------#


def crunch_udevadm_pci_section(udevadm_section, udevadm_file):

    udevadm_lines = udevadm_section.split('\n')

    process_pci_line = False
    i = 0

    for line in udevadm_lines:
        i += 1

        if line == "":
            continue

        if line.startswith("P: /devices/pci") and "/host" in line:
            if "/block" in line:
                process_pci_line = True
            elif "/scsi_disk" in line:
                process_pci_line = True
            elif "/scsi_tape" in line:
                process_pci_line = True
            elif "/scsi_device" in line:
                process_pci_line = True
            elif "/scsi_generic" in line:
                process_pci_line = True

        if process_pci_line:
            # see crunch_pci_and_host() comment prolog for more expamples of "P: /devices/..." data
            words = line.split()
            path = words[1]
            p_words = path.split("/")
            pwc = len(p_words)
            crunch_pci_and_host(i, line, words, path, p_words, udevadm_file)
            process_pci_line = False  # don't need additional lines at the point
    # end: for line in udevadm_lines:

    del udevadm_lines
    debug_print(1, "processed {0} lines from a pci section of {1}".format(i, udevadm_file))
    return

# ---------------------------------------------#
# function: crunch_udevadm_md_section()
# process an md data section from the udevadm file
#
# P: /devices/virtual/block/md3
# N: md3
# L: 100
# S: disk/by-id/md-name-3
# S: disk/by-id/md-uuid-47d0eb79:9eaa1e60:b7f11804:621a8eed
# S: disk/by-uuid/b1e8ad12-f666-45d6-a6ce-dcb908163274
# S: md/3
# E: DEVLINKS=/dev/disk/by-id/md-name-3 /dev/disk/by-id/md-uuid-47d0eb79:9eaa1e60:b7f11804:621a8eed /dev/disk/by-uuid/b1e8ad12-f666-45d6-a6ce-dcb908163274 /dev/md/3
# E: DEVNAME=/dev/md3
# E: DEVPATH=/devices/virtual/block/md3
# E: DEVTYPE=disk
# E: ID_FS_TYPE=xfs
# E: ID_FS_USAGE=filesystem
# E: ID_FS_UUID=b1e8ad12-f666-45d6-a6ce-dcb908163274
# E: ID_FS_UUID_ENC=b1e8ad12-f666-45d6-a6ce-dcb908163274
# E: MAJOR=9
# E: MD_DEVICES=2
# E: MD_DEVICE_sdg3_DEV=/dev/sdg3
# E: MD_DEVICE_sdg3_ROLE=0
# E: MD_DEVICE_sdh3_DEV=/dev/sdh3
# E: MD_DEVICE_sdh3_ROLE=1
# E: MD_DEVNAME=3
# E: MD_LEVEL=raid1
# E: MD_METADATA=1.2
# E: MD_NAME=3
# E: MD_UUID=47d0eb79:9eaa1e60:b7f11804:621a8eed
# E: MINOR=3
# E: SUBSYSTEM=block
# E: SYSTEMD_WANTS=mdmonitor.service
# E: TAGS=:systemd:
# E: USEC_INITIALIZED=89193
#
# ---------------------------------------------#


def crunch_udevadm_md_section(udevadm_section, udevadm_file):

    udevadm_lines = udevadm_section.split('\n')

    sd_devs = ''
    md_uuid = ''
    md_dev_uuid = ''
    i = 0

    for line in udevadm_lines:
        i += 1

        if line == "":
            continue

        # debug_print(z,"{0}:'{1}'".format(i,line))
        words = line.split()
        wc = len(words)
        w0 = words[0]
        w1 = ''
        if wc > 1:
            w1 = words[1]  # 2nd word

        if w0 == "P:":
            md_dev_id = words[1]
            tmp = md_dev_id.split('/')
            md_id = tmp[4]

        if w0 == "E:" and w1.startswith("DEVLINKS="):
            md_uuid = ''
            md_dev_uuid = ''
            line = line[len("E: DEVLINKS="):]
            tmp = line.split()
            for tmp_word in tmp:
                if tmp_word.startswith("/dev/disk/by-id/md-uuid-"):
                    md_uuid = tmp_word[len("/dev/disk/by-id/md-uuid-"):]
                if tmp_word.startswith("/dev/disk/by-uuid/"):
                    md_dev_uuid = tmp_word[len("/dev/disk/by-uuid/"):]
            # end: for tmp_word in tmp:

        if w0 == "E:" and w1.startswith("MD_DEVICE_sd") and "_DEV=/dev" in line:
            tmp = w1.split('/')
            twc = len(tmp)
            sd_dev = tmp[twc - 1]  # last word
            sd_devs = unique_list(sd_devs, sd_dev)
    # end: for line in udevadm_lines:

    track_md_id(md_id, sd_devs, md_uuid, md_dev_uuid, udevadm_file)

    del udevadm_lines
    debug_print(1, "processed {0} lines from a md section of {1}".format(i, udevadm_file))
    return


# ---------------------------------------------#
# function: crunch_systool_info()
# extract data from systool files
# ---------------------------------------------#
def crunch_systool_info():

    systool_file_list = "" \
        "sos_commands/devicemapper/systool_-v_-c_scsi_host "\
        "sos_commands/hardware/systool_-v_-c_scsi_host "\
        "sos_commands/devicemapper/systool_-v_-c_scsi_generic "\
        "sos_commands/hardware/systool_-v_-c_scsi_generic "\
        "sos_commands/devicemapper/systool_-v_-c_scsi_disk "\
        "sos_commands/hardware/systool_-v_-c_scsi_disk "\
        ""

    systool_files = systool_file_list.split()
    for systool_file in systool_files:
        if file_exists_with_data(systool_file):
            crunch_systool_file(systool_file)

    return

# ---------------------------------------------#
# function: crunch_systool_file()
# read a systool file
#
# ---------------------------------------------#


def crunch_systool_file(systool_file):

    fh = openfile(systool_file)
    if fh is None:
        return

    scsi_generic = False
    scsi_disk = False
    scsi_host = False
    if systool_file.endswith("scsi_generic"):
        scsi_generic = True
    if systool_file.endswith("scsi_disk"):
        scsi_disk = True
    if systool_file.endswith("scsi_host"):
        scsi_host = True
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        line = line.strip()
        if line == "":
            continue

        if (scsi_generic or scsi_disk or scsi_host) and line.startswith("Class Device path ="):
            words = line.split()
            path = words[4]
            path = path.strip('"')
            p_words = path.split("/")
            pwc = len(p_words)
            # if scsi_generic: debug_print(z,line)
            crunch_pci_and_host(i, line, words, path, p_words, systool_file)
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, systool_file))
    return

# ---------------------------------------------#
# function: find_first_sd()
# return the first scsi device id on host
# ---------------------------------------------#


def find_first_sd(host):
    global scsi_bus  # Key_data()
    global scsi_target  # Key_data()
    global scsi_lun  # Key_data()
    global lun_2_type  # Key_data()
    global lun_2_id  # Key_data()
    global max_host
    global max_bus
    global max_target
    global lo_lun
    global max_lun

    if host > max_host:
        return ""

    for bus in range(0, max_bus + 1):
        scsi_adr = "{0}:{1}".format(host, bus)
        if scsi_bus[scsi_adr] == "":
            continue

        for target in range(0, max_target + 1):
            scsi_adr = "{0}:{1}:{2}".format(host, bus, target)
            if scsi_target[scsi_adr] == "":
                continue

            for lun in range(lo_lun, max_lun + 1):
                scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
                if scsi_lun[scsi_adr] == "":
                    continue

                if word_in_list(lun_2_type[scsi_adr], "sd sr st"):
                    dev_id = lun_2_dev[scsi_adr]
                    if dev_id != "":
                        return(dev_id)

            # end: for lun in range(lo_lun,max_lun+1):
        # end: for target in range(0,max_target+1):
    # end: for bus in range(0,max_bus+1):

    return ""

# ---------------------------------------------#
# function: display_mm_devices()
# ---------------------------------------------#


def display_mm_devices():
    display_mm_char_devices()
    display_mm_block_devices()
    return

# ---------------------------------------------#
# function: display_mm_char_devices()
# display char devices arragned by major, minor numbers
# ---------------------------------------------#


def display_mm_char_devices():
    global lo_char_major  # big_num
    global hi_char_major  # -1
    if hi_char_major == -1:
        return  # probably means this sos report is incomplete...
    for j in range(lo_char_major, hi_char_major + 1):
        display_char_major(j)
    return

# ---------------------------------------------#
# function: display_char_major()
# ---------------------------------------------#


def display_char_major(major):
    global lo_char_minor  # Key_data_min()
    global hi_char_minor  # Key_data_max()
    global mm_2_cd  # Key_data()

    lcm = lo_char_minor[major]
    hcm = hi_char_minor[major]

    if hcm == -1:
        return  # no char minor devices for this major

    dm_print("{0} char major type ({1}):".format(get_char_major_name(major), char_minor_cnt[major]))

    for i in range(lcm, hcm + 1):
        minor = i
        mm = "{0}:{1}".format(major, minor)
        dev_name = mm_2_cd[mm]
        if dev_name != "":
            dm_print("{0} {1}".format(format_mm(major, minor, ''), dev_name))
    # end: for i in range(lcm,hcm+1):

    dm_print("")

    return

# ---------------------------------------------#
# function: get_char_major_name()
# ---------------------------------------------#


def get_char_major_name(major):
    global major_char_type  # Key_data()

    if major_char_type[major] != '':
        return(major_char_type[major])

    if major_char_type_default[major] != '':
        return(major_char_type_default[major])

    return(format("majchar_{0}".format(major)))

# ---------------------------------------------#
# function: format_mm()
# routine to provide consistent display of mm.
# this ensures that the ':' will always be in the same spot
# ---------------------------------------------#


def format_mm(major, minor, mm):
    global max_major  # -1
    global max_minor  # -1
    global major_size  # -1
    global minor_size  # -1

    if major_size == -1:  # first time used
        major_size = max(2, len("{0}".format(max_major)))
        minor_size = max(2, len("{0}".format(max_minor)))
    if mm == '':  # typical case
        str_major = "{0}".format(major)
        str_minor = "{0}".format(minor)
    else:  # atypical, mm might be '?:?', or other non-numeric values so be lax in that regard here
        tmp = mm.split(':')
        str_major = tmp[0]
        str_minor = tmp[1]

    return(str_major.rjust(major_size) + ":" + str_minor.ljust(minor_size))


# ---------------------------------------------#
# function: display_mm_block_devices()
# display block devices arragned by major, minor numbers
# ---------------------------------------------#
def display_mm_block_devices():
    global lo_block_major  # big_num
    global hi_block_major  # -1

    global all_md_ids  # ''
    global all_cciss_devs  # ''

    all_md_ids = sort_list(dedup_list(all_md_ids))
    all_cciss_devs = sort_list(dedup_list(all_cciss_devs))

    if hi_block_major == -1:
        return  # probably means this sos report is incomplete...

    for major in range(lo_block_major, hi_block_major + 1):
        if major == get_device_mapper_major():
            display_block_major_dm(major)
        else:
            display_block_major(major)
    return

# ---------------------------------------------#
# function: display_block_major()
# ---------------------------------------------#


def display_block_major(major):
    global mm_2_bd  # Key_data()
    global mm_2_path_errs  # Counter()
    global dev_2_errs  # Counter()
    global block_minor_cnt  # Counter()         # key: block major device number, data: count of minor device numbers

    minor = get_first_block_minor_no(major)

    if minor == -1:
        return  # no block minor devices for this major

    major_type = get_block_major_name(major)
    dm_print("{0} block major type ({1}):".format(major_type, block_minor_cnt[major]))

    i = 0

    while minor != -1:

        mm = "{0}:{1}".format(major, minor)
        dev_name = mm_2_bd[mm]
        aliases = mm_2_bd_aliases[mm]
        if dev_name == "" and aliases == "":
            continue
        if dev_name == "":
            dev_name = "''"
        point = ''
        if aliases != "":
            point = "->"

        md_data = ''
        if major_type == "md":
            md_data = display_block_major_md(mm, dev_name)

        io_sched = ''
        if dev_name != '':
            io_sched = dev_2_scheduler[dev_name]
        if io_sched != '':
            io_sched = "[{0}]".format(io_sched)

        io_err = ''
        io_errors = dev_2_errs[dev_name]
        if io_errors > 0:
            io_err = "(I/O errors {0})".format(io_errors)
        # lun_or_dev_errs = max(scsi_lun_io_errs[scsi_adr],dev_2_errs[dev_id])

        p_err = ''
        path_errors = mm_2_path_errs[mm]
        if path_errors > 0:
            p_err = "(path errors {0})".format(path_errors)

        extra_data = squeeze("{0} {1} {2} {3} {4} {5}".format(md_data, point, aliases, io_sched, io_err, p_err))

        dm_print("{0} {1} {2}".format(format_mm(major, minor, ''), dev_name, extra_data))

        i += 1
        minor = get_next_block_minor_no(major, i)

    # while minor != -1:

    if major_type == "md":
        display_block_major_md_no_mm(major, major_type)
    if major_type.startswith("cciss"):
        display_block_major_cciss_no_mm(major, major_type)

    dm_print("")

    return


# ---------------------------------------------#
# function: display_block_major_md_no_mm()
# display any stray md devices that we did see as having a mm number
# ---------------------------------------------#
def display_block_major_md_no_mm(major, major_type):
    global all_md_ids  # ''
    global bd_2_mm  # Key_data()

    tmp = all_md_ids.split()
    for md_id in tmp:
        if bd_2_mm[md_id] != '':
            continue
        display_block_major_md(format_mm(0, 0, "?:?"), md_id)
    # end: for md_id in tmp:
    return
# ---------------------------------------------#
# function: display_block_major_cciss_no_mm()
# display any stray cciss devices that we did see as having a mm number
# ---------------------------------------------#


def display_block_major_cciss_no_mm(major, major_type):
    global all_cciss_devs  # ''
    global bd_2_mm  # Key_data()

    tmp = all_cciss_devs.split()
    for cciss in tmp:
        if bd_2_mm[cciss] != '':
            continue
        dm_print("{0} {1}".format(format_mm(0, 0, "?:?"), cciss))
    # end: for cciss in tmp:
    return

# ---------------------------------------------#
# function: display_block_major_md()
# ---------------------------------------------#


def display_block_major_md(mm, dev_name):
    global md_id_2_devs  # Key_data()
    global md_id_2_uuid  # Key_data()
    global md_id_2_dev_uuid  # Key_data()
    md_id = dev_name
    devs = sort_list(dedup_list(md_id_2_devs[md_id]))
    tmp = devs.split()
    md_data = " md uuid: {0} dev uuid: '{1}' device{2}: '{3}'".\
        format(md_id_2_uuid[md_id], md_id_2_dev_uuid[md_id], plural(len(tmp)), devs)

    if dev_2_dms[md_id] != '':
        dms = sort_list(dedup_list(dev_2_dms[md_id]))
        tmp = dms.split()
        # skipping for now - dm-n info avail in the dm major display block
        # print("{0} {1} device{2}: {3}".format(format_mm(0,0,mm),md_id,plural(len(tmp)),dms))

    return(md_data)


# ---------------------------------------------#
# function: get_block_major_name()
# ---------------------------------------------#
def get_block_major_name(major):
    global major_block_type  # Key_data()

    if major_block_type[major] != '':
        return(major_block_type[major])

    if major_block_type_default[major] != '':
        return(major_block_type_default[major])

    return(format("majblock_{0}".format(major)))


# ---------------------------------------------#
# function: display_id_devices()
# ---------------------------------------------#
def display_id_devices():
    global mp_2_parts  # Key_data()             # key: mp id,               data: mp part_id(s);    e.g. mpathe,  mpathep1,mpathep2,...
    global all_scsi_ids
    global scsi_id_2_devs  # Key_data()
    global all_fc_ids
    global fc_id_2_devs  # Key_data()
    global all_wwn_ids
    global wwn_id_2_devs  # Key_data()
    global all_uuids
    global uuid_2_dev  # Key_data()
    global uuid_2_pdev  # Key_data()
    global all_sata_ids  # ''
    global sata_id_2_devs  # Key_data()
    global sata_id_2_parts  # Key_data()
    global all_ata_ids  # ''
    global ata_id_2_devs  # Key_data()
    global ata_id_2_parts  # Key_data()
    global all_usb_ids  # ''
    global usb_id_2_devs  # Key_data()
    global usb_id_2_parts  # Key_data()
    global all_sas_ids  # ''
    global sas_id_2_devs  # Key_data()
    global sas_id_2_parts  # Key_data()
    global all_virtio_ids  # ''
    global virtio_id_2_devs  # Key_data()
    global virtio_id_2_parts  # Key_data()
    global all_label_ids  # ""
    global label_2_devs         # Key_data()

    errorprint("")
    errorprint("id data:")
    errorprint("")

    if all_ata_ids != '':
        errorprint("")
        words = sort_list(all_ata_ids)
        words = words.split()
        for ata_id in words:
            devs = sort_list(ata_id_2_devs[ata_id])
            tmp = devs.split()
            errorprint("ata id: {0} device{1}: {2}".format(ata_id, plural(len(tmp)), devs))
            parts = sort_list(ata_id_2_parts[ata_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("        {0}".format(part))  # ataidpn:device

    if all_sata_ids != '':
        errorprint("")
        words = sort_list(all_sata_ids)
        words = words.split()
        for sata_id in words:
            devs = sort_list(sata_id_2_devs[sata_id])
            tmp = devs.split()
            errorprint("sata id: {0} device{1}: {2}".format(sata_id, plural(len(tmp)), devs))
            parts = sort_list(sata_id_2_parts[sata_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("         {0}".format(part))  # sataidpn:device

    if all_scsi_ids != '':
        errorprint("")
        words = sort_list(all_scsi_ids)
        words = words.split()
        for scsi_id in words:
            devs = sort_list(scsi_id_2_devs[scsi_id])
            tmp = devs.split()
            errorprint("scsi id: {0} device{1}: {2}".format(scsi_id, plural(len(tmp)), devs))
            parts = sort_list(scsi_id_2_parts[scsi_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("         {0}".format(part))  # scsidpn:device

    if all_fc_ids != '':
        errorprint("")
        words = sort_list(all_fc_ids)
        words = words.split()
        for fc_id in words:
            devs = sort_list(fc_id_2_devs[fc_id])
            tmp = devs.split()
            errorprint("fc id: {0} device{1}: {2}".format(fc_id, plural(len(tmp)), devs))
            parts = sort_list(fc_id_2_parts[fc_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("       {0}".format(part))  # fcidpn:device

    if all_wwn_ids != '':
        errorprint("")
        words = sort_list(all_wwn_ids)
        words = words.split()
        for wwn_id in words:
            devs = sort_list(wwn_id_2_devs[wwn_id])
            tmp = devs.split()
            errorprint("wwn id: {0} device{1}: {2}".format(wwn_id, plural(len(tmp)), devs))
            parts = sort_list(wwn_id_2_parts[wwn_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("        {0}".format(part))  # wwnidpn:device

    if all_uuids != '':
        errorprint("")
        words = sort_list(all_uuids)
        words = words.split()
        for uuid in words:
            devs = sort_list(uuid_2_dev[uuid])
            wc = word_count(devs)
            if wc == 0:
                continue
            disp_uuid = uuid
            if len(uuid) == 32:
                disp_uuid = format_uuid(uuid)
            errorprint("uuid: {0} device{1}: {2}".format(disp_uuid, plural(wc), devs))
        for uuid in words:
            devs = sort_list(uuid_2_pdev[uuid])
            wc = word_count(devs)
            if wc == 0:
                continue
            disp_uuid = uuid
            if len(uuid) == 32:
                disp_uuid = format_uuid(uuid)
            errorprint("partition uuid: {0} device{1}: {2}".format(disp_uuid, plural(wc), devs))

    if all_iscsi_ids != '':
        errorprint("")
        words = sort_list(all_iscsi_ids)
        words = words.split()
        for iscsi_id in words:
            devs = sort_list(iscsi_id_2_devs[iscsi_id])
            tmp = devs.split()
            errorprint("iscsi id: {0} device{1}: {2}".format(iscsi_id, plural(len(tmp)), devs))
            parts = sort_list(iscsi_id_2_parts[iscsi_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("         {0}".format(part))  # iscsidpn:device

    if all_virtio_ids != '':
        errorprint("")
        words = sort_list(all_virtio_ids)
        words = words.split()
        for virtio_id in words:
            devs = sort_list(virtio_id_2_devs[virtio_id])
            tmp = devs.split()
            errorprint("virtio id: {0} device{1}: {2}".format(virtio_id, plural(len(tmp)), devs))
            parts = sort_list(virtio_id_2_parts[virtio_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("           {0}".format(part))  # virtioidpn:device

    if all_usb_ids != '':
        errorprint("")
        words = sort_list(all_usb_ids)
        words = words.split()
        for usb_id in words:
            devs = sort_list(usb_id_2_devs[usb_id])
            tmp = devs.split()
            errorprint("usb id: {0} device{1}: {2}".format(usb_id, plural(len(tmp)), devs))
            parts = sort_list(usb_id_2_parts[usb_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("        {0}".format(part))  # usbidpn:device

    if all_sas_ids != '':
        errorprint("")
        words = sort_list(all_sas_ids)
        words = words.split()
        for sas_id in words:
            devs = sort_list(sas_id_2_devs[sas_id])
            tmp = devs.split()
            errorprint("sas id: {0} device{1}: {2}".format(sas_id, plural(len(tmp)), devs))
            parts = sort_list(sas_id_2_parts[sas_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("        {0}".format(part))  # sasidpn:device

    if all_label_ids != '':
        errorprint("")
        words = sort_list(all_label_ids)
        words = words.split()
        for label_id in words:
            devs = sort_list(label_2_devs[label_id])
            tmp = devs.split()
            errorprint("label id: {0} device{1}: {2}".format(label_id, plural(len(tmp)), devs))
            # parts = sort_list(other_id_2_parts[label_id])
            # if parts != '':
            # ptmp = parts.split()
            # for part in ptmp:
            # print("         {0}".format(part)) # otheridpn:device

    if all_other_ids != '':
        errorprint("")
        words = sort_list(all_other_ids)
        words = words.split()
        for other_id in words:
            devs = sort_list(other_id_2_devs[other_id])
            tmp = devs.split()
            errorprint("other id: {0} device{1}: {2}".format(other_id, plural(len(tmp)), devs))
            parts = sort_list(other_id_2_parts[other_id])
            if parts != '':
                ptmp = parts.split()
                for part in ptmp:
                    errorprint("         {0}".format(part))  # otheridpn:device

    errorprint("")
    errorprint("end id data")
    errorprint("")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: check_scsi_paths()
# check for multiple scsi paths, if not create anomaly
# ---------------------------------------------#
def check_scsi_paths(dm_dev, mpath_dev, sd_devs):
    global dev_2_lun  # Key_data()
    debug_print(3, "{0} {1} '{2}'".format(dm_dev, mpath_dev, sd_devs))

    tmp = sd_devs.split()
    if len(tmp) == 1:
        # anom:only one sd dev for dm-nn
        return

    host_list = ''
    for sd_dev in tmp:
        scsi_adr = dev_2_lun[sd_dev]
        if scsi_adr != '':
            tmp2 = scsi_adr.split(':')
            host = tmp2[0]
            host_list = unique_list(host_list, host)
    host_count = word_count(host_list)
    if host_count == 0:
        anomaly_line = "{0}->{1}->'{2}' has no known scsi hosts".format(dm_dev, mpath_dev, sd_devs)
        handle_anomaly_with_points("SCSI", anomaly_line, 'hardware', 1)
    elif host_count == 1:
        anomaly_line = "Warning: {0}->{1}->'{2}' are only on scsi host {3}".format(dm_dev, mpath_dev, sd_devs, host_list)
        handle_anomaly_with_points("SCSI", anomaly_line, 'hardware', 1)
    else:
        return  # multiple devices in multiple hosts

    return


# ---------------------------------------------#
# function: display_block_major_dm()
# ---------------------------------------------#
def display_block_major_dm(maj):
    global mm_2_bd  # Key_data()

    global dm_2_devs  # Key_data()
    global mp_2_devs  # Key_data()              # key: mp id,               data: device id(s);     e.g. mpathe,  sdab,...
    global major_minor_2_lt  # Key_data()       # key: mm                   data: lintape id;       e.g. 247:12,  IBMtape12
    global mp_2_parts  # Key_data()             # key: mp id,               data: mp part_id(s);    e.g. mpathe,  mpathep1,mpathep2,...
    global max_major
    global max_minor
    global max_dm  # 0 max len of "dm-nnn" names
    global max_dm_nn  # 0 max value of nnn portion of "dm-nnn"

    # global dm_2_path_errs # Counter()
    global mm_2_path_errs  # Counter()
    global dev_2_errs  # Counter()
    global dm_2_lvm_errs  # Counter()           # key: dm id,               data: lvm error count  e.g. dm-215,  1
    global sd_re

    tmp_alias_data = Key_data()

    lit_mm = "ma:mi"
    lit_dm = "dm-dev"
    lit_alias = "alias dev"
    lit_errs = "path / lvm / io errors"
    lit_devs = "devices"

    oz_limit = 16  # more than this many sub devices, assume zoning issue
    dm_oz_dev_cnt = 0  # oz: overzoned, see case
    dm_oz_max = 0
    dm_oz_max_nn = ''

    max_dm_len = len(lit_dm)
    max_alias_len = len(lit_alias)
    max_err_len = len(lit_errs)

    max_dm_len = max(max_dm_len, max_dm)
    minor = get_first_block_minor_no(maj)

    # first loop over the data: accumulate all alias info and put it in tmp_alias_data[mm]
    data_pres = False
    i = 0

    while minor != -1:

        mm = "{0}:{1}".format(maj, minor)
        dm_dev = mm_2_bd[mm]

        if dm_dev == "" and \
           mm_2_bd_aliases[mm] == "" and \
           dm_2_devs[mm] == "":
                continue

        data_pres = True

        tmp_alias_data[mm] = conv_mm_2_bd_alias_list(mm)
        max_alias_len = max(max_alias_len, len(tmp_alias_data[mm]))

        i += 1
        minor = get_next_block_minor_no(maj, i)

    # end: while minor != -1:
    if data_pres is False:
        return

    minor = get_first_block_minor_no(maj)
    hdr_written = False
    i = 0

    while minor != -1:

        mm = "{0}:{1}".format(maj, minor)

        dm_dev = mm_2_bd[mm]
        if dm_dev == "" and \
           tmp_alias_data[mm] == "":
            continue

        if hdr_written is False:
            dm_print("{0} | {1} | {2} | {3} | {4}".
                     format(format_mm(0, 0, lit_mm),
                            lit_dm.ljust(max_dm_len),
                            lit_alias.ljust(max_alias_len),
                            lit_errs.ljust(max_err_len),
                            lit_devs,
                            ))
            hdr_written = True

        blurb = ''
        # p_err  = "{0}".format(dm_2_path_errs[dm_dev])
        p_err = "{0}".format(mm_2_path_errs[conv_id_2_mm(dm_dev, '')])
        # debug_print(z,"{0} {1}".format(dm_dev,dm_2_path_errs[dm_dev])) REMOVE
        io_err = "{0}".format(dev_2_errs[dm_dev])
        lvm_err = "{0}".format(dm_2_lvm_errs[dm_dev])

        err_blurb = "{0} / {1} /{2}".format(p_err.rjust(4), lvm_err.rjust(3), io_err.rjust(6))

        dm_real_devs = dm_2_devs[mm]

        alias_devs = tmp_alias_data[mm]
        tmp = alias_devs.split()
        lvm_alias = False
        for alias_dev in tmp:
            pvs = get_lv_pvs(alias_dev)
            if pvs != '':
                dm_real_devs = dm_real_devs + " " + pvs
                lvm_alias = True
        # end: for alias_dev in tmp:

        dm_real_devs = sort_list(dedup_list(dm_real_devs))

        if not lvm_alias:
            check_for_single_disk_device(mm, dm_real_devs)

        dm_print("{0} | {1} | {2} | {3} | {4}".
                 format(format_mm(0, 0, mm),
                        dm_dev.ljust(max_dm_len),
                        tmp_alias_data[mm].ljust(max_alias_len),
                        err_blurb.ljust(max_err_len),
                        dm_real_devs.strip()
                        ))

        tmp = dm_real_devs.split()
        wc = len(tmp)
        if wc > oz_limit:
            dm_oz_sub_dev_cnt = 0
            for dev in tmp:
                if not re.match(sd_re, dev):
                    continue
                dm_oz_sub_dev_cnt += 1
                dm_oz_max = max(dm_oz_max, wc)
            # end: for dev in tmp:
            if dm_oz_sub_dev_cnt > 8:
                dm_oz_dev_cnt += 1
                dm_oz_max = max(dm_oz_max, dm_oz_sub_dev_cnt)
                if dm_oz_max == dm_oz_sub_dev_cnt:
                    dm_oz_max_nn = dm_dev
        # end: if wc > 8:

        i += 1
        minor = get_next_block_minor_no(maj, i)

    # while minor != -1:

    dm_print("")

    if dm_oz_dev_cnt > 0:
        anomaly_line = "Found {0} dm-nn device{1} with more than {2} sub devices (high: {3} [{4}]) - possible zoning issue".\
                       format(dm_oz_dev_cnt, plural(dm_oz_dev_cnt), oz_limit, dm_oz_max_nn, dm_oz_max)
        handle_anomaly("HW", anomaly_line)
    return


# ---------------------------------------------#
# function dm_print()
# print str is sw_dm is on
# ---------------------------------------------#
def dm_print(string):
    global sw_dm  # False

    if sw_dm:
        errorprint(string)
    return

# ---------------------------------------------#
# function: check_for_single_disk_device()
# create an anomaly if a mp device doesn't point to multiple devices
# ---------------------------------------------#


def check_for_single_disk_device(mm, dm_devs):

    tmp = dm_devs.split()
    disk_count = 0
    disk_id = ''
    for dev in tmp:
        if re.match(sd_re, dev):
            disk_count += 1
            disk_id = dev
    # end: for dev in tmp:

    if disk_count == 1:
        anomaly_line = "multipath device {0} points to a single device [{1}]".format(mm, disk_id)
        handle_anomaly("MULTIPATHCONF", anomaly_line)

    return
# ---------------------------------------------#
# function: get_lv_pvs()
# return all the pvs (physical volumes) for the vg that the lv is in
# ---------------------------------------------#


def get_lv_pvs(lv):
    global vg_2_all_pvs

    vg = split_valid_vg_name(lv, '')
    if vg == '':
        return('')
    return(vg_2_all_pvs[vg])


# ---------------------------------------------#
# function: check_volume_groups()
# ---------------------------------------------#
def check_volume_groups():
    global all_vg_names
    global vg_2_all_lvs
    global vg_2_attr
    global lv_2_path
    global vg_2_all_pvs
    global pv_2_uuid
    global all_vgs_with_no_pvs  # ''

    vgs = all_vg_names.split()
    vg_count = len(vgs)
    debug_print(4, "vg# ={0} '{1}'".format(vg_count, all_vg_names))

    for vg in vgs:

        attr = vg_2_attr[vg]
        lvs = vg_2_all_lvs[vg]
        lvs = lvs.split()
        lv_count = len(lvs)
        # for lv in lvs:
        # end: for lv in lvs:

        pvs = vg_2_all_pvs[vg]
        pvs = pvs.split()
        pv_count = len(pvs)
        # for pv in pvs:
        # end: for pv in pvs:

        debug_print(4, "vg={0} lv# ={1} pv# ={2}".format(vg, lv_count, pv_count))
        if lv_count == 0 or pv_count == 0:
            blurb = ''
            if lv_count == 0:
                if len(attr) == 6 and attr[2] == 'x':
                    blurb = ", volume group e'x'port attribute is on, has the vg been imported?"
            if pv_count == 0:
                all_vgs_with_no_pvs = unique_list(all_vgs_with_no_pvs, vg)
            anomaly_line = "VG {0} contains {1} LV{2} and {3} PV{4}{5}".\
                           format(vg, lv_count, plural(lv_count), pv_count, plural(pv_count), blurb)
            handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 1)

    # end: for vg in vgs:
    debug_print(1, "complete")

    return


# ---------------------------------------------#
# function: display_volume_groups()
# ---------------------------------------------#
def display_volume_groups():
    global all_vg_names
    global vg_2_all_lvs
    global lv_2_path
    global vg_2_all_pvs
    global pv_2_uuid

    vgs = all_vg_names.split()
    wc = len(vgs)

    errorprint("")
    errorprint("Volume Group data ({0} group{1}):".format(wc, plural(wc)))
    errorprint("    {0}".format(all_vg_names))
    errorprint("")

    for vg in vgs:

        lvs = vg_2_all_lvs[vg]
        lvs = lvs.split()
        wcl = len(lvs)
        errorprint("volume group {0} (uuid:{1}) contains the following logical volume{2}:".
                   format(vg, format_uuid(vg_2_uuid[vg]), plural(wcl)))

        for lv in lvs:
            errorprint("    {0} {1} {2} (uuid: {3})".
                       format(lv, lv_2_path[lv], conv_id_2_mm(lv, "lvm"), format_uuid(lv_2_uuid[lv])))

        pvs = vg_2_all_pvs[vg]
        pvs = pvs.split()
        wcp = len(pvs)
        errorprint("volume group {0} contains the following physical volume{1}:".format(vg, plural(wcp)))
        for pv in pvs:
            errorprint("    {0} {1} {2} (uuid: {3})".
                       format(pv, pv_2_path[pv], conv_id_2_mm(pv, ""), format_uuid(pv_2_uuid[pv])))

        errorprint("")

    errorprint("end Volume Group data")
    errorprint("")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: display_filesystems()
# ---------------------------------------------#
def display_filesystems():
    global all_filesystems
    global fs_2_blocks
    global fs_2_type
    global all_fs_types  # ""             # all filesystem types encountered
    global fstype_count  # Counter()      # key: fstype: count of filesystem of various types

    filesystems = all_filesystems.split()

    errorprint("")
    errorprint("Filesystem data:")
    errorprint("")

    for fs in filesystems:
        fstype_count[fs_2_type[fs]] += 1
        if not local_fs(fs, ''):
            continue  # first print all local fs <<<---- local

        display_fs(fs)
    # end: for fs in filesystems:

    # this display will keep like fs types (remote) grouped together
    tmp = all_fs_types.split()
    for fs_type in tmp:
        if local_fs('', fs_type):
            continue  # display non-local filesystems now
        for fs in filesystems:
            if fs_2_type[fs] == fs_type:
                display_fs(fs)
        # end: for fs in filesystems:
    # end: for nlfs in tmp:

    errorprint("")
    errorprint("Filesystem summary:")
    errorprint("")

    tmp = all_fs_types.split()
    for fs_type in tmp:
        cnt = fstype_count[fs_type]
        if cnt == 0:
            continue
        if not local_fs('', fs_type):
            continue  # first print summary of all local fstypes <<<---- local
        errorprint("{0}: {1}".format(fs_type, cnt))
    # end: for fs in filesystems:

    tmp = all_fs_types.split()
    for fs_type in tmp:
        cnt = fstype_count[fs_type]
        if cnt == 0:
            continue
        if local_fs('', fs_type):
            continue  # first print summary of all NON-local fstypes <<<---- NON-local
        errorprint("{0}: {1}".format(fs_type, cnt))
    # end: for fs in filesystems:

    errorprint("")
    errorprint("end Filesystem data")
    errorprint("")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: display_fs()
# ---------------------------------------------#
def display_fs(fs):
    global fs_2_mountpoint
    global fs_2_pctused
    global fs_2_blocks
    global fs_2_block_size
    global fs_2_alias
    global fs_2_type
    global fs_2_opts

    if fs_2_alias[fs] == '':
        alias_blurb = ''
    else:
        alias_blurb = " alias " + fs_2_alias[fs]
    errorprint("{0} mounted on {1} {2} blocks ({3}) {4} used, fs type({5}), mount options ({6}){7}".
               format(fs,
                      fs_2_mountpoint[fs],
                      fs_2_blocks[fs],
                      mg_disp(fs_2_blocks[fs], fs_2_block_size[fs]),
                      fs_2_pctused[fs],
                      fs_2_type[fs],
                      fs_2_opts[fs],
                      alias_blurb))

    if not fs.startswith("/"):
        fs_label_devs = get_devs_in_label(fs)
        if fs_label_devs != '':
            errorprint("[{0}]".format(fs_label_devs))
    return

# ---------------------------------------------#
# function: local_fs()
# return True/False if the fs is local or not
# ---------------------------------------------#


def local_fs(fs, fs_type):
    global fs_2_type
    global non_local_fs_types

    if fs_type == '':
        fs_type = fs_2_type[fs]
    if fs_type == '':
        error_print('d', "'{0}' '{1}' no fs type value".format(fs, fs_type))

    if word_in_list(fs_type, non_local_fs_types):
        return(False)
    return(True)


# ---------------------------------------------#
# function: check_fs_size()
# returns:
# 1: fs size is available for this fs
# 0: fs size is *NOT* available for this fs
# -1: ok not to have fs size for this (type of) fs
# formerly had issued FS anomaly if we can't determine filesystem size:
# ---------------------------------------------#
def check_fs_size(fs):
    global fs_2_type
    global fs_2_mountpoint

    skip_fs_types = "swap autofs auto none fuse"
    skip_fs_devices = "/dev/cdrom /dev/dvd /dev/fd0 /dev/sr0"

    if fs_2_blocks[fs] > 0:
        return(1)

    # no filesystem blockcount, a few other checks to avoid FS size anoms of little or no value...

    if word_in_list(fs_2_type[fs], skip_fs_types):
        return(-1)

    if word_in_list(fs, skip_fs_devices):
        return(-1)

    if fs.startswith("LABEL=") or fs.startswith("UUID="):
        return(-1)  # haven't been able to correlate to actual device

    if fs.endswith("dvd.iso"):
        return(-1)

    # anomaly_line = "Unable to determine filesystem size for {0} mounted on {1}".format(fs_2_mountpoint[fs],fs)
    # handle_anomaly("FS",anomaly_line)
    return(0)


# ---------------------------------------------#
# function: check_fs_dev()
# ensure that we have found the fs device
# True - fs device was found / exists
# False - fs device was not found / does not exist
# ---------------------------------------------#
def check_fs_dev(fs, fs_type):
    global sd_re, sd_re_p, ccd_re, xvd_rd, dm_re

    if fs_type == "iso9660":
        return(True)  # don't need to flag/check iso's

    if fs_type == "gpfs":
        return(True)  # gpfs is an odd beast

    if fs.startswith("/export/home/"):
        return(True)  # don't need to flag/check dynamic home mounts

    if not fs.startswith("/"):
        label_devs = get_devs_in_label(fs)
        if label_devs != '':
            return(True)
    if not fs.startswith("/dev/"):
        # DONE: check for 'fs' as previous mount point. e.g.:
        # /dev/vg_01/LogVol02 mounted on /tmp 9948012 blocks (9.5Gb) 1% used, fs type(ext4), mount options (defaults,nodev,nosuid,rw,seclabel,relatime,barrier=1,data=ordered)
        # /tmp mounted on /var/tmp 9948012 blocks (9.5Gb) 1% used, fs type(none), mount options (rw,nosuid,nodev,bind)
        # 3 unique instances of anomaly type FS found:
        # [1] Unable to find filesystem device for /tmp
        # (case )
        #
        tfs = find_fs_by_mountpoint(fs, fs_type)
        if tfs != '':
            # debug_print(z,tfs)
            return(True)
        return(False)  # should not occur

    _dir = ''

    fs = fs[len("/dev/"):]  # strip off beginning "/dev/"

    if fs.startswith("mapper/"):
        fs = fs[len("mapper/"):]  # strip off "mapper/"
        _dir = "mapper"

    if fs.startswith("asm/"):
        _dir = "asm"

    if re.match(dm_re, fs):
        mm = conv_id_2_mm(fs, '')
        if mm != '':
            return(True)  # have maj/min for /dev/dm-nn ?
        return(False)

    # did fs come in as /dev/VG/LV(/some/dir)  ??
    if re.match(".*/.*\(.*\)", fs):
        paren1 = fs.find('(')
        if paren1 != -1:  # should not be -1..
            fs = fs[0:paren1]  # yes, just search for vg/lv

    # do this stuff if /dev/VG/LV ?? (but not if /dev/mapper/vg-lv )
    # debug_print(z,fs)
    tfs = fs

    # possible /dev/VG/LV name?
    if re.match(".*/.*", fs):
        # tfs = tfs.replace("--","~") #
        tfs = tfs.replace("-", "--")
        tfs = tfs.replace("/", "-")
        tfs = tfs.replace("~", "--")
        # if "VgMdmDB" in fs: debug_print(z,tfs)

    # vxfs doesn't support lvm: https://sort.symantec.com/public/documents/sfha/6.0/linux/productguides/html/sf_admin/ch07s01.htm
    if '-' in tfs and fs_type != "vxfs" and _dir != "asm":  # vg-lv?
        lv = split_valid_lv_name(tfs, 'check_fs_dev')
        # if "VgMdmDB" in fs: debug_print(z,"lv={0}".format(lv))
        if lv != '':
            return(True)  # verifies that both the vg and lv are valid

    mm = conv_id_2_mm(fs, '')
    if mm != '':
        return(True)  # have maj/min for fs dev

    return(False)


# ---------------------------------------------#
# function: display_hba_mfgs()
# ---------------------------------------------#
def display_hba_mfgs():
    global all_hba_mfgs
    global mfg_hba_count  # Counter()
    global total_hosts

    hbas = all_hba_mfgs.split()
    wc = len(hbas)

    errorprint("hba vendor{0} found: {1}".format(plural(wc), all_hba_mfgs))

    total_mfg_hba_count = 0

    for hba in hbas:

        hba_count = mfg_hba_count[hba]

        if hba_count:
            errorprint("    {0} hba{1} found: {2}".
                       format(hba, plural(hba_count), hba_count))
            total_mfg_hba_count += hba_count

    errorprint("")

    if total_mfg_hba_count > total_hosts:  # should not occur
        anomaly_line = "Total mfg hba count[{0}] > total host count[{1}]".format(total_mfg_hba_count, total_hosts)
        handle_anomaly("MFG", anomaly_line)

    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: display_stg_mfgs()
# ---------------------------------------------#
def display_stg_mfgs():
    global all_dev_mfgs
    global mfg_lun_count  # Counter()
    global mfg_models  # Key_data()
    global scsi_host
    global scsi_bus
    global scsi_target
    global scsi_lun
    global total_luns
    global service_procs  # Counter()
    global LIN_TAPED

    mfgs = all_dev_mfgs.split()
    wc = len(mfgs)

    errorprint("storage vendor{0} found: {1}".format(plural(wc), all_dev_mfgs))

    total_mfg_lun_count = 0

    for mfg in mfgs:
        x = mfg_models[mfg].count(",")
        lit_model = "model" if x == 0 else "models"

        lun_count = mfg_lun_count[mfg]
        errorprint("    {0} lun{1} found: {2},   {3}: {4}".
                   format(mfg, plural(lun_count), lun_count, lit_model, mfg_models[mfg]))

        total_mfg_lun_count += lun_count

    if service_procs[LIN_TAPED]:
        errorprint("    IBM lin taped procs: {0}".format(service_procs[LIN_TAPED]))

    errorprint("")

    if total_mfg_lun_count > total_luns:  # should not occur
        anomaly_line = "Total mfg lun count[{0}] > total lun count[{1}]".format(total_mfg_lun_count, total_luns)
        handle_anomaly("MFG", anomaly_line)

    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: display uptime info, check for high load
#
#
# If up more a day and more than an hour in the current day: (12 words)
# hh:mm:ss up nn day, hh:mm, nn users, load average: nn.nn, nn.nn, nn.nn
# hh:mm:ss up nn days, hh:mm, nn users, load average: nn.nn, nn.nn, nn.nn
#
# If up more a day and less than an hour in the current day: (13 words)
# hh:mm:ss up nn day, nn min, nn users, load average: nn.nn, nn.nn, nn.nn
# hh:mm:ss up nn days, nn min, nn users, load average: nn.nn, nn.nn, nn.nn
#
# If up less than an hour: (11 words)
# hh:mm:ss up nn min, nn users, load average: nn.nn, nn.nn, nn.nn
#
# If up less than a day and more than an hour: (10 words)
# hh:mm:ss up hh:mm, nn users, load average: nn.nn, nn.nn, nn.nn
#
# the 'nn.nn, nn.nn, nn.nn' portion is load average for the past 1, 5, and 15 minutes respectively.
# ---------------------------------------------#
def display_uptime():
    global uptime
    global cpus_active
    global per_cpu_load_avg_1min  # 0.0
    global per_cpu_load_avg_5min  # 0.0
    global per_cpu_load_avg_15min  # 0.0

    uptime_blurb = ''
    words = uptime.split()
    wc = len(words)

    if wc >= 10:
        if words[3] == "day," or words[3] == "days,":
            if wc != 12 and wc != 13:
                error_print("d", uptime)
                return
        elif words[3] == "min," or words[3] == "mins,":
            if wc != 11:
                error_print("d", uptime)
                return
        elif wc != 10:
            error_print("d", uptime)
            return

        load_avg_1m = words[wc - 3].rstrip(',')  # 3rd to last word
        load_avg_5m = words[wc - 2].rstrip(',')  # 2nd to last word
        load_avg_15m = words[wc - 1]  # last word

        if is_float(load_avg_1m):  # check to be safe
            ld_avg = float(load_avg_1m)
            if cpus_active > 0 and ld_avg > 1.0:
                per_cpu_load_avg_1min = ld_avg / cpus_active
                if per_cpu_load_avg_1min > 1.0:
                    pass  # uptime_blurb = ATTN+"1 min. per cpu load avg exceeds 1.0"

        if is_float(load_avg_5m):  # check to be safe
            ld_avg = float(load_avg_5m)
            if cpus_active > 0 and ld_avg > 1.0:
                per_cpu_load_avg_5min = ld_avg / cpus_active
                if per_cpu_load_avg_5min > 1.0:
                    pass  # uptime_blurb = ATTN+"5 min. per cpu load avg exceeds 1.0"

        if is_float(load_avg_15m):  # check to be safe
            ld_avg = float(load_avg_15m)
            if cpus_active > 0 and ld_avg > 1.0:
                per_cpu_load_avg_15min = ld_avg / cpus_active
                if per_cpu_load_avg_15min > 1.0:
                    uptime_blurb = ATTN + "15 min. per cpu load avg exceeds 1.0"

    # end: if wc >= 10:

    errorprint("uptime: {0} {1}".format(uptime, uptime_blurb))
    debug_print(1, "complete")
    return

# ---------------------------------------------#
# function: crunch_mem_info
# set total_mem
# ---------------------------------------------#


def crunch_mem_info():
    process_mem_info(False)
    return
# ---------------------------------------------#
# function: display basic memory info
# ---------------------------------------------#


def display_mem_info():
    process_mem_info(True)
    return

# ---------------------------------------------#
# function: process basic memory info
# bDisplay -> True / False indicating process & display or just process
# ---------------------------------------------#


def process_mem_info(bDisplay):

    files = "free sos_commamds/memory/free"
    tmp = files.split()

    for fn in tmp:
        if file_exists_with_data(fn):
            process_mem_file(fn, bDisplay)
            break  # just need to process one of the files
    # end: for fn in tmp:

    return

# ---------------------------------------------#
# function: process basic memory info
# bDisplay -> True / False indicating process & display or just process
# ---------------------------------------------#


def process_mem_file(fn, bDisplay):
    global sysctl  # Key_data()
    global Oracle  # True/False
    global data_xxx_out  # False

    fh = openfile(fn)
    if fh is None:
        return

    used = ''
    free = ''
    bc_adj_avail = False
    Mem_line = ''
    Swap_line = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1

        if "XXX.XXX.XXX.XXX" in line:  # case
            data_xxx_out = True
            continue

        if line.startswith("Mem:"):
            Mem_line = line
            continue

        if line.startswith("-/+ buffers/cache:") and i == 3:
            bc_adj_avail = True
            tmp = line.split()
            used = tmp[2]
            free = tmp[3]
            continue

        if line.startswith("Swap:"):
            Swap_line = line
            continue

    # end: for line in fh:

    if Mem_line != '':
        if bc_adj_avail:
            tmp = Mem_line.split()
            wc = len(tmp)
            if wc > 4:
                tline = "{0} {1} {2} {3} {4} {5} {6}".format(tmp[0], tmp[1], used, free, tmp[4], tmp[5], tmp[6])
            else:
                tline = "{0} {1} {2} {3}".format(tmp[0], tmp[1], used, free)
            mem_disp(tline, bDisplay)
        else:
            mem_disp(Mem_line, bDisplay)

    if Swap_line != '':
        mem_disp(Swap_line, bDisplay)

    # mem_hp_tcnt = sysctl['meminfo.HugePages_Total']
    mem_hp_tcnt = sysctl['vm.nr_hugepages']
    mem_hp_fcnt = sysctl['meminfo.HugePages_Free']
    mem_hp_ucnt = mem_hp_tcnt - mem_hp_fcnt
    mem_hp_size = get_hugepage_size()

    if mem_hp_tcnt > 0:
        mem_hp_tsize = mem_hp_tcnt * mem_hp_size
        if bDisplay:
            errorprint("Huge pages in use, page size: {0}, total pages: {1}".
                       format(mg_disp(mem_hp_size, 1), mem_hp_tcnt))

        # divide by 1k as mem_disp expects values in kb
        hpl = "HugePages: {0} {1} {2}".format((mem_hp_tsize / kb),
                                              (mem_hp_ucnt * mem_hp_size / kb),
                                              (mem_hp_fcnt * mem_hp_size / kb))
        mem_disp(hpl, bDisplay)

        if bDisplay:
            errorprint("HugePages: {0}% of total memory".format(pct_disp(mem_hp_tsize, total_mem * kb)))

        # errorprint(" TODO: can we make a recommendation on a max value for vm.nr_hugepages?")
        # TODO: can we determine if HugePageCnt is too high?? e.g. shouldn't more that 25% of total mem??
        # TODO: per Nick Yelle in case , 75% of memory is the rule of thumb for hugepage allocations

        if mem_hp_tcnt == mem_hp_fcnt:
            if Oracle:
                oracle_blurb = "Check Oracle configuration"
            else:
                oracle_blurb = ""
            anomaly_line = "Huge pages allocated, but none in use. {0}".format(oracle_blurb)
            handle_anomaly_with_points("MEM", anomaly_line, 'configuration', 1)

    # end: if mem_hp_tcnt > 0:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# Function display_scsi_errors()
# ---------------------------------------------#


def display_scsi_errors():
    global scsi_err_count  # Counter()
    global scsi_err_dev_ids  # Key_data()
    global scsi_err_scsi_adrs  # Key_data()
    global scsi_err_desc  # Key_data()
    global all_scsi_err_codes  # ""

    words = all_scsi_err_codes.split()
    wc = len(words)
    if wc == 0:
        return

    med_err_kcs = " See KCS {0}".format(kcs_url("35465"))

    scsi_err_desc["0x00000018"] = "Reservation conflict"
    scsi_err_desc["0x00010000"] = "IO could not be issued as there is no connection to the device."
    scsi_err_desc["0x00020000"] = "A bus busy condition is being returned back from the hardware which prevents the command from being processed."
    scsi_err_desc["0x00020008"] = "Device is truely busy; not a transport issue."
    scsi_err_desc["0x00040000"] = "Target device is not usable."
    scsi_err_desc["0x00070000"] = "The driver detected an anomolous condition within the returned completion information from storage."
    scsi_err_desc["0x00070028"] = "The key issue is the queue full condition.  The DID_ERROR is likely secondary to the queue full."
    scsi_err_desc["0x000D0000"] = "Known issue. See BZ {0}".format(bz_url("627836"))
    scsi_err_desc["0x000F0000"] = "The FAILFAST option is enabled so if/when a error is encountered, the io is immediately returned up the io stack rather then being retried (as it normally would be)."
    scsi_err_desc["0x00110018"] = "A reservation conflict scsi status has been returned by the storage device."
    scsi_err_desc["0x06000000"] = "Commands timing out"
    scsi_err_desc["0x06000008"] = "The SAM_STAT_BUSY is the scsi status code back from the target (disk, device)."
    scsi_err_desc["0x60D00000"] = "Command has timed out, being requeued rather than immediately retried."
    scsi_err_desc["0x08000002"] = "Device has returned back a CHECK CONDITION (CC) SCSI status and a sense buffer." + med_err_kcs
    scsi_err_desc["0x08070002"] = "IO failing with medium error, or other target type failure against device." + med_err_kcs
    scsi_err_desc["0x08100002"] = "The IO is failing with sense information that flags the device as in a permanent error state." + med_err_kcs

    errorprint("")
    errorprint("summary of scsi errors as described in KCS {0}:".format(kca_url("280653")))
    errorprint("")

    for code in words:
        sa_cnt = word_count(scsi_err_scsi_adrs[code])
        di_cnt = word_count(scsi_err_dev_ids[code])
        errorprint("scsi error code: {0} [count: {1}, scsi address count {2}, device id count {3}]".
                   format(code, scsi_err_count[code], sa_cnt, di_cnt))
        # print("     scsi address{0}: {1}  device id{2}: {3}".format(plurale(sa_cnt),sa_cnt,plural(di_cnt),di_cnt))
        # print("     device ids: {0}".format(scsi_err_dev_ids[code]))
        desc = scsi_err_desc[code]
        if desc == "":
            # desc = build_scsi_desc(code)
            desc = "<not available>"
        build_scsi_desc(code)
        errorprint("     description: {0}".format(desc))
        # print("     breakdown: {0}".format(build_scsi_desc(code)))
        errorprint("")

    # print("")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: build_scsi_desc()
# code = "0x12 34 56 78"
# /\ /\ /\ /\
# |  |  |  |
# driver byte ---------------+  |  |  |
# host byte --------------------+  |  |
# message byte---------------------+  |
# status byte ------------------------+
# ---------------------------------------------#
def build_scsi_desc(code):
    if len(code) != 10 or not code.startswith("0x"):
        return("?:{0}".format(code))

    status_byte = Key_data()

    status_byte["00"] = "SAM_STAT_GOOD - Target has successfully completed the command"
    status_byte["02"] = "SAM_STAT_CHECK_CONDITION - Indicates a contingent allegiance condition has occurred (see sense buffer for more details)"
    status_byte["04"] = "SAM_STAT_CONDITION_MET - Requested operation is satisfied"
    status_byte["08"] = "SAM_STAT_BUSY - Indicates the target is busy. Returned whenever a target is unable to accept a command from an otherwise acceptable initiator."
    status_byte["10"] = "SAM_STAT_INTERMEDIATE - Shall be returned for every successfully completed command in a series of linked commands (except the last command)"
    status_byte["14"] = "SAM_STAT_INTERMEDIATE_CONDITION_MET - Combination of CONDITION MET and INTERMEDIATE status's."
    status_byte["18"] = "SAM_STAT_RESERVATION_CONFLICT - Logical unit or an extent (portion) within the logical unit is reserved for another device"
    status_byte["22"] = "SAM_STAT_COMMAND_TERMINATED - Target terminates the current I/O process. This also indicates that a contingent allegiance condition has occurred."
    status_byte["28"] = "SAM_STAT_TASK_SET_FULL - Shall be implemented if tagged command queuing is supported. Indicated that the target command queue is full."
    status_byte["30"] = "SAM_STAT_ACA_ACTIVE - Indicates an auto contingent allegiance condition exists"
    status_byte["40"] = "SAM_STAT_TASK_ABORTED"                # 0x40

    message_byte = Key_data()
    message_byte["00"] = "COMMAND_COMPLETE"                    # 0x00
    message_byte["01"] = "EXTENDED_MESSAGE"                    # 0x01
    # message_byte["00"] = "EXTENDED_MODIFY_DATA_POINTER"        # 0x00
    # message_byte["01"] = "EXTENDED_SDTR"                       # 0x01
    # message_byte["02"] = "EXTENDED_EXTENDED_IDENTIFY"          # 0x02    /* SCSI-I only */
    # message_byte["03"] = "EXTENDED_WDTR"                       # 0x03
    message_byte["02"] = "SAVE_POINTERS"                       # 0x02
    message_byte["03"] = "RESTORE_POINTERS"                    # 0x03
    message_byte["04"] = "DISCONNECT"                          # 0x04
    message_byte["05"] = "INITIATOR_ERROR"                     # 0x05
    message_byte["06"] = "ABORT"                               # 0x06
    message_byte["07"] = "MESSAGE_REJECT"                      # 0x07
    message_byte["08"] = "NOP"                                 # 0x08
    message_byte["09"] = "MSG_PARITY_ERROR"                    # 0x09
    message_byte["0a"] = "LINKED_CMD_COMPLETE"                 # 0x0a
    message_byte["0b"] = "LINKED_FLG_CMD_COMPLETE"             # 0x0b
    message_byte["0c"] = "BUS_DEVICE_RESET"                    # 0x0c

    message_byte["0f"] = "INITIATE_RECOVERY"                   # 0x0f            /* SCSI-II only */
    message_byte["10"] = "RELEASE_RECOVERY"                    # 0x10            /* SCSI-II only */
    message_byte["20"] = "SIMPLE_QUEUE_TAG"                    # 0x20
    message_byte["21"] = "HEAD_OF_QUEUE_TAG"                   # 0x21
    message_byte["22"] = "ORDERED_QUEUE_TAG"                   # 0x22

    host_byte = Key_data()
    host_byte["00"] = "DID_OK - NO error"
    host_byte["01"] = "DID_NO_CONNECT - Couldn't connect before timeout period"
    host_byte["02"] = "DID_BUS_BUSY - BUS stayed busy through time out period"
    host_byte["03"] = "DID_TIME_OUT - TIMED OUT for other reason"
    host_byte["04"] = "DID_BAD_TARGET - BAD target"
    host_byte["05"] = "DID_ABORT - Told to abort for some other reason"
    host_byte["06"] = "DID_PARITY - Parity error"
    host_byte["07"] = "DID_ERROR - Internal error"
    host_byte["08"] = "DID_RESET - Reset by somebody"
    host_byte["09"] = "DID_BAD_INTR - Got an interrupt we weren't expecting"
    host_byte["0a"] = "DID_PASSTHROUGH - Force command past mid-layer"
    host_byte["0b"] = "DID_SOFT_ERROR - The low level driver just wish a retry"
    host_byte["0c"] = "DID_IMM_RETRY - Retry without decrementing retry count"
    host_byte["0d"] = "DID_REQUEUE - Requeue"
    # host_byte["0e"] = "DID_COND_REQUEUE - Requeue cmd w/o decr of retry count IFF"
    host_byte["0e"] = "DID_TRANSPORT_DISRUPTED - Transport error disrupted execution"
    host_byte["0f"] = "DID_TRANSPORT_FAILFAST - Transport class fastfaileld the io"
    host_byte["10"] = "DID_TARGET_FAILURE - Permanent target failure, do not retry on other paths"
    host_byte["11"] = "DID_NEXUS_FAILURE - Permanent nexus failure, retry on other paths might yield different results"
    host_byte["12"] = "DID_ALLOC_FAILURE - Space allocation on device failed"
    host_byte["13"] = "DID_MEDIUM_FAILURE - Medium error"

    driver_byte = Key_data()
    driver_byte["00"] = "DRIVER_OK - Driver status"
    driver_byte["01"] = "DRIVER_BUSY"
    driver_byte["02"] = "DRIVER_SOFT"
    driver_byte["03"] = "DRIVER_MEDIA"
    driver_byte["04"] = "DRIVER_ERROR"
    driver_byte["05"] = "DRIVER_INVALID"
    driver_byte["06"] = "DRIVER_TIMEOUT"
    driver_byte["07"] = "DRIVER_HARD"
    driver_byte["08"] = "DRIVER_SENSE - scsi sense buffer available from target"
    driver_byte["10"] = "SUGGEST_RETRY"
    driver_byte["20"] = "SUGGEST_ABORT"
    driver_byte["30"] = "SUGGEST_REMAP"
    driver_byte["40"] = "SUGGEST_DIE"
    driver_byte["80"] = "SUGGEST_SENSE"
    driver_byte["ff"] = "SUGGEST_IS_OK"
    driver_byte["0f"] = "DRIVER_MASK"
    driver_byte["f0"] = "SUGGEST_MASK"

    sb_ss = code[8:10]
    mb_ss = code[6:8]
    hb_ss = code[4:6]
    db_ss = code[2:4]
    # "0x" = code[0:2]

    sb_desc = status_byte[sb_ss]
    if sb_desc == "":
        sb_desc = "??"
    disp_scsi_ec_byte(3, sb_ss, sb_desc)

    mb_desc = message_byte[mb_ss]
    if mb_desc == "":
        mb_desc = "??"
    disp_scsi_ec_byte(2, mb_ss, mb_desc)

    hb_desc = host_byte[hb_ss]
    if hb_desc == "":
        hb_desc = "??"
    disp_scsi_ec_byte(1, hb_ss, hb_desc)

    db_desc = driver_byte[db_ss]
    if db_desc == "":
        db_desc = "??"
    disp_scsi_ec_byte(0, db_ss, db_desc)
    # return("db:{0}:{1}/hb:{2}:{3}/mb:{4}:{5}/sb:{6}:{7}".\
    # format(db_ss,db_desc,hb_ss,hb_desc,mb_ss,mb_desc,sb_ss,sb_desc))

    return


# ---------------------------------------------#
# function: disp_scsi_ec_byte()
# ---------------------------------------------#
def disp_scsi_ec_byte(byte_no, by_ss, by_desc):
    if byte_no == 3:
        msg_beg = "                         " + by_ss + "   status byte: "
    elif byte_no == 2:
        msg_beg = "                       " + by_ss + "        msg byte: "
    elif byte_no == 1:
        msg_beg = "                     " + by_ss + "         host byte: "
    elif byte_no == 0:
        msg_beg = "                   " + by_ss + "         driver byte: "
    else:
        error_print('d', '{0} ??'.format(byte_no))

    errorprint(msg_beg + by_desc)

# ---------------------------------------------#
# function: tainted_desc(taint_mask,rhel_major_version)
# print any/all taint bit descriptions
# ---------------------------------------------#


def tainted_desc(tm, rhmv):

    if tm == -1:
        errorprint("Unable to get value of kernel symbol tainted_mask")
        return
    hexdig = "%x" % tm
    padded = hexdig.zfill(8)  # pad with 0 if necessary
    oxd = "0x" + padded
    # print(oxd)
    if tm == 0:
        # print('Note: taint mask {0} - kernel not tainted'.format(oxd))
        return
    tech_prev = ", see {0}".format(kcs_url("21101"))
    errorprint('Warning: taint mask {0} - kernel tainted'.format(oxd))

    rh5_taint_array = "0x00000001 PROPRIETARY_MODULE: Proprietary module(s) has been loaded\n"\
        "0x00000002 FORCED_MODULE: Module has been forcibly loaded\n"\
        "0x00000004 UNSAFE_SMP: SMP with CPUs not designed for SMP\n"\
        "0x00000008 FORCED_RMMOD: User forced a module(s) unload\n"\
        "0x00000010 MACHINE_CHECK: System experienced a machine check exception\n"\
        "0x00000020 BAD_PAGE: System has hit bad_page\n"\
        "0x00000040 UNSIGNED_MODULE: Unsigned module(s) has been loaded\n"\
        "0x00000080 BIT  7: undefined/reserved\n"\
        "0x00000100 BIT  8: undefined/reserved\n"\
        "0x00000200 BIT  9: undefined/reserved\n"\
        "0x00000400 BIT 10: undefined/reserved\n"\
        "0x00000800 BIT 11: undefined/reserved\n"\
        "0x00001000 BIT 12: undefined/reserved\n"\
        "0x00002000 BIT 13: undefined/reserved\n"\
        "0x00004000 BIT 14: undefined/reserved\n"\
        "0x00008000 BIT 15: undefined/reserved\n"\
        "0x00010000 BIT 16: undefined/reserved\n"\
        "0x00020000 BIT 17: undefined/reserved\n"\
        "0x00040000 BIT 18: undefined/reserved\n"\
        "0x00080000 BIT 19: undefined/reserved\n"\
        "0x00100000 BIT 20: undefined/reserved\n"\
        "0x00200000 BIT 21: undefined/reserved\n"\
        "0x00400000 BIT 22: undefined/reserved\n"\
        "0x00800000 BIT 23: undefined/reserved\n"\
        "0x01000000 BIT 24: undefined/reserved\n"\
        "0x02000000 BIT 25: undefined/reserved\n"\
        "0x04000000 BIT 26: undefined/reserved\n"\
        "0x08000000 BIT 27: undefined/reserved\n"\
        "0x10000000 HARDWARE_UNSUPPORTED: Hardware is unsupported " + ATTN + "\n"\
        "0x20000000 TECH_PREVIEW: Technology Preview code is loaded " + tech_prev + "\n"\
        "0x40000000 BIT 30: undefined/reserved\n"\
        "0x80000000 BIT 31: undefined/reserved"

    rh6_taint_array = "0x00000001 PROPRIETARY_MODULE: Proprietary module(s) has been loaded\n"\
        "0x00000002 FORCED_MODULE: Module has been forcibly loaded\n"\
        "0x00000004 UNSAFE_SMP: SMP with CPUs not designed for SMP\n"\
        "0x00000008 FORCED_RMMOD: User forced a module(s) unload\n"\
        "0x00000010 MACHINE_CHECK: System experienced a machine check exception\n"\
        "0x00000020 BAD_PAGE: System has hit bad_page\n"\
        "0x00000040 USER: The user has asked that the system be marked tainted\n"\
        "0x00000080 DIE: Kernel has oopsed before\n"\
        "0x00000100 OVERRIDDEN_ACPI_TABLE: ACPI table overridden\n"\
        "0x00000200 WARN: A kernel warning has occurred\n"\
        "0x00000400 CRAP: Modules from drivers/staging are loaded\n"\
        "0x00000800 FIRMWARE_WORKAROUND: Working around severe firmware bug\n"\
        "0x00001000 BIT 12: undefined/reserved\n"\
        "0x00002000 BIT 13: undefined/reserved\n"\
        "0x00004000 BIT 14: undefined/reserved\n"\
        "0x00008000 BIT 15: undefined/reserved\n"\
        "0x00010000 BIT 16: undefined/reserved\n"\
        "0x00020000 BIT 17: undefined/reserved\n"\
        "0x00040000 BIT 18: undefined/reserved\n"\
        "0x00080000 BIT 19: undefined/reserved\n"\
        "0x00100000 BIT 20: undefined/reserved\n"\
        "0x00200000 BIT 21: undefined/reserved\n"\
        "0x00400000 BIT 22: undefined/reserved\n"\
        "0x00800000 BIT 23: undefined/reserved\n"\
        "0x01000000 BIT 24: undefined/reserved\n"\
        "0x02000000 BIT 25: undefined/reserved\n"\
        "0x04000000 BIT 26: undefined/reserved\n"\
        "0x08000000 BIT_BY_ZOMBIE: Kernel booted with OMGZOMBIES param\n"\
        "0x10000000 HARDWARE_UNSUPPORTED: Hardware is unsupported " + ATTN + "\n"\
        "0x20000000 TECH_PREVIEW: Technology Preview code is loaded " + tech_prev + "\n"\
        "0x40000000 BIT 30: undefined/reserved\n"\
        "0x80000000 BIT 31: undefined/reserved\n"

    rh7_taint_array = "0x00000001 PROPRIETARY_MODULE: Proprietary module(s) has been loaded\n"\
        "0x00000002 FORCED_MODULE: Module has been forcibly loaded\n"\
        "0x00000004 UNSAFE_SMP: SMP with CPUs not designed for SMP\n"\
        "0x00000008 FORCED_RMMOD: User forced a module(s) unload\n"\
        "0x00000010 MACHINE_CHECK: System experienced a machine check exception\n"\
        "0x00000020 BAD_PAGE: System has hit bad_page\n"\
        "0x00000040 USER: The user has asked that the system be marked tainted\n"\
        "0x00000080 DIE: Kernel has oopsed before\n"\
        "0x00000100 OVERRIDDEN_ACPI_TABLE: ACPI table overridden\n"\
        "0x00000200 WARN: A kernel warning has occurred\n"\
        "0x00000400 CRAP: Modules from drivers/staging are loaded\n"\
        "0x00000800 FIRMWARE_WORKAROUND: Working around severe firmware bug\n"\
        "0x00001000 OOT_MODULE: Out-of-tree module(s) has been loaded\n"\
        "0x00002000 UNSIGNED_MODULE: Unsigned module(s) has been loaded\n"\
        "0x00004000 SOFTLOCKUP: A soft lockup has previously occurred\n"\
        "0x00008000 BIT 15: undefined/reserved\n"\
        "0x00010000 BIT 16: undefined/reserved\n"\
        "0x00020000 BIT 17: undefined/reserved\n"\
        "0x00040000 BIT 18: undefined/reserved\n"\
        "0x00080000 BIT 19: undefined/reserved\n"\
        "0x00100000 BIT 20: undefined/reserved\n"\
        "0x00200000 BIT 21: undefined/reserved\n"\
        "0x00400000 BIT 22: undefined/reserved\n"\
        "0x00800000 BIT 23: undefined/reserved\n"\
        "0x01000000 BIT 24: undefined/reserved\n"\
        "0x02000000 BIT 25: undefined/reserved\n"\
        "0x04000000 BIT 26: undefined/reserved\n"\
        "0x08000000 BIT 27: undefined/reserved\n"\
        "0x10000000 HARDWARE_UNSUPPORTED: Hardware is unsupported " + ATTN + "\n"\
        "0x20000000 TECH_PREVIEW: Technology Preview code is loaded " + tech_prev + "\n"\
        "0x40000000 BIT 30: undefined/reserved\n"\
        "0x80000000 BIT 31: undefined/reserved\n"

    if rhmv == 5:
        tainted_detail(tm, rh5_taint_array)
    elif rhmv == 6:
        tainted_detail(tm, rh6_taint_array)
    elif rhmv == 7:
        tainted_detail(tm, rh7_taint_array)
    else:
        errorprint("unrecognized Red Hat major release: {0}".format(rhmv))

    return


# ---------------------------------------------#
# function: tainted_detail(taint_mask,taint_list)
# ---------------------------------------------#
def tainted_detail(taint_mask, taint_list):  # print any/all taint bit descriptions
    global sw_tained_mods

    tmp = taint_list.split("\n")
    # for ele in sorted(taint_list):
    i = 0

    for ele in tmp:
        tm_tmp = taint_mask & (2**i)
        if tm_tmp > 0:
            errorprint("Warning: Bit {0}: {1}".format(i, ele))
            if tm_tmp == 1:
                sw_tainted_mods = True
        i = i + 1
    # end: for ele in tmp:
    # end: for ele in sorted(taint_list):

    return


# ---------------------------------------------#
# function: chk_performance()
# ---------------------------------------------#
def chk_performance():
    global sysctl
    global total_mem
    global Oracle
    global sar_device_perf_data  # False
    global all_fs_types

    perf_print("** start of performance related section **")
    perf_print("")
    vm_db = int(sysctl["vm.dirty_bytes"])            # deprecated
    vm_dbb = int(sysctl["vm.dirty_background_bytes"])  # deprecated
    vm_dr = int(sysctl["vm.dirty_ratio"])
    vm_dbr = int(sysctl["vm.dirty_background_ratio"])
    vm_dec = int(sysctl["vm.dirty_expire_centisecs"])
    vm_dwc = int(sysctl["vm.dirty_writeback_centisecs"])

    if vm_dbb > 0 or vm_db > 0:
        perf_print("Warning: using deprecated settings: vm.dirty_background_bytes[{0}] vm.dirty_bytes[{1}]".
                   format(vm_dbb, vm_db))

    if vm_dr > 0:
        vm_db = (vm_dr * .01) * (total_mem * 1024)

    if vm_dbr > 0:
        vm_dbb = (vm_dbr * .01) * (total_mem * 1024)

    perf_print("** dirty page checks (write cache)")
    perf_print("** Note: HAVING TO SUDDENLY WRITE OUT A LARGE NUMBER OF DIRTY PAGES CAN STALL APPLICATION PROCESSES")
    perf_print("** flusher threads will wake up every {0} centisecs and check for dirty data to write out".
               format(vm_dwc))
    perf_print("**   knob: {0}".format("vm.dirty_writeback_centisecs"))

    perf_print("** flusher threads will start writing out dirty pages when total dirty pages exceed {0} ({1}%)".
               format(mg_disp(vm_dbb, 1), vm_dbr))
    perf_print("**   knob: {0}".format("vm.dirty_background_ratio"))
    perf_print("** flusher threads will start writing out data which has been dirty in-memory for longer than {0} centisecs".
               format(vm_dec))
    perf_print("**   knob: {0}".format("vm.dirty_expire_centisecs"))

    perf_print("** any single process will start writing out dirty pages when its total dirty pages exceed {0} ({1}%)".
               format(mg_disp(vm_db, 1), vm_dr))
    perf_print("**   knob: {0}".format("vm.dirty_ratio"))
    # TODO: need recommendations for vm.dirty... settings
    # perf_print("**   TODO: need recommendations for vm.dirty... settings")

    vm_mfk = int(sysctl["vm.min_free_kbytes"])
    r_mfk = 0
    if total_mem <= (4 * (gb / kb)):
        r_mfk = (32 * (mb / kb))
    elif total_mem <= (8 * (gb / kb)):
        r_mfk = (64 * (mb / kb))
    elif total_mem <= (16 * (gb / kb)):
        r_mfk = (96 * (mb / kb))
    elif total_mem <= (64 * (gb / kb)):
        r_mfk = (128 * (mb / kb))
    elif total_mem <= (128 * (gb / kb)):
        r_mfk = (256 * (mb / kb))
    else:
        r_mfk = (512 * (mb / kb))
    perf_print("**")
    perf_print("** minimum kernel free memory setting check")
    perf_print("** HAVING TOO LITTLE MINIMUM FREE MEMORY CAN CAUSE GLOBAL KERNEL LOCK AND STALL")
    perf_print("**   see KCS {0}".format(kcs_url("1460103")))
    perf_print("** vm.min_free_kbytes checks are based on total available memory of {0}".format(mg_disp(total_mem, kb)))
    system_check('vm.min_free_kbytes', 'GE', r_mfk, "R", kb)

    # if Oracle is True or sw_sim_oracle:
    if database_procs["Oracle"] > 0 or sw_sim_oracle:
        chk_oracle_performance()

    if database_procs["Db2"] > 0:
        chk_db2_performance()

    if database_procs["sybase"] > 0:
        chk_sybase_performance()

    if database_procs["MySQL"] > 0:
        chk_mysql_performance()

    if (Virtual_guest and Virtual_type == "VMware") or sw_sim_vmware:
        chk_vmware_performance()

    if "nfs" in all_fs_types:
        chk_nfs_perf()

    if sar_device_perf_data:  # exceptional sar device performance data to report on?
        report_on_sar_device_data()

    display_top_cpu_procs()
    display_top_mem_procs()
    display_top_tim_procs()

    perf_print("")
    perf_print("** end of performance related section **")
    perf_print("")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: report_on_sar_device_data():
# ---------------------------------------------#
def report_on_sar_device_data():
    global await_dev_samples  # counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
    global await_dev_total_time  # counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
    global svctm_dev_samples  # counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
    global svctm_dev_total_time  # counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
    global lo_major_perf  # big_num
    global hi_major_perf  # 0
    global lo_minor_perf  # Key_data_min()
    global hi_minor_perf  # Key_data_max()
    global high_await_mm  # ''
    global high_await_time  # 0
    global high_svctm_mm  # ''
    global high_svctm_time  # 0
    global host_await_event_count  # Counter()  # key: host,                data: count of excessive await events for this host from sar data
    global host_await_device_count  # Counter() # key: host,                data: count of excessive await events for this host from sar data
    global host_svctm_event_count  # Counter()  # key: host,                data: count of excessive svctm events for this host from sar data
    global host_svctm_device_count  # Counter() # key: host,                data: count of excessive svctm events for this host from sar data
    global max_host  # 0
    global Virtual_guest, Virtual_type
    global dev_2_lun  # Key_data()

    # TODO: see if kcs 400403 can be worked into analysis, see case

    dm_await_samples = 0
    dm_await_total_time = 0
    dm_svctm_samples = 0
    dm_svctm_total_time = 0
    non_dm_await_samples = 0
    non_dm_await_total_time = 0
    non_dm_svctm_samples = 0
    non_dm_svctm_total_time = 0

    perf_print("**")
    perf_print("** start of sar performance await and svctm reporting")
    perf_print("**")

    dm_major = get_device_mapper_major()

    for i in range(lo_major_perf, hi_major_perf + 1):

        lo_min_perf = lo_minor_perf[i]
        hi_min_perf = hi_minor_perf[i]

        if hi_min_perf == -1:
            continue  # no data captured for this major number
        debug_print(3, "{0}:{1}-{2}".format(i, lo_min_perf, hi_min_perf))

        for j in range(lo_min_perf, hi_min_perf + 1):
            mm = "{0}:{1}".format(i, j)

            dev_id = ''
            lun = ''
            host = -1

            await_samples = await_dev_samples[mm]
            svctm_samples = svctm_dev_samples[mm]
            if await_samples == 0 and svctm_samples == 0:
                continue

            dev_id = conv_mm_2_bd(mm)
            top_ten_dev_id = dev_id
            if top_ten_dev_id == "":
                top_ten_dev_id = mm  # should be a rare occurence

            dev_blurb = ''
            alias_blurb = ''
            if dev_id != '' and i != dm_major:
                lun = dev_2_lun[dev_id]
                dev_blurb = "{0} {1}".format(dev_id, lun)
                if lun != '':
                    tmp = lun.split(':')
                    if tmp[0].isdigit():
                        host = int(tmp[0])
            elif dm_major == i:
                alias = mm_2_bd_aliases[mm]
                if alias != '':
                    tmp = alias.split()
                    for tmp_alias in tmp:
                        alias_blurb = squeeze("{0} {1}".format(alias_blurb, perf_alias_expand(tmp_alias)))
                    # end: for tmp_alias in tmp:
                dev_blurb = squeeze("{0} {1} {2}".format(dev_id, dm_2_devs[mm], alias_blurb))

            if await_dev_samples[mm] > 0:
                aa = round((await_dev_total_time[mm] / await_samples), 2)
                track_top_await_devs(aa, await_samples, top_ten_dev_id)
                await_avg = "{0}".format(aa)
                if dm_major == i:
                    dm_await_samples += await_samples
                    dm_await_total_time += await_dev_total_time[mm]
                else:
                    non_dm_await_samples += await_samples
                    non_dm_await_total_time += await_dev_total_time[mm]
                if host >= 0:
                    host_await_device_count[host] += 1
                    host_await_event_count[host] += await_samples
            else:
                await_avg = "n/a"

            if svctm_dev_samples[mm] > 0:
                sa = round((svctm_dev_total_time[mm] / svctm_samples), 2)
                track_top_svctm_devs(sa, svctm_samples, top_ten_dev_id)
                svctm_avg = "{0}".format(sa)
                if dm_major == i:
                    dm_svctm_samples += svctm_samples
                    dm_svctm_total_time += svctm_dev_total_time[mm]
                else:
                    non_dm_svctm_samples += svctm_samples
                    non_dm_svctm_total_time += svctm_dev_total_time[mm]
                if host >= 0:
                    host_svctm_device_count[host] += 1
                    host_svctm_event_count[host] += svctm_samples
            else:
                svctm_avg = "n/a"

            dev_blurb = dev_blurb.strip()
            perf_print("dev{0}-{1} await avg: {2} events: {3}  svctm avg: {4} events {5}  device: {6}".
                       format(i, j, await_avg, await_samples, svctm_avg, svctm_samples, dev_blurb))

        # end: for j in range(lo_min_perf,hi_min_perf+1):

    # end: for i in range(lo_major_perf,hi_major_perf+1):
    perf_print("")

    display_top_await_devs()
    display_top_svctm_devs()

    pvscsi_host_count = 0
    for host in range(0, max_host + 1):
        shl = get_host_desc("{0}".format(host))
        if 'PVSCSI' in shl:
            pvscsi_host_count += 1
    # end: for host in range(0,max_host+1):

    for host in range(0, max_host + 1):
        haec = host_await_event_count[host]
        hadc = host_await_device_count[host]

        hsec = host_svctm_event_count[host]
        hsdc = host_svctm_device_count[host]

        shl = get_host_desc("{0}".format(host))
        hba_mfg = get_hba_mfg(shl)
        pvscsi = 'PVSCSI' in shl
        debug_print(3, "{0} {1} {2} {3} {4} {5} '{6}'".format(host, haec, hadc, hsec, hsdc, pvscsi, shl))
        cpl_max = 254  # cmd_per_lun max

        if haec > 0:  # atime events for this host (hba)?
            if pvscsi:
                p = shl.find('cmd_per_lun=')
                if p != -1:
                    thl = shl[p:]
                    tmp = thl.split()
                    thl = tmp[0]
                    tmp = thl.split('=')
                    cmd_per_lun = tmp[1].strip()
                    if cmd_per_lun != '' and cmd_per_lun.isdigit():
                        cpl = int(cmd_per_lun)
                        if cpl < cpl_max:
                            anomaly_line = "{0} host {1} has {2} device{3} with {4} 'sar-await' event{5}, consider raising 'cmd_per_lun' from {6} to {7}, see {8}".\
                                format(hba_mfg, host, hadc, plural(hadc), haec, plural(haec), cpl, cpl_max, kcs_url("625853"))
                            handle_anomaly_with_points("VMWARE", anomaly_line, 'performance', 10 * hadc)
                        else:
                            anomaly_line = "{0} host {1} has {2} device{3} with {4} 'sar-await' event{5}, however 'cmd_per_lun' already at or above {6}, consult {7} team".\
                                format(hba_mfg, host, hadc, plural(hadc), haec, plural(haec), cpl_max, Virtual_type)
                            handle_anomaly_with_points("VMWARE", anomaly_line, 'performance', 10 * hadc)

        if hsec > 0:  # svctm events for this host (hba)?
            if pvscsi:
                if pvscsi_host_count == 1:
                    anomaly_line = "{0} host {1} has {2} device{3} with {4} 'sar-svctm' event{5}, consider having the {6} team add one or more PVSCSI hosts, see {7}".\
                        format(hba_mfg, host, hsdc, plural(hsdc), hsec, plural(hsec), Virtual_type, kcs_url("1148683"))
                    handle_anomaly_with_points("VMWARE", anomaly_line, 'performance', 10 * hsdc)
                else:
                    anomaly_line = "{0} host {1} has {2} device{3} with {4} 'sar-svctm' event{5}, but there are already multiple PVSCSI hosts ({6}) present, ask the {7} team to check hypervisor storage performance".\
                        format(hba_mfg, host, hsdc, plural(hsdc), hsec, plural(hsec), pvscsi_host_count, Virtual_type)
                    handle_anomaly_with_points("VMWARE", anomaly_line, 'performance', 10 * hsdc)
        # see sfdc 01679873

    # end: for host in range(0,max_host+1):
    if dm_await_samples or dm_svctm_samples or non_dm_await_samples or non_dm_svctm_samples:
        perf_print("")

    if dm_await_samples:
        avg = round((dm_await_total_time / dm_await_samples), 2)
        perf_print("Total dm device await events: {0}, average await time: {1}".format(dm_await_samples, avg))

    if dm_svctm_samples:
        avg = round((dm_svctm_total_time / dm_svctm_samples), 2)
        perf_print("Total dm device svctm events: {0}, average svctm time: {1}".format(dm_svctm_samples, avg))

    if non_dm_await_samples:
        avg = round((non_dm_await_total_time / non_dm_await_samples), 2)
        perf_print("Total non-dm device await events: {0}, average await time: {1}".format(non_dm_await_samples, avg))

    if non_dm_svctm_samples:
        avg = round((non_dm_svctm_total_time / non_dm_svctm_samples), 2)
        perf_print("Total non-dm device svctm events: {0}, average svctm time: {1}".format(non_dm_svctm_samples, avg))

    perf_print("**")
    perf_print("** end of sar performance await and svctm reporting")
    perf_print("**")
    debug_print(1, "complete")

    return

# ---------------------------------------------#
# function track_top_await_devs()
# ---------------------------------------------#


def track_top_await_devs(await_avg, event_count, dev):
    global sar_slots  # 10                      # track this many instances of sar await data in sar_xxxxx arrays
    global sar_await     # Counter()           # 'sar_slots' count ordered array (highest->lowest) for await data
    global sar_await_dev  # Key_data()          # 'sar_slots' count ordered array  of device id
    global sar_await_cnt  # Counter()           # 'sar_slots' count ordered array  of await data

    if event_count < 10:
        return

    if await_avg < sar_await[sar_slots]:
        return

    insert = False
    for i in range(1, sar_slots + 1):
        if insert:
            prv_await = sar_await[i]
            prv_dev = sar_await_dev[i]
            prv_cnt = sar_await_cnt[i]

            sar_await[i] = tmp_await
            sar_await_dev[i] = tmp_dev
            sar_await_cnt[i] = tmp_cnt

            tmp_await = prv_await
            tmp_dev = prv_dev
            tmp_cnt = prv_cnt
            continue
        if await_avg > sar_await[i]:
            tmp_await = sar_await[i]
            tmp_dev = sar_await_dev[i]
            tmp_cnt = sar_await_cnt[i]
            insert = True
            sar_await[i] = await_avg
            sar_await_dev[i] = dev
            sar_await_cnt[i] = event_count
    # end: for i in range(1,sar_slots+1):
    return

# ---------------------------------------------#
# function track_top_svctm_devs()
# ---------------------------------------------#


def track_top_svctm_devs(svctm_avg, event_count, dev):
    global sar_slots  # 10                      # track this many instances of sar svctm data in sar_xxxxx arrays
    global sar_svctm     # Counter()           # 'sar_slots' count ordered array (highest->lowest) for svctm data
    global sar_svctm_dev  # Key_data()          # 'sar_slots' count ordered array  of device id
    global sar_svctm_cnt  # Counter()           # 'sar_slots' count ordered array  of svctm data

    if event_count < 10:
        return

    if svctm_avg < sar_svctm[sar_slots]:
        return

    insert = False
    for i in range(1, sar_slots + 1):
        if insert:
            prv_svctm = sar_svctm[i]
            prv_dev = sar_svctm_dev[i]
            prv_cnt = sar_svctm_cnt[i]

            sar_svctm[i] = tmp_svctm
            sar_svctm_dev[i] = tmp_dev
            sar_svctm_cnt[i] = tmp_cnt

            tmp_svctm = prv_svctm
            tmp_dev = prv_dev
            tmp_cnt = prv_cnt
            continue
        if svctm_avg > sar_svctm[i]:
            tmp_svctm = sar_svctm[i]
            tmp_dev = sar_svctm_dev[i]
            tmp_cnt = sar_svctm_cnt[i]
            insert = True
            sar_svctm[i] = svctm_avg
            sar_svctm_dev[i] = dev
            sar_svctm_cnt[i] = event_count
    # end: for i in range(1,sar_slots+1):
    return

# ---------------------------------------------#
# function display_top_await_devs()
# ---------------------------------------------#


def display_top_await_devs():
    global sar_slots  # 10                      # track this many instances of sar await data in sar_xxxxx arrays
    global sar_await     # Counter()           # 'sar_slots' count ordered array (highest->lowest) for await data
    global sar_await_dev  # Key_data()          # 'sar_slots' count ordered array  of device id
    global sar_await_cnt  # Counter()           # 'sar_slots' count ordered array  of await data

    if sar_await_dev[1] == "# # # ":
        return      # no data

    perf_print(" **** Top {0} await devices (min. 10 events w/await > 10ms) ****".format(sar_slots))

    for i in range(1, sar_slots + 1):
        if sar_await_dev[i] == "# # # ":
            continue
        perf_print("{0} await avg: {1}  events: {2}  hba: {3}".
                   format(sar_await_dev[i], sar_await[i], sar_await_cnt[i], conv_dev_2_hba_no(sar_await_dev[i])))
    # end: for in in range(1,sar_slots+1):
    perf_print("")

    return

# ---------------------------------------------#
# function display_top_svctm_devs()
# ---------------------------------------------#


def display_top_svctm_devs():
    global sar_slots  # 10                      # track this many instances of sar svctm data in sar_xxxxx arrays
    global sar_svctm     # Counter()           # 'sar_slots' count ordered array (highest->lowest) for svctm data
    global sar_svctm_dev  # Key_data()          # 'sar_slots' count ordered array  of device id
    global sar_svctm_cnt  # Counter()           # 'sar_slots' count ordered array  of svctm data

    if sar_svctm_dev[1] == "# # # ":
        return      # no data

    perf_print(" **** Top {0} svctm devices (min. 10 events w/svctm > 10ms) ****".format(sar_slots))

    for i in range(1, sar_slots + 1):
        if sar_svctm_dev[i] == "# # # ":
            continue
        perf_print("{0} svctm avg: {1}  events: {2}  hba: {3}".
                   format(sar_svctm_dev[i], sar_svctm[i], sar_svctm_cnt[i], conv_dev_2_hba_no(sar_svctm_dev[i])))
    # end: for in in range(1,sar_slots+1):

    perf_print("")

    return

# ---------------------------------------------#
# function conv_dev_2_hba_no(dev):
# ---------------------------------------------#


def conv_dev_2_hba_no(dev):
    global sd_re
    global sd_re_p
    global dev_2_lun  # Key_data()

    if not re.match(sd_re, dev):
        return("<n/a>")

    scsi_adr = dev_2_lun[dev]
    if scsi_adr == '':
        return("<unknown>")

    tmp = scsi_adr.split(":")
    hba_no = tmp[0]
    return(hba_no)

# ---------------------------------------------#
# function: perf_alias_expand()
# ---------------------------------------------#


def perf_alias_expand(alias):
    global all_vg_names
    global lv_2_path
    global vg_2_all_pvs

    if all_vg_names == '':
        return('')

    lv_pv_blurb = ''
    vg_name = split_vg_name(alias, '')
    if vg_name != '':
        lv_name = split_lv_name(alias, '')
        lv_dev = lv_2_path[alias]
        if lv_dev == '':
            lv_pv_blurb = "{0} -> {1}".format(alias, '(pv dev unknown)')
        else:
            lv_pv_blurb = "{0} -> {1}".format(lv_dev, vg_2_all_pvs[vg_name])
    else:
        lv_pv_blurb = alias

    return lv_pv_blurb

# ---------------------------------------------#
# function: chk_oracle_performance()
# ---------------------------------------------#


def chk_oracle_performance():
    global total_mem
    global oracle_sga
    global sysctl

    global total_rt_procs  # 0
    global rt_procs  # ''
    global rt_proc_count  # Counter()

    perf_print("**")
    perf_print("** start of Oracle performance and tuning checks (based on KCS {0} & KCA {1})".
               format(kcs_url("39188"), kca_url("215703")))
    perf_print("**")

    remediate = False
    system_check('vm.swappiness', 'LE', 10, "R", 0)

    system_check('vm.dirty_background_ratio', 'LE', 3, "R", 0)

    system_check('vm.dirty_ratio', 'LE', 40, "R", 0)

    # system_check('vm.dirty_expire_centisecs','EQ',100,"R",0)
    system_check('vm.dirty_expire_centisecs', 'EQ', 500, "R", 0)  # updated to 500 Oct.7.2015 from KCS above

    system_check('vm.dirty_writeback_centisecs', 'EQ', 100, "R", 0)

    perf_print("**")
    perf_print("** the following guidelines are based on an Oracle SGA size of {0}".format(mg_disp(oracle_sga, 1)))

    nr_hugepages = sysctl['vm.nr_hugepages']

    if nr_hugepages == 0:
        perf_print("** HugePages are not in use; consider enabling per above KCS and KCS {0}.".format(kcs_url("69306")))

    mem_hp_size = get_hugepage_size()
    min_hp_cnt = oracle_sga / mem_hp_size
    if system_check('vm.nr_hugepages', 'GE', min_hp_cnt, "R", 0) is False:
        perf_print("** additional remediation in /etc/sysctl.conf;")
        perf_print("**   vm.hugetlb_shm_group=<insert oracle group ID here>")

    # For reference:
    #
    # SHMMAX is the maximum size of a single shared memory segment set in “bytes”.
    # ------
    # SHMALL is the total size of Shared Memory Segments System wide set in “pages”.
    #

    # TODO: is 75% valid as min / recommended shmmax for a multi gig 64 bit  box??
    shmmax_min = ((total_mem * kb) / 4) * 3  # step 1: calc .75 of total mem in bytes
    shmmax_min = (((shmmax_min + (2047 * 1024)) / 2048) * 2048)  # round up to the next 2Mb boundary

    if nr_hugepages == 0:
        shm_pagesize = 4096
    else:
        # shm_pagesize = mem_hp_size
        shm_pagesize = 4096  # not sure that shmall page size jumps to hugepage size when hugepages are in use

    # kernel.shmall total amount of shared memory pages that can be used system wide. Hence, SHMALL should always be at least ceil(shmmax/PAGE_SIZE).

    # TODO: need to review shmmax_min calc
    shmall_min = shmmax_min / shm_pagesize

    system_check('kernel.shmmax', 'GE', shmmax_min, "R", 1)
    system_check('kernel.shmall', 'GE', shmall_min, "R", shm_pagesize)
    system_check('kernel.shmmni', 'GE', 4096, "R", 0)

    sem_rem = False
    semmsl = sysctl['kernel.semmsl']
    semmsl_min = 250
    if system_check('kernel.semmsl', 'GE', semmsl_min, "", 0) is False:
        semmsl = semmsl_min
        sem_rem = True

    semmns = sysctl['kernel.semmns']
    semmns_min = 32000
    if system_check('kernel.semmns', 'GE', semmns_min, "", 0) is False:
        semmns = semmns_min
        sem_rem = True

    semopm = sysctl['kernel.semopm']
    semopm_min = 100
    if system_check('kernel.semopm', 'GE', semopm_min, "", 0) is False:
        semopm = semopm_min
        sem_rem = True

    semmni = sysctl['kernel.semmni']
    semmni_min = 128
    if system_check('kernel.semmni', 'GE', semmni_min, "", 0) is False:
        semmni = semmni_min
        sem_rem = True

    if sem_rem is True:
        perf_print("** remediate any/all semaphore setting permanently in /etc/sysctl.conf by setting:")
        perf_print("**   kernel.sem = {0} {1} {2} {3}".
                   format(semmsl, semmns, semopm, semmni))
        perf_print("** or immediately and temporarily by issuing:")
        perf_print("**   sysctl -w 'kernel.sem = {0} {1} {2} {3}'".
                   format(semmsl, semmns, semopm, semmni))

    if total_rt_procs > 0:
        oracle_prefix_list = "asm_ ora_ osysmod cssd ocssd"
        tmp = rt_procs.split()
        tmp_ora = oracle_prefix_list.split()
        oracle_rt_procs = ''
        for rt_proc in tmp:
            for prefix in tmp_ora:
                if rt_proc.startswith(prefix):
                    oracle_rt_procs = unique_list(oracle_rt_procs, rt_proc)
            # end: for prefix in tmp_ora:
        # end: for rt_proc in tmp:
        if oracle_rt_procs != '':
            wc = wordcount(oracle_rt_procs)
            perf_print("** Found {0} Oracle real time process{1} [{2}], see KCS {3} & SFDC {4}".
                       format(wc, plurale(wc), oracle_rt_procs, kcs_url("109283"), sfdc_url("01662472")))
    # end: if total_rt_procs > 0:

    perf_print("**")
    perf_print("** end of Oracle checks")
    perf_print("**")
    debug_print(1, "complete")
    return

# ---------------------------------------------#
# function: chk_db2_performance()
# ---------------------------------------------#


def chk_db2_performance():
    global total_mem
    global sysctl
    global gb, kb

    perf_print("**")
    perf_print("** start of Db2 performance and tuning checks (based on KCS {0})".format(kcs_url("189473")))
    perf_print("**")

    remediate = False
    system_check('vm.swappiness', 'LE', 5, "R", 0)

    system_check('vm.dirty_background_ratio', 'LE', 3, "R", 0)

    system_check('vm.dirty_ratio', 'LE', 15, "R", 0)

    system_check('vm.dirty_expire_centisecs', 'EQ', 500, "R", 0)

    system_check('vm.dirty_writeback_centisecs', 'EQ', 100, "R", 0)

    # perf_print("**")
    # perf_print("** the following guidelines are based on an Db2 SGA size of {0}".format(mg_disp(db2_sga,1)))

    if sysctl['vm.nr_hugepages'] == 0:
        perf_print("** HugePages are not in use; consider enabling per above KCS")

    mem_hp_size = get_hugepage_size()
    # min_hp_cnt = db2??_sga / mem_hp_size
    # if system_check('vm.nr_hugepages','GE',min_hp_cnt,"R",0) is False:
    # perf_print("** additional remediation in /etc/sysctl.conf;")
    # perf_print("**   vm.hugetlb_shm_group=<insert oracle group ID here>")

    # DB2 SHM/SEM/MSG settings reference:
    # https://www.ibm.com/support/knowledgecenter/en/SSEPGG_10.5.0/com.ibm.db2.luw.qb.server.doc/doc/t0008238.html?view=embed
    #
    shmmax_min = (total_mem * kb)
    if not shmmax_min:
        shmmax_min = gb

    if mem_hp_size == 0:
        shm_pagesize = 4096
    else:
        shm_pagesize = mem_hp_size

    size_of_ram_in_gb = max((total_mem / (gb / kb)), 1)  # total_mem is in kb

    shmall_min = 2 * ((total_mem * kb) / shm_pagesize)

    system_check('kernel.shmmax', 'GE', shmmax_min, "R", 1)
    system_check('kernel.shmall', 'GE', shmall_min, "R", shm_pagesize)
    system_check('kernel.shmmni', 'GE', 4096, "R", 0)

    sem_rem = False
    semmsl = sysctl['kernel.semmsl']
    semmsl_min = 250
    if system_check('kernel.semmsl', 'GE', semmsl_min, "", 0) is False:
        semmsl = semmsl_min
        sem_rem = True

    semmns = sysctl['kernel.semmns']
    semmns_min = 256000
    if system_check('kernel.semmns', 'GE', semmns_min, "", 0) is False:
        semmns = semmns_min
        sem_rem = True

    semopm = sysctl['kernel.semopm']
    semopm_min = 32
    if system_check('kernel.semopm', 'GE', semopm_min, "", 0) is False:
        semopm = semopm_min
        sem_rem = True

    semmni = sysctl['kernel.semmni']
    size_of_ram_in_gb = max((total_mem / (gb / kb)), 1)  # total_mem is in kb
    semmni_min = 256 * size_of_ram_in_gb
    if system_check('kernel.semmni', 'GE', semmni_min, "", 0) is False:
        semmni = semmni_min
        sem_rem = True

    if sem_rem is True:
        perf_print("** remediate any/all semaphore setting permanently in /etc/sysctl.conf by setting:")
        perf_print("**   kernel.sem = {0} {1} {2} {3}".
                   format(semmsl, semmns, semopm, semmni))
        perf_print("** or immediately and temporarily by issuing:")
        perf_print("**   sysctl -w 'kernel.sem = {0} {1} {2} {3}'".
                   format(semmsl, semmns, semopm, semmni))

    msgmni_min = size_of_ram_in_gb * kb
    system_check('kernel.msgmni', 'GE', msgmni_min, "R", 1)
    system_check('kernel.msgmax', 'GE', 65536, "R", 0)
    system_check('kernel.msgmnb', 'GE', 65536, "R", 1)

    perf_print("**")
    perf_print("** end of Db2 checks")
    perf_print("**")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# function: chk_sybase_performance()
# ---------------------------------------------#
def chk_sybase_performance():
    global total_mem
    global sysctl

    perf_print("**")
    perf_print("** start of sybase performance and tuning checks (based on KCS {0})".format(kcs_url("69988")))
    perf_print("**")

    remediate = False
    system_check('vm.swappiness', 'LE', 10, "R", 0)

    system_check('vm.dirty_background_ratio', 'LE', 5, "R", 0)

    system_check('vm.dirty_ratio', 'LE', 10, "R", 0)

    system_check('vm.dirty_expire_centisecs', 'EQ', 500, "R", 0)

    system_check('vm.dirty_writeback_centisecs', 'EQ', 100, "R", 0)

    # perf_print("**")
    # perf_print("** the following guidelines are based on a sybase SGA size of {0}".format(mg_disp(sybase_sga,1)))

    if sysctl['vm.nr_hugepages'] == 0:
        perf_print("** HugePages are not in use; review sybase documentation and consider enabling")

    # mem_hp_size = get_hugepage_size()
    # min_hp_cnt = sybase??_sga / mem_hp_size
    # if system_check('vm.nr_hugepages','GE',min_hp_cnt,"R",0) is False:
        # perf_print("** additional remediation in /etc/sysctl.conf;")
        # perf_print("**   vm.hugetlb_shm_group=<insert oracle group ID here>")

    # TODO: is 75% valid as min / recommended shmmax for a multi gig 64 bit  box??
    # shmmax_min = ((total_mem*kb)/4)*3  # * .75
    # shmmax_min = ( ((shmmax_min+(2047*1024)) / 2048) * 2048) # round up to the next 2Mb boundary

    # if mem_hp_size == 0:
        # shm_pagesize = 4096
    # else:
        # shm_pagesize = mem_hp_size

    # TODO: need to review shmmax_min calc
    # shmall_min = shmmax_min / mem_hp_size

    # system_check('kernel.shmmax','GE',shmmax_min,"R",1)
    # system_check('kernel.shmall','GE',shmall_min,"R",shm_pagesize)
    # system_check('kernel.shmmni','GE',4096,"R",0)

    # sem_rem = False
    # semmsl = sysctl['kernel.semmsl']
    # semmsl_min = 250
    # if system_check('kernel.semmsl','GE',semmsl_min,"",0) is False:
        # semmsl = semmsl_min
        # sem_rem = True

    # semmns = sysctl['kernel.semmns']
    # semmns_min = 32000
    # if system_check('kernel.semmns','GE',semmns_min,"",0) is False:
        # semmns = semmns_min
        # sem_rem = True

    # semopm = sysctl['kernel.semopm']
    # semopm_min = 100
    # if system_check('kernel.semopm','GE',semopm_min,"",0) is False:
        # semopm = semopm_min
        # sem_rem = True

    # semmni = sysctl['kernel.semmni']
    # semmni_min = 128
    # if system_check('kernel.semmni','GE',semmni_min,"",0) is False:
        # semmni = semmni_min
        # sem_rem = True

    # if sem_rem is True:
        # perf_print("** remediate any/all semaphore setting permanently in /etc/sysctl.conf by setting:")
        # perf_print("**   kernel.sem = {0} {1} {2} {3}".\
        # format(semmsl,semmns,semopm,semmni))
        # perf_print("** or immediately and temporarily by issuing:")
        # perf_print("**   sysctl -w 'kernel.sem = {0} {1} {2} {3}'".\
        # format(semmsl,semmns,semopm,semmni))

    perf_print("**")
    perf_print("** end of sybase checks")
    perf_print("**")
    debug_print(1, "complete")
    return

# ---------------------------------------------#
# function: chk_mysql_performance()
# ---------------------------------------------#


def chk_mysql_performance():
    global total_mem
    global sysctl

    perf_print("**")
    perf_print("** start of MySQL performance and tuning checks (based on KCS {0} & {1})".format(kcs_url("2733981"), kcs_url("62151")))
    perf_print("**")

    remediate = False
    system_check('vm.swappiness', 'LE', 10, "R", 0)

    system_check('vm.dirty_background_ratio', 'LE', 3, "R", 0)

    system_check('vm.dirty_ratio', 'LE', 40, "R", 0)

    system_check('vm.dirty_expire_centisecs', 'EQ', 500, "R", 0)

    system_check('vm.dirty_writeback_centisecs', 'EQ', 100, "R", 0)

    # perf_print("**")
    # perf_print("** the following guidelines are based on an MySQL SGA size of {0}".format(mg_disp(mysql_sga,1)))

    if sysctl['vm.nr_hugepages'] == 0:
        perf_print("** HugePages are not in use; review MySQL documentation and consider enabling")

    # mem_hp_size = get_hugepage_size()
    # min_hp_cnt = sybase??_sga / mem_hp_size
    # if system_check('vm.nr_hugepages','GE',min_hp_cnt,"R",0) is False:
        # perf_print("** additional remediation in /etc/sysctl.conf;")
        # perf_print("**   vm.hugetlb_shm_group=<insert oracle group ID here>")

    # TODO: is 75% valid as min / recommended shmmax for a multi gig 64 bit  box??
    # shmmax_min = ((total_mem*kb)/4)*3  # * .75
    # shmmax_min = ( ((shmmax_min+(2047*1024)) / 2048) * 2048) # round up to the next 2Mb boundary

    # if mem_hp_size == 0:
        # shm_pagesize = 4096
    # else:
        # shm_pagesize = mem_hp_size

    # TODO: need to review shmmax_min calc
    # shmall_min = shmmax_min / mem_hp_size

    # system_check('kernel.shmmax','GE',shmmax_min,"R",1)
    # system_check('kernel.shmall','GE',shmall_min,"R",shm_pagesize)
    # system_check('kernel.shmmni','GE',4096,"R",0)

    sem_rem = False
    semmsl = sysctl['kernel.semmsl']
    semmsl_min = 250
    if system_check('kernel.semmsl', 'GE', semmsl_min, "", 0) is False:
        semmsl = semmsl_min
        sem_rem = True

    semmns = sysctl['kernel.semmns']
    semmns_min = 32000
    if system_check('kernel.semmns', 'GE', semmns_min, "", 0) is False:
        semmns = semmns_min
        sem_rem = True

    semopm = sysctl['kernel.semopm']
    semopm_min = 100
    if system_check('kernel.semopm', 'GE', semopm_min, "", 0) is False:
        semopm = semopm_min
        sem_rem = True

    semmni = sysctl['kernel.semmni']
    semmni_min = 128
    if system_check('kernel.semmni', 'GE', semmni_min, "", 0) is False:
        semmni = semmni_min
        sem_rem = True

    if sem_rem is True:
        perf_print("** remediate any/all semaphore setting permanently in /etc/sysctl.conf by setting:")
        perf_print("**   kernel.sem = {0} {1} {2} {3}".
                   format(semmsl, semmns, semopm, semmni))
        perf_print("** or immediately and temporarily by issuing:")
        perf_print("**   sysctl -w 'kernel.sem = {0} {1} {2} {3}'".
                   format(semmsl, semmns, semopm, semmni))

    perf_print("**")
    perf_print("** end of MySQL checks")
    perf_print("**")
    debug_print(1, "complete")
    return


# ---------------------------------------------#
# ---------------------------------------------#
# function: chk_vmware_performance()
# ---------------------------------------------#
def chk_vmware_performance():
    global total_mem
    global oracle_sga
    global sysctl

    perf_print("**")
    perf_print("** start of VMware performance and tuning checks")
    perf_print("**")

    ht_timeout_secs = sysctl["kernel.hung_task_timeout_secs"]
    blurb = ""
    if sysctl["kernel.hung_task_panic"] > 0:
        blurb = " and panics"

    vmware_timeout = get_vmware_devpath_timeout()
    perf_print('Note: VMware guest machines generally have IO timeout set to 180 seconds.')
    if vmware_timeout != '':
        perf_print('      Confirmed to be {0} in this instance.'.format(vmware_timeout))
    perf_print('      To match this within RHEL, see {0}'.format(info_kcs("129773")))
    # kernel.hung_task_timeout_secs
    # system_check('kernel.hung_task_timeout_secs','GE',240,"R",0)
    if ht_timeout_secs < 190:
        perf_print('Warning: To avoid hung task messages{0}, increase kernel.hung_task_timeout_seconds from {1} to 240'.
                   format(blurb, ht_timeout_secs))
    else:
        perf_print('Note: With kernel.hung_task_timeout_seconds set to {0} hung task messages{1} are being avoided'.
                   format(ht_timeout_secs, blurb))

    perf_print("**")
    perf_print("** end of VMware checks")
    perf_print("**")
    debug_print(1, "complete")
    return

# ---------------------------------------------#
# function: get_vmware_devpath_timeout():
# ---------------------------------------------#


def get_vmware_devpath_timeout():

    fn = "etc/udev/rules.d/99-vmware-scsi-udev.rules"
    fh = openfile(fn)
    if fh is None:
        return ''

    vmware_timeout = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)

        # ACTION=="add", SUBSYSTEMS=="scsi", ATTRS{vendor}=="VMware  ", ATTRS{model}=="Virtual disk    ", RUN+="/bin/sh -c 'echo 180 >/sys$DEVPATH/timeout'"
        if "/sys$DEVPATH/timeout" in words[wc - 1]:
            vmware_timeout = words[wc - 2]

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return vmware_timeout

# ---------------------------------------------#
# function: chk_nfs_perf()
# ---------------------------------------------#


def chk_nfs_perf():
    global all_fs_types
    global sysctl

    perf_print("** key nfs kernel settings: net.ipv4.tcp_rmem='{0}' net.ipv4.tcp_wmem='{1}'".
               format(sysctl['net.ipv4.tcp_rmem'], sysctl['net.ipv4.tcp_wmem']))
    perf_print("** {0}".format(info_sfdc("01953772")))
    perf_print("** {0}".format(info_kca("1153563")))
    perf_print("** {0}".format(info_kcs("2216")))
    perf_print("** {0}".format(info_kcs("2178441")))
    perf_print("** {0}".format(info_kca("333973")))
    perf_print("** {0}".format(info_kca("3018")))  # of limited value
    perf_print("** {0}".format(info_kcs("170713")))  # of limited value
    return


# ---------------------------------------------#
# function: system_check(key,op,rval,units)
# ---------------------------------------------#
def system_check(key, op, rval, flags, units):
    global sysctl

    Rflag = ""
    if len(flags) > 0:
        Rflag = flags[0:1]

    if Rflag == "R":
        remediate = True
    else:
        remediate = False

    kern_value = sysctl[key]

    if kern_value == -1:  # skip if sym not defined
        return False

    blurb1 = "Warning"
    blurb2 = ""
    blurb3 = ""

    if op == "EQ":
        blurb2 = "is not equal to"
        if kern_value == rval:
            blurb1 = "Note"
            blurb2 = "is equal to"
    elif op == "GT":
        blurb2 = "is less than or equal to"
        blurb3 = "or more"
        if kern_value > rval:
            blurb1 = "Note"
            blurb2 = "is greater than"
    elif op == "GE":
        blurb2 = "is less than"
        blurb3 = "or more"
        if kern_value >= rval:
            blurb1 = "Note"
            blurb2 = "is greater than or equal to"
    elif op == "LT":
        blurb2 = "is greater than or equal to"
        blurb3 = "more"
        if kern_value < rval:
            blurb1 = "Note"
            blurb2 = "is less than"
    elif op == "LE":
        blurb2 = "is greater than"
        blurb3 = "or less"
        if kern_value <= rval:
            blurb1 = "Note"
            blurb2 = "is less than or equal to"
    else:
        blurb2 = "unrecognized opcode({0})".format(op)

    if units != 0:  # for fields which describe memory, also add mg_disp() version of the data
        perf_print('** {0}: {1}={2} ({3}) which {4} the recommendation of {5} ({6}) {7}'.
                   format(blurb1, key, kern_value, mg_disp(kern_value, units), blurb2, rval, mg_disp(rval, units), blurb3))
    else:
        perf_print('** {0}: {1}={2} which {3} the recommendation of {4} {5}'.
                   format(blurb1, key, kern_value, blurb2, rval, blurb3))

    if blurb1 == "Note":
        return True
    elif blurb1 == "Warning":
        if remediate is True:
            perf_print("** remediate permanently in /etc/sysctl.conf and/or immediately by issuing:")
            perf_print("**   {0}={1}  /  sysctl -w {0}={1} (reset at next reboot)".
                       format(key, rval, key, rval))
        return False
    else:
        perf_print("?system_check({0},{1},{2}): {3}".
                   format(key, op, val, blurb1))
        return False


# ---------------------------------------------#
# function display_top_cpu_procs()
# ---------------------------------------------#
def display_top_cpu_procs():
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_cpu      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %CPU
    global proc_cpu_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file
    global total_procs  # 0                     # total number of processes at time of sos report

    if total_procs == 0:
        return               # no data

    perf_print(" ")
    perf_print("  **** Top %CPU processes (min. 1.0% of cpu) ****")

    if proc_cpu_line[1] == "# # # ":             # no data
        perf_print("None of the {0} processes used more than 1.0% CPU".format(total_procs))
        perf_print(" ")
        return

    for i in range(0, proc_slots + 1):
        display_top_line(proc_cpu_line[i])
    # end: for i in range(1,proc_slots+1):

    return

# ---------------------------------------------#
# function display_top_mem_procs()
# ---------------------------------------------#


def display_top_mem_procs():
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_mem      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %MEM
    global proc_mem_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    if total_procs == 0:
        return               # no data

    perf_print(" ")
    perf_print("  **** Top %MEM processes (min. 1.0% of memory) ****")

    if proc_mem_line[1] == "# # # ":             # no data
        perf_print("None of the {0} processes used more than 1.0% MEM".format(total_procs))
        perf_print(" ")
        return

    for i in range(0, proc_slots + 1):
        display_top_line(proc_mem_line[i])
    # end: for i in range(1,proc_slots+1):

    return

# ---------------------------------------------#
# function display_top_tim_procs()
# ---------------------------------------------#


def display_top_tim_procs():
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_tim      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for TIME
    global proc_tim_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    if proc_tim_line[1] == "# # # ":
        return      # no data

    perf_print(" ")
    perf_print("  **** Top TIME processes ****")
    for i in range(0, proc_slots + 1):
        display_top_line(proc_tim_line[i])
    # end: for i in range(1,proc_slots+1):

    return

# ---------------------------------------------#
# function display_top_line()
# ---------------------------------------------#


def display_top_line(line):
    if line == "# # # ":
        return
    disp_line = line
    max_disp_len = 100
    if len(line) > max_disp_len:
        disp_line = line[0:max_disp_len] + "..."
    perf_print(disp_line)
    return

# ---------------------------------------------#
# function: perf_print()
# ---------------------------------------------#


def perf_print(perf_string):
    global sw_performance  # True/False

    if sw_performance:
        errorprint(perf_string)
    return

# ---------------------------------------------#
# function: crunch_hostname()
# set globals hostname & hostname_short
# ---------------------------------------------#


def crunch_hostname():
    global hostname
    global hostname_short

    hostname = get_general_data("hostname")
    hostname_short = domain_strip(hostname, "hostname")

    return

# ---------------------------------------------#
# function: crunch_rsyslog_conf()
# set globals such as localhostname
# ---------------------------------------------#


def crunch_rsyslog_conf():
    global localhostname  # ''

    fn = 'etc/rsyslog.conf'
    fh = openfile(fn)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == '':
            continue

        if line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)

        if wc < 2:
            continue

        if words[0] == "$LocalHostName":
            localhostname = words[1]

    # eend: for line in lines:
    # end: for line in fh:

    debug_print(3, "$LocalHostName:'{0}'".format(localhostname))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_ip_addrs()
#
# ---------------------------------------------#


def crunch_ip_addrs():
    global ip_addr_re  # "[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}"
    global ip_addr_and_port_re  # ip_addr_re+":[0-9]{1,5}"
    global ip_addr_and_mask_re  # ip_addr_re+"/[0-9]{1,3}"
    global all_ipv4_addrs  # ''
    global all_ipv6_addrs  # ''
    global all_host_ip_names  # ''

    fn = 'ip_addr'
    fh = openfile(fn)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == '':
            continue
        words = line.split()
        wc = len(words)

        if wc < 4:
            continue

        if not re.match("[0-9]{1,2}:", words[0]):
            continue

        interface = words[1]
        if re.match("eth[0-9]{1,2}", interface):
            pass
        elif re.match("em[0-9]{1,2}", interface):
            pass
        else:
            continue  # above may need to be expanded from time to time

        if words[2] != "inet" and words[2] != "inet6":
            continue

        if words[2] == "inet":
            ip_addr = words[3]
            if re.match(ip_addr_and_mask_re, ip_addr):
                tmp = ip_addr.split("/")
                ip_addr = tmp[0]
                if not re.match(ip_addr_re, ip_addr):
                    continue
            elif re.match(ip_addr_re, ip_addr):
                pass
            else:
                continue
            all_ipv4_addrs = unique_list(all_ipv4_addrs, ip_addr)
            host_ip_name = "host-" + ip_addr.replace(".", "-")
            all_host_ip_names = unique_list(all_host_ip_names, host_ip_name)
        if words[2] == "inet6":
            ipv6_addr = words[3]
            if "/" in ipv6_addr:
                tmp = ipv6_addr.split("/")
                ipv6_addr = tmp[0]
            all_ipv6_addrs = unique_list(all_ipv6_addrs, ipv6_addr)

    # end: for line in fh:

    debug_print(3, "all ipv4 addresses:'{0}'".format(all_ipv4_addrs))
    debug_print(3, "all ipv6 addresses:'{0}'".format(all_ipv6_addrs))
    debug_print(3, "all host ip names:'{0}'".format(all_host_ip_names))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ---------------------------------------------#
# function: crunch_network()
# ---------------------------------------------#
def crunch_network():

    crunch_network_files("./sos_commands/networking/")
    return

# ---------------------------------------------#
# function: crunch_network_files():
# ---------------------------------------------#


def crunch_network_files(path):

    if stat_dir(path, '', 0) is None:
        return

    fn_prefix_list_1 = "ethtool_-S "\
                       ""
    fn_prefixes_1 = fn_prefix_list_1.split()

    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:

        for fn_prefix in fn_prefixes_1:  # dumpe2fs output files
            if fn.startswith(fn_prefix):
                crunch_network_file(path + fn, fn)

    # done: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_network_file()
# ---------------------------------------------#


def crunch_network_file(path_fn, fn):

    fh = openfile(path_fn)
    if fh is None:
        return

    rx_errors = 0
    tx_errors = 0

    patterns = ""\
               "rx_.*_errors: "\
               "rx_.*_err: "\
               "tx_.*_errors: "\
               "tx_.*_err: "\
               ""
    tmp = patterns.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1

        line = line.strip()
        words = line.split()
        wc = len(words)
        if wc != 2:
            continue

        count = words[1]
        # debug_print(0,count)
        if not count.isdigit():
            continue
        count = int(count)
        # debug_print(0,line)
        if count == 0:
            continue
        field_tag = words[0]

        for ptrn in tmp:
            if not re.match(ptrn, field_tag):
                continue

            if field_tag.startswith('rx'):
                rx_errors += count
            elif field_tag.startswith('tx'):
                tx_errors += count
            else:
                error_print('l', "'{0}' ({1})".format(line, path_fn))

        # end: for ptrn in tmp:

    # end: for line in fh:

    if rx_errors or tx_errors:
        anomaly_line = "Found {0} rx error{1} and {2} tx error{3} ({4})".\
                       format(rx_errors, plural(rx_errors), tx_errors, plural(tx_errors), path_fn)
        handle_anomaly("NETWORK", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, path_fn))
    return

# ---------------------------------------------#
# function: crunch_release()
# check various files for release data
# redhat-release: "Red Hat Enterprise Linux Server release 6.7 (Santiago)"
# oracle-release: "Oracle Linux Server release 6.7"
# Note: in a non red hat env., redhat-relase is often a symlink to centos-relase, fedora-relase, etc.
# ---------------------------------------------#


def crunch_release():
    global rh_major
    global rh_minor
    global release
    global release_extra
    global release_origin

    files = "" \
            "etc/redhat-release "\
            "etc/centos-release "\
            "etc/fedora-release "\
            "etc/oracle-release "\
            "etc/enterprise-release "\
            ""
    tmp = files.split()

    alt_files = "" \
        "etc/os-release "\
        "etc/lsb-release "\
        ""
    alt_tmp = alt_files.split()

    for file in tmp:
        if not file_exists_with_data(file):
            continue
        if rh_major == 0:
            crunch_release_file(file)
    # end: for file in tmp:

    if rh_major == 0:
        # no etc/xxxxx-release file or it's blank / bad / corrupt
        crunch_rpm_release_file()

    if rh_major == 0:  # still nothing - maybe ubuntu, try alternate files
        for alt_file in alt_tmp:
            if not file_exists_with_data(alt_file):
                continue
            if rh_major == 0:
                crunch_alt_release_file(alt_file)
        # end: for alt_file in alt_tmp:

    if release.startswith("Red Hat"):
        pass  # normal
    elif release == "red hat":
        release_extra = ATTN + "Unknown Version!"
    elif release == "Unknown":
        release_extra = ATTN + "Unknown OS!"
    else:
        release_extra = ATTN + "Non-RHEL OS!"

    debug_print(3, "release: {0}{1} ({2})".format(release, release_extra, release_origin))
    debug_print(3, "release: maj/min: {0}/{1}".format(rh_major, rh_minor))
    return

# ---------------------------------------------#
# function: crunch_release_file()
# get red hat (or other) release data
# ---------------------------------------------#


def crunch_release_file(file):
    global rh_major
    global rh_minor
    global release
    global release_extra
    global release_origin
    global ATTN

    line = readline1(file)
    line = line.strip()
    if line == '':
        return

    release = line
    release_origin = file

    words = release.split()

    # Typical: Red Hat Enterprise Linux Server release 5.10 (Tikanga)
    # Oracle: Oracle Linux Server release 6.7
    # CentOS: CentOS release 6.4
    # RHEL4: Red Hat Enterprise Linux AS release 4 (Nahant Update 8)
    # RHEV: Red Hat Enterprise Virtualization Hypervisor release 6.5 (20140603.2.el6ev)
    # RHEV: Red Hat Enterprise Virtualization Hypervisor 7.1 (20150420.0.el7ev)
    # RHEV: Red Hat Enterprise Virtualization Hypervisor release 7.2 (20151129.1.el7ev)

    release_extra = ""
    for i in range(0, len(words)):
        if words[i] == "Hypervisor" and words[i + 1] == "release":
            continue  # get rh_rel on next iteration else on next time

        if words[i] == "release" or words[i] == "Hypervisor":
            rh_rel = words[i + 1]
            if rh_rel.count('.') > 0:
                rh_rel = rh_rel.split(".")
                rh_major = int(rh_rel[0])
                rh_minor = int(rh_rel[1])
            else:
                rh_major = int(rh_rel)
            if words[i] == "(Nahant" and words[i + 1] == "Update":
                minor = words[i + 2]
                minor = minor.rstrip(")")
                rh_minor = int(minor)
    # end: for i in range(0,len(words)):

    check_hypervisor_status(release, file)

    return

# ---------------------------------------------#
# function: crunch_alt_release_file()
# get red hat (or other) release data
# ---------------------------------------------#


def crunch_alt_release_file(fn):
    global rh_major
    global rh_minor
    global release
    global release_extra
    global release_origin
    global ATTN

    fh = openfile(fn)
    if fh is None:
        return

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        line = line.strip()
        if line == '':
            continue

        if line.startswith("DISTRIB_ID="):  # lsb-release
            release = line[len("DISTRIB_ID="):].strip('"')
            release_origin = fn
            continue

        if line.startswith("NAME="):  # os-release
            release = line[len("NAME="):].strip('"')
            release_origin = fn
            continue

        if line.startswith("DISTRIB_RELEASE="):  # lsb-release
            rh_rel = line[len("DISTRIB_RELEASE="):].strip('"')
            if rh_rel.count('.') > 0:
                rh_rel = rh_rel.split(".")
                rh_major = int(rh_rel[0])
                rh_minor = int(rh_rel[1])
            continue

        if line.startswith("VERSION_ID="):  # os-release
            rh_rel = line[len("VERSION_ID="):].strip('"')
            if rh_rel.count('.') > 0:
                rh_rel = rh_rel.split(".")
                rh_major = int(rh_rel[0])
                rh_minor = int(rh_rel[1])
            continue

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ---------------------------------------------#
# function: crunch_rpm_release_file()
# get red hat (or other) release data from rpm data
# ---------------------------------------------#
def crunch_rpm_release_file():
    global rh_major
    global rh_minor
    global release
    global release_origin
    global release_extra
    global ATTN

    debug_print(3, "{0}.{1} '{2}' '{3}' '{4}'".format(rh_minor, rh_major, release, release_origin, release_extra))
    fn = 'installed-rpms'
    fh = openfile(fn)
    if fh is None:
        return

    # redhat-release-5Server-5.11.0.2.0.1.x86_64                  Wed Jun 15 12:15:16 2016
    # +-----------------+
    #
    # redhat-release-server-6Server-6.7.0.3.el6.x86_64            Tue Nov  3 13:44:16 2015    1446576256  Red Hat, Inc.   x86-026.build.eng.bos.redhat.com
    # +-----------------+
    #

    # redhat-release-server-7.2-9.el7.x86_64                      Mon Mar 21 20:23:22 2016    1458563002    Red Hat, Inc.    x86-030.build.eng.bos.redhat.com
    # +--------------+
    rhel_search_strings = ""\
        "redhat-release-5Server- "\
        "redhat-release-server-6Server- "\
        "redhat-release-server-7. "\
        ""

    rhel_search_words = rhel_search_strings.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if line == '':
            continue
        words = line.split()
        wc = len(words)
        if wc < 6:
            continue

        for rhel_sw in rhel_search_words:
            if line.startswith(rhel_sw):
                debug_print(3, line)
                if rhel_sw.endswith("Server-"):
                    gen_rel = words[0][len(rhel_sw):]
                elif rhel_sw.endswith("-7."):
                    gen_rel = words[0][len(rhel_sw) - 2:]
                else:
                    gen_rel = ''  # ??
                # gen_rel = words[0][len(rhel_sw):]
                debug_print(3, gen_rel)
                if gen_rel.count('.') > 0:
                    gen_rel = gen_rel.split(".")
                    gen_major = gen_rel[0]
                    gen_minor = gen_rel[1]
                    if gen_major == "7" and '-' in gen_minor:
                        tmp = gen_minor.split('-')
                        gen_minor = tmp[0]
                    if gen_major.isdigit() and gen_minor.isdigit():
                        rh_major = int(gen_major)
                        rh_minor = int(gen_minor)
                        release = words[0]
            # end: if line.startswith(rhel_sw):
        # end: for rhel_sw in rhel_search_words:

        if rh_major != 0:
            release_origin = fn
            break

    # end: for line in lines:

    debug_print(3, "{0}.{1} '{2}' '{3}' '{4}'".format(rh_minor, rh_major, release, release_origin, release_extra))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ---------------------------------------------#
# function crunch_uname()
# Uname format:
# Linux <nodename> <kernel_version> # 1 SMP Day Mon dd hh:mm:ss TZ yyyy x86_64 x86_64 x86_64 GNU/Linux
# Linux <nodename> 2.6.9-89.EL # 1 Mon Apr 20 10:22:29 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux
#
# ---------------------------------------------#
def crunch_uname():
    fns = "uname sos_commands/kernel/uname_-a"
    tmp = fns.split()
    for fn in tmp:

        if file_exists_with_data(fn):
            crunch_uname_file(fn)

    # end: for fn in tmp:
    return

# ---------------------------------------------#
# function: crunch_uname_file():
# ---------------------------------------------#


def crunch_uname_file(fn):

    line = readline1(fn)
    if line == "" or "timeout:" in line or "warning:" in line:
        return

    crunch_linux_version_line(line, fn)
    return


# ---------------------------------------------#
# function crunch_linux_version_line(line,source):
#
# process linux version info from 'Linux version' lines from var/log/dmesg, var/log/messages or uname
#
# Examples from dmseg:
# Linux version 2.6.9-103.ELsmp (mockbuild@hs20-bc2-4.build.redhat.com) (gcc version 3.4.6 20060404 (Red Hat 3.4.6-11)) # 1 SMP Fri Nov 11 14:34:02 EST 2011
# Linux version 2.6.18-308.el5 (mockbuild@x86-007.build.bos.redhat.com) (gcc version 4.1.2 20080704 (Red Hat 4.1.2-50)) # 1 SMP Fri Jan 27 17:17:51 EST 2012
#
# Example from syslog:
# kernel: Linux version 2.6.32-431.23.3.el6.x86_64 (mockbuild@x86-027.build.eng.bos.redhat.com) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) # 1 SMP Wed Jul 16 06:12:23 EDT 2014
#
#
# Example from uname:
# Linux nodename 2.6.32-504.23.4.el6.x86_64 # 1 SMP Fri May 29 10:16:43 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux
#
# Red hat kernel built and provided by Oracle: (from messages file)
# kernel: Linux version 2.6.32-504.1.3.el6.x86_64 (mockbuild@ca-build44) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) ) # 1 SMP Tue Nov 11 07:57:22 PST 2014
# kernel: Linux version 2.6.32-300.3.1.el6uek.x86_64 (mockbuild@ca-build44.us.oracle.com) (gcc version 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) ) # 1 SMP Fri Dec 9 18:57:35 EST 2011
# kernel: Linux version 2.6.18-164.el5PAE (mockbuild@ca-build10.us.oracle.com) (gcc version 4.1.2 20080704 (Red Hat 4.1.2-46)) # 1 SMP Thu Sep 3 02:28:20 EDT 2009
#
#
# Red hat kernel built and provided by fedora:
# kernel: Linux version 4.0.5-200.fc21.x86_64 (mockbuild@bkernel02.phx2.fedoraproject.org) (gcc version 4.9.2 20150212 (Red Hat 4.9.2-6) (GCC) ) # 1 SMP Mon Jun 8 16:25:02 UTC 2015
#
# Red hat kernel built and provided by centos:
# kernel: Linux version 2.6.32-504.el6.x86_64 (mockbuild@c6b9.bsys.dev.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) ) # 1 SMP Wed Oct 15 04:27:16 UTC 2014
# Linux version 3.10.0-514.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) ) # 1 SMP Tue Dec 6 23:06:41 UTC 2016
#
# Example from sos_commands/kernel/uname_-a:
# Linux <nodename> 2.6.32-573.22.1.el6.x86_64 # 1 SMP Thu Mar 17 03:23:39 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux
#
# Example from sos_commands/kernel/uname_-a
# Linux <nodename> 4.4.0-47-generic # 68-Ubuntu SMP Wed Oct 26 19:39:52 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
# Linux <nodename> 4.4.0-45-generic # 66-Ubuntu SMP Wed Oct 19 14:12:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
# Linux <nodename> 4.4.0-36-generic # 55~14.04.1-Ubuntu SMP Fri Aug 12 11:49:30 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
#
# Debian sos_commands/kernel/uname_-a
# Linux <nodename> 3.16.0-4-amd64 # 1 SMP Debian 3.16.43-2+deb8u2 (2017-06-26) x86_64 GNU/Linux
# ---------------------------------------------#
def crunch_linux_version_line(line, source):

    global kernelStr        # Key_data()      # Key: various kernel attributes
    global kernelStr_origin  # Key_data()      # Key: attribute source (var/log/dmesg, etc)
    global kernelNum        # Counter()       # Key: various numeric kernel attributes
    global kernelNum_origin  # Key_data()      # Key: attribute source (var/log/dmesg, etc)
    global uname_nodename   # ''
    global s390             # False
    global release
    global release_origin
    global release_extra

    if line == "":
        return

    if "XXX.XXX.XXX.XXX" in line:
        return  # case

    if line.startswith("kernel: "):
        line = line.replace("kernel: ", '')

    line_error = False
    tmp_level = ''
    tmp_major = -1
    tmp_minor = -1
    tmp_rel1 = -1
    tmp_rel2 = -1
    tmp_expanded = ''
    tmp_builder = ''
    tmp_date = ''
    tmp_arch = ''

    words = line.split()
    wc = len(words)

    if wc < 12:
        if " Debian " in line:
            # tmp = words[2].split("-")
            # twc = len(tmp)
            # if twc > 1: tmp_arch = tmp[twc-1] "3.16.0-4-amd64" -> amd64
            release = "Debian"
            release_origin = source
        else:
            line_error = True
            emsg = 'too few words'

    if words[0] != "Linux":
        line_error = True
        emsg = 'first word not Linux'

    if 'uname' in source:
        uname_nodename = words[1]
        uname_nodename_short = domain_strip(uname_nodename, source)
    elif words[1] != "version":
        line_error = True
        emsg = 'second word not version'
    sep_word_no = -1
    for i in range(0, wc - 1):
        word = words[i]
        if word.startswith("#"):
            if re.match("#" + n2_re, word) or word.endswith("Ubuntu"):
                if word.endswith("Ubuntu"):
                    release = "Ubuntu"
                    release_origin = source
                sep_word_no = i
                break
    # end: for word in words:
    if sep_word_no != -1:
        tmp = " ".join(words[sep_word_no + 1:wc])
        ttmp = tmp.split()
        twc = len(ttmp)
        min_wc = 6
        if release == "Debian":
            min_wc = 4
        if twc < min_wc:
            line_error = True
            emsg = 'too few words after [' + tmp + ']'
        else:
            tmp_date = ' '
            remove_words = 'SMP PREEMPT RT'
            rwords = remove_words.split()
            for rw in rwords:
                if word_in_list(rw, tmp):
                    tmp = tmp.replace(rw, '')
            tmp = tmp.split()
            twc = len(ttmp)
            if twc < min_wc:
                line_error = True
                emsg = 'too few words after # 1 (2nd pass)'
            else:
                tmp_date = tmp_date.join(tmp[0:6])
    else:
        line_error = True
        emsg = '# 1 (etc.) not found in line'

    if line_error:
        error_print('d', "Error in Linux version line [{0}] '{1}' ({2})".format(emsg, line, source))
        return

    pos1 = line.find("(mockbuild@")
    if pos1 == -1:
        pos1 = line.find("(builder@")
    if pos1 == -1:
        pos1 = line.find("(debian-kernel@")
    if pos1 != -1:
        pos2 = line.find(")")
        if pos2 != -1:
            build_site = line[pos1 + 1:pos2]
            if "redhat.com" in build_site:
                tmp_builder = "RedHat"
            elif "centos.org" in build_site:
                tmp_builder = "CentOS"
            elif "fedora" in build_site:
                tmp_builder = "fedora"
            elif "debian.org" in build_site:
                tmp_builder = "Debian"
            elif "oracle.com" in build_site:
                tmp_builder = "Oracle"
            elif "@ca-build" in build_site:
                tmp_builder = "Oracle"
            else:
                tmp_builder = "(unknown)"

    if tmp_builder == '' and re.match("Linux version .* \(.*\) \(gcc version .*\) .*", line):
        tmp_builder = "(unknown)"

    # Uname format:
    # Linux <nodename> <kernel_version> # 1 SMP Day Mon dd hh:mm:ss TZ yyyy x86_64 x86_64 x86_64 GNU/Linux
    #
    tmp_level = words[2]
    if ".el" in tmp_level and "xen" in tmp_level:
        # (not necessarily)
        # Virtual_guest = True
        # Virtual_type  = "Xen"
        pass

    if ".el" in tmp_level and "uek" in tmp_level:
        tmp_builder = "Oracle UEK"
        if release == "":
            release = "Oracle"
        # release_extra = ATTN+"Non-RHEL OS!"  # REMOVE

    tk = tmp_level.split('.')
    wtk = len(tk)

    tmp_major = int(tk[0])         # -> 2
    tmp_minor = int(tk[1])         # -> 6

    tk_rel1 = tk[2]                # -> 32-431
    if "-" in tk_rel1:
        stk = tk_rel1.split("-")
        tmp_rel1 = int(stk[0])    # -> 32
        if stk[1].startswith("rt") or not stk[1].isdigit():
            pass
        else:
            tmp_rel2 = int(stk[1])  # -> 431
    elif tk_rel1.isdigit():
        # eg: CentOS kernel in uname: 4.0.5
        tmp_rel1 = int(tk[2])      # -> n

    if tmp_arch == '':
        tmp_arch = tk[wtk - 1]       # arch is the last word, e.g.: x86_64
    tmp_expanded = kernel_normalize(tmp_major, tmp_minor, tmp_rel1, tmp_rel2)

    if "s390" in line:
        s390 = True

    if release == "":
        if "redhat.com" in line:
            release = "red hat"
        else:
            release = "Unknown"

    check_kernelStr_element("level", tmp_level, source)
    check_kernelStr_element("builder", tmp_builder, source)
    check_kernelStr_element("date", tmp_date, source)
    check_kernelStr_element("arch", tmp_arch, source)

    check_kernelNum_element("major", tmp_major, source)
    check_kernelNum_element("minor", tmp_minor, source)
    check_kernelNum_element("rel1", tmp_rel1, source)
    check_kernelNum_element("rel2", tmp_rel2, source)

    check_kernelStr_element("expanded", tmp_expanded, source)

    return

# ---------------------------------------------#
# function: check_kernelStr_element()
# check (and set if appropriate) a string kernel attribute
# ---------------------------------------------#


def check_kernelStr_element(element_name, new_value, source):
    global kernelStr        # Key_data()      # Key: various kernel attributes
    global kernelStr_origin  # Key_data()      # Key: attribute source (var/log/dmesg, etc)

    if new_value == '':
        return
    if new_value == kernelStr[element_name]:
        return
    if kernelStr[element_name] == '':
        kernelStr[element_name] = new_value
        kernelStr_origin[element_name] = source
        return
    anomaly_line = "Linux version value [{0}] already seen as {1} ({2}), attempting to set to {3} ({4})".\
                   format(element_name, kernelStr[element_name], kernelStr_origin[element_name], new_value, source)
    handle_anomaly("KERN", anomaly_line)
    return

# ---------------------------------------------#
# function: check_kernelNum_element()
# check (and set if appropriate) a numeric kernel attribute
# ---------------------------------------------#


def check_kernelNum_element(element_name, new_value, source):
    global kernelNum        # Counter()       # Key: various numeric kernel attributes
    global kernelNum_origin  # Key_data()      # Key: attribute source (var/log/dmesg, etc)

    if new_value == -1:
        return
    if new_value == kernelNum[element_name]:
        return
    if kernelNum[element_name] == 0:
        kernelNum[element_name] = new_value
        kernelNum_origin[element_name] = source
        return
    anomaly_line = "Linux version value [{0}] already seen as {1} ({2}), attempting to set to {3} ({4})".\
                   format(element_name, kernelNum[element_name], kernelNum_origin[element_name], new_value, source)
    handle_anomaly("KERN", anomaly_line)
    return


# ---------------------------------------------#
# function: crunch_files_for_vg_names()
# get all vg names
# ---------------------------------------------#
def crunch_files_for_vg_names():
    global all_vg_names
    global no_volume_groups_found  # 0
    global all_lsblk_lvm_names  # ''

    vg_file_list = "sos_commands/devicemapper/vgdisplay_-vv "\
                   "sos_commands/devicemapper/vgdisplay_-vv_--config_global_locking_type_0 "\
                   "sos_commands/devicemapper/vgs_-v "\
                   "sos_commands/devicemapper/vgs_-v_--config_global_locking_type_0 "\
                   "sos_commands/lvm2/vgdisplay_-vv_--config_global_locking_type_0 "\
                   "sos_commands/lvm2/vgdisplay_-vv_--config_global_locking_type_0_2 "\
                   "sos_commands/lvm2/vgs_-v_-o_vg_mda_count_vg_mda_free_vg_mda_size_vg_mda_used_count_vg_tags_--config_global_locking_type_0 "\
                   "sos_commands/lvm2/vgs_-v_-o_vg_mda_count_vg_mda_free_vg_mda_size_vg_mda_used_count_vg_tags_--config_global_locking_type_0_2 "\
                   "sos_commands/devicemapper/dmsetup_info_-c "\
                   "sos_commands/filesys/lsblk "\
                   "sos_commands/block/lsblk "\
                   ""

    # In case other lvm/vgs files aren't lsblk files are added. See case

    files = vg_file_list.split()
    for file in files:

        if file == '' or file.startswith("#"):
            continue
        if not file_exists_with_data(file):
            continue

        if "dmsetup" in file:
            crunch_vg_names_dmsetup(file)
        elif "lsblk" in file:
            crunch_lsblk_file(file, True)
        else:
            crunch_vg_names(file)

    if all_vg_names == '':
        crunch_mount_data(True)

    if no_volume_groups_found:
        if all_vg_names != "":
            vg_count = wordcount(all_vg_names)
            lsblk_lvm_count = wordcount(all_lsblk_lvm_names)
            anomaly_line = "Found {0} 'No volume groups found' line{1}, but found {2} vg name{3} and {4} lsblk lvm name{5}".\
                           format(no_volume_groups_found, plural(no_volume_groups_found), vg_count, plural(vg_count), lsblk_lvm_count, plural(lsblk_lvm_count))
            handle_anomaly("LVM", anomaly_line)
            # error_print('l',"'No volume groups found' line(s) found, but all_vg_names='{0}'".format(all_vg_names))
            # this can happen, see cases 01693697 & 01920872, gluster vgs, but no vgs in vg files...
            # (lvm data found in dmsetup_ls_--tree)

    return


# ---------------------------------------------#
# function: vg_corrupt_line()
# vg files can have asyn lines written to
# them which corrupt the normal data.
# The un/locking messages can show up *anywhere* in the vgdisplay output - very hard to code for
# see cases 01383877, 01490278 (to name just a few)
# ---------------------------------------------#
def vg_line_corrupt(line):
    corrupt_words = "Unlocking Locking Archiving Reloading Processing Adding Requesting Reloading Wiping detected Finding"

    # if not "ing" in line: # save some processing (good as long as all corrupt words end in "ing")
    # return False  # nice while it lasted...(really, they could have used 'detecting')

    words = corrupt_words.split()
    for word in words:
        if word_in_list(word, line):
            return True

    return False

# ---------------------------------------------#
# function: crunch_vg_names()
# get all vg names
# ---------------------------------------------#


def crunch_vg_names(fn):
    global vg_2_dup_uuids  # Key_data()         # key: vg name              data: list of duplicate uuids vg was known as
    global vg_2_attr      # Key_data()         # key: vg name              data: attributes of vg
    global no_volume_groups_found  # 0

    vg_file = fn
    fh = openfile(vg_file)
    if fh is None:
        return

    found_hdr_1 = False
    found_hdr_2 = False
    corrupt_line = False
    corruption_seen = False
    corruption_count = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        words = line.split()
        wc = len(words)
        if wc < 3:
            continue

        vg_name = ''
        vg_Attr = ''
        # vg_Ext  = ''
        # vg_noPV = ''
        # vg_noLV = ''
        # vg_noSN = ''
        # vg_VSize = ''
        # vg_VFree = ''
        vg_uuid = ''
        vg_profile = ''

        corrupt_line = vg_line_corrupt(line)
        if corrupt_line:
            corruption_count += 1
            # debug_print(0,line)
            # debug_print(0,vg_file)

        if "No volume groups found" in line:
            # debug_print(z,line)
            no_volume_groups_found += 1
            continue

        # WARNING: Duplicate VG name rootvg: Existing TzpgF2-vFWQ-kKn1-fpbk-nfiX-hZc5-Mra1NP (created here) takes precedence over eMIbP8-Y4dD-A7ga-o5QT-oDtL-wI3L-AGj2ix
        if line.startswith("WARNING: Duplicate VG name") and "takes precedence over" in line:
            if corrupt_line:
                continue
            else:
                vg_name = words[4].rstrip(":")  # take off trailing ':'
                vg_uuid = words[5]
                vg_dup_uuid = words[wc - 1]
                if vg_uuid == "Existing":
                    vg_uuid = words[6]
                vg_2_dup_uuids[vg_name] = unique_list(vg_2_dup_uuids[vg_name], clean_uuid(vg_dup_uuid))
                vg_name = update_vg_override(vg_name, vg_uuid, vg_file)

        if words[0] == "WARNING:":
            if corrupt_line:
                corruption_seen = True
                continue
            else:
                blurb = ''
                if line.startswith("WARNING: Duplicate VG name"):
                    blurb = "{0}".format(cfa_kcs("39278"))
                anomaly_line = squeeze("'{0}' ({1})".format(line, vg_file))
                handle_anomaly_with_points("LVMW", anomaly_line, 'lvm', 4)

        if line.startswith("Couldn't find device"):
            if corrupt_line:
                corruption_seen = True
                continue
            else:
                anomaly_line = "'{0}' ({1})".format(line, vg_file)
                handle_anomaly_with_points("LVMW", anomaly_line, 'lvm', 5)

        if line.endswith(": Checksum error"):
            if corrupt_line:
                corruption_seen = True
                continue
            else:
                do_checksum_anom(line, vg_file)
                continue

        if line.endswith(" Was device resized?"):
            if corrupt_line:
                corruption_seen = True
                continue
            else:
                do_resized_anom(line, vg_file)
                continue

        if words[0] == "VG" and words[1] == "Name":
            if corrupt_line:
                corruption_seen = True
                vg_name = ""
            else:
                vg_name = words[2]
                vg_name = update_vg(vg_name, "", vg_file)

        if "Finding volume group" in line:
            if corrupt_line:
                corruption_seen = True
                vg_name = ""
            else:
                vg_name = words[3].strip('"')
                vg_name = update_vg(vg_name, "", vg_file)

        # The last 2 words in the header lines are "VG UUID",  but the last word in a detail line is the UUID
        # so the header lines have 1 more word than the detial lines.

        if wc == 9 or wc == 10 or wc == 11:
            if wc == 10 and words[0] == "VG" and words[1] == "Attr":
                found_hdr_2 = True
                continue
            if wc == 11 and words[0] == "VG" and words[1] == "Attr":
                found_hdr_2 = True
                continue
            if wc == 9 and found_hdr_2:
                if corrupt_line:
                    corruption_seen = True
                else:
                    vg_name = words[0]
                    vg_Attr = words[1]
                    # vg_Ext = words[2]
                    # vg_noPV = words[3]
                    # vg_noLV = words[4]
                    # vg_noSN = words[5]
                    # vg_VSize = words[6]
                    # vg_VFree = words[7]
                    vg_uuid = words[8]
                    if wc == 10:
                        vg_profile = words[9]

        if wc == 13:
            if words[0] == "VG" and words[1] == "Attr":
                found_hdr_1 = True
                continue  # Header
            if found_hdr_1:
                if corrupt_line:
                    corruption_seen = True
                else:
                    vg_name = words[0]
                    vg_Attr = words[1]
                    # vg_Ext = words[2]
                    # vg_noPV = words[3]
                    # vg_noLV = words[4]
                    # vg_noSN = words[5]
                    # vg_VSize = words[6]
                    # vg_VFree = words[7]
                    vg_uuid = words[8]

        if vg_name != '':
            vg_name = update_vg(vg_name, vg_uuid, vg_file)

        # VG_ATTR_NOTE:
        #
        # vg_Attr[0] = Permissions: (w)riteable, (r)eadable
        # vg_Attr[1] = Resi(z)eable
        # vg_Attr[2] = E(x)ported
        # vg_Attr[3] = (p)artial: one or more physical volumes belonging to the volume group are missing from the system
        # vg_Attr[4] = Allocation policy: (c)ontiguous, c(l)ing, (n)ormal, (a)nywhere
        # vg_Attr[5] = (c)lustered, (s)hared

        if len(vg_Attr) == 6:
            vg_2_attr[vg_name] = vg_Attr
            if vg_Attr[3] == 'p':
                anomaly_line = "One or more physical volumes belonging to volume group {0} are missing from the system, {1} ({2})".\
                               format(vg_name, cfa_sfdc("01645434"), vg_file)
                handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 1)

    # end: for line in vg_lines:

    if corruption_seen:
        anomaly_line = "{0}: async processing messages have split {1} line{2} ({3})".\
                       format(this_script_name, corruption_count, plural(corruption_count), vg_file)
        handle_anomaly("DATA-4", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, vg_file))
    return

# ---------------------------------------------#
# function: do_checksum_anom()
# issue anom (Checksum error) in one spot
# ---------------------------------------------#


def do_checksum_anom(line, source):
    global cluster_status  # False
    if cluster_status:
        blurb = "{0}".format(cfa_kcs("65999"))
    else:
        blurb = "{0}".format(cfa_sfdc("01629791"))
    anomaly_line = "'{0}', {1} ({2})".format(line, blurb, source)
    handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 1)
    return

# ---------------------------------------------#
# function: do_resized_anom()
# issue anom (Was device resized?) in one spot
# ---------------------------------------------#


def do_resized_anom(line, source):
    anomaly_line = "'{0}', {1} ({2})".format(line, cfa_sfdc("01655457"), source)
    handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 1)
    return


# ---------------------------------------------#
# function: crunch_vg_names_dmsetup()
# catch any vg names referenced in dmsetup_info_-c
#
# Name                   Maj Min Stat Open Targ Event  UUID
# vg_rootdisk-lv_swap    253   0 L--w    2    1      0 LVM-lR23zF3ZN2Ni6wlJH2Xml0eA4WV9ktSvBh4e3el8SOo2twj5lk96eHHHOJ8WvgMp
# vg_rootdisk-lv_root    253   1 L--w    1    1      0 LVM-lR23zF3ZN2Ni6wlJH2Xml0eA4WV9ktSvKpAeimrsXxNK9e0aNuLJFvw2ddvdgvGF
#
# ---------------------------------------------#
def crunch_vg_names_dmsetup(dm_file):

    fh = openfile(dm_file)
    if fh is None:
        return

    flush = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if line == "":
            continue
        if line == "/proc/devices: fopen failed: No such file or directory":
            flush = True
        if flush:
            continue

        words = line.split()
        wc = len(words)
        if wc < 8:
            continue

        if words[0] == "Name" and words[1] == "Maj":
            continue  # Header
        name = words[0]
        uuid = words[7]
        if uuid.startswith("LVM-"):
            debug_print(4, "'{0}' ({1})".format(line, dm_file))
            vg_name = split_vg_name(name, dm_file)
            lv_name = split_lv_name(name, dm_file)
            vg_name = update_vg(vg_name, "", dm_file)
            uuid = uuid[len("LVM-"):]
            mm = "{0}:{1}".format(words[1], words[2])
            update_lv(vg_name, lv_name, '', uuid, mm, dm_file)
            continue

        if uuid.startswith("mpath-"):
            scsi_id = uuid[len('mpath-'):]
            if is_scsi_id(scsi_id):
                track_scsi_id(scsi_id, name, dm_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dm_file))
    return


# ---------------------------------------------#
# function: crunch_pvs()
#
# 'pvs_-a_-v' file example:
#
# File descriptor 4 (/tmp/pl070118-2016052514121464178330/sos_logs/sos.log) leaked on pvs invocation. Parent PID 7008: /usr/bin/python
# Wiping cache of LVM-capable devices
# PV                        VG   Fmt  Attr PSize   PFree   DevSize PV UUID
# /dev/ram0                           ---       0       0   16.00m
# /dev/ram1                           ---       0       0   16.00m
# /dev/ram10                          ---       0       0   16.00m
# /dev/ram11                          ---       0       0   16.00m
# <snip>
# /dev/sda1                           ---       0       0  512.00m
# /dev/sda2                 vg00 lvm2 a--   39.50g   6.50g  39.50g hEQb2o-LqnQ-yVcN-7dHd-Dixc-WTef-rybzBd
# /dev/sdb                  vg01 lvm2 a--   11.00g      0   11.00g d7G8Av-zcUh-2yfC-UWWR-01OG-K5VE-joxk9R
# /dev/sdc                  vgDP lvm2 a--    2.00t      0    2.00t fXwsPV-dizK-NM4e-upz8-4IZV-AtpJ-6VKzUo
# /dev/sdd                  vgDP lvm2 a--    2.00t      0    2.00t iXkz18-fk0w-W1ub-HdX0-XklL-Jdz3-CD2Uw2
# /dev/sde1                 vgDP lvm2 a--  850.00g 301.99g 300.00g Qq67ZC-wXZa-SskI-aHi7-26tm-ozLG-UOrOGr
# /dev/vg00/lv_opt                    ---       0       0    3.00g
# /dev/vg00/lv_swap                   ---       0       0   16.00g
# <snip>
#
#
# PV               VG         Fmt  Attr PSize   PFree
# /dev/emcpowerag1 vg_canales lvm2 a--u 500.00g     0
# /dev/emcpowerah1 vg_canales lvm2 a--u 500.00g     0
# /dev/emcpowerai1 vg_canales lvm2 a--u 500.00g     0
# /dev/emcpoweraj1 vg_canales lvm2 a--u 500.00g     0
# /dev/emcpowerc   vg_twdc    lvm2 a--u 120.00g 20.00g
# /dev/emcpoweru   vg_agent   lvm2 a--u  50.00g 96.00m
# /dev/sda2        vg00alt    lvm2 a--u 130.50g 20.38g
# /dev/sda3        vg00       lvm2 a--u 148.50g 14.38g
#
# ---------------------------------------------#
def crunch_pvs():

    pv_files = "" \
               "sos_commands/devicemapper/pvs_-a_-v "\
               "sos_commands/lvm2/pvs_-a_-v "\
               "sos_commands/lvm2/pvs_-a_-v_-o_pv_mda_free_pv_mda_size_pv_mda_count_pv_mda_used_count_pe_start_--config_global_locking_type_0 "\
               "sos_commands/lvm2/pvs_-a_-v_-o_pv_mda_free_pv_mda_size_pv_mda_count_pv_mda_used_count_pe_start_--config_global_locking_type_0_2 "\
               ""
    words = pv_files.split()

    for file in words:

        if file == '' or file.startswith("#"):
            continue
        if file_exists_with_data(file):
            crunch_pv_file(file)

    # end: for file in words:

    return


# ---------------------------------------------#
# function: crunch_pv_file()
#
# Examples:
#
# WARNING: Locking disabled. Be careful! This could corrupt your metadata.
# Using physical volume(s) on command line.
# PV           VG      Fmt  Attr PSize    PFree   DevSize PV UUID:UUID  <<--- wc = 9
# /dev/sda1                 ---        0       0  500.00m                                               0         0      0        0      0
# /dev/sda2    vg_data lvm2 a--    19.53g  20.00m  19.53g 30x4PG-26ol-gGme-qZGL-kTKj-MQjt-rk7jL7   508.50k  1020.00k     1        1   1.00m <<--- wc = 13
# /dev/sda3    vg_root lvm2 a--   259.34g  40.00m 259.34g woX1M9-iot1-tfms-FJgF-vtsm-8jnJ-xWdEtq   508.00k  1020.00k     1        1   1.00m
# /dev/sddlmaa sat_vg  lvm2 a--  1024.00g 324.00g   1.00t n0YqmM-8Z9R-hh7m-uEUk-w7AK-AdWZ-Y73O4s   504.50k  1020.00k     1        1   1.00m
# Reloading config files
# Wiping internal VG cache
#
# PV                     VG    Fmt  Attr PSize   PFree DevSize PV UUID                                PMdaFree  PMdaSize  # PMda # PMdaUse 1st PE
# /dev/ram0                         ---       0     0   16.00m                                               0         0      0        0      0
# /dev/ram1                         ---       0     0   16.00m                                               0         0      0        0      0
# /dev/sda2              vg00  lvm2 a--   49.47g 5.47g  49.50g 2Jvihf-cj7q-6TJ7-l8nl-52fd-mCYm-gnXtCe   506.50k  1020.00k     1        1   1.00m
# /dev/sdb               vgapp lvm2 a--  129.97g 9.97g 130.00g n7ZdK8-QjRF-efUu-BAZX-Cc3z-70G3-f2XVei   508.00k  1020.00k     1        1   1.00m
# /dev/vg00/lvhome                  ---       0     0    2.00g                                               0         0      0        0      0
#
#
# This combo is seen frequently (hence the prev_line_corrupt & flush_next_line kludge):
#
# /dev/mapper/mpatht  ax4      lvm2 a--     Reloading config files
# Wiping internal VG cache
# 2.00t 516.00m   2.00t qrXt3M-ufDG-q8sI-1ckG-PhuQ-SgZ8-n0hAvU
# (at some point we could try to recombine the data and toss the 'Reloading../Wiping' data that interjects itself.)
#
# ---------------------------------------------#
def crunch_pv_file(pv_file):
    global all_unassoc_uuids  # ""

    fh = openfile(pv_file)
    if fh is None:
        return

    all_dup_devs = ''
    corruption_seen = False
    corrupt_line = False
    prev_line_corrupt = False
    flush_next_line = False
    corruption_count = 0

    header_found = False
    header_word_cnt = 0
    header_line = ''
    p_vg = -1
    p_fmt = -1
    p_attr = -1
    p_uuid = -1
    word_uuid = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()

        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)

        prev_line_corrupt = corrupt_line
        corrupt_line = vg_line_corrupt(line)
        if corrupt_line:
            corruption_count += 1

        if flush_next_line:
            flush_next_line = False
            continue

        if wc < 2:
            continue

        if line == "Reloading config files":
            continue

        if line == "Wiping internal VG cache":
            if prev_line_corrupt:
                flush_next_line = True
            continue

        if line.startswith("Configuration setting") and "invalid." in line:
            anomaly_line = "'{0}' ({1})".format(line, pv_file)
            handle_anomaly("LVMCONF", anomaly_line)
            continue

        if line.startswith("Configuration setting") and "unknown." in line:
            anomaly_line = "'{0}' ({1})".format(line, pv_file)
            handle_anomaly("LVMCONF", anomaly_line)
            continue

        if line.endswith(" Was device resized?"):
            do_resized_anom(line, pv_file)
            continue

        if line.startswith("WARNING:"):
            if "This could corrupt your metadata" in line:  # ignore as it seems to be printed most of the time...
                pass
            else:
                anomaly_line = "'{0}' ({1})".format(line, pv_file)
                handle_anomaly_with_points("LVMW", anomaly_line, "lvm", 10)
            continue

        if line.endswith("physical volumes missing."):
            anomaly_line = "'{0}' ({1})".format(line, pv_file)
            handle_anomaly_with_points("LVMW", anomaly_line, "lvm", 10)

        if line.endswith(": Checksum error"):
            do_checksum_anom(line, pv_file)
            continue

        if line.endswith(" Was device resized?"):
            do_resized_anom(line, pv_file)
            continue

        # ' Found duplicate PV 48Eb590Ff36x7aqHSXtnn0lEcgsRqsQr: using /dev/emcpowerc not /dev/sdp'
        # ' Using duplicate PV /dev/emcpowerc from subsystem POWER2, ignoring /dev/sdp'
        if line.startswith("Found duplicate PV ") or line.startswith("Using duplicate PV "):
            dup_dev = words[wc - 1]
            # if dup_dev.startswith("/dev/"): dup_dev = dup_dev[len("/dev/"):]
            all_dup_devs = unique_list(all_dup_devs, dup_dev)
            continue

        if words[0] == "PV" and words[1] == "VG":
            header_found = True
            header_word_cnt = wc
            header_line = line
            if wc > 8:
                if words[7] == "PV" and (words[8] == "UUID" or words[8] == "UUID:UUID"):
                    header_word_cnt -= 1  # "PV UUID" is 2 words in hdr, but 1 in report
                    word_uuid = 7
            if wc > 14:
                if words[13] == "1st" and words[14] == "PE":
                    header_word_cnt -= 1  # "1st PE" is 2 words in hdr, but 1 in report

            p_vg = header_line.find("VG")
            p_fmt = header_line.find("Fmt")
            p_attr = header_line.find("Attr")
            p_uuid = header_line.find("PV UUID")
            continue  # Header
        if not header_found:
            continue

        if corrupt_line:                        # if corruption seen on this line
            corruption_seen = True
            continue

        if line.startswith("unknown device "):
            # keep word count consistent
            line = line.replace("unknown device", "unknown_device")
            words = line.split()
            wc = len(words)

        if line.startswith("[unknown] "):
            # keep word count consistent
            line = line.replace("[unknown]", "unknown_device")
            words = line.split()
            wc = len(words)

        if not words[0].startswith("/dev/") and words[0] != "unknown_device":
            if corruption_seen:
                pass
            else:
                error_print("d", "'{0}' ({1})".format(line, pv_file))
            continue

        # if wc > header_word_cnt:
            # error_print("d","'{0}' ({1})".format(line,pv_file))
            # continue

        if line[p_vg] == ' ' and line[p_fmt] == '':
            continue  # not intersted

        # VG name missing?
        # if wc == (header_word_cnt -1) and words[1].startswith("lvm"):
        if words[1].startswith("lvm"):
            unassoc_uuid = '?'
            if wc > 6:
                unassoc_uuid = words[6]
                all_unassoc_uuids = unique_list(all_unassoc_uuids, unassoc_uuid)
            anomaly_line = "PV {0} does not appear to be associated with any VG, uuid: {1} ({2})".\
                           format(words[0], unassoc_uuid, pv_file)
            handle_anomaly_with_points('LVM', anomaly_line, 'configuration', 1)
            continue

        # VG, fmt and uuid missing?
        if words[1].startswith("---") or words[1] == "--":
            anomaly_line = "PV {0} does not appear to be associated with any VG, nor does it have a format and uuid ({1})".\
                           format(words[0], pv_file)
            # more than 75% of cases had these anomalies so removing until it can be refined
            # handle_anomaly('LVM',anomaly_line)
            continue

        pv_path = words[0]
        # if not pv_path.startswith("/dev/"): continue # most likely preceeding line split by async corruption

        if word_in_list(pv_path, all_dup_devs):
            continue

        # PV                                            VG                                   Fmt  Attr PSize  PFree  DevSize PV UUID                                PMdaFree  PMdaSize  # PMda # PMdaUse 1st PE
        # /dev/mapper/3690b11c00039d46a0000070a544ad00e 7df311de-51ee-4ad7-9e7c-663c07963b35 lvm2 a--  64.00t 33.82t  64.00t XWHtWk-EQWa-ffMo-58pb-j7ST-qTmi-GCAMRL    63.48m   128.00m     2        2 129.00m

        pv_name = ""
        vg_name = words[1]
        vg_name = update_vg(vg_name, "", pv_file)
        pv_fmt = words[2]
        pv_attr = words[3]
        # The pv_attr codes  are [3 bytes]: (a)llocatable, e(x)ported and (m)issing.
        # [4 bytes]: (a)llocatable, e(x)ported (m)issing and (u)used
        pv_psize = '0'
        pv_pfree = '0'
        pv_devsize = '0'
        pv_uuid = ''
        if wc > 4:
            pv_psize = words[4].strip('<')  # case
        if wc > 5:
            pv_pfree = words[5]
        if wc > 6:
            pv_devsize = words[6].strip('<')  # case
        if wc > 7:
            pv_uuid = words[7]

        if pv_psize != '0' and pv_devsize != '0' and (pv_psize != pv_devsize):
            # debug_print(z,"'{0}' ({1})".format(line,pv_file))
            i_psize = mg_conv(pv_psize, 0, 0)
            i_devsize = mg_conv(pv_devsize, 0, 0)
            if i_psize > i_devsize:
                blurb = "larger"
            else:
                blurb = "smaller"  # unlikely to be significant
            if blurb == "larger":
                anomaly_line = "VG/PV {0} {1} appears to be sized {2} ({3}) than actual device ({4}) ({5})".\
                               format(vg_name, pv_path, blurb, pv_psize, pv_devsize, pv_file)
                handle_anomaly_with_points('LVM', anomaly_line, 'configuration', 1)

        if pv_path == "unknown_device":
            pv_name = pv_path
        # the following fields are not in sos_commands/devicemapper/pvs_-a_-v
        # pv_pdmafree = words[8]
        # pv_pdmasize = words[9]
        # pv_pdma = words[10]
        # pv_pdmause = words[11]
        # pv_1stPE = words[12]
        if pv_name == "unknown_device":
            pv_path = ""
        else:
            tmp = pv_path.split("/")
            pv_name = tmp[len(tmp) - 1]  # last element in /pv_path
        update_pv(vg_name, pv_name, pv_path, pv_uuid, "", pv_file)

    # end: for line in fh:

    if corruption_seen:
        anomaly_line = "{0}: async processing messages have split {1} line{2} ({3})".\
                       format(this_script_name, corruption_count, plural(corruption_count), pv_file)
        handle_anomaly("DATA-4", anomaly_line)

    wc_all_dup_devs = word_count(all_dup_devs)
    if wc_all_dup_devs:
        anomaly_line = "pvs module found {0} duplicate PV{1} ({2})".\
                       format(wc_all_dup_devs, plural(wc_all_dup_devs), pv_file)
        handle_anomaly("LVM", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, pv_file))
    return


# ---------------------------------------------#
# function: crunch_vgdisplay()
# ---------------------------------------------#
def crunch_vgdisplay():

    vg_files = ""\
        "sos_commands/devicemapper/vgdisplay_-vv " \
        "sos_commands/devicemapper/vgdisplay_-vv_--config_global_locking_type_0 " \
        "sos_commands/lvm2/vgdisplay_-vv_--config_global_locking_type_0 " \
        "sos_commands/lvm2/vgdisplay_-vv_--config_global_locking_type_0_2 " \
        ""
    tmp = vg_files.split()
    for vg_file in tmp:
        if vg_file == '' or vg_file.startswith("#"):
            continue
        if file_exists_with_data(vg_file):
            crunch_vgdisplay_file(vg_file)
    # end: for vg_file in tmp:

    return

# ---------------------------------------------#
# function: crunch_vgdisplay()
# ---------------------------------------------#


def crunch_vgdisplay_file(vg_file):
    global Oracle  # False

    fh = openfile(vg_file)
    if fh is None:
        return

    vg_name = ""
    vg_uuid = ""
    pv_name = ""
    pv_uuid = ""
    pv_path = ""
    lv_path = ""
    lv_name = ""
    lv_uuid = ""

    corruption_seen = False
    corrupt_line = False
    corruption_count = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        line = line.strip()
        if line == "":
            continue
        words = line.split()
        wc = len(words)
        check_for_partitioned_dev(line, words[0], vg_file)

        if wc < 3:
            continue

        corrupt_line = vg_line_corrupt(line)
        if corrupt_line:
            corruption_count += 1

        if "--- Volume group ---" in line:          # reset everything
            vg_name = ""
            vg_uuid = ""
            pv_name = ""
            pv_uuid = ""
            pv_path = ""
            lv_path = ""
            lv_name = ""
            lv_uuid = ""

        if "--- Logical volume ---" in line:          # reset LV & PV fields
            pv_name = ""
            pv_uuid = ""
            pv_path = ""
            lv_path = ""
            lv_name = ""
            lv_uuid = ""

        if "--- Physical volumes ---" in line:          # reset PV fields
            pv_name = ""
            pv_uuid = ""
            pv_path = ""

        if words[0] == "VG" and words[1] == "Name":  # 1st seen in VG status, but repeated in each LV so don't clear
            if corrupt_line:                        # if corruption seen on this line
                corruption_seen = True
            else:
                vg_name = words[2]
                vg_name = update_vg(vg_name, vg_uuid, vg_file)

        if words[0] == "VG" and words[1] == "UUID":
            if corrupt_line:
                corruption_seen = True
            else:
                vg_uuid = words[2]
                if vg_name != "":
                    vg_name = update_vg(vg_name, vg_uuid, vg_file)

        if words[0] == "LV" and words[1] == "Path":  # typical: /dev/vg_name/lv_name
            if corrupt_line:
                corruption_seen = True
                lv_path = ""
            else:
                lv_path = words[2]

        if words[0] == "PV" and words[1] == "Name":
            if corrupt_line:
                corruption_seen = True
                pv_name = ""
            else:
                pv_name = words[2]
                if pv_name == "unknown" and words[3] == "device":
                    # pv_name = ""
                    pv_path = ""
                else:
                    pv_path = pv_name
                    if pv_name[0:5] == "/dev/":
                        tmp = pv_name.split("/")
                        pv_name = tmp[len(tmp) - 1]  # last element in /dev/pv_name

        if words[0] == "PV" and words[1] == "UUID":
            if corrupt_line:
                corruption_seen = True
                pv_uuid = ""
            else:
                pv_uuid = words[2]
                if (vg_name != "" and pv_name != "") or pv_name == "unknown":
                    update_pv(vg_name, pv_name, pv_path, pv_uuid, "", vg_file)

        if words[0] == "LV" and words[1] == "Name":
            if corrupt_line:
                corruption_seen = True
                lv_name = ""
            else:
                lv_name = words[2]
                if lv_name.count("/") > 2:
                    lv_path = lv_name
                    tmp = lv_path.split("/")
                    lv_name = tmp[len(tmp) - 1]  # last element in /dev/vg_name/lv_name

        if words[0] == "LV" and words[1] == "UUID":
            if corrupt_line:
                corruption_seen = True
                lv_uuid = ""
            else:
                lv_uuid = words[2]

        # last line, gather up elements and call routines to update vg and lv data
        if words[0] == "Block" and words[1] == "device":
            if corrupt_line:
                corruption_seen = True
                lv_major_minor = ""
            else:
                if words[2].isdigit():
                    lv_major_minor = words[2]
                else:
                    lv_major_minor = ""
                # 'Block device   Finding volume group "vg_nclinux_02"' - see case

            if corruption_seen and lv_path.count("/") > 2 and (vg_name == "" or lv_name == ""):
                tmp = lv_path.split("/")
                # if vg_name == "": vg_name = check_vg_prefix(tmp[2],vg_file)
                if vg_name == "":
                    vg_name = split_valid_vg_name(tmp[2], vg_file)
                if lv_name == "":
                    lv_name = tmp[len(tmp) - 1]  # last element in /dev/vg_name/lv_name
            if vg_name != "":
                vg_name = update_vg(vg_name, vg_uuid, vg_file)
            if vg_name != "" and lv_name != "":
                update_lv(vg_name, lv_name, lv_path, lv_uuid, lv_major_minor, vg_file)

    # end: for line in fh:

    if corruption_seen:
        anomaly_line = "{0}: async processing messages have split {1} line{2} ({3})".\
                       format(this_script_name, corruption_count, plural(corruption_count), vg_file)
        handle_anomaly("DATA-4", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, vg_file))
    return


# ---------------------------------------------#
# function: possible_vg_lv_name()
# check if name has a chance of being a legit vg-lv
# return True/False
# ---------------------------------------------#
def possible_vg_lv_name(name, calling_routine, source):
    global all_vg_names
    global no_volume_groups_found  # 0
    global all_dev_mfgs  # "" # EMC, NETAPP, etc. <<-- N.B. These values can be seen in upper/lower/mixed case. Because of this and
    global mfg_models  # Key_data()            # key: mfg                  data: model(s)          e.g. EMC,     SYMMETRIX
    global all_lsblk_lvm_names  # ''
    global all_lsblk_mpath_names  # ''
    global all_lsblk_dm_names  # ''
    global vg_lv_fs_but_no_vgs_list  # '' # vg_lv_name~source list of these items
    global data_xxx_out  # False
    if name == "":
        # debug_print(z,"name is null '{0}' called by {1} ({2})".format(name,calling_routine,source))
        return(False)

    if name.startswith("-"):
        # debug_print(z,"name starts with dash '{0}' called by {1} ({2})".format(name,calling_routine,source))
        return(False)

    if '-' not in name:
        # debug_print(z,"name has no '-' '{0}' called by {1}  ({2})".format(name,calling_routine,source))
        return(False)
    if name.startswith("mapper-"):
        if no_volume_groups_found:
            return(False)
        # part2 = name[len("mapper-"):]
        # if part2.startswith("mpath"):
            # debug_print(z,"name has mapper-mpath fmt '{0}' called by {1}  ({2})".format(name,calling_routine,source))
            # return(False)
        # if is_scsi_id(part2):
            # debug_print(z,"name has mapper-scsi_id fmt '{0}' called by {1}  ({2})".format(name,calling_routine,source))
            # return(False)

    if name.startswith("rootvg-"):
        return(True)

    if word_in_list(name, all_lsblk_mpath_names):
        return(False)
    last_char = name[len(name) - 1:]
    if re.match(nf1_re, last_char):  # 1-9?
        non_part_name = name[0:len(name) - 1]
        if word_in_list(non_part_name, all_lsblk_mpath_names):
            return(False)
    if name.startswith("mpath-"):
        tmp = name.split('-')  # mpath-mpathb, check mpathb (see case )
        if word_in_list(tmp[1], all_lsblk_mpath_names):
            return(False)

    if word_in_list(name, all_lsblk_dm_names):
        return(False)

    # case , e.g. name = 'eql-esx--cl1--alc--sata--datastore--1'
    # data in all_lsblk_dm_names: eql-8-661fc6-81a2ba6be-1fca8aed7955563a-esx-cl1-alc-sata-datastore-1
    if all_lsblk_dm_names != '' and (name.startswith("eql-") or name.startswith("ignore_eql-")):
        tmp_name = name.replace("--", "-")
        if tmp_name.startswith("eql-"):
            tmp_name = tmp_name[len("eql-"):]
        elif tmp_name.startswith("ignore_eql-"):
            tmp_name = tmp_name[len("ignore_eql-"):]
        tmp = all_lsblk_dm_names.split()
        for dm_name in tmp:
            if dm_name.endswith(tmp_name):
                return(False)
        # end: for dm_name in tmp:

    if word_in_list(name, all_lsblk_lvm_names):
        return(True)

    # check for a specific uuid format: 36 char length, 4 dashes, all hex characters,
    # eg: cd57be2c-8965-6444-9bbc-afa6dd2cfa32
    if len(name) == 36 and '-' in name and is_uuid(name):
        tmp_name = name.replace('-', '')  # remove all dashes
        if len(tmp_name) == 32 and is_hex(tmp_name):
            # debug_print(z,"name has uuid fmt '{0}' called by {1}  ({2})".format(name,calling_routine,source))
            return(False)

    # check for a specific "luks-"uuid format: 36 char length, 4 dashes, all hex characters,
    # eg: luks-cd57be2c-8965-6444-9bbc-afa6dd2cfa32
    if name.startswith("luks-") and len(name) == 36 + len("luks-") and '-' in name and is_uuid(name[len("luks-"):]):
        tmp_name = name[len("luks-"):]
        tmp_name = tmp_name.replace('-', '')  # remove all dashes
        if len(tmp_name) == 32 and is_hex(tmp_name):
            # debug_print(z,"name has uuid fmt '{0}' called by {1}  ({2})".format(name,calling_routine,source))
            return(False)

    ln = len(name)
    for i in range(0, ln):
        ch = name[i:i + 1]
        if ch.isalpha():
            continue
        if ch.isdigit():
            continue
        if ch == '-':
            continue
        if ch == '_':
            continue
        if ch == '.':
            continue
        if ch == '+':
            continue
        # debug_print(z,"name contains inv ch '{0}' '{1}' called by {2} ({3})".format(ch,name,calling_routine,source))
        return(False)
    # end: for i in range(0:ln):

    if name.startswith("disk-by--id"):
        return(False)
    if name.startswith("crypt-dm-uuid-mpath-"):
        return(False)

    if name.startswith("cd"):
        if name.startswith("cdrom"):
            return(False)
        if name.startswith("cdrw"):
            return(False)
        if name.startswith("cdwriter"):
            return(False)

    if name.startswith("dvd"):
        if name.startswith("dvd-"):
            return(False)
        if name.startswith("dvdrw"):
            return(False)
        if name.startswith("dvdwriter"):
            return(False)

    if name.startswith("live-"):
        if name.startswith("live-rw"):
            return(False)
        if name.startswith("live-base"):
            return(False)

    if all_vg_names == '' and name.startswith("MD3") and word_in_list("DELL", all_dev_mfgs):
        if re.match("MD3620f-" + nf1_re + "_(meta|data|home)" + nf2_re, name) and "MD36xxf" in mfg_models["DELL"]:
            return(False)
        if re.match("MD3660f-" + nf1_re + "_(meta|data|home)" + nf2_re, name) and "MD36xxf" in mfg_models["DELL"]:
            return(False)
        if re.match("MD3820f-" + nf1_re + "_(meta|data|home)" + nf2_re, name) and "MD38xxf" in mfg_models["DELL"]:
            return(False)
        if re.match("MD3860f-" + nf1_re + "_(meta|data|home)" + nf2_re, name) and "MD38xxf" in mfg_models["DELL"]:
            return(False)

    # see case
    # eql-0-8a0906-1141f670c-af9000444f755cbf-esx-cl1-alc-sata-datastore-2
    # eql-8-661fc6-0a12ba6be-02700629b70536d9_c
    if all_vg_names == '' and name.startswith("eql-") and word_in_list("EQLOGIC", all_dev_mfgs):
        if re.match("eql-" + nf1_re + "-.*", name):
            return(False)

    # see case
    # from fstab:
    # /dev/bwaprd2-01/bwaprd2-01 /bwaprd2-01 ext4 _netdev 0 0
    # /dev/bwaprd2-02/...
    if all_vg_names == '' and fs_related_source(source):
        vg_lv_fs_but_no_vgs_list = unique_list(vg_lv_fs_but_no_vgs_list, name + '~' + source)
        return(False)

    # if "snapshot" in name: return(False)
    # if "pvmove"   in name: return(False)
    # if "_mlog"    in name: return(False)
    # if "_mimage"  in name: return(False)

    # name has passed basic checks, but are there any volume groups present?

    if all_vg_names == '':
        if name.startswith("vx-"):
            return(False)  # most likely something like: /dev/vx/dmpconfig: Aliased to /dev/dmpconfig
        if data_xxx_out:
            return(False)
        if "QEMU_HARDDISK" in name:
            return(False)
        if name.startswith("cciss-"):
            return(False)
        if name.startswith(".tmp-") or name.startswith("temporary-"):
            return(False)  # see cases 01504534 and 01559455, should be a better way to recognize this naming scheme..
        if re.match("floppy-" + fd_re, name):
            return(False)  # see case  in sos_commands/devicemapper/vgscan_-vvv_--config_global_locking_type_0 line follows:
        # /dev/floppy-fd0: Aliased to /dev/floppy in device cache
        if name.startswith("mpath-mpath"):
            return(False)  # see case  in sos_commands/devicemapper/vgscan_-vvv_--config_global_locking_type_0
        # /dev/mpath/mpath0: Aliased to /dev/mapper/mpath0 in device cache
        # /dev/block/252:256513: Aliased to /dev/asm/oraappvol1-501 in device cache (case )
        # /dev/block/251:0: Aliased to /dev/asm/.asm_ctl_spec in device cache (case )
        if Oracle:  # see case  in sos_commands/devicemapper/vgscan_-vvv_---config_global_locking_type_0
            if (name.startswith("mpath-asm") or
                name.startswith("mpath-ocr") or
                name.startswith("mpath-redo") or
                name.startswith("mpath-temporary") or
                    name.startswith("asm-")):
                    return(False)
                # name.startswith("asm-lab") or \ # case
                # name.startswith("asm-ora") or \
                # name.startswith("asm-.asm")): return(False)
        # /dev/mpath/asmd100: Aliased to /dev/mapper/asmd100 in device cache (preferred name)
        #
        if re.match("luks-" + sd_re, name):
            return(False)  # case  "luks-sdc"
        #
        #
        # if we get here we have something that looks like a vg-lv but there aren't any as far as we know.
        # typically we need to come up with test to provide a false as is seen above
        error_print('l', "called with all_vg_names='' name='{0}' called by {1} ({2})".format(name, calling_routine, source))
        debug_print(0, "mpath names:'{0}'".format(all_lsblk_mpath_names))
        debug_print(0, "lvm names:'{0}'".format(all_lsblk_lvm_names))
        debug_print(0, "dm names:'{0}'".format(all_lsblk_dm_names))
        # print 4 / 0 # REMOVE -- leave for now as various cases are eliminated

    # debug_print(z,"{0} {1} ({2})".format(name,calling_routine,source))
    return(True)  # may possibly be a vg-lv name...


# ---------------------------------------------#
# function: fs_related_source()
# helper rtn for possible_vg_lv_name()
# ---------------------------------------------#
def fs_related_source(source):
    fs_source_list = ""\
                     "etc/fstab "\
                     "sos_commands/filesys/mount_-l mount "\
                     "sos_commands/filesys/df_-al df "\
                     "proc/mounts "\
                     "check_fs_dev "\
                     ""
    return(word_in_list(source, fs_source_list))

# ---------------------------------------------#
# function: split_valid_lv_name()
# called by routines when all valid vg names are known
# ---------------------------------------------#


def split_valid_lv_name(name, source):
    global vg_2_all_lvs

    if not possible_vg_lv_name(name, 'split_valid_lv_name', source):
        return('')

    # debug_print(z,name)
    vg_name = split_valid_vg_name(name, source)
    # if "VgMdmDB" in name and source == '':
    # debug_print(z,vg_name)
    if vg_name == '':
        return('')
    lv_name = split_lv_name(name, source)
    # if "VgMdmDB" in name and source == '':
    # debug_print(z,lv_name)
    if lv_name == '':
        return('')

    lvs = vg_2_all_lvs[vg_name]
    lvs = lvs.split()
    for lv in lvs:
        # debug_print(z,"{0}: {1}".format(name,lv))
        if name == lv:
            return(lv_name)  # found, done (not lv is actually vg-lv)
        if name.replace("--", "-") == lv:
            return(lv_name)
    # end: for lv in lvs:

    return('')

# ---------------------------------------------#
# function: split_valid_vg_name()
# called by routines when all valid vg names are known
# ---------------------------------------------#


def split_valid_vg_name(name, source):
    global all_vg_names

    if not possible_vg_lv_name(name, 'split_valid_vg_name', source):
        return('')

    vg_name = split_vg_name(name, source)
    if vg_name == '':
        return('')
    if not word_in_list(vg_name, all_vg_names):
        return('')
    return(vg_name)

# ---------------------------------------------#
# function: split_vg_name()
# can be called by routines prior to knowing all the valig vg names
# ---------------------------------------------#


def split_vg_name(name, source):

    debug_print(3, "{0}".format(name))
    return(split_lvm_name(name, 0, source))

# ---------------------------------------------#
# function: split_lv_name()
# ---------------------------------------------#


def split_lv_name(name, source):

    debug_print(3, "{0}".format(name))
    return(split_lvm_name(name, 1, source))


# ---------------------------------------------#
# VG/LV naming note:
#
# When a combined volume group and logical volume is expressed,
# a dash ('-') is used to separate them:  vg_name-lv_name
#
# However, if a dash appears in either a vg_name or an lv_name,
# then, at some points it is replaced with a double-dash ('--').
#
# The double-dash convention is not universally present in all command
# output. So to ease the burden the following two practices are in place
#
# 1. Any vg_name containing one dash will be converted to the double-dash format.
# 2. Any lv_name containing one or more double-dashes wil be converted to single-dash format.
# This will minimizie false-positive mis-matched name anomalies.
#
# See: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=428769
#
# ---------------------------------------------#

# ---------------------------------------------#
# function: split_lvm_name()
# ---------------------------------------------#
def split_lvm_name(name, element, source):
    # (desired) element is 0 (vg_name) or 1 (lv_name)

    # debug_print(z,"'{0}' '{1}' ({2})".format(name,element,source))
    ans = ""
    tmp_name = name

    if tmp_name.count("-") == 0:  # no dashes whatsoever?
        return('')

    ddc = tmp_name.count("--")

    if ddc > 0:
        tmp_name = tmp_name.replace("--", "~")

    sdc = tmp_name.count("-")
    if sdc == 0:  # should not occur (only one or more double-dash(es) ??)
        error_print('d', "{0},{1}".format(name, source))  # should not occur
        # print 11 / 0
        return(name)

    d1 = tmp_name.find("-")  # find first dash

    # don't use tmp_name.split('-') in case there are multiple single dashes
    ele0 = tmp_name[0:d1]
    ele1 = tmp_name[d1 + 1:]  # don't want the dash itself
    # debug_print(z,"{0} {1}".format(ele0,ele1))

    if element == 0:
        ans = ele0
    else:
        ans = ele1

    if ddc:
        ans = ans.replace("~", "--")  # revert any double-dashes

    # if element == 1: # lv name
        # ans = ans.replace("--","-")
        # ans = ans.rstrip(":")

    # do it for both vg and lv name
    ans = ans.replace("--", "-")
    ans = ans.rstrip(":")

    debug_print(4, "{0},{1},({2}) -> '{3}'".format(name, element, source, ans))
    return(ans)


# ---------------------------------------------#
# function: update_vg()
# ---------------------------------------------#
def update_vg(vg_name, vg_uuid, source):
    return(update_vg_actual(vg_name, vg_uuid, source, 0))
# ---------------------------------------------#
# function: update_vg()
# ---------------------------------------------#


def update_vg_override(vg_name, vg_uuid, source):
    return(update_vg_actual(vg_name, vg_uuid, source, 1))
# ---------------------------------------------#
# function: update_vg_actual()
# ---------------------------------------------#


def update_vg_actual(vg_name, vg_uuid, source, overrideB):
    global all_vg_names
    global vg_2_uuid  # Key_data()
    global vg_2_uuid_origin  # Key_data()
    global uuid_2_vg  # Key_data()
    global uuid_2_vg_origin  # Key_data()
    global vg_2_dup_uuids  # Key_data()         # key: vg name              data: list of duplicate uuids vg was known as

    debug_print(3, "({0},{1},{2},{3})".format(vg_name, vg_uuid, source, overrideB))

    if vg_name == "":  # corrupt source file
        error_print('l', "called with null arg ({0})".format(source))
        errorprint(3 / 0)  # remove
        return ''

    # if '--' in vg_name: print 878 / 0
    # see VG/LV naming note above
    # if vg_name.count("-") > 0 and vg_name.count("--") == 0:
        # vg_name = vg_name.replace("-","--")
    if '--' in vg_name:
        vg_name = vg_name.replace("--", "-")

    all_vg_names = unique_list(all_vg_names, vg_name)

    vg_uuid = clean_uuid(vg_uuid)

    if vg_uuid != "":

        if vg_2_uuid[vg_name] == "":
            vg_2_uuid[vg_name] = vg_uuid
            vg_2_uuid_origin[vg_name] = source
        else:
            if not uuids_equal(vg_2_uuid[vg_name], vg_uuid):
                if overrideB == 1:
                    vg_2_uuid[vg_name] = vg_uuid
                    vg_2_uuid_origin[vg_name] = source
                else:
                    # skip if this vg_uuid is a known dup from a "Warning: .. precedence ..." msg
                    if not word_in_list(vg_uuid, vg_2_dup_uuids[vg_name]):
                        anomaly_line = "vg name {0} already has uuid set to {1} ({2}), attempting to set to {3} ({4})".\
                            format(vg_name, vg_2_uuid[vg_name], vg_2_uuid_origin[vg_name], vg_uuid, source)
                        handle_anomaly("DUP-1", anomaly_line)

        if uuid_2_vg[vg_uuid] == "":
            uuid_2_vg[vg_uuid] = vg_name
            uuid_2_vg_origin[vg_uuid] = source
        else:
            if uuid_2_vg[vg_uuid] != vg_name:
                anomaly_line = "vg uuid {0} already has name set to {1} ({2}), attempting to set to {3} ({4})".\
                    format(vg_uuid, uuid_2_vg[vg_uuid], uuid_2_vg_origin[vg_uuid], vg_name, source)
                handle_anomaly("DUP-2", anomaly_line)

    return(vg_name)

# ---------------------------------------------#
# function: update_pv()
# ---------------------------------------------#


def update_pv(vg_name, pv_name, pv_path, _pv_uuid, pv_major_minor, source):
    global vg_2_all_pvs  # Key_data()
    global pv_2_uuid  # Key_data()
    global pv_2_uuid_origin  # Key_data()
    global pv_2_path  # Key_data()
    global pv_2_path_origin  # Key_data()
    global uuid_2_pv  # Key_data()
    global uuid_2_pv_origin  # Key_data()
    global uuids_to_check  # ''

    debug_print(4, "({0},{1},{2},{3},{4},{5})".format(vg_name, pv_name, pv_path, _pv_uuid, pv_major_minor, source))

    if pv_name.startswith("unknown"):
        anomaly_line = "PV name 'unknown', uuid: {0}, check /etc/lvm/lvm.conf filter ({1})".format(_pv_uuid, source)
        handle_anomaly("LVM", anomaly_line)
        uuids_to_check = unique_list(uuids_to_check, _pv_uuid)
        return

    pv_uuid = clean_uuid(_pv_uuid)

    vg_2_all_pvs[vg_name] = unique_list(vg_2_all_pvs[vg_name], pv_name)

    if pv_path != "":
        if pv_2_path[pv_name] == "":
            pv_2_path[pv_name] = pv_path
            pv_2_path_origin[pv_name] = source
        else:
            if pv_2_path[pv_name] != pv_path:
                anomaly_line = "pv name {0} in vg {1} already has path set to {2} ({3}), attempting to set to {4} ({5})".\
                    format(pv_name, vg_name, pv_2_path[pv_name], pv_2_path_origin[pv_name], pv_path, source)
                handle_anomaly("DUP-1", anomaly_line)

    if pv_uuid != "":
        if pv_2_uuid[pv_name] == "":
            pv_2_uuid[pv_name] = pv_uuid
            pv_2_uuid_origin[pv_name] = source
        else:
            if pv_uuid != pv_2_uuid[pv_name]:
                anomaly_line = "pv name {0} in vg {1} already has uuid set to {2} ({3}), attempting to set to {4} ({5})".\
                    format(pv_name, vg_name, pv_2_uuid[pv_name], pv_2_uuid_origin[pv_name], pv_uuid, source)
                handle_anomaly("DUP-2", anomaly_line)

        if uuid_2_pv[pv_uuid] == "":
            uuid_2_pv[pv_uuid] = pv_name
            uuid_2_pv_origin[pv_uuid] = source
        else:
            # if uuid_2_pv[pv_uuid] != pv_name:
            if not pvs_equivalent(uuid_2_pv[pv_uuid], pv_name):
                anomaly_line = "uuid {0} already set to {1} ({2}), attempting to set to {3}, vg {4} ({5})".\
                    format(pv_uuid, uuid_2_pv[pv_uuid], uuid_2_pv_origin[pv_uuid], pv_name, vg_name, source)
                handle_anomaly("DUP-1", anomaly_line)

    return

# ---------------------------------------------#
# function: pvs_equivalent()
# TODO explain this rtn
# ---------------------------------------------#


def pvs_equivalent(pv1, pv2):
    global all_scsi_ids
    global dm_re
    if pv1 == pv2:
        return(True)
    scsi_id = ''
    dev_id = ''
    scsi_id_cnt = 0

    if is_scsi_id(pv1):
        scsi_id_cnt += 1
        scsi_id = pv1
        dev_id = pv2

    if is_scsi_id(pv2):
        scsi_id_cnt += 1
        scsi_id = pv2
        dev_id = pv1

    # if scsi_id_cnt != 1: return(False)
    if scsi_id_cnt == 1:
        return(True)
    # if scsi_id_cnt == 2: error_print("l","{0} {1} ?both scsi ids?".format(pv1,pv2))
    if scsi_id_cnt == 2:
        return(False)
    # if scsi_id_cnt == 0: fall thru and do dm / ufn test

    debug_print(3, "{0} {1}".format(scsi_id, dev_id))
    debug_print(3, "{0}".format(scsi_id_2_devs[scsi_id]))

    if not word_in_list(scsi_id, all_scsi_ids):
        return(False)

    if not word_in_list(dev_id, scsi_id_2_devs[scsi_id]):
        return(False)
    return(True)


# ---------------------------------------------#
# function: update_lv()
# ---------------------------------------------#
def update_lv(vg_name, lv_name, lv_path, _lv_uuid, lv_major_minor, source):
    global vg_2_all_lvs  # Key_data()
    global lv_2_uuid  # Key_data()
    global lv_2_uuid_origin  # Key_data()
    global lv_2_path  # Key_data()
    global uuid_2_lv  # Key_data()
    global uuid_2_lv_origin  # Key_data()
    global all_vg_names
    global vg_2_dup_uuids  # Key_data()         # key: vg name              data: list of duplicate uuids vg was known as

    debug_print(4, "({0},{1},{2},{3},{4},({5}))".format(vg_name, lv_name, lv_path, _lv_uuid, lv_major_minor, source))

    if not word_in_list(vg_name, all_vg_names):
        error_print('l', "vgn '{0}' not in '{1}' ({2})".format(vg_name, all_vg_names, source))
        return ''

    if lv_name == '':
        error_print('l', "lvn is null, vgn='{0}' ({1})".format(vg_name, source))
        return ''

    full_lv_name = build_vg_lv(vg_name, lv_name, source)

    lv_uuid = clean_uuid(_lv_uuid)
    vg_uuid = vg_2_uuid[vg_name]

    vg_2_all_lvs[vg_name] = unique_list(vg_2_all_lvs[vg_name], full_lv_name)

    if lv_uuid != "":

        # if incoming lv_uuid has vg_uuid prepended to it, remove it
        if vg_uuid != "":
            if lv_uuid.startswith(vg_uuid):
                lv_uuid = lv_uuid[len(vg_uuid):]  # remove vg_uuid prefixed on lv_uuid

            # if existing lv_uuid has vg_uuid prepended to it, remove it (set before we knew what vg_uuid was)
            if lv_2_uuid[full_lv_name] != "" and lv_2_uuid[full_lv_name].startswith(vg_uuid):
                lv_2_uuid[full_lv_name] = lv_2_uuid[full_lv_name][len(vg_uuid):]

        # if incoming lv_uuid has a vg_dup_uuid prepended to it, remove it
        vg_dup_uuids = vg_2_dup_uuids[vg_name]
        if vg_dup_uuids != '':
            dup_uuids = vg_dup_uuids.split()
            for dup_uuid in dup_uuids:

                if lv_uuid.startswith(dup_uuid):
                    lv_uuid = lv_uuid[len(dup_uuid):]  # remove vg_dup_uuid prefixed on lv_uuid

                if lv_2_uuid[full_lv_name] != "" and lv_2_uuid[full_lv_name].startswith(dup_uuid):
                    lv_2_uuid[full_lv_name] = lv_2_uuid[full_lv_name][len(dup_uuid):]

        if lv_2_uuid[full_lv_name] == "":
            lv_2_uuid[full_lv_name] = lv_uuid
            lv_2_uuid_origin[full_lv_name] = source
        else:
            if not uuids_equal(lv_2_uuid[full_lv_name], lv_uuid):
                anomaly_line = "lv name {0} in vg {1} already has uuid set to {2} ({3}), attempting to set to {4} ({5})".\
                    format(full_lv_name, vg_name, lv_2_uuid[full_lv_name], lv_2_uuid_origin[full_lv_name], lv_uuid, source)
                handle_anomaly("DUP-1", anomaly_line)

        if uuid_2_lv[lv_uuid] == "":
            uuid_2_lv[lv_uuid] = full_lv_name
            uuid_2_lv_origin[lv_uuid] = source
        else:
            if uuid_2_lv[lv_uuid] != full_lv_name:
                anomaly_line = "lv uuid {0} in vg {1} already has name set to {2} ({3}), attempting to set to {4} ({5})".\
                    format(lv_uuid, vg_name, uuid_2_lv[lv_uuid], uuid_2_lv_origin[lv_uuid], full_lv_name, source)
                handle_anomaly("DUP-2", anomaly_line)

    if lv_path != "":
        if lv_2_path[full_lv_name] == "":
            lv_2_path[full_lv_name] = lv_path
        else:
            if lv_2_path[full_lv_name] != lv_path:
                anomaly_line = "lv name {0} in vg {1} already has path set to {2}, attempting to set to {3} ({4})".\
                    format(full_lv_name, vg_name, lv_2_path[full_lv_name], lv_path, source)
                handle_anomaly("DUP-1", anomaly_line)

    if lv_major_minor != "":
        add_mm_bd(full_lv_name, lv_major_minor, source)

    return


# ---------------------------------------------#
# function: crunch_vgscan()
# ---------------------------------------------#
def crunch_vgscan():
    vg_files = "" \
        "sos_commands/devicemapper/vgscan_-vvv "\
        "sos_commands/devicemapper/vgscan_-vvv_--config_global_locking_type_0 "\
        "sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0 "\
        "sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0_2 "\
        ""

    tmp = vg_files.split()
    for vg_file in tmp:
        if vg_file == '' or vg_file.startswith("#"):
            continue
        if file_exists_with_data(vg_file):
            crunch_vgscan_file(vg_file)

    # end: for vg_file in tmp:

    return

# ---------------------------------------------#
# function: crunch_vgscan()
# ---------------------------------------------#


def crunch_vgscan_file(vg_file):
    global all_unrecognised_disk_label_devices  # ''

    fh = openfile(vg_file)
    if fh is None:
        return

    found_start = False
    curr_dev_id = ""
    i = 0
    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "":
            continue
        # debug_print(z,"'{0}' ({1})".format(line,vg_file))
        if line.endswith("stat failed: No such file or directory"):
            continue

        if line == "Wiping cache of LVM-capable devices":
            found_start = True
            continue

        if line.endswith(": Checksum error"):
            do_checksum_anom(line, vg_file)
            continue

        if line.endswith(" Was device resized?"):
            do_resized_anom(line, vg_file)
            continue

        words = line.split()
        wc = len(words)
        word1 = words[0]

        if line.endswith(": No label detected"):
            dev_id = word1.rstrip(":")
            all_unrecognised_disk_label_devices = unique_list(all_unrecognised_disk_label_devices, dev_id)
            continue

        check_for_partitioned_dev(line, word1, vg_file)
        # debug_print(z,"'{0}' ({1})".format(line,vg_file))
        check_for_aliased_dev(line, word1, vg_file)

        if found_start is False:
            continue

        if wc >= 7:
            if word1 == "lvmcache:" and words[4] == "VGID":
                vg_name = words[3]
                vg_uuid = words[6]
                vg_name = update_vg(vg_name, vg_uuid, vg_file)

    # end: for line in vg_lines:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, vg_file))
    return


# ---------------------------------------------#
# function: dev_block()
# return mm portion of /dev/block/ma:mi
# -----
# ---------------------------------------------#
def dev_block(dev_path):
    global mm_re

    if ':' not in dev_path:
        return('')

    if not re.match("\/dev\/block\/" + mm_re, dev_path):
        return('')

    tmp = dev_path.split("/")
    mm = tmp[3]  # leading '/' means tmp[0]='', tmp[1]='dev', etc.
    return(mm)


# ---------------------------------------------#
# function: check_for_aliased_dev()
#
# e.g.:
# (word 0)   (word 1&2) (word 3)                     (remaining words...)
# /dev/sdkr: Aliased to /dev/orcaleasm/disks/DISK113 in device cache (preferred name)
# /dev/mapper/mpathk: Aliased to /dev/disk/by-label/BACKUPDG in device cache (preferred name)
# /dev/sda3: Aliased to /dev/root in device cache
# /dev/disk/by-uuid/d0f60ab1-4eda-4f68-9f3d-ffd364df8379: Aliased to /dev/sdcc in device cache
# /dev/disk/by-uuid/d0f60ab1-4eda-4f68-9f3d-ffd364df8379: Aliased to /dev/root in device cache
# ---------------------------------------------#
def check_for_aliased_dev(line, word1, source):
    global scsi_id_2_devs  # Key_data()
    global scsi_id_2_parts  # Key_data()
    global dev_id_2_parts  # Key_data()
    global dm_re, hex16_re, n3_re

    if not line.startswith('/dev/'):
        return

    if "Aliased to" not in line:
        return

    words = line.split()
    wc = len(words)

    if wc < 4:
        return ''  # Should not occur

    # debug_print(z,"'{0}' ({1})".format(line,source))
    dev_path1 = words[0].rstrip(":")
    # dir1 = os.path.dirname(dev_path1)
    # subdir1 = dir1[len("/dev/"):]
    # if subdir1 == '': subdir1_count = 0
    # else: subdir1_count = subdir1.count("/") + 1
    # dev_id1 = os.path.basename(dev_path1)

    # "Aliased" = words[1]
    # "to" = words[2]

    dev_path2 = words[3]
    # dir2 = os.path.dirname(dev_path2)
    # subdir2 = dir2[len("/dev/"):]
    # if subdir2 == '': subdir2_count = 0
    # else: subdir2_count = subdir2.count("/") + 1
    # dev_id2 = os.path.basename(dev_path2)

    mm = words[wc - 1]
    if re.match(mm_pa_re, mm):
        mm = mm.strip("()")
        if not valid_major_minor(mm, True, source):
            return  # SNO
        # tmp = mm.split(":")
        # major = int(tmp[0])
        # minor = int(tmp[1])
    else:
        mm = ''  # SNO (other than rhel 5 / early 6)
        # debug_print(z,'aa') # REMOVE
        mm = dev_block(dev_path1)
        # debug_print(0,'bb') # REMOVE
        if mm == '':
            mm = dev_block(dev_path2)
        # debug_print(0,'cc') # REMOVE
        if mm == '':
            mm = conv_id_2_mm(dev_path1, 'sd')
        # debug_print(0,'dd') # REMOVE
        if mm == '':
            mm = conv_id_2_mm(dev_path2, 'sd')
        # debug_print(0,'ee') # REMOVE
        # if mm == '': debug_print(z,"unable to get mm ...")
        # else: debug_print(z,"mm found to be '{0}'".format(mm))

    if mm == '':
        # debug_print(z,line) # REMOVE
        return  # primarily to short circuit rhel 5 which didn't append (mm) on the end of the 'Aliased to' msgs.

    if len(dev_path2) > len(dev_path1):  # process, the shorter and typically simpler device first (e.g., /dev/sda, /dev/dm-4)
        array1 = disect_dev(dev_path1, mm, line, source)
        array2 = disect_dev(dev_path2, mm, line, source)
    else:
        array2 = disect_dev(dev_path2, mm, line, source)
        array1 = disect_dev(dev_path1, mm, line, source)

    # at one point it was though that the data in the returned arrays would be used further but that has not been the case so returning here
    return

    tmp = array1.split("~")
    dir1 = tmp[0]
    subdir1 = tmp[1]
    subdir1_count = tmp[2]
    ele1_type = tmp[3]
    ele1_name = tmp[4]
    id1_type = tmp[5]
    id1_name = tmp[6]

    tmp = array2.split("~")
    dir2 = tmp[0]
    subdir2 = tmp[1]
    subdir2_count = tmp[2]
    ele2_type = tmp[3]
    ele2_name = tmp[4]
    id2_type = tmp[5]
    id2_name = tmp[6]

    # /dev/block/7:0: Aliased to /dev/loop0 in device cache (7:0)
    # /dev/block/8:48: Aliased to /dev/sdd in device cache (8:48)
    # /dev/block/253:5: Aliased to /dev/appvg/optmqmlv in device cache (253:5)
    # /dev/block/253:6: Aliased to /dev/appvg/varmqmlv in device cache (253:6)
    # /dev/block/252:0: Aliased to /dev/asm/.asm_ctl_spec in device cache (252:0)
    # /dev/block/253:10: Aliased to /dev/san/lvm/backup1/msxiv07-61062_xmgtb3a_lvm_backup1_006 in device cache (253:10)
    # /dev/block/253:106: Aliased to /dev/san/asm/data3/msxiv307_xmgtb_asm_data3_023 in device cache (253:106)
    # /dev/dm-0: Aliased to /dev/disk/by-id/dm-name-rootvg-lv_swap1 in device cache (253:0)
    # /dev/dm-44: Aliased to /dev/disk/by-id/dm-name-08c_fs02_d03 in device cache (253:44)
    # /dev/mapper/rootvg-lv_opt: Aliased to /dev/disk/by-id/dm-name-rootvg-lv_opt in device cache (preferred name) (253:4)
    # /dev/mapper/03c_fs01_d01: Aliased to /dev/disk/by-id/dm-name-03c_fs01_d01 in device cache (preferred name) (253:330)
    # /dev/mapper/eql-4-42a846-b3852f608-0bc0058b023559bb_a: Aliased to /dev/ignore_eql/4-42a846-b3852f608-0bc0058b023559bb_a in device cache (253:11)
    # /dev/rootvg/lv_opt: Aliased to /dev/mapper/rootvg-lv_opt in device cache (preferred name) (253:4)
    # /dev/rootvg/agn-itm: Aliased to /dev/mapper/rootvg-agn--itm in device cache (preferred name) (251:7)
    # /dev/ram9: Aliased to /dev/block/1:9 in device cache (preferred name) (1:9)
    # /dev/nvme0n1: Aliased to /dev/disk/by-path/pci-0000:0b:00.0 in device cache (preferred name) (259:0)
    # /dev/sdaa3: Aliased to /dev/block/65:163 in device cache (preferred name) (65:163)
    # /dev/sdtx: Aliased to /dev/disk/by-path/pci-0000:05:00.0 in device cache (preferred name) (65:752)
    # /dev/sds: Aliased to /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0 in device cache (preferred name) (65:32)
    # /dev/mapper/appvg-varmqmlv: Aliased to /dev/dm-6 in device cache (preferred name) (253:6)
    # /dev/mapper/asm_fra100: Aliased to /dev/dm-10 in device cache (preferred name) (253:10)
    # /dev/mapper/volgrp01-var: Aliased to /dev/dm-1 in device cache (preferred name)  <<--- rhel 5
    # /dev/mapper/mpathz: Aliased to /dev/dm-26 in device cache (preferred name) (253:26)  # TODO: verfiy this exists...
    # /dev/mapper/appsvg-U002: Aliased to /dev/appsvg/U002 in device cache (251:2)
    # /dev/mapper/mpathk: Aliased to /dev/disk/by-label/BACKUPDG in device cache (preferred name)
    # /dev/mapper/360002ac0000000000000052500019fbb1: Aliased to /dev/disk/by-id/dm-name-360002ac0000000000000052500019fbb1 in device cache (preferred name) (253:102)
    # /dev/sdxz: Aliased to /dev/disk/by-id/scsi-360002ac000000000000005e400019fbb in device cache (preferred name) (128:656)
    # /dev/rootvg/slashlv: Aliased to /dev/mapper/rootvg-slashlv
    # /dev/ora1_vg/ora1_vg_ora01_lv: Aliased to /dev/mapper/ora1_vg-ora1_vg_ora01_lv in device cache (preferred name)
    # /dev/disk/by-id/dm-name-clustervg-clusterlv: Aliased to /dev/clustervg/clusterlv in device cache (253:11)
    # /dev/disk/by-id/dm-name-rootvg-lv_var: Aliased to /dev/block/253:3 in device cache (preferred name) (253:3)
    # /dev/disk/by-id/dm-name-360060e8016020f000001020f00000030: Aliased to /dev/dm-0 in device cache (preferred name) (253:0)
    # /dev/disk/by-id/dm-name-vg09-lvol2: Aliased to /dev/dm-218 in device cache (preferred name) (253:218)
    # /dev/disk/by-id/dm-name-u05_oradata_VIBPRD: Aliased to /dev/dm-14 in device cache (preferred name) (253:14)
    # /dev/disk/by-id/scsi-360000970000192606755533030313836: Aliased to /dev/block/8:16 in device cache (preferred name) (8:16)
    # /dev/disk/by-id/virtio-982bd6c0-dac4-46da-a: Aliased to /dev/vda in device cache (252:0)
    # /dev/disk/by-id/virtio-982bd6c0-dac4-46da-a-part1: Aliased to /dev/vda1 in device cache (252:1)
    # /dev/vda1: Aliased to /dev/disk/by-id/virtio-2affc36f-ba27-4307-9-part1 in device cache (preferred name) (252:1)
    # /dev/vda: Aliased to /dev/disk/by-id/virtio-2affc36f-ba27-4307-9 in device cache (preferred name) (252:0)
    # /dev/datavgf/d3_vol: Aliased to /dev/block/253:11 in device cache (preferred name) (253:11)
    # /dev/disk/by-id/wwn-0x60000970000192606755533030313836: Aliased to /dev/disk/by-id/scsi-360000970000192606755533030313836 in device cache (8:16)
    # /dev/disk/by-id/wwn-0x60000970000192606755533030313837-part1: Aliased to /dev/disk/by-id/scsi-360000970000192606755533030313837-part1 in device cache (133:97)
    # /dev/disk/by-id/wwn-0x50060160bde034e650060160bde034e6: Aliased to /dev/disk/by-id/scsi-350060160bde034e650060160bde034e6 in device cache (8:112)
    # /dev/disk/by-id/wwn-0x5001b44f19905d78: Aliased to /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0 in device cache (65:32)
    # /dev/disk/by-id/wwn-0x5001b44f19905d78-part1: Aliased to /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952-part1 in device cache (65:33)
    # /dev/disk/by-id/wwn-0x600508b1001c25be2222e2d8fd6e8fc1: Aliased to /dev/sda in device cache (8:0)
    # /dev/disk/by-id/wwn-0x600508b1001c25be2222e2d8fd6e8fc1-part1: Aliased to /dev/sda1 in device cache (8:1)
    # /dev/disk/by-id/wwn-0x600508b1001c155c1d181a5f188ad6d3-part2: Aliased to /dev/disk/by-id/lvm-pv-uuid-ZkSz9f-eWT8-3DD4-lxj1-JD3b-1iNb-G9n2Ae in device cache (8:2)
    # /dev/glustervg/glusterlv: Aliased to /dev/disk/by-id/dm-name-glustervg-glusterlv in device cache (preferred name) (254:0)
    # /dev/disk/by-label/EFI-SYSTEM: Aliased to /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952-part1 in device cache (65:33)
    # /dev/disk/by-label/mdcsedarapp:cluster13: Aliased to /dev/clustervg/clusterlv in device cache (253:11)
    # /dev/disk/by-label/config-2: Aliased to /dev/sda1 in device cache (8:1)
    # /dev/disk/by-label/img-rootfs: Aliased to /dev/sda2 in device cache (8:2)
    # /dev/disk/by-label/ARCH1: Aliased to /dev/block/202:81 in device cache (preferred name) (202:81)
    # /dev/oracleasm/disks/ARCH1: Aliased to /dev/disk/by-label/ARCH1 in device cache (preferred name) (202:81)
    # /dev/xvda1: Aliased to /dev/disk/by-label/\x2fboot in device cache (preferred name) (202:1)
    # /dev/sdxz1: Aliased to /dev/disk/by-id/scsi-360002ac000000000000005e400019fbb-part1 in device cache (preferred name) (128:657)
    # /dev/sdzs1: Aliased to /dev/disk/by-path/pci-0000:05:00.1-fc-0x50060e80101ae5ef-lun-40-part1 in device cache (preferred name) (131:609)
    # /dev/sdzt: Aliased to /dev/disk/by-path/pci-0000:05:00.0-fc-0x500507680130bceb-lun-43 in device cache (preferred name) (131:624)
    # /dev/sdp: Aliased to /dev/disk/by-path/fc-0x5742b0f000053321-lun-4 in device cache (preferred name) (8:240)
    # /dev/sda3: Aliased to /dev/root in device cache
    # /dev/disk/by-uuid/d0f60ab1-4eda-4f68-9f3d-ffd364df8379: Aliased to /dev/sdcc in device cache
    # /dev/disk/by-uuid/d0f60ab1-4eda-4f68-9f3d-ffd364df8379: Aliased to /dev/root in device cache
    # /dev/root: Aliased to /dev/rootvg/slashlv in device cache (preferred name) (253:0)
    # /dev/root: Aliased to /dev/mapper/rootvg-lv_root in device cache (preferred name) (253:1)
    # /dev/rootvg/lv_root: Aliased to /dev/root in device cache (253:1)
    # /dev/dvd: Aliased to /dev/cdrom in device cache (11:0)
    # /dev/scd0: Aliased to /dev/sr0 in device cache (preferred name) (11:0)
    # /dev/cdrom-hda: Aliased to /dev/cdrom in device cache   <<<--- rhel 5
    # /dev/disk/by-path/ip-10.26.62.78:3260-iscsi-freenas.rhevm-iot:iotlab-lun-0: Aliased to /dev/sdb in device cache (8:16)
    # /dev/disk/by-path/pci-0000:13:00.0-scsi-0:0:3:0: Aliased to /dev/sdh in device cache (8:112)
    # /dev/disk/by-path/pci-0000:13:00.0-scsi-0:0:3:0-part1: Aliased to /dev/sdh1 in device cache (8:113)
    # /dev/disk/by-path/scsi-0:0:0:0: Aliased to /dev/disk/by-id/scsi-3600224807cef35855a55c97fd5806469
    # /dev/disk/by-path/scsi-0:0:0:0-part1: Aliased to /dev/disk/by-id/scsi-3600224807cef35855a55c97fd5806469-part1
    # /dev/root: Aliased to /dev/disk/by-path/pci-0000:03:00.0-scsi-0:0:0:0-part2 in device cache (preferred name) (8:2)
    # /dev/sda1: Aliased to /dev/disk/by-path/pci-0000:00:10.0-scsi-0:0:0:0-part1 in device cache (preferred name) (8:1)
    # /dev/sdc: Aliased to /dev/disk/by-path/pci-0000:03:00.0-scsi-0:0:2:0 in device cache (preferred name) (8:32)
    # /dev/disk/by-path/pci-0000:44:00.0-fc-0x5000097208698d58-lun-1: Aliased to /dev/block/8:32 in device cache (preferred name) (8:32)
    # /dev/disk/by-path/pci-0000:44:00.0-fc-0x5000097208698d58-lun-0-part1: Aliased to /dev/block/8:17 in device cache (preferred name) (8:17)
    # /dev/disk/by-path/pci-0000:47:00.0-fc-0x50000973501948d8-lun-44: Aliased to /dev/disk/by-id/scsi-360000970000196701618533030334430 in device cache (129:496)
    # /dev/disk/by-path/pci-0000:47:00.0-fc-0x50000973501948d8-lun-44-part8: Aliased to /dev/disk/by-id/scsi-360000970000196701618533030334430-part8 in device cache (129:504)
    # /dev/disk/by-path/pci-0000:41:00.0-fc-0x5001738032c50142-lun-11: Aliased to /dev/sdw in device cache (65:96)
    # /dev/disk/by-path/pci-0000:02:00.0-sas-exp0x50000d1108d9fabf-phy10-lun-0: Aliased to /dev/disk/by-id/scsi-35000cca242d5e74f in device cache (8:64)
    # /dev/disk/by-path/pci-0000:00:01.1-ata-1.1: Aliased to /dev/cdrom in device cache (11:0)
    # /dev/disk/by-path/pci-0000:03:00.2-ip-172.31.16.3:3260-iscsi-iqn.2003-10.com.lefthandnetworks:pinkroccade-healthcare-mgm:271:hp-sa-vol01-lun-0: Aliased to /dev/block/8:16 in device cache (preferred name) (8:16)
    # /dev/disk/by-path/ip-192.168.0.13:3260-iscsi-iqn.2010-10.org.openstack:volume-d6489278-034f-4b50-86be-2c615c7327c4-lun-0-part1: Aliased to /dev/sdd1 in device cache (8:49)
    # /dev/disk/by-path/virtio-pci-0000:00:0c.0-scsi-0:0:0:2: Aliased to /dev/sdb in device cache (8:16) (sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0)
    # /dev/disk/by-path/acpi-VMBUS:01-scsi-0:0:0:0: Aliased to /dev/sda in device cache (8:0) (sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0)
    # /dev/disk/by-path/acpi-VMBUS:01-scsi-0:0:0:0-part1: Aliased to /dev/sda1 in device cache (8:1) (sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0)
    # /dev/disk/by-id/ata-QEMU_DVD-ROM_QM00003: Aliased to /dev/scd0 in device cache (11:0)
    # /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952-part1: Aliased to /dev/block/65:33 in device cache (preferred name) (65:33)
    # /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952: Aliased to /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0 in device cache (65:32)
    # /dev/sds1: Aliased to /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952-part1 in device cache (preferred name) (65:33)
    # /dev/sds: Aliased to /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0 in device cache (preferred name) (65:32)
    # /dev/disk/by-path/fc-0x5742b0f000053321-lun-3: Aliased to /dev/block/8:224 in device cache (preferred name) (8:224)
    # /dev/disk/by-path/fc-0x5742b0f000053331-lun-4: Aliased to /dev/disk/by-id/scsi-36742b0f00000053300000000001a0e60 in device cache (65:112)
    # /dev/disk/by-path/ip-192.168.81.251:3260-iscsi-iqn.1992-04.com.emc:cx.apm00142532959.a7-lun-0: Aliased to /dev/sdd in device cache (8:48)
    # /dev/disk/by-path/ip-172.17.19.20:3260-iscsi-iqn.1992-08.com.netapp:sn.be4bb72aa0f011e6af7b00a098a778f5:vs.10-lun-3: Aliased to /dev/block/65:48 in device cache (preferred name) (65:48)
    # /dev/disk/by-path/ip-172.17.19.22:3260-iscsi-iqn.1992-08.com.netapp:sn.be4bb72aa0f011e6af7b00a098a778f5:vs.10-lun-3: Aliased to /dev/disk/by-id/scsi-3600a09803830384a525d4a3145743132 in device cache (66:96)
    # /dev/sdab: Aliased to /dev/disk/by-path/ip-172.17.19.23:3260-iscsi-iqn.1992-08.com.netapp:sn.be4bb72aa0f011e6af7b00a098a778f5:vs.10-lun-1 in device cache (preferred name) (65:176)
    # /dev/disk/by-path/xen-vbd-268439552: Aliased to /dev/block/202:4096 in device cache (preferred name) (202:4096)
    # /dev/disk/by-path/xen-vbd-268439552-part1: Aliased to /dev/disk/by-label/RECO1 in device cache (202:4097)
    # /dev/xvdp: Aliased to /dev/disk/by-path/xen-vbd-51952 in device cache (preferred name) (202:240)
    # /dev/xvdq: Aliased to /dev/disk/by-path/xen-vbd-268439552 in device cache (preferred name) (202:4096)
    # /dev/disk/by-id/dm-name-asm_disk100p1: Aliased to /dev/mapper/asm_disk100p1 in device cache (253:27)
    # /dev/disk/by-id/dm-name-mpathg: Aliased to /dev/san/lvm/backup1/msxiv07-61062_xmgtb3a_lvm_backup1_006 in device cache (253:10)
    # /dev/disk/by-id/dm-name-eql-4-42a846-b3852f608-0bc0058b023559bb-ds-eql-g7-rz1prod-10: Aliased to /dev/disk/by-id/lvm-pv-uuid-l01DgB-980Q-kMH4-VsbE-gi34-anRT-UY403b in device cache (preferred name) (253:13)
    # /dev/xvdz1: Aliased to /dev/oracleasm/disks/OCR5 in device cache (preferred name) (202:6401)
    # /dev/xvdo1: Aliased to /dev/oracleasm/disks/OLOG1 in device cache (preferred name) (202:225)
    # /dev/appvg/apps: Aliased to /dev/dm-7 in device cache (preferred name) (253:7)
    # /dev/oracleasm/disks/ARCH1: Aliased to /dev/disk/by-label/ARCH1 in device cache (preferred name) (202:81)
    # /dev/oracleasm/disks/B439_ASMDISK001: Aliased to /dev/mapper/mpath6p1 in device cache (253:584)
    # /dev/oracleasm/disks/B439_ASMDISK002: Aliased to /dev/mapper/mpath7p1 in device cache (253:586)
    # /dev/disk/by-id/ccw-0X0102: Aliased to /dev/dasde in device cache (94:16)
    # /dev/disk/by-id/ccw-0X0102-part1: Aliased to /dev/dasde1 in device cache (94:17)
    # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02: Aliased to /dev/dasde in device cache (94:16)
    # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02.0000bff20000ffec0000000000000000: Aliased to /dev/dasde in device cache (94:16)
    # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02-part1: Aliased to /dev/dasde1 in device cache (94:17)
    # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02.0000bff20000ffec0000000000000000-part1: Aliased to /dev/dasde1 in device cache (94:17)
    # /dev/disk/by-path/ccw-0.0.0102: Aliased to /dev/dasde in device cache (94:16)
    # /dev/disk/by-path/ccw-0.0.0102-part1: Aliased to /dev/dasde1 in device cache (94:17)
    # /dev/dasdc: Aliased to /dev/disk/by-id/ccw-LXSWAP in device cache (preferred name) (94:8)
    # /dev/dasdc1: Aliased to /dev/disk/by-id/ccw-LXSWAP-part1 in device cache (preferred name) (94:9)
    # /dev/disk/by-id/ccw-VOL10X: Aliased to /dev/dasda in device cache (94:0)
    # /dev/disk/by-id/ccw-VOL10X-part1: Aliased to /dev/dasda1 in device cache (94:1)
    # /dev/disk/by-id/ccw-HTC.85000000057006.8000.1c: Aliased to /dev/dasdc in device cache (94:8)
    # /dev/disk/by-id/md-uuid-43493444:056c9079:21befa5f:5e094a52: Aliased to /dev/md4 in device cache (9:4)
    # /dev/disk/by-id/md-uuid-4db70934:99e5b53e:e0aca036:7b5c32c2: Aliased to /dev/md1 in device cache (9:1)
    # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab: Aliased to /dev/md126 in device cache (9:126)
    # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab-part1: Aliased to /dev/md126p1 in device cache (259:0)
    # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab-part2: Aliased to /dev/md126p2 in device cache (259:1)
    # /dev/disk/by-id/md-name-128: Aliased to /dev/md126 in device cache (9:126)
    # /dev/disk/by-id/md-name-129: Aliased to /dev/md125 in device cache (9:125)
    # /dev/disk/by-id/md-name-2: Aliased to /dev/md127 in device cache (9:127)
    # /dev/disk/by-id/md-name-athos.drcmr:boot: Aliased to /dev/md126 in device cache (9:126)
    # /dev/disk/by-id/md-name-athos.drcmr:pv00: Aliased to /dev/md127 in device cache (9:127)
    # /dev/disk/by-id/md-name-eagnmnmed141c:2: Aliased to /dev/md2 in device cache (9:2)
    # /dev/disk/by-id/md-name-eagnmnmed141c:3: Aliased to /dev/md3 in device cache (9:3)
    # /dev/disk/by-id/md-name-eagnmnmed141c:4: Aliased to /dev/md4 in device cache (9:4)
    # /dev/disk/by-id/md-name-fsldojt1:0: Aliased to /dev/md0 in device cache (9:0)
    # /dev/disk/by-id/md-name-fsldojt1:1: Aliased to /dev/md1 in device cache (9:1)
    # /dev/disk/by-id/md-name-localhost.localdomain:0: Aliased to /dev/md0 in device cache (9:0)
    # /dev/disk/by-id/emc-vol-4b7837cd1e146dcb-db982bc700000001: Aliased to /dev/scinia in device cache (252:0)
    # /dev/disk/by-id/emc-vol-4b7837cd1e146dcb-db982bc800000002: Aliased to /dev/scinib in device cache (252:16)
    # /dev/disk/by-id/emc-vol-4b7837cd1e146dcb-db9852d500000003: Aliased to /dev/scinic in device cache (252:32)
    # /dev/disk/by-id/lvm-pv-uuid-F4bGJw-dH6q-5BbN-91BF-7jCR-7FsW-gDRV2G: Aliased to /dev/sdh1 in device cache (8:113)
    # /dev/sda2: Aliased to /dev/disk/by-id/lvm-pv-uuid-ZkSz9f-eWT8-3DD4-lxj1-JD3b-1iNb-G9n2Ae in device cache (preferred name) (8:2)
    # /dev/dm-62: Aliased to /dev/disk/by-uuid/302B-B662 in device cache (253:62)
    # /dev/dm-64: Aliased to /dev/disk/by-uuid/ee86eb6c-77e0-4328-865c-974cf4531bb4 in device cache (253:64)
    # /dev/disk/by-id/dm-name-360002ac000000000000004ed00019fbb1: Aliased to /dev/disk/by-uuid/302B-B662 in device cache (preferred name) (253:62)
    # /dev/disk/by-id/dm-name-360002ac000000000000004ed00019fbb2: Aliased to /dev/disk/by-uuid/ee86eb6c-77e0-4328-865c-974cf4531bb4 in device cache (preferred name) (253:64)
    # /dev/disk/by-id/lvm-pv-uuid-59YFu6-UCQD-fnLD-2yQJ-6CJx-5uWB-tQSunD: Aliased to /dev/disk/by-id/dm-name-u08_oradata_PDSPRD in device cache (253:11)
    # /dev/ignore_eql/4-42a846-b3852f608-0bc0058b023559bb_a: Aliased to /dev/disk/by-id/dm-name-eql-4-42a846-b3852f608-0bc0058b023559bb_a in device cache (preferred name) (253:11)
    # /dev/disk/by-id/dm-uuid-LVM-vPP1J15ughv5WYaMneTYGcPko7C8g6rvCTzq68D8QHHHXKUtjDpdbmMpVOQ1F7HC: Aliased to /dev/appvg/varmqmlv in device cache (253:6)
    # /dev/disk/by-id/dm-uuid-LVM-VO76iodQrLHK2ywq1nlCXyUE55SDsSVPXAqDnYoYMT3O6KZn3LmUBced6NKrVVMp: Aliased to /dev/clustervg/clusterlv in device cache (253:11)
    # /dev/disk/by-uuid/99def471-1f00-4aa1-9fc9-1959583c1198: Aliased to /dev/appvg/datalv in device cache (253:3)
    # (uuid is for filesystem)
    # /dev/disk/by-id/dm-uuid-mpath-360002ac0000000000000052600019fbb: Aliased to /dev/disk/by-id/dm-name-360002ac0000000000000052600019fbb in device cache (253:97)
    # /dev/disk/by-id/dm-uuid-mpath-4b7837cd1e146dcb-db982bc600000000: Aliased to /dev/disk/by-id/dm-name-4b7837cd1e146dcb-db982bc600000000 in device cache (253:22)
    # /dev/disk/by-id/dm-uuid-part1-mpath-360002ac0000000000000052200019fbb: Aliased to /dev/disk/by-id/dm-name-360002ac0000000000000052200019fbb1 in device cache (253:99)
    # /dev/disk/by-id/dm-uuid-part2-mpath-SATA_SSD_AF3407611E2400195988: Aliased to /dev/disk/by-id/dm-name-SATA_SSD_AF3407611E2400195988p2 in device cache (253:3)
    # /dev/disk/by-id/dm-uuid-part1-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450: Aliased to /dev/disk/by-id/dm-name-ddf1_4c53492020202020808627c3000000004711471100001450p1 in device cache (253:1)
    # /dev/disk/by-id/dm-uuid-part2-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450: Aliased to /dev/disk/by-id/dm-name-ddf1_4c53492020202020808627c3000000004711471100001450p2 in device cache (253:2)
    # /dev/disk/by-id/dm-uuid-switch-2f924bb5b33ed54d06c9ce9006b8d35f6: Aliased to /dev/disk/by-id/dm-name-2f924bb5b33ed54d06c9ce9006b8d35f6 in device cache (253:12)
    # /dev/disk/by-id/dm-uuid-CRYPT-LUKS1-b533ac8a3ede4e6384367ecdfbdb39a3-5e83173a-a7dc-4557-b34f-e6230155b254: Aliased to /dev/disk/by-id/dm-name-5e83173a-a7dc-4557-b34f-e6230155b254 in device cache (253:11)
    # /dev/disk/by-partlabel/EFI\x20System\x20Partition: Aliased to /dev/disk/by-id/scsi-360002ac000000000000004ed00019fbb-part1 in device cache (71:385)
    # /dev/disk/by-partuuid/1b36440f-ea00-4c7d-80cb-96ba7dc75561: Aliased to /dev/disk/by-id/scsi-360002ac000000000000004ed00019fbb-part1 in device cache (71:385)
    # /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0: Aliased to /dev/block/65:32 in device cache (preferred name) (65:32)
    # /dev/disk/by-id/dm-uuid-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450: Aliased to /dev/disk/by-id/dm-name-ddf1_4c53492020202020808627c3000000004711471100001450 in device cache (253:0)
    # /dev/disk/by-id/edd-int13_dev80: Aliased to /dev/block/8:32 in device cache (preferred name) (8:32)
    # /dev/disk/by-id/scsi-36000eb342fe8a6e0000000000000010f-part1: Aliased to /dev/disk/by-id/edd-int13_dev80-part1 in device cache (8:33)
    # /dev/disk/by-id/wwn-0x6000eb342fe8a6e0000000000000010f-part1: Aliased to /dev/disk/by-id/edd-int13_dev80-part1 in device cache (8:33)
    # /dev/disk/by-id/nvme-Dell_Express_Flash_NVMe_SM1715_800GB_SFF_______S29HNYAH200026: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-HWE36P43016M000N_032BEH10GC000513: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-HWE36P43016M000N_032BEH10GC000513-part1: Aliased to /dev/nvme0n1p1 in device cache (259:1)
    # /dev/disk/by-id/nvme-nvme.144d-20202020202053314a304e594147423031323134-44656c6c204578707265737320466c617368204e564d65203430304742-00000001: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-HUSMR7676BHP3Y1_SDM00000EF14: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-LT0800KEXVA_CVMD5390007B800BGN-part12: Aliased to /dev/nvme0n1p12 in device cache (259:12)
    # /dev/disk/by-id/nvme-LT1600KEXVB_CVMD5443003H1P6DGN-part1: Aliased to /dev/nvme0n1p1 in device cache (259:1)
    # /dev/disk/by-id/nvme-eui.0000000000000000000cca0b01416a80: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-RMS-200_0038435: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-PLEXTOR_PX-1TM8PeY_P02633105792: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/disk/by-id/nvme-PLEXTOR_PX-1TM8PeY_P02633105792-part1: Aliased to /dev/nvme0n1p1 in device cache (259:1)
    # /dev/disk/by-id/emc-vol-4b7837cd1e146dcb-db982bc600000000: Aliased to /dev/scinid in device cache (252:48)
    # /dev/disk/by-ld/cache: Aliased to /dev/sdb in device cache (8:16)
    # /dev/disk/by-ld/filer: Aliased to /dev/sda in device cache (8:0)
    # /dev/disk/by-ld/filer-part1: Aliased to /dev/sda1 in device cache (8:1)
    # /dev/disk/by-path/FIO-1439G0384: Aliased to /dev/fioa in device cache (252:0)
    # /dev/disk/by-path/FIO-: Aliased to /dev/block/252:208 in device cache (preferred name) (252:208)
    # /dev/disk/by-path/pci-0000:05:00.0: Aliased to /dev/block/65:752 in device cache (preferred name) (65:752)
    # /dev/disk/by-path/pci-0000:0b:00.0: Aliased to /dev/block/259:0 in device cache (preferred name) (259:0)
    # /dev/disk/by-path/pci-0000:05:00.0: Aliased to /dev/sdb in device cache (8:16)
    # /dev/disk/by-path/pci-0000:08:00.0: Aliased to /dev/sdc in device cache (8:32)
    # /dev/disk/by-path/pci-0000:0b:00.0: Aliased to /dev/disk/by-id/wwn-0x65cd2e40808643564d54000000010000 in device cache (259:0)
    # /dev/disk/by-path/pci-0000:0b:00.0-part1: Aliased to /dev/disk/by-id/lvm-pv-uuid-b5ZSgR-f1bq-GiqG-V55i-9Mdu-l3EL-6gNeUv in device cache (259:1)
    # /dev/disk/by-path/pci-0000:06:00.0-nvme-1: Aliased to /dev/nvme0n1 in device cache (259:0)
    # /dev/dsk/FIO-: Aliased to /dev/disk/by-path/FIO- in device cache (preferred name) (252:208)
    # /dev/disk/by-slot/disk-0: Aliased to /dev/sde in device cache (8:64)
    # /dev/disk/by-slot/disk-10part1: Aliased to /dev/sda1 in device cache (8:1)
    # /dev/disk/by-type/HDD-1part1: Aliased to /dev/sde1 in device cache (8:65)
    # /dev/disk/by-slot/ssd-2part7: Aliased to /dev/sdl7 in device cache (8:183)
    # /dev/disk/by-type/OS-1part1: Aliased to /dev/sdk1 in device cache (8:161)
    # /dev/disk/by-type/SSD-2part1: Aliased to /dev/sda1 in device cache (8:1)
    # /dev/disk/by-vdev/F01-part1: Aliased to /dev/sdc1 in device cache (8:33)

    return

# ---------------------------------------------#
# function: disect_dev()
# slice up one of the two devices listed in a "/dev/...: Aliased to /dev/... in device cache (preferred name) (ma:mi)"
# ---------------------------------------------#


def disect_dev(dev_path, mm, line, source):
    global pci_long_re
    global dev_san_hana_count  # 0

    _dir = os.path.dirname(dev_path)
    subdir = _dir[len("/dev/"):]

    if subdir == '':
        subdir_count = 0
    else:
        subdir_count = subdir.count("/") + 1

    dev_id = os.path.basename(dev_path)

    ele_type = ''  # dev|block|vg_lv|subdir
    ele_name = ''
    id_type = ''  # scsi_id|fc_id|wwn_id|ata_id|sata_id|usb_id
    id_name = ''

    # debug_print(z,"{0} {1} '{2}' ({3})".format(dev_path,mm,line,source))

    for i in range(0, 1):  # so 'continue' will jump to the end...

        # /dev/dm-30
        # /dev/sda
        # /dev/sda1
        # /dev/sdxz1
        # /dev/vda
        # /dev/vda1
        # /dev/xvda1
        # /dev/root
        # /dev/dvd
        # /dev/scd0
        # /dev/cdrom
        # /dev/cdrom-hda
        # /dev/sr0
        # /dev/dasde
        # /dev/md4
        # /dev/md1
        # /dev/md126
        # /dev/md126p1
        # /dev/md126p2
        if subdir_count == 0:
            if dev_path == "/dev/root":
                id_type = "label"
                it_name = "root"
                track_label("root", conv_mm_2_bd(mm), source)
            ele_type = "dev"
            ele_name = dev_id
            add_mm_bd(dev_id, mm, source)
            continue  # to end

        # /dev/md/boot
        # /dev/md/root
        # /dev/md/swap
        if dev_path.startswith("/dev/md/") and subdir_count == 1:
            # if word_in_list(dev_id,"boot root swap"):
                # add_mm_bd(dev_id,mm,source)
                # continue
            add_mm_bd(dev_id, mm, source)
            continue

        # /dev/block/253:3
        if dev_path.startswith("/dev/block/") and subdir_count == 1 and dev_id == mm:
            ele_type = "block"
            ele_name = dev_id
            continue  # to end

        # /dev/vg/lv
        if subdir_count == 1:  # check for /dev/vg/lv ...
            vg_lv = build_vg_lv(subdir, dev_id, source)
            vg_lv = clean_vg_lv(vg_lv, source)
            if vg_lv != '':
                ele_type = "vg_lv"
                ele_name = vg_lv
                add_mm_bd(vg_lv, mm, source)
                continue  # to end

        # /dev/mapper/volgrp01-var
        # /dev/mapper/mpathz
        # /dev/mapper/mpath6p1
        # /dev/mapper/360002ac0000000000000052500019fbb1
        # /dev/mapper/asm_fra100
        # /dev/mapper/asm_disk100p1
        if dev_path.startswith("/dev/mapper/"):
            mapper_name = dev_id
            vg_lv = mapper_name
            if split_valid_lv_name(vg_lv, source) != '':
                ele_type = "vg_lv"
                ele_name = vg_lv
                add_mm_bd(vg_lv, mm, source)
                continue  # to end
            if subdir_count == 1:
                ele_type = "subdir"
                ele_name = subdir + "/" + mapper_name
                if is_scsi_id(mapper_name):
                    id_type = "scsi_id"
                    id_name = mapper_name
                    track_scsi_id(id_name, conv_mm_2_bd(mm), source)
                    continue  # to end
                add_mm_bd(ele_name, mm, source)
                continue  # to end

        # /dev/disk/by-id/dm-name-360060e8016020f000001020f00000030
        # /dev/disk/by-id/dm-name-vg09-lvol2
        # /dev/disk/by-id/dm-name-asm_disk100p1
        # /dev/disk/by-id/dm-name-mpathg
        if dev_path.startswith("/dev/disk/by-id/dm-name-"):
            dm_name = dev_id[len("dm-name-"):]
            ele_type = "dm_name"
            ele_name = dm_name
            if is_scsi_id(dm_name):
                id_type = "scsi_id"
                id_name = dm_name
                track_scsi_id(id_name, conv_mm_2_bd(mm), source)
                continue  # to end
            vg_lv = dm_name
            if split_valid_lv_name(vg_lv, source) != '':
                ele_type = "vg_lv"
                ele_name = vg_lv
                add_mm_bd(vg_lv, mm, source)
                continue  # to end
            add_mm_bd(dm_name, mm, source)
            continue  # to end
        # /dev/disk/by-id/dm-uuid-mpath-360002ac0000000000000052600019fbb
        if dev_path.startswith("/dev/disk/by-id/dm-uuid-mpath-"):
            dm_name = dev_id[len("dm-uuid-mpath-"):]
            if is_scsi_id(dm_name):
                id_type = "scsi_id"
                id_name = dm_name
                track_scsi_id(id_name, conv_mm_2_bd(mm), source)
                continue  # to end
            ele_type = "dm_uuid_mpath"
            ele_name = dm_name

        # /dev/disk/by-id/dm-uuid-part1-mpath-360002ac0000000000000052200019fbb
        # /dev/disk/by-id/dm-uuid-part1-mpath-1Dell\x20\x20\x20\x20Internal\x20Dual\x20SD\x20\x20\x20\x20\x20\x20\x20\x200123456789AB: Aliased to /dev/disk/by-id/dm-name-mpathap1 in device cache (253:2)
        # /dev/disk/by-id/dm-uuid-part1-mpath-Dell_Internal_Dual_SD_0123456789AB-0:0: Aliased to /dev/disk/by-id/dm-name-Dell_Internal_Dual_SD_0123456789AB-0:0p1 in device cache (253:7)
        # /dev/disk/by-id/dm-uuid-part3-mpath-TOSHIBA_TOSHIBA_USB_DRV_070823F67255FA02-0:0: Aliased to /dev/disk/by-id/dm-name-TOSHIBA_TOSHIBA_USB_DRV_070823F67255FA02-0:0p3 in device cache (253:6)
        # /dev/disk/by-id/dm-uuid-part1-mpath-HP_iLO_LUN_00_Media_0_000002660A01-0:0: Aliased to /dev/disk/by-id/dm-name-HP_iLO_LUN_00_Media_0_000002660A01-0:0p1 in device cache (253:15)
        # /dev/disk/by-id/dm-uuid-part1-mpath-iDRAC_OEMDRV_20151118-0-0:0:
        # /dev/disk/by-id/dm-uuid-part2-mpath-SATA_SSD_AF3407611E2400195988: Aliased to /dev/disk/by-id/dm-name-SATA_SSD_AF3407611E2400195988p2 in device cache (253:3)
        # /dev/disk/by-id/dm-uuid-part3-mpath-SIBM_3303_NVDISK3627d5fd45a9d35b78ca53143b07232c: Aliased to /dev/disk/by-id/dm-name-mpathv3 in device cache (253:3)
        # /dev/disk/by-id/dm-uuid-part1-mpath-Lacie_ST1000DM003-9YN1_573144304C39393800000000-0:0: Aliased to /dev/disk/by-id/dm-name-Lacie_ST1000DM003-9YN1_573144304C39393800000000-0:0p1
        # /dev/disk/by-id/dm-uuid-part1-mpath-HP_8GB_EM_USB_Drive_070375F994804938-0:0: Aliased to /dev/disk/by-id/dm-name-HP_8GB_EM_USB_Drive_070375F994804938-0:0p1 in device cache (253:2)
        # /dev/disk/by-id/dm-uuid-part1-mpath-INTEL\x20SSDPE2ME012T4_CVMD7174003C1P2WGN: Aliased to /dev/disk/by-id/dm-name-INTEL\x20SSDPE2ME012T4_CVMD7174003C1P2WGN1 in device cache (253:3)
        # /dev/disk/by-id/dm-uuid-part1-mpath-UNIGEN_PHF16H0CM1-DTE_070076A1C68B0050-0:0: Aliased to /dev/disk/by-id/dm-name-UNIGEN_PHF16H0CM1-DTE_070076A1C68B0050-0:0p1 in device cache (253:2)
        # /dev/disk/by-id/dm-uuid-part3-mpath-Micron_5100_MTFDDAK960TCB_1710168771F0: Aliased to /dev/disk/by-id/dm-name-Micron_5100_MTFDDAK960TCB_1710168771F0p3 in device cache (253:10)

        if dev_path.startswith("/dev/disk/by-id/dm-uuid-part") and "-mpath-" in dev_id:
            m = dev_id.find("-mpath-")
            dm_name = dev_id[m + len("-mpath-"):]
            p = dev_id.find("-part")
            part = dev_id[p:m]  # partn, e.g. '-partn'
            dm_name = dm_name + part
            if is_scsi_id(dm_name):
                id_type = "scsi_id"
                id_name = dm_name
                track_scsi_id(id_name, conv_mm_2_bd(mm), source)
                continue  # to end
            if dm_name.startswith("0QEMU_"):
                continue
            if dm_name.startswith("1Dell"):
                continue
            if dm_name.startswith("Dell_Internal_"):
                continue
            if dm_name.startswith("TOSHIBA_"):
                continue
            if dm_name.startswith("HP_iLO_LUN"):
                continue
            if dm_name.startswith("HP_iLO_Internal_SD"):
                continue
            if dm_name.startswith("HP_8GB_EM"):
                continue
            if dm_name.startswith("iDRAC"):
                continue
            if dm_name.startswith("INTEL"):
                continue
            if dm_name.startswith("SAMSUNG"):
                continue
            if dm_name.startswith("SATA_SSD_"):
                continue
            if dm_name.startswith("Memorex_Mini_"):
                continue
            if dm_name.startswith("INTEL_SSDSC2B"):
                continue
            if dm_name.startswith("SIBM"):
                continue
            if dm_name.startswith("Lacie"):
                continue
            if dm_name.startswith("UNIGEN"):
                continue
            if dm_name.startswith("Micron"):
                continue
            else:
                debug_print(0, "{0} '{1}'".format(dm_name, line))
            ele_type = "dm_uuid_mpath"
            ele_name = dm_name

        # /dev/disk/by-id/dm-uuid-LVM-vPP1J15ughv5WYaMneTYGcPko7C8g6rvCTzq68D8QHHHXKUtjDpdbmMpVOQ1F7HC
        if dev_path.startswith("/dev/disk/by-id/dm-uuid-LVM-"):
            dm_name = dev_id[len("dm-uuid-LVM-"):]
            ele_type = "dm_uuid_LVM"
            ele_name = dm_name
            continue

        # /dev/disk/by-id/scsi-360000970000192606755533030313836
        # /dev/disk/by-id/scsi-3600224807cef35855a55c97fd5806469
        # /dev/disk/by-id/scsi-3600224807cef35855a55c97fd5806469-part1
        if dev_path.startswith("/dev/disk/by-id/scsi-"):
            scsi_id = dev_id[len("scsi-"):]
            if is_scsi_id(scsi_id):
                id_type = "scsi_id"
                id_name = scsi_id
                track_scsi_id(scsi_id, conv_mm_2_bd(mm), source)
                continue  # to end
            else:
                # scsi-0QEMU_QEMU_HARDDISK_drive-scsi0-0-0-1
                # scsi-SASR8805_logdev01_08AB952F
                # scsi-SATA_MB1000EAMZE_9WK4PA01-part3
                # scsi-SATA_INTEL_SSDSC2BB1_PHWA605500GM120CGN
                # scsi-SATA_SAMSUNG_MZ7LM96S35RNXAH300135-part1
                # scsi-SHITACHI_OPEN-V_50450328
                # scsi-SATA_WDC_WD10EZRX-00_WD-WMC1U5184213
                #
                # could track "alt-scsi" ids, but until the info is needed just skip
                continue  # to end

        # /dev/disk/by-id/cciss-3600508b100104d39535749304a300004
        # /dev/disk/by-id/cciss-3600508b100104d39535749304a300004-part1
        if dev_path.startswith("/dev/disk/by-id/cciss-"):
            scsi_id = dev_id[len("cciss-"):]
            if is_scsi_id(scsi_id):
                id_type = "scsi_id"
                id_name = scsi_id
                track_scsi_id(scsi_id, conv_mm_2_bd(mm), source)
                continue  # to end

        # /dev/disk/by-id/usb-Cisco_Virtual_CD_DVD_20111102-00000002-0:0
        if dev_path.startswith("/dev/disk/by-id/usb-"):
            usb_id = dev_id[len("usb-"):]
            if is_usb_id(usb_id):
                id_type = "usb_id"
                id_name = usb_id
                track_usb_id(usb_id, conv_mm_2_bd(mm), source)
                continue  # to end

        # /dev/disk/by-id/virtio-982bd6c0-dac4-46da-a
        # /dev/disk/by-id/virtio-982bd6c0-dac4-46da-a-part1
        if dev_path.startswith("/dev/disk/by-id/virtio-"):
            virtio_id = dev_id[len("virtio-"):]
            if is_virtio_id(virtio_id):
                id_type = "virtio_id"
                id_name = virtio_id
                track_virtio_id(virtio_id, conv_mm_2_bd(mm), source)
                continue  # to end

        # /dev/disk/by-id/wwn-0x60000970000192606755533030313836
        # /dev/disk/by-id/wwn-0x60000970000192606755533030313837-part1
        # /dev/disk/by-id/wwn-0x5001b44f19905d78
        # # /dev/disk/by-id/wwn-0x5001b44f19905d78-part1
        if dev_path.startswith("/dev/disk/by-id/wwn-"):
            wwn_id = dev_id[len("wwn-0x"):]
            id_type = "wwn_id"
            id_name = wwn_id
            track_wwn_id(wwn_id, conv_mm_2_bd(mm), source)
            continue

        # /dev/disk/by-label/ARCH1
        # /dev/disk/by-label/\x2fboot
        # /dev/disk/by-label/B439_ASMDISK001
        # /dev/disk/by-label/EFI-SYSTEM
        if dev_path.startswith("/dev/disk/by-label/"):
            label = dev_id
            if label.startswith("\\x2f"):
                label = label[len("\\x2f"):]
            id_type = "label"
            id_name = label
            track_label(label, conv_mm_2_bd(mm), source)
            continue

        # /dev/disk/by-id/ata-SanDisk_SD7SB7S512G1122_154853400952-part1
        # /dev/disk/by-id/ata-QEMU_DVD-ROM_QM00003
        if dev_path.startswith("/dev/disk/by-id/ata-"):
            ata_id = dev_id[len("ata-"):]
            id_type = "ata_id"
            id_name = ata_id
            track_ata_id(ata_id, conv_mm_2_bd(mm), source)
            continue  # to end

        # /dev/disk/by-uuid/d0f60ab1-4eda-4f68-9f3d-ffd364df8379
        if dev_path.startswith("/dev/disk/by-uuid/"):
            uuid = clean_uuid(dev_id)
            ele_type = "uuid"
            ele_name = ""  # skip for now
            # track_uuid(uuid,conv_mm_2_bd(mm),source)
            continue

        # /dev/disk/by-diskuuid/dcb03197-380d-4bdd-ac05-4823e57eb2e0
        if dev_path.startswith("/dev/disk/by-diskuuid/"):
            ele_type = "diskuuid"
            ele_name = ""  # skip for now
            continue  # to end

        # /dev/disk/by-path/scsi-0:0:0:0
        # /dev/disk/by-path/scsi-0:0:0:0-part1
        if dev_path.startswith("/dev/disk/by-path/scsi-"):
            s = dev_id.find("scsi-")
            scsi_id_or_adr = dev_id[s + len("scsi-"):]
            part_id = ''
            p = scsi_id_or_adr.find("-part")
            if p != -1:
                part_id = scsi_id_or_adr[p:]
                scsi_id_or_adr = scsi_id_or_adr[0:p]
            if is_scsi_adr(scsi_id_or_adr):  # scsi adr (h:b:t:l) ?
                id_type = "scsi_adr"
                id_name = scsi_id_or_adr
                add_normalized_scsi_data(scsi_id_or_adr, '', conv_mm_2_bd(mm), '', '', source)
                if part_id != '':
                    sd_part = conv_mm_2_bd(mm)
                    sd_id = get_dev_from_part_id(sd_part, source)
                    add_partition_2_dev(sd_id, sd_part, source)
                continue  # to end
            if is_scsi_id(scsi_id_or_adr):  # scsi id (36xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx)?
                id_type = "scsi_id"
                id_name = scsi_id_or_adr
                track_scsi_id(scsi_id_or_adr + part_id, conv_mm_2_bd(mm), source)
                add_mm_bd(scsi_id_or_adr + part_id, mm, source)
                continue  # to end

        # /dev/disk/by-path/virtio-pci-0000:00:0c.0-scsi-0:0:0:2
        if dev_path.startswith("/dev/disk/by-path/virtio-pci-") and "-scsi-" in dev_path:
            vp = dev_id.find("virtio-pci-")
            s = dev_id.find("-scsi-")
            e = dev_id.find("-part")  # may be -1 if no "-partn"
            pci_adr = dev_id[vp + len("virtio-pci-"):s]
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            if e == -1:
                scsi_adr = dev_id[s + len("-scsi-"):]
            else:
                scsi_adr = dev_id[s + len("-scsi-"):e]
            tmp = scsi_adr.split(':')
            scsi_adr = "{0}:{1}:{2}:{3}".format(host, tmp[1], tmp[2], tmp[3])
            add_normalized_scsi_data(scsi_adr, '', conv_mm_2_bd(mm), '', '', source)
            if e != -1:  # partition
                sd_part = conv_mm_2_bd(mm)
                sd_id = get_dev_from_part_id(sd_part, source)
                add_partition_2_dev(sd_id, sd_part, source)
            continue  # to end

        # /dev/disk/by-path/pci-0000:13:00.0-scsi-0:0:3:0
        # /dev/disk/by-path/pci-0000:13:00.0-scsi-0:0:3:0-part1
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-scsi-" in dev_path:
            p = dev_id.find("pci-")
            s = dev_id.find("-scsi-")
            e = dev_id.find("-part")  # may be -1 if no "-partn"
            pci_adr = dev_id[p + len("pci-"):s]
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            if e == -1:
                scsi_adr = dev_id[s + len("-scsi-"):]
            else:
                scsi_adr = dev_id[s + len("-scsi-"):e]
            tmp = scsi_adr.split(':')
            scsi_adr = "{0}:{1}:{2}:{3}".format(host, tmp[1], tmp[2], tmp[3])
            add_normalized_scsi_data(scsi_adr, '', conv_mm_2_bd(mm), '', '', source)
            if e != -1:  # partition
                sd_part = conv_mm_2_bd(mm)
                sd_id = get_dev_from_part_id(sd_part, source)
                add_partition_2_dev(sd_id, sd_part, source)
            continue  # to end

        # /dev/disk/by-path/acpi-VMBUS:00-scsi-0:0:0:0
        # /dev/disk/by-path/acpi-VMBUS:00-scsi-0:0:0:0-part1
        # /dev/disk/by-path/acpi-VMBUS:01-scsi-0:0:0:0
        # /dev/disk/by-path/acpi-VMBUS:01-scsi-0:0:0:0-part1
        # /dev/disk/by-path/acpi-VMBUS:01-scsi-0:0:0:0-part2
        if dev_path.startswith("/dev/disk/by-path/acpi-VMBUS:") and "-scsi-" in dev_path:
            a = dev_id.find("acpi-")
            s = dev_id.find("-scsi-")
            e = dev_id.find("-part")  # may be -1 if no "-partn"
            if e == -1:
                scsi_adr = dev_id[s + len("-scsi-"):]
            else:
                scsi_adr = dev_id[s + len("-scsi-"):e]
            tmp = scsi_adr.split(':')
            scsi_adr = "{0}:{1}:{2}:{3}".format(tmp[0], tmp[1], tmp[2], tmp[3])
            # Stopped using this alias info as the scsi address seems to always be bogus (typically 0:0:0:0)
            # see any of the following case; 01954862,01954862,01945560,01945560,02040420)
            # see sos_commands/lvm2/vgscan_-vvv_--config_global_locking_type_0 in each of the above cases
            # add_normalized_scsi_data(scsi_adr,'',conv_mm_2_bd(mm),'','',source)
            if e != -1:  # partition
                sd_part = conv_mm_2_bd(mm)
                sd_id = get_dev_from_part_id(sd_part, source)
                add_partition_2_dev(sd_id, sd_part, source)
            continue  # to end

        # /dev/disk/by-path/pci-0000:00:05.0-virtio-pci-virtio2-part1
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-virtio-pci-" in dev_path:
            p = dev_id.find("pci-")
            v = dev_id.find("-virtio-pci-")
            e = dev_id.find("-part")  # may be -1 if no "-partn"
            pci_adr = dev_id[p + len("pci-"):v]
            host = pci_address_2_host(pci_adr)
            # debug_print(z,dev_path)
            # debug_print(z,host)
            # if host == '': continue # SNO # ----> does occur for virtio
            if e == -1:
                virtio_id = dev_id[v + len("-virtio-pci-"):]
            else:
                virtio_id = dev_id[v + len("-virtio-pci-"):e]
            # debug_print(z,virtio_id)
            track_virtio_id(virtio_id, conv_mm_2_bd(mm), source)
            continue  # to end

        # /dev/disk/by-path/pci-0000:0b:00.0
        if dev_path.startswith("/dev/disk/by-path/pci-") and len(dev_id) == len("pci-0000:0b:00.0"):
            pci_adr = dev_id[len("pci-"):]
            host = pci_address_2_host(pci_adr)
            # debug_print(z,dev_path)
            # debug_print(z,host)
            if host == '':
                continue
            # nothing to do at present (skipping)
            continue  # to end

        # /dev/disk/by-path/pci-0000:0b:00.0-part1
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-part" in dev_path:
            p = dev_id.find("pci-")
            e = dev_id.find("-part")
            pci_adr = dev_id[p + len("pci-"):e]
            host = pci_address_2_host(pci_adr)
            # debug_print(z,dev_path)
            # debug_print(z,host)
            if host == '':
                continue
            # nothing to do at present (skipping)
            continue  # to end

        #
        # /dev/drbd/by-disk/disk/by-id/scsi-3600507605b407f791ca62d401599d90d-part3
        if dev_path.startswith("/dev/drbd/by-disk/disk/by-id/scsi-"):
            scsi_id = dev_id[len("scsi-"):]
            if is_scsi_id(scsi_id):
                track_scsi_id(scsi_id, conv_mm_2_bd(mm), source)
                continue  # to end

        # /dev/disk/by-path/pci-0000:02:00.0-sas-exp0x50000d1108d9fabf-phy10-lun-0
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-sas-" in dev_path:
            p = dev_id.find("pci-")
            s = dev_id.find("-sas-")
            pci_adr = dev_id[p + len("pci-"):s]
            # debug_print(z,pci_adr)
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            sas_id = dev_id[s + len("-sas-"):]  # take the entire sas-id, including '-partn', if present
            track_sas_id(sas_id, conv_mm_2_bd(mm), source)
            id_type = "sas_id"
            id_name = sas_id
            continue  # to end
        # /dev/disk/by-path/pci-0000:00:01.1-ata-1.1
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-ata-" in dev_path:
            p = dev_id.find("pci-")
            a = dev_id.find("-ata-")
            pci_adr = dev_id[p + len("pci-"):a]
            # debug_print(z,pci_adr)
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            ata_id = dev_id[a + len("-ata-"):]  # take the entire ata-id, including '-partn', if present
            track_ata_id(ata_id, conv_mm_2_bd(mm), source)
            id_type = "ata_id"
            id_name = ata_id
            continue  # to end
        # /dev/disk/by-path/pci-0000:00:07.1-ide-0:1
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-ide-" in dev_path:
            p = dev_id.find("pci-")
            ii = dev_id.find("-ide-")  # 'i' in use in control loop
            pci_adr = dev_id[p + len("pci-"):ii]
            # debug_print(z,pci_adr)
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            ide_id = dev_id[ii + len("-ide-"):]  # take the entire ide-id, including '-partn', if present
            track_ide_id(ide_id, conv_mm_2_bd(mm), source)
            id_type = "ide_id"
            id_name = ide_id
            continue  # to end
        # /dev/disk/by-path/pci-0000:05:00.1-fc-0x50060e80101ae5ef-lun-40-part1
        # /dev/disk/by-path/pci-0000:05:00.0-fc-0x500507680130bceb-lun-43
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-fc-" in dev_path:
            p = dev_id.find("pci-")
            f = dev_id.find("-fc-")
            pci_adr = dev_id[p + len("pci-"):f]
            # debug_print(z,pci_adr)
            host = pci_address_2_host(pci_adr)
            if host == '':
                continue  # SNO
            fc_id = dev_id[f + len("-fc-"):]  # take the entire fc-id, including '-partn', if present
            track_fc_id(fc_id, conv_mm_2_bd(mm), source)
            id_type = "fc_id"
            id_name = fc_id
            continue  # to end

        # /dev/disk/by-path/pci-0000:03:00.2-ip-172.31.16.3:3260-iscsi-iqn.2003-10.com.lefthandnetworks:pinkroccade-healthcare-mgm:271:hp-sa-vol01-lun-0
        if dev_path.startswith("/dev/disk/by-path/pci-") and "-iscsi-iqn" in dev_path:
            id_type = "iscsi"
            id_name = ""
            p = dev_id.find("pci-")
            i = dev_id.find("-ip-")
            pci_adr = dev_id[p + len("pci-"):i]
            pci_host = pci_address_2_host(pci_adr)
            scsi_host = ''
            scsi_adr = dev_2_lun[conv_mm_2_bd(mm)]
            if scsi_adr != '':
                tmp = scsi_adr.split(":")
                scsi_host = tmp[0]
            hba_host = ''
            if scsi_host == '' and pci_host != '':
                hba_host = pci_host
            elif scsi_host != '' and pci_host == '':
                hba_host = scsi_host
            elif scsi_host == '' and pci_host == '':
                hba_host = ''
            elif scsi_host == pci_host:
                hba_host = scsi_host
            else:
                error_print('d', "pci_host({0}) != scsi_host({1})[{2}] '{3}' ({4})".
                            format(pci_host, scsi_host, conv_mm_2_bd(mm), line, source))
                continue
            if hba_host != '':
                track_hba(hba_host, "iscsi", source)
            continue  # to end

        # /dev/disk/by-path/fc-0x5742b0f000053321-lun-4
        # /dev/disk/by-path/fc-0x5742b0f000053321-lun-3
        if dev_path.startswith("/dev/disk/by-path/fc-"):
            fc_id = dev_id[len("fc-"):]  # take the entire fc-id, including '-partn', if present
            track_fc_id(fc_id, conv_mm_2_bd(mm), source)
            id_type = "fc_id"
            id_name = fc_id
            continue  # to end

        # /dev/disk/by-path/ip-192.168.81.251:3260-iscsi-iqn.1992-04.com.emc:cx.apm00142532959.a7-lun-0
        # /dev/disk/by-path/ip-172.17.19.20:3260-iscsi-iqn.1992-08.com.netapp:sn.be4bb72aa0f011e6af7b00a098a778f5:vs.10-lun-3
        # /dev/disk/by-path/ip-10.1.29.10:3260-iscsi-iqn.2010-06.com.purestorage:flasharray.5bb3d49012dc72af-lun-1-part1
        # /dev/disk/by-path/ip-10.244.208.240:3260-iscsi-iqn.2001-05.com.equallogic:4-42a846-2da52f608-89e0058a4bf555f6-ds-eql-g7-rz3prod-07-lun-0-part5
        if dev_path.startswith("/dev/disk/by-path/ip-") and "-iscsi-iqn" in dev_id:
            id_type = "iscsi"
            id_name = ""
            scsi_adr = dev_2_lun[conv_mm_2_bd(mm)]
            # debug_print(z,"{0} '{1}' ({2})".format(mm,scsi_adr,source))
            if scsi_adr != '':
                tmp = scsi_adr.split(":")
                scsi_host = tmp[0]
                track_hba(scsi_host, "iscsi", source)
                continue  # to end
            # end: if scsi_adr != '':
            continue  # to end # probably a partition

        # /dev/disk/by-path/xen-vbd-268439552
        if dev_path.startswith("/dev/disk/by-path/xen-vbd-"):
            # TODO: research what can be made of the numeric portion
            # of "xen-vbd-nnnnnnnnn" and "xen-vbd-nnnnn"
            continue  # to end

        # /dev/disk/by-id/ccw-0X0102
        # /dev/disk/by-id/ccw-0X0102-part1
        # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02
        # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02.0000bff20000ffec0000000000000000
        # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02-part1
        # /dev/disk/by-id/ccw-IBM.750000000FWC41.5f00.02.0000bff20000ffec0000000000000000-part1
        # /dev/disk/by-id/ccw-LXSWAP
        # /dev/disk/by-id/ccw-LXSWAP-part1
        # /dev/disk/by-id/ccw-VOL10X
        # /dev/disk/by-id/ccw-VOL10X-part1
        # /dev/disk/by-id/ccw-HTC.85000000057006.8000.1c
        # /dev/disk/by-id/ccw-LXNAME
        # /dev/disk/by-id/ccw-LXNAME-part1
        # /dev/disk/by-id/ccw-LX7F0B
        # /dev/disk/by-id/ccw-LX7F0B-part1
        # /dev/disk/by-id/ccw-LF7F17
        # /dev/disk/by-id/ccw-LF7F17-part1
        # /dev/disk/by-id/ccw-SWAP
        # /dev/disk/by-id/ccw-EMC.080000000AHNNM.4f00.78
        # /dev/disk/by-id/ccw-EMC.080000000AHNNM.4f00.78-part1
        # /dev/disk/by-id/ccw-EMC.080000000AHNNM.4f00.78.000000330000ffef0000000000000000
        # /dev/disk/by-id/ccw-EMC.080000000AHNNM.4f00.78.000000330000ffef0000000000000000-part1
        # /dev/disk/by-id/ccw-EMC.080000000AHNNM.4f00.78.000000330000ffef0000000000000000-part2
        # /dev/disk/by-id/ccw-DAT241-part1
        if dev_path.startswith("/dev/disk/by-id/ccw-"):
            # debug_print(0,"/dev/disk/by-id/ccw-.... '{0}'".format(dev_id))
            add_mm_bd(conv_mm_2_bd(mm), mm, source)
            if dev_id.startswith("ccw-EMC"):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-IBM"):
                s = len("ccw-IBM.750000000FWC41.")
                e = s + 4
                cuuu = dev_id[s:e]
                track_s390_dasd(cuuu, conv_mm_2_bd(mm), '', mm, 'dasd', '3390', '', source)
                continue
            if dev_id.startswith("ccw-LXNAME"):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-LXSWAP"):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-SWAP"):
                continue  # TODO: is there more we can do with this info?
            if re.match("ccw-L.....-part" + n2_re, dev_id):
                continue  # TODO: is there more we can do with this info?
            if re.match("ccw-L.....", dev_id):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-VOL1"):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-DAT"):
                continue  # TODO: is there more we can do with this info?
            if dev_id.startswith("ccw-HTC"):
                s = len("ccw-HTC.85000000057006.")
                e = s + 4
                cuuu = dev_id[s:e]
                track_s390_dasd(cuuu, conv_mm_2_bd(mm), '', mm, 'dasd', '3390', '', source)
                continue
            if dev_id.startswith("ccw-0X"):
                s = len("ccw-0X")
                e = s + 4
                cuuu = dev_id[s:e]
                track_s390_dasd(cuuu, conv_mm_2_bd(mm), '', mm, 'dasd', '3390', '', source)
                continue

        # /dev/disk/by-path/ccw-0.0.0102
        # /dev/disk/by-path/ccw-0.0.0102-part1
        if dev_path.startswith("/dev/disk/by-path/ccw-"):
            add_mm_bd(conv_mm_2_bd(mm), mm, source)
            s = len("ccw-")
            e = s + 8
            cuuu = dev_id[s:e]
            track_s390_dasd(cuuu, conv_mm_2_bd(mm), '', mm, '', '', '', source)
            continue

        # /dev/disk/by-id/md-uuid-43493444:056c9079:21befa5f:5e094a52
        # /dev/disk/by-id/md-uuid-4db70934:99e5b53e:e0aca036:7b5c32c2
        # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab
        # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab-part1
        # /dev/disk/by-id/md-uuid-55ca7a37:dafbcf7d:d57250b1:a7a40cab-part2
        if dev_path.startswith("/dev/disk/by-id/md-uuid-"):
            uuid = dev_id[len("md-uuid-"):]
            track_md_id(conv_mm_2_bd(mm), '', uuid, '', source)
            continue

        # -----------------------------------------------------------------
        # S K I P P I N G   T H E S E:
        # /dev/disk/by-dname/sdp
        # /dev/disk/by-dname/sdp-part1
        # /dev/disk/by-dpid/disk-104001
        # /dev/disk/by-dpid/disk-104001-part1
        # /dev/disk/by-id/dm-uuid-switch-2f924bb5b33ed54d06c9ce9006b8d35f6
        # /dev/disk/by-id/dm-uuid-CRYPT-LUKS1-b533ac8a3ede4e6384367ecdfbdb39a3-5e83173a-a7dc-4557-b34f-e6230155b254
        # /dev/disk/by-id/dm-uuid-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450
        # /dev/disk/by-id/dm-uuid-mpath-4b7837cd1e146dcb-db982bc600000000
        # /dev/disk/by-id/dm-uuid-part1-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450
        # /dev/disk/by-id/dm-uuid-part2-DMRAID-ddf1_4c53492020202020808627c3000000004711471100001450
        # /dev/disk/by-id/edd-int13_dev80
        # /dev/disk/by-id/edd-int13_dev80-part1
        # /dev/disk/by-id/emc-vol-4b7837cd1e146dcb-db9852d500000003
        # /dev/disk/by-id/google-ocf-oic-nonprod-openshift-master-001
        # /dev/disk/by-id/google-persistent-disk-0
        # /dev/disk/by-id/google-docker
        # /dev/disk/by-id/google-openshift
        # /dev/disk/by-id/lvm-pv-uuid-3pbbSo-0Imp-lM0J-Vqiw-Pd0e-YB3v-fI1Ut0
        # /dev/disk/by-id/md-name-bdan4.nerc-essc.ac.uk:0
        # /dev/disk/by-id/nvme-Amazon_EC2_NVMe_Instance_Storage_AWS259D1B832215992E1
        # /dev/disk/by-id/nvme-Dell_Express_Flash_NVMe_SM1715_800GB_SFF_______S29HNYAH200026
        # /dev/disk/by-id/nvme-HWE36P43016M000N_032BEH10GC000513-part1
        # /dev/disk/by-id/nvme-MT0800KEXUU_PHFT6201006B800CGN
        # /dev/disk/by-id/nvme-MO001600KWJSN_PHLE7423009R1P6CGN-part1
        # /dev/disk/by-id/nvme-MK001600KWDUN_ZC5022Q9-part2
        # /dev/disk/by-id/nvme-nvme.144d-20202020202053314a304e594147423031323134-44656c6c204578707265737320466c617368204e564d65203430304742-00000001
        # /dev/disk/by-id/nvme-HUSMR7676BHP3Y1_SDM00000EF14
        # /dev/disk/by-id/nvme-eui.0000000000000000000cca0b01416a80
        # /dev/disk/by-id/nvme-RMS-200_0038435
        # /dev/disk/by-id/nvme-PLEXTOR_PX-1TM8PeY_P02633105792
        # /dev/disk/by-id/nvme-PLEXTOR_PX-1TM8PeY_P02633105792-part1
        # /dev/disk/by-id/nvme-SAMSUNG_MZ1LW960HMJP-000MV_S3E4NX0J303736
        # /dev/disk/by-id/nvme-SAMSUNG_MZ1LW960HMJP-000MV_S3E4NX0J303736-part1
        # /dev/disk/by-id/nvme-THNSN51T02DU7_NVMe_TOSHIBA_1024GB_________47IS1028TEMT
        # /dev/disk/by-id/nvme-THNSN51T02DU7_NVMe_TOSHIBA_1024GB_________47IS1028TEMT-part1
        # /dev/disk/by-id/nvme-LO0800KEFJR_CVMD724100AR800VGN
        # /dev/disk/by-id/nvme-LO0800KEFJR_CVMD724100AR800VGN-part1
        # /dev/disk/by-id/nvme-LT0800KEXVA_CVMD5390007B800BGN-part12
        # /dev/disk/by-id/nvme-LT1600KEXVB_CVMD5443003H1P6DGN-part1
        # /dev/disk/by-id/pcie-shannon-SS14A23K755025
        # /dev/disk/by-ld/cache
        # /dev/disk/by-ld/filer
        # /dev/disk/by-ld/filer-part3
        # /dev/disk/by-partuuid/1b36440f-ea00-4c7d-80cb-96ba7dc75561
        # /dev/disk/by-parttypeuuid/4fbd7e29-9d25-41b8-afd0-062c0ceff05d.cb81da7d-11c5-4999-8b00-39df148a9859
        # /dev/disk/by-path/FIO-1429D009D
        # /dev/disk/by-path/ip-10.26.62.78:3260-iscsi-freenas.rhevm-iot:iotlab-lun-0
        # /dev/disk/by-path/virtio-pci-0000:00:0a.0
        # /dev/disk/by-path/virtio-pci-0000:00:0a.0-part1
        # /dev/disk/by-partlabel/EFI\x20System\x20Partition
        # /dev/disk/by-partlabel/9
        # /dev/disk/by-slot/disk-0
        # /dev/disk/by-slot/disk-5part1
        # /dev/disk/by-slot/ssd-2part7
        # /dev/disk/by-type/HDD-1part1
        # /dev/disk/by-type/OS-1part1
        # /dev/disk/by-type/SSD-2part1
        # /dev/disk/by-vdev/F01
        # /dev/disk/by-vdev/F01-part1
        # /dev/xiv/by-machine/7803200/143/single_path/sdaia
        if dev_path.startswith("/dev/disk/by-dname/sd") or \
           dev_path.startswith("/dev/disk/by-dpid/disk-") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-switch-") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-CRYPT-LUKS") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-CRYPT-PLAIN") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-DMRAID-") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-mpath-") or \
           dev_path.startswith("/dev/disk/by-id/dm-uuid-part") or \
           dev_path.startswith("/dev/disk/by-id/edd-int") or \
           dev_path.startswith("/dev/disk/by-id/emc-vol-") or \
           dev_path.startswith("/dev/disk/by-id/google-") or \
           dev_path.startswith("/dev/disk/by-id/lvm-pv-uuid-") or \
           dev_path.startswith("/dev/disk/by-id/md-name-") or \
           dev_path.startswith("/dev/disk/by-id/nvme-Amazon") or \
           dev_path.startswith("/dev/disk/by-id/nvme-Dell_Express_Flash") or \
           dev_path.startswith("/dev/disk/by-id/nvme-eui.") or \
           dev_path.startswith("/dev/disk/by-id/nvme-HUSMR") or \
           dev_path.startswith("/dev/disk/by-id/nvme-HW") or \
           dev_path.startswith("/dev/disk/by-id/nvme-INTEL_SSD") or \
           dev_path.startswith("/dev/disk/by-id/nvme-LO0800KEFJR") or \
           dev_path.startswith("/dev/disk/by-id/nvme-LT1600KEXVB") or \
           dev_path.startswith("/dev/disk/by-id/nvme-LLT0800KEXVA") or \
           dev_path.startswith("/dev/disk/by-id/nvme-MT") or \
           dev_path.startswith("/dev/disk/by-id/nvme-MO") or \
           dev_path.startswith("/dev/disk/by-id/nvme-MK") or \
           dev_path.startswith("/dev/disk/by-id/nvme-nvme") or \
           dev_path.startswith("/dev/disk/by-id/nvme-PLEXTOR") or \
           dev_path.startswith("/dev/disk/by-id/nvme-RMS-") or \
           dev_path.startswith("/dev/disk/by-id/nvme-SAMSUNG") or \
           dev_path.startswith("/dev/disk/by-id/nvme-Samsung") or \
           dev_path.startswith("/dev/disk/by-id/nvme-SM") or \
           dev_path.startswith("/dev/disk/by-id/nvme-THNSN") or \
           dev_path.startswith("/dev/disk/by-id/nvme-UCSC") or \
           dev_path.startswith("/dev/disk/by-id/pcie-shannon-") or \
           dev_path.startswith("/dev/disk/by-ld/cache") or \
           dev_path.startswith("/dev/disk/by-ld/filer") or \
           dev_path.startswith("/dev/disk/by-partuuid/") or \
           dev_path.startswith("/dev/disk/by-parttypeuuid/") or \
           dev_path.startswith("/dev/disk/by-path/FIO-") or \
           dev_path.startswith("/dev/disk/by-path/ip-") or \
           dev_path.startswith("/dev/disk/by-path/virtio-pci-") or \
           dev_path.startswith("/dev/disk/by-partlabel/EFI") or \
           dev_path.startswith("/dev/disk/by-partlabel/") or \
           dev_path.startswith("/dev/disk/by-slot/disk-") or \
           dev_path.startswith("/dev/disk/by-slot/ssd-") or \
           dev_path.startswith("/dev/disk/by-type/HDD-") or \
           dev_path.startswith("/dev/disk/by-type/OS-") or \
           dev_path.startswith("/dev/disk/by-type/SSD-") or \
           dev_path.startswith("/dev/disk/by-vdev/") or \
           dev_path.startswith("/dev/xiv/by-machine/"):
            continue  # SKIP

        # /dev/san/HANA/EHQ/...
        # /dev/san/HANA/EHX/...
        # /dev/san/HANA/EHD/...
        # /dev/san/HANA/EHPSBY/...
        if re.match("/dev/san/HANA/", dev_path):
            dev_san_hana_count += 1
            continue  # SKIP

        # /dev/disk/by-path/pci-0000:08:00.0-cciss-disk0
        # /dev/disk/by-path/pci-0000:08:00.0-cciss-disk1
        if re.match("/dev/disk/by-path/pci-" + pci_long_re + "-cciss-", dev_path):
            continue  # SKIP

        # /dev/disk/by-path/pci-0000:06:00.0-nvme-1: Aliased to /dev/nvme0n1 in device cache (259:0)
        if re.match("/dev/disk/by-path/pci-" + pci_long_re + "-nvme-", dev_path):
            continue  # SKIP

        # /dev/disk/by-path/pci-disk0-: Aliased to /dev/cciss/c0d0 in device cache # case
        if dev_path.startswith("/dev/disk/by-path/pci-disk"):
            continue  # SKIP

        # /dev/secvm/dev/vx/dsk/perf2ol/data19: Aliased to /dev/mapper/secvm_dev_vx_dsk_perf2ol_data19 in device cache (preferred name) (253:96)
        if dev_path.startswith("/dev/secvm/dev/vx/dsk/"):
            continue  # SKIP

        # MISC.:
        # /dev/asmdisk/asmdisk5
        # -
        # /dev/oracleasm/disks/OLOG1
        # /dev/oracleasm/disks/B439_ASMDISK001
        # -
        # /dev/san/lvm/backup1/msxiv07-61062_xmgtb3a_lvm_backup1_006
        if not dev_path.startswith("/dev/disk/by-") and \
           subdir_count > 0 and subdir_count < 4:
            ele_type = "subdir"
            ele_name = subdir + "/" + dev_id
            add_mm_bd(ele_name, mm, source)
            continue

        debug_print(0, "unhandled: [{0}] {1} ({2})".format(dev_path, line, source))

    # end: for i in range(0,1): # so 'continue' will jump to the end...

    # debug_print(z,"{0} '{1}' ({2})".format(dev_path,line,source))
    # at one point it was though that the data in the returned arrays would be used further but that has not been the case so returning here
    return('')

    array = "{0}~{1}~{2}~{3}~{4}~{5}~{6}".format(
        _dir,
        subdir,
        subdir_count,
        ele_type,
        ele_name,
        id_type,
        id_name)
    return(array)

# ---------------------------------------------#
# function: is_virtio_id()
# ---------------------------------------------#


def is_virtio_id(virtio_id):
    if virtio_id == '':
        return(False)
    return(True)  # TODO: check for what constitutes a valid virtio

# ---------------------------------------------#
# function: is_usb_id()
# ---------------------------------------------#


def is_usb_id(usb_id):
    if usb_id == '':
        return(False)
    return(True)  # TODO: check for what constitutes a usb virtio

# ---------------------------------------------#
# function: is_sas_id()
# ---------------------------------------------#


def is_sas_id(sas_id):
    if sas_id == '':
        return(False)
    return(True)  # TODO: check for what constitutes a usb virtio


# ---------------------------------------------#
# function: track_alua_states()
# ---------------------------------------------#
def track_alua_states(line, source):
    return


# ---------------------------------------------#
# function: check_for_partitioned_dev()
# process partition data from "/dev/sda1: size is ..." type statements in vgscan/vgdisplay files
# ---------------------------------------------#
def check_for_partitioned_dev(line, word1, source):

    if not line.startswith('/dev/sd'):
        return

    tmp = word1.split('/')
    dev_id = tmp[2].rstrip(':')
    check_dev_partition(dev_id, source)
    return

# ---------------------------------------------#
# function: check_dev_partition()
# if dev_id is a partition id then track it
# ---------------------------------------------#


def check_dev_partition(dev_id, source):

    part_id = dev_id

    if not is_partition_id(part_id, source):
        return False

    _dev_id = get_dev_from_part_id(part_id, source)

    debug_print(3, "add_partition_2_dev({0},{1}) ({2})".format(_dev_id, part_id, source))
    add_partition_2_dev(_dev_id, part_id, source)
    return True


# ---------------------------------------------#
# function: get_len_partition_suffix()
# determine if id ends with a known style of partition suffix.
# if it does, return its length, else return 0
# ---------------------------------------------#
def get_len_partition_suffix(id):
    global sd_re
    global sd_re_p
    global len_std_scsi_id  # 33

    re_sdpn = sd_re_p + "$"
    re_part_n = ".*-part[0-9]{1,3}$"
    re_pn = ".*p[0-9]{1,2}$"
    re_vx_1_sn = "disk_.*s[0-9]{1,3}$"
    re_vx_2_sn = "emc_clariion.*s[0-9]{1,3}$"

    extra_one = 0
    last_2 = id[len(id) - 2:]
    if last_2.isdigit():
        extra_one = 1

    # check the re_sdpn mask first as we don't want sdap1 to match the re_pn mask below
    # (in this example, sdap is the device id for sdap1, not sda; see case )
    if re.match(re_sdpn, id):
        return(len("1") + extra_one)

    if re.match(re_part_n, id):
        return(len("-part1") + extra_one)

    if re.match(re_pn, id):
        return(len("p1") + extra_one)

    if re.match(re_vx_1_sn, id):
        return(len("s1") + extra_one)

    if re.match(re_vx_2_sn, id):
        return(len("s1") + extra_one)

    if len(id) == len_std_scsi_id + 1:
        test_scsi_id = id[0:len_std_scsi_id]
        if is_scsi_id(test_scsi_id):
            part_id = id[len_std_scsi_id:]
            # debug_print(z,'{0} {1}'.format(test_scsi_id,part_id))
            return(len(part_id))

    return(0)  # no partition id found

# ---------------------------------------------#
# function: get_dev_from_part_id()
# return the device portion of a partition id
# (partition id should have been previously validated with is_partition_id())
# ---------------------------------------------#


def get_dev_from_part_id(part_id, source):
    lps = get_len_partition_suffix(part_id)
    if lps == 0:
        return('')

    dev_id = part_id[0:len(part_id) - lps]
    if dev_id.endswith("-"):
        dev_id = dev_id[0:len(dev_id) - 1]
    return(dev_id)

# ---------------------------------------------#
# function: is_partition_id()
# test if part_id is a partition id, return True/False
# ---------------------------------------------#


def is_partition_id(part_id, source):

    if get_len_partition_suffix(part_id) > 0:
        return(True)
    else:
        return(False)


# ---------------------------------------------#
# function: do_corosync_not_scheduled()
# corosync[4319]: [MAIN  ] Corosync main process was not scheduled for 1757.6204 ms (threshold is 800.0000 ms). Consider token timeout increase.
# ---------------------------------------------#
def do_corosync_not_scheduled(line, words, source):
    global corosync_ms_not_sched_total  # 0.0
    global corosync_ms_threshold_total  # 0.0
    global corosync_ms_msg_count  # 0

    not_sched_time = words[10]
    if not is_float(not_sched_time):
        return

    threshold_time = words[14]
    if not is_float(threshold_time):
        return

    corosync_ms_msg_count += 1
    corosync_ms_not_sched_total += float(not_sched_time)
    corosync_ms_threshold_total += float(threshold_time)


def summ_corosync_ms_values():
    global corosync_ms_not_sched_total  # 0.0
    global corosync_ms_threshold_total  # 0.0
    global corosync_ms_msg_count  # 0

    return("[avg: {0} (threshold {1} ms)]".format(corosync_ms_not_sched_total / corosync_ms_msg_count,
                                                  corosync_ms_threshold_total / corosync_ms_msg_count))

# ---------------------------------------------#
# function: crunch_cluster_data()
# crunch data in cluster status file
# ---------------------------------------------#


def crunch_cluster_data():
    global cluster_status  # False
    global cluster_status_line  # ''
    global syslog_nodenames_match_words  # '' # set to syslog_nodenames_match.split()

    cs_file = "sos_commands/cluster/clustat"
    fh = openfile(cs_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == '':
            continue

        if line.startswith("Could not connectto CMAN:"):
            continue

        words = line.split()
        wc = len(words)
        if " Online, " in line:
            for nn in syslog_nodenames_match_words:
                if nn in words[0]:
                    cluster_status = True
                    cluster_status_line = line

    # end: for line in cs_lines:
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, cs_file))
    return

# ---------------------------------------------#
# function: crunch_ls_sys_block()
# crunch data in ls_-laR_.sys.block
# ---------------------------------------------#


def crunch_ls_sys_block():
    global rh_major
    global rh_minor
    global kenrelStr  # Key_data()

    tmp_kern_level = "{0}.{1}.{2}".format(kernelNum['major'], kernelNum['minor'], kernelNum['rel1'])

    # TODO rh 4?, rh unknown??
    if rh_major == 0 and tmp_kern_level == "0.0.0":
        return  # probably just have var/log/messages
    elif rh_major == 4 or tmp_kern_level == "2.6.9":
        crunch_ls_sys_block_rhel5()  # use RHEL5 for RHEL4
    elif rh_major == 5 or tmp_kern_level == "2.6.18":
        crunch_ls_sys_block_rhel5()
    elif rh_major == 6 or tmp_kern_level == "2.6.32":
        crunch_ls_sys_block_rhel6()
    elif tmp_kern_level == "2.6.39":
        crunch_ls_sys_block_rhel6()  # uek
    elif rh_major == 7 or kernelNum['major'] >= 3:
        crunch_ls_sys_block_rhel6()
    else:
        error_print("l", "rh_major={0} kern_level={1}".format(rh_major, tmp_kern_level))

    global scsi_host
    global scsi_host_2_pci
    global max_host
    global pci_address

    for int_host in range(0, max_host + 1):
        host = "{0}".format(int_host)
        if scsi_host[host] != '':
            pci_adr = scsi_host_2_pci[host]
            debug_print(4, "host{0}: pci_id:{1} pci_line:'{2}'".format(host, pci_adr, pci_address[pci_adr]))

    return

# ---------------------------------------------#
# function: crunch_ls_sys_block_rhel5()
# crunch data in ls_-laR_.sys.block
# ---------------------------------------------#


def crunch_ls_sys_block_rhel5():

    ls_files = "sos_commands/devicemapper/ls_-laR_.sys.block "\
               "sos_commands/block/ls_-lanR_.sys.block"
    tmp = ls_files.split()

    for ls_file in tmp:
        if file_exists_with_data(ls_file):
            crunch_ls_sys_block_file_rhel5(ls_file)
    # end: for ls_file in tmp:
    return

# ---------------------------------------------#
# function: crunch_ls_sys_block_rhel5()
# crunch data in ls_-laR_.sys.block
# ---------------------------------------------#


def crunch_ls_sys_block_file_rhel5(ls_file):
    global yyyy_mm_dd_re, hhmm_re

    fh = openfile(ls_file)
    if fh is None:
        return

    # REVISIT -- missing anything? case
    # fns_to_ignore="loop ram dm- hd fd cciss vd rssda xvd"
    # fns_to_ignore="loop ram dm- hd fd cciss vd rssda"
    # fns_to_ignore="loop ram dm- hd fd vd rssda"
    fns_to_ignore = ""
    ifns = fns_to_ignore.split()
    curr_dev_id = ""
    subdir = ""
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        if line == "":
            continue

        words = line.split()
        word1 = words[0]
        wc = len(words)

        if wc == 1 and word1.startswith("/sys/block/"):
            tmp = word1.split("/")  # NB - leading slash causes tmp[0] to be null and tmp[1] is 'sys'
            curr_dev_id = tmp[3].rstrip(":")
            subdir = ""
            if len(tmp) > 4:
                subdir = tmp[4].rstrip(":")
            debug_print(4, "({0} {1}) dir line: {2} {3}".format(i, ls_file, curr_dev_id, subdir))
            continue

        word_adj = 0
        if wc > 6:
            if re.match(yyyy_mm_dd_re, words[5]) and re.match(hhmm_re, words[6]):
                word_adj = -1
            # this means that the date format is 'yyyy-mm-dd hh:mm' (2 tokens) rather than 'Mon dd hh:mm' (3 tokens)

        if wc < (11 + word_adj):
            continue

        perm = words[0]
        fn = words[8 + word_adj]
        lit_arrow = words[9 + word_adj]
        path = words[10 + word_adj]
        if perm[0:1] == "l":
            if lit_arrow != "->":
                debug_print(2, "({0} {1}) lit_arrow?: {2}".format(i, ls_file, lit_arrow))
        else:
            debug_print(3, "({0} {1}) perms?: {2}".format(i, ls_file, perm))
            continue
        debug_print(4, "({0} {1}) lrw line: {2} {3} {4}".format(i, ls_file, subdir, fn, line))

        if subdir == "" and fn == "device":
            skip_sw = False
            for ifn in ifns:
                if curr_dev_id.startswith(ifn):
                    skip_sw = True
                    break
            if skip_sw is False:
                crunch_ls_host_line_rhel5(i, curr_dev_id, subdir, fn, path, line, ls_file)
            continue
        if (subdir == "holders" or subdir == "slaves") and fn.startswith("dm-"):
            debug_print(4, "({0} {1}) dm- line: {2} {3} {4}".format(i, ls_file, curr_dev_id, fn, line))
            if curr_dev_id[0:3] != "dm-":
                add_normalized_mm_data("", curr_dev_id, fn, "", "", "", ls_file)
            continue

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ls_file))
    return


# ---------------------------------------------#
# function: crunch_ls_host_line_rhel5()
# ---------------------------------------------#
def crunch_ls_host_line_rhel5(i, curr_dev_id, subdir, fn, path, line, source):
    p_words = path.split("/")
    pwc = len(p_words)
    p_scsi_adr = p_words[pwc - 1]
    p_scsi_adr = normalize_scsi_adr(p_scsi_adr)  # will return '' if not a valid h:b:t:l

    curr_dev_type = curr_dev_id[0:2]
    if curr_dev_type != "sd" and curr_dev_type != "st" and curr_dev_type != "sr":
        debug_print(2, "({0} {1}) curr_dev_type/id?: {2}/{3} ".format(i, source, curr_dev_type, curr_dev_id))
        curr_dev_type = ""
    debug_print(4, "[{0},{1},{2},{3}] {4} ({5})".format(p_scsi_adr, curr_dev_type, curr_dev_id, line, i, source))

    if p_scsi_adr == '':
        return False
    if '/pci' in path:
        crunch_pci_and_host(i, line, '', path, p_words, source)
    add_normalized_scsi_data(p_scsi_adr, curr_dev_type, curr_dev_id, "", line, source)
    return True


# ---------------------------------------------#
# function: crunch_ls_sys_block_rhel6()
# crunch data in ls_-laR_.sys.block
# ---------------------------------------------#
def crunch_ls_sys_block_rhel6():
    ls_files = "sos_commands/devicemapper/ls_-laR_.sys.block "\
               "sos_commands/block/ls_-lanR_.sys.block"
    tmp = ls_files.split()

    for ls_file in tmp:
        if file_exists_with_data(ls_file):
            crunch_ls_sys_block_file_rhel6(ls_file)
    # end: for ls_file in tmp:
    return

# ---------------------------------------------#
# function: crunch_ls_sys_block_rhel6()
# crunch data in ls_-laR_.sys.block
# ---------------------------------------------#


def crunch_ls_sys_block_file_rhel6(ls_file):
    global s390
    global yyyy_mm_dd_re, hhmm_re

    fh = openfile(ls_file)
    if fh is None:
        return

    # TODO: do we need to track & classify these file name prefixes?? (esp VxDMP/VxVM)
    # cases TODO 01383877 01440696 01445426 01447850 01454862 01463349 01466223 01469884 01470053 01473588 01477905
    #
    # lrwxrwxrwx  1 0 0 0 Dec 10 14:18 rssda -> ../devices/pci0000:40/0000:40:02.0/0000:42:00.0/0000:43:06.0/0000:46:00.0/block/rssda
    #
    # fns_to_ignore="loop VxDMP VxVM dmpconfig ram hd md fd ofsctl dasd vd drdb drbd"
    fns_to_ignore = "loop VxDMP VxVM dmpconfig ram hd md fd ofsctl      vd drdb drbd rss nvme "
    fns_to_ignore = fns_to_ignore + " dm- emcpower asm!"  # TODO -- do further investigate on whether to do more w/these
    ifns = fns_to_ignore.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        words = line.split()
        wc = len(words)

        word_adj = 0
        if wc > 6:
            if re.match(yyyy_mm_dd_re, words[5]) and re.match(hhmm_re, words[6]):
                word_adj = -1
            # this means that the date format is 'yyyy-mm-dd hh:mm' (2 tokens) rather than 'Mon dd hh:mm' (3 tokens)

        if wc < (11 + word_adj):
            continue

        # 0            1 2    3      4  5    6 7     8       9  10
        # lrwxrwxrwx   1 root root   95 Jun  2 13:37 b68:240 -> /devices/pci0000:00/0000:00:15.0/0000:07:00.1/host5/rport-5:0-2/target5:0:0/5:0:0:14/block/sdcb
        #
        # 0           1 2    3    4 5    6 7     8   9  10
        # lrwxrwxrwx  1 root root 0 Apr  7 13:30 sdz -> ../devices/pci0000:00/0000:00:16.0/0000:0a:00.1/host7/rport-7:0-4/target7:0:1/7:0:1:21/block/sdz
        #
        # 0           1 2    3    4  5    6 7     8    9    10 11
        # lrwxrwxrwx  1 root root 0  7月 26 15:46 2017 dm-0 -> ../devices/virtual/block/dm-0
        #
        perm = words[0]
        if wc >= 12:
            path = words[wc - 1]  # last word
            lit_arrow = words[wc - 2]  # 2nd to last word
            fn = words[wc - 3]  # 3rd to last word
        else:
            fn = words[8 + word_adj]
            lit_arrow = words[9 + word_adj]
            path = words[10 + word_adj]
        if perm[0:1] != "l":
            error_print('d', "({0} {1}) perms?: {2}".format(i, ls_file, perm))
            continue

        if lit_arrow != "->":
            error_print('d', "({0} {1}) lit_arrow?: {2}".format(i, ls_file, lit_arrow))
            continue

        # 0 1       2          3            4            5      6          7           8        9     10
        # ->   /devices/pci0000:00/0000:00:15.0/0000:07:00.1/host5/rport-5:0-2/target5:0:0/5:0:0:14/block/sdcb
        #
        # 0  1       2          3            4            5      6          7           8        9     10
        # -> ../devices/pci0000:00/0000:00:16.0/0000:0a:00.1/host7/rport-7:0-4/target7:0:1/7:0:1:21/block/sdz
        #
        # 0  1       2          3            4            5      6          7           8        9     10
        # -> ../devices/pci0000:80/0000:80:03.0/0000:87:00.0/block/ocznvme0n1

        p_words = path.split("/")
        pwc = len(p_words)
        p_fn = p_words[pwc - 1]
        p_lit_block = p_words[pwc - 2]
        p_scsi_adr = p_words[pwc - 3]

        if "/devices/pci" in line:
            if "/host" in line:
                crunch_pci_and_host(i, line, words, path, p_words, ls_file)
            else:
                continue

        if fn != p_fn:
            error_print('d', "({0} {1}) fn/p_fn?: {2}/{3}".format(i, ls_file, fn, p_fn))
            continue

        if p_scsi_adr == "nvme":
            continue

        if p_lit_block != "block":
            error_print('d', "({0} {1}) p_lit_block?: {2}".format(i, ls_file, p_lit_block))
            continue

        cont_sw = False
        for ifn in ifns:
            if p_fn.startswith(ifn):
                cont_sw = True
                break
        if cont_sw is True:
            continue

        if s390 and fn.startswith("dasd"):
            cuuu = p_scsi_adr
            track_s390_dasd(cuuu, fn, '', '', '', '', '', ls_file)
            continue

        if ":" not in p_scsi_adr:
            continue

        if p_scsi_adr == "virtual":
            debug_print(2, "({0} {1}) fn/scsi_adr?: {2}/{3}".format(i, ls_file, fn, p_fn))
            continue

        p_dev_type = p_fn[0:2]
        if p_dev_type != "sd" and p_dev_type != "st" and p_dev_type != "sr":
            debug_print(2, "({0} {1}) p_fn {2} p_dev_type?: {3}".format(i, ls_file, p_dev_type, p_fn))
            p_dev_type = ""
        # print("({0} {1}) {2} {3} {4} {5}".format(i,ls_file,p_scsi_adr,p_dev_type,p_fn,line))
        add_normalized_scsi_data(p_scsi_adr, p_dev_type, p_fn, "", line, ls_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ls_file))
    return


# ---------------------------------------------#
# function: crunch_pci_and_host():
# ensure this line contains information needed to call track_pci_address_and_host()
# ---------------------------------------------#
def crunch_pci_and_host(i, line, words, path, p_words, source):
    global sd_re, sd_re_p
    global pci_short_re, pci_long_re

    # From sos_commands/devicemapper/ls_-laR_.dev and
    # sos_commands/devicemapper/ls_-laR_.sys.block
    # 0            1 2    3      4  5    6 7     8       9  10
    # lrwxrwxrwx   1 root root   95 Jun  2 13:37 b68:240 -> /devices/pci0000:00/0000:00:15.0/0000:07:00.1/host5/rport-5:0-2/target5:0:0/5:0:0:14/block/sdcb
    #
    # 0           1 2    3    4 5    6 7     8   9  10
    # lrwxrwxrwx  1 root root 0 Apr  7 13:30 sdz -> ../devices/pci0000:00/0000:00:16.0/0000:0a:00.1/host7/rport-7:0-4/target7:0:1/7:0:1:21/block/sdz
    #
    # 0 1       2          3            4            5      6          7           8        9     10
    # ->   /devices/pci0000:00/0000:00:15.0/0000:07:00.1/host5/rport-5:0-2/target5:0:0/5:0:0:14/block/sdcb
    #
    # 0  1       2          3            4            5      6          7           8        9     10
    # -> ../devices/pci0000:00/0000:00:16.0/0000:0a:00.1/host7/rport-7:0-4/target7:0:1/7:0:1:21/block/sdz
    #
    #
    # path words (p_words) can contain multiple pci addresses:
    #
    # 0 1       2          3            4            5            6            7            8            9     10          11           12      13    14
    # /devices/pci0000:00/0000:00:07.0/0000:04:00.0/0000:05:00.0/0000:06:00.0/0000:07:06.0/0000:0e:00.0/host2/rport-2:0-2/target2:0:0/2:0:0:16/block/sde
    #
    #
    # From sos_commands/devices/udevadm_info_--export-db
    #
    # P: /devices/pci0000:00/0000:00:02.0/0000:0a:00.0/host8/rport-8:0-5/target8:0:3/8:0:3:9/block/sdbr
    # P: /devices/pci0000:00/0000:00:02.2/0000:0c:00.0/host0/target0:2:0/0:2:0:0/block/sda
    # P: /devices/pci0000:00/0000:00:02.2/0000:0c:00.0/host0/target0:2:0/0:2:0:0/block/sda/sda1
    # P: /devices/pci0000:00/0000:00:02.2/0000:0c:00.0/host0/target0:2:0/0:2:0:0/block/sda/sda2
    # P: /devices/pci0000:00/0000:00:03.2/0000:0e:00.0/host11/rport-11:0-2/target11:0:0/11:0:0:0/block/sdf
    #
    # From sos_commands/devicemapper/systool_-v_-c_scsi_generic
    #
    # Class Device path = "/sys/devices/pci0000:00/0000:00:02.0/0000:02:00.0/0000:03:00.0/0000:04:00.0/0000:05:06.0/0000:0c:00.0/host1/rport-1:0-1/target1:0:0/1:0:0:0/scsi_generic/sg0"
    # Class Device path = "/sys/devices/pci0000:00/0000:00:02.0/0000:02:00.0/0000:03:00.0/0000:04:00.0/0000:05:06.0/0000:0c:00.0/host1/rport-1:0-1/target1:0:0/1:0:0:1/scsi_generic/sg1"
    # Class Device path = "/sys/devices/pci0000:00/0000:00:02.0/0000:02:00.0/0000:03:00.0/0000:04:00.0/0000:05:06.0/0000:0c:00.0/host1/rport-1:0-2/target1:0:1/1:0:1:3/scsi_generic/sg10"
    #
    # From sos_commands/devicemapper/ls_-laR_.sys.block (rhel 5):
    # /sys/block/sdaj:
    # total 0
    # drwxr-xr-x   5 root root    0 May 10 16:12 .
    # drwxr-xr-x 208 root root    0 May 10 17:44 ..
    # -r--r--r--   1 root root 4096 May 10 16:12 dev
    # lrwxrwxrwx   1 root root    0 May 10 16:12 device -> ../../devices/pci0000:00/0000:00:03.0/0000:04:00.0/host5/rport-5:0-2/target5:0:0/5:0:0:0  <<<-- this line passed
    #
    #

    path_prefix_list = ""\
        "/devices/pci "\
        "../devices/pci "\
        "../../devices/pci "\
        "/sys/devices/ "\
        ""
    # "/sys/devices/pci "  # allow scsi generic on vmbus
    path_prefixes = path_prefix_list.split()
    valid_prefix = False
    for path_prefix in path_prefixes:

        if path.startswith(path_prefix):
            valid_prefix = True
            break

    if not valid_prefix:
        error_print('d', "{0} '{1}' ({2})".format(i, line, source))
        return(False)

    pwc = len(p_words)
    debug_print(4, "{0} '{1}'".format(pwc, p_words))
    pci_adr_cnt = 0
    pci_adr = ''
    host = ''
    scsi_adr = ''
    sd_partition = ''
    sd_devid = ''
    dev_sgn = ''

    for w in range(3, pwc):
        # debug_print(z,"{0} of {1} '{2}'".format(w,pwc,p_words[w]))
        # pci_adr will be the last token that is a valid pci address
        # use long pci address now:
        if re.match(pci_long_re, p_words[w]):
            pci_adr = p_words[w]
            pci_adr_cnt += 1
            continue  # next path word
        # (old way using short pci addresses)
        # if p_words[w].startswith("0000:"):
            # pci_adr = p_words[w][len("0000:"):]
            # if re.match(pci_short_re,pci_adr):
            # pci_adr_cnt+=1
            # continue # next path word
            # error_print('d',"[pci] {0} '{1}' ({2})".format(i,line,source))
            # continue

        if p_words[w].startswith("host"):
            host = p_words[w]
            host = host[len("host"):]
            if host.isdigit():
                continue  # next path token
            error_print('d', "[host] {0} '{1}' ({2})".format(i, line, source))
            continue

        if p_words[w].startswith("rport-"):
            continue  # TODO # track port numbers?

        if p_words[w] == "block" or p_words[w] == "scsi_generic" or p_words[w] == "scsi_disk" or p_words[w] == "scsi_tape":
            scsi_adr = p_words[w - 1]  # scsi address is previous word
            # for "scsi_disk" also then next word
            if p_words[w] == "scsi_disk":
                dev_type = "sd"
            if p_words[w] == "scsi_tape":
                dev_type = "st"
            continue

        if re.match(sd_re_p, p_words[w]):
            sd_partition = p_words[w]
        elif re.match(sd_re, p_words[w]):
            sd_devid = p_words[w]
        elif re.match(sg_re, p_words[w]):
            dev_sgn = p_words[w]

    # end: for w in (3,pwc+1):

    if pci_adr != '':
        debug_print(3, "{0} {1} ({2})".format(pci_adr, host, source))
        pci_desc = ''
        track_pci_address_and_host(pci_adr, pci_desc, host, source)

    if scsi_adr != '' and sd_devid != '':
        dev_type = sd_devid[0:2]
        dev_sgn = ''
        detail_line = ''
        add_normalized_scsi_data(scsi_adr, dev_type, sd_devid, dev_sgn, detail_line, source)

    if sd_devid != '' and sd_partition != '':
        add_partition_2_dev(sd_devid, sd_partition, source)

    return


# ---------------------------------------------#
# function: track_pci_address_and_host():
# manage correlations between pci_addresses and host numbers
# ---------------------------------------------#
def track_pci_address_and_host(pci_adr, pci_desc, host, source):
    global all_pci_addresses  # ""
    global pci_address  # Key_data()             # key: pci address         data: pci line
    global pci_address_2_hosts  # Key_data()     # key: pci address         data: scsi host number(s)
    # global pci_address_2_host_origin # Key_data() # key: pci address       data: file origin
    global scsi_host_2_pci  # Key_data()         # key: host,               data: pci address;      e.g. 0,       xx:xx.x
    global scsi_host_2_pci_origin  # Key_data()  # key: host,               data: file origin

    debug_print(3, "pci address:{0} desc:'{1}' host:{2} ({3})".format(pci_adr, pci_desc, host, source))

    if len(pci_adr) == len("xx:xx.x"):
        errorprint(8 / 0)
    all_pci_addresses = unique_list(all_pci_addresses, pci_adr)

    if pci_address[pci_adr] == '' and pci_desc != '':
        pci_address[pci_adr] = pci_desc
    elif pci_address[pci_adr] != '' and pci_address[pci_adr] != pci_desc and pci_desc != '':
        error_print("d", "pci_address[{0}] already set to '{1}' while attempting to set it to '{2}' ({3})".
                    format(pci_adr, pci_address[pci_adr], pci_desc, source))

    if host == '':
        return

    #
    # A given pci address may support one or more hosts (hbas).
    # The original code assumeed a 1-1 relationship but this proved incorrect as it is potentially 1-many.
    #
    # if pci_address_2_host[pci_adr] == '':
        # pci_address_2_host[pci_adr] = host
        # pci_address_2_host_origin[pci_adr] = source
    # else:
        # if pci_address_2_host[pci_adr] != host:
        #    anomaly_line = "pci address {0} already has host number set to {1} ({2}), attempting to set to {3} ({4})".\
        #    format(pci_adr,pci_address_2_host[pci_adr],pci_address_2_host_origin[pci_adr],host,source)
        #    handle_anomaly("DUP-1",anomaly_line)
    h = int(host)
    tmp_pci_a = host_2_pci_address(h)
    if tmp_pci_a == '':
        pci_address_2_hosts[pci_adr] = unique_list(pci_address_2_hosts[pci_adr], host)
        # pci_address_2_host_origin[pci_adr] = source # more work than it's woth to try and map/coordinate multiple hosts & sources
        debug_print(2, "mapping host {0} to pci address {1}, all:[{2}] ({3})".format(host, pci_adr, pci_address_2_hosts[pci_adr], source))
    else:
        if tmp_pci_a == pci_adr:
            pass
        # else: # no need for DUP-1 anom as it is giving the same info as DUP-2
        #     anomaly_line = "pci address {0} already maps host number {1}, attempting to map to {2} ({3})".\
        #     format(tmp_pci_a,host,pci_adr,source)
        #     handle_anomaly("DUP-1",anomaly_line)

    if scsi_host_2_pci[host] == '':
        scsi_host_2_pci[host] = pci_adr
        scsi_host_2_pci_origin[host] = source
        debug_print(4, "scsi_host_2_pci[{0}] now = {1}".format(host, scsi_host_2_pci[host]))
    else:
        if scsi_host_2_pci[host] != pci_adr:
            action = file_check(scsi_host_2_pci_origin[host], source)
            if do_anomaly(action):
                anomaly_line = "host address {0} already has pci address set to {1} ({2}), attempting to set to {3} ({4})".\
                    format(host, scsi_host_2_pci[host], scsi_host_2_pci_origin[host], pci_adr, source)
                handle_anomaly("DUP-2", anomaly_line)
            if action == "overridden":
                scsi_host_2_pci[host] = pci_adr
                scsi_host_2_pci_origin[host] = source
                debug_print(4, "scsi_host_2_pci[{0}] now = {1}".format(host, scsi_host_2_pci[host]))

    # call after setting pci_address_2_host and scsi_host_2_pci so get_host_desc() returns updated data
    track_hba(host, '', source)

    return

# ---------------------------------------------#
# function: track_pci_errors()
# adjust a pci address's error count up or down
# ---------------------------------------------#


def track_pci_errors(line, plus_minus, source):
    global pci_errors  # Counter()               # key: pci address         data: number of errors assoc w/this pci address
    global all_pci_addresses

    words = line.split()

    pci_adr = words[2].lstrip("[")

    # rb = pci_adr.find("]")
    # if rb != -1:
    # pci_adr = pci_adr[0:rb]

    ml = len("xxxx:xx:xx.x")
    lp = len(pci_adr)

    if lp == ml:
        pass
    elif lp > ml:
        pci_adr = pci_adr[0:ml]
    elif lp < ml:
        error_print('l', "'{0}' '{1}'".format(line, plus_minus))

    # debug_print(z,"'{0}' '{1}'".format(line,plus_minus))

    if not word_in_list(pci_adr, all_pci_addresses):
        track_pci_address_and_host(pci_adr, '', '', source)

    if plus_minus == "++":
        pci_errors[pci_adr] += 1
    elif plus_minus == "--":
        pci_errors[pci_adr] -= 1
    else:
        error_print('l', "'{0}' '{1}'".format(line, plus_minus))

    # debug_print(z,"{0} {1} {2}".format(pci_adr,pci_errors[pci_adr],plus_minus))

    return

# ---------------------------------------------#
# function: host_2_pci_address(host):
# return pci address assocaiated with a host number
# ---------------------------------------------#


def host_2_pci_address(host):
    global all_pci_addresses  # ""
    global pci_address_2_hosts  # Key_data()     # key: pci address         data: scsi host number(s)

    h = "{0}".format(host)
    tmp = all_pci_addresses.split()
    for pci_a in tmp:
        if word_in_list(h, pci_address_2_hosts[pci_a]):
            return(pci_a)
    # end: for pci_a in tmp:

    return('')

# ---------------------------------------------#
# function: pci_address_2_host(pci_address):
# return host number associated with a host number
# ---------------------------------------------#


def pci_address_2_host(pci_a):
    global all_pci_addresses  # ""
    global pci_address_2_hosts  # Key_data()     # key: pci address         data: scsi host number(s)

    if not word_in_list(pci_a, all_pci_addresses):
        return ''

    hosts = pci_address_2_hosts[pci_a]
    if hosts == '':
        return ''

    if word_count(hosts) == 1:
        return(hosts)  # simple one to one relationship

    tmp = hosts.split()
    return(tmp[0])  # return 1st host if more than one -- could be an issue

    return('')


# ---------------------------------------------#
# function: crunch_proc_partitions():
# get device & partition maj/min & size
# ---------------------------------------------#
#
# Example file:
#
# major minor  # blocks  name
#
# 252        0    8388608 vda
# 252        1     512000 vda1
# 252        2    7875584 vda2
# 253        0     839680 dm-0
# 253        1    6991872 dm-1
# 7        0   21600256 loop0
# 253        2    1048576 dm-2
# 8        0    1048576 sda
#
# 134      496   31457280 sdsb
# 135      272   31457280 sdsd
# 135      304   31457280 sdsf
# 252    33281    2097152 asm/acfs_rman-65
# 252    33282  398458880 asm/lotmprd_ggs-65
# 135      320   31457280 sdsg
# 135      336   31457280 sdsh
# 135      352   31457280 sdsi
#
# 104     0  292964110 cciss/c0d0
# 104     1     110144 cciss/c0d0p1
# 104     2   33553920 cciss/c0d0p2
# 104     3  259296240 cciss/c0d0p3
#
# ---------------------------------------------#
def crunch_proc_partitions():
    global sd_re, dm_re
    global dev_2_parts  # Key_data()            # key: device id,           data: partion id(s)     e.g. sda,     sda1, sda2, ...

    pp_file = "proc/partitions"
    fh = openfile(pp_file)
    if fh is None:
        return

    found_header = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == '':
            continue

        _dir = ''
        words = line.split()
        wc = len(words)
        if wc != 4:
            continue

        if words[0] == "major" and words[1] == "minor":
            found_header = True
            continue  # skip heading line

        if not found_header:
            continue

        partition = False
        dev_part = ''
        maj = words[0]
        min = words[1]
        mm = maj + ":" + min
        if words[2] == "XXX.XXX.XXX.XXX":
            size = 0  # case
        else:
            size = int(words[2]) * 1024  # conv to bytes
        dev = words[3]

        if dev.startswith("cciss/"):
            dev = dev[len("cciss/"):]
            _dir = "cciss"
            # track_cciss_devs(dev,'',pp_file)

        if dev.startswith("asm/"):
            dev = dev[len("asm/"):]
            _dir = "asm"

        tmp_dev = get_dev_from_part_id(dev, pp_file)
        if tmp_dev != '':
            dev_part = dev
            dev = tmp_dev
            partition = True

        if partition:
            set_device_size(dev_part, size, pp_file)
            add_partition_2_dev(dev, dev_part, pp_file)
            add_mm_bd(dev_part, mm, pp_file)
        else:
            set_device_size(dev, size, pp_file)
            add_mm_bd_w_dir(dev, mm, _dir, pp_file)
    # end: for line in pp_lines:
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, pp_file))
    return

# ---------------------------------------------#
# function: set_device_size():
# size is in Kbytes
# ---------------------------------------------#


def set_device_size(dev, size, source):
    global dev_2_size  # Counter()              # key: device or partition id     data: size        e.g. sda,     size(KB)
    global dev_2_size_origin  # Key_data()      # key: device or partition id     data: file origin

    new_size = int(size)
    current_size = dev_2_size[dev]
    # if dev == "sdb":
    # debug_print(z,"{0} {1} ({2}):: {3} ({4})".format(dev,size,source,current_size,dev_2_size_origin[dev]))

    if current_size == 0:
        dev_2_size[dev] = new_size
        dev_2_size_origin[dev] = source
        return

    origin = dev_2_size_origin[dev]

    if current_size == size:
        # debug_print(z,"{0} {1} ({2}) == {3} ({4})".format(dev,size,source,current_size,origin))
        return

    # current_size != size:
    debug_print(2, "{0} {1} ({2}) != {3} ({4})".format(dev, size, source, current_size, origin))

    # verb = file_check(origin,source)
    # if verb == "overridden":
    # dev_2_size[dev] = new_size
    # dev_2_size_origin[dev] = source

    # take the larger size, most likely the raw dev size as opposed to calculated size
    # such as size = cylinder_count * blocks_cyclinder * block_size
    if new_size > current_size:
        old_size = current_size
        old_origin = dev_2_size_origin[dev]
        dev_2_size[dev] = new_size
        dev_2_size_origin[dev] = source

    # if dev == "sdb":
    # if True:
        # debug_print(z,"{0} {1} ({2}):was: {3} ({4})".\
        # format(dev,new_size,source,old_size,old_origin))

    return

# ---------------------------------------------#
# function: crunch_s390_dasd_data()
# read the dasdview_-x*.dev.dasd* files and get relavent info
# (class, type, etc.)
# ---------------------------------------------#


def crunch_s390_dasd_data():
    global s390
    if not s390:
        return

    crunch_s390_dasd_directory("./sos_commands/s390/")
    crunch_ls_dasd()
    crunch_ls_tape()
    crunch_ls_css()

    return

# ---------------------------------------------#
# function: crunch_s390_dasd_directory()
# ---------------------------------------------#


def crunch_s390_dasd_directory(path):

    if stat_dir(path, '', 0) is None:
        return

    fn_prefix_list_1 = "dasdview_-x "\
                       ""
    fn_prefixes_1 = fn_prefix_list_1.split()

    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:

        for fn_prefix in fn_prefixes_1:  # parted or fdisk output files
            if fn.startswith(fn_prefix) and re.match(".*\.dev\.dasd[a-z]{1}", fn):
                crunch_dasd_file(path + fn)

    # done: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_s390_dasd_file()
#
#
# --- general DASD information --------------------------------------------------
# device node: /dev/dasda
# busid: 0.0.0100
# type: ECKD
# device type: hex 3390       dec 13200
#
# --- DASD geometry -------------------------------------------------------------
# number of cylinders: hex 7ff6       dec 32758
# tracks per cylinder: hex f          dec 15
# blocks per track: hex c          dec 12
# blocksize: hex 1000       dec 4096
#
# --- extended DASD information -------------------------------------------------
# real device number: hex 0          dec 0
# subchannel identifier: hex 0          dec 0
# CU type  (SenseID): hex 3990       dec 14736
# CU model (SenseID): hex e9         dec 233
# device type  (SenseID): hex 3390       dec 13200
# device model (SenseID): hex c          dec 12
# open count: hex 2          dec 2
# req_queue_len: hex 0          dec 0
# chanq_len: hex 0          dec 0
# status: hex 5          dec 5
# label_block: hex 2          dec 2
# FBA_layout: hex 0          dec 0
# characteristics_size: hex 40         dec 64
# confdata_size: hex 100        dec 256
# format: hex 2          dec 2           CDL formatted
# features: hex 0          dec 0           default
# .
# .
# .
# ....
#
# --- general DASD information --------------------------------------------------
# device node: /dev/dasde
# busid: 0.0.0101
# type: DIAG           <<<------------ should be fba ??
# device type: hex 9336       dec 37686
#
# --- DASD geometry -------------------------------------------------------------
# number of cylinders: hex 0          dec 0
# tracks per cylinder: hex 10         dec 16
# blocks per track: hex 80         dec 128
# blocksize: hex 200        dec 512
#
# --- extended DASD information -------------------------------------------------
# real device number: hex 0          dec 0
# subchannel identifier: hex 15         dec 21
# CU type  (SenseID): hex 6310       dec 25360
# CU model (SenseID): hex 80         dec 128
# device type  (SenseID): hex 9336       dec 37686
# device model (SenseID): hex 10         dec 16
# open count: hex 2          dec 2
# req_queue_len: hex 0          dec 0
# chanq_len: hex 0          dec 0
# status: hex 5          dec 5
# label_block: hex 1          dec 1
# FBA_layout: hex 1          dec 1
# characteristics_size: hex c          dec 12
# confdata_size: hex 0          dec 0
# format: hex 1          dec 1           LDL formatted
# features: hex 0          dec 0           default
#
# characteristics: 0101000c 0140004b  01401002
#
#
# ---------------------------------------------#


def crunch_dasd_file(fn):

    fh = openfile(fn)
    if fh is None:
        return

    general_section = False
    geometry_section = False
    extended_section = False
    cuuu = ''
    dasd_id = ''
    dasd_dev = ''
    dasd_class = ''
    dasd_type = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        line = line.strip()
        if line == '':
            continue

        if line.startswith("--- general DASD information"):
            general_section = True
            geometry_section = False
            extended_section = False
            continue

        if line.startswith("--- DASD geometry"):
            general_section = False
            geometry_section = True
            extended_section = False
            continue

        if line.startswith("--- extended DASD information"):
            general_section = False
            geometry_section = False
            extended_section = True
            continue

        if not general_section and not geometry_section and not extended_section:
            continue

        words = line.split()
        wc = len(words)

        if general_section:
            if line.startswith("device node"):
                dasd_dev = words[3]
                tmp = dasd_dev.split('/')
                dasd_id = tmp[2]  # 0/1/2
                continue
            if line.startswith("busid "):
                cuuu = words[2]
                tmp = cuuu.split('.')
                cuuu = tmp[2]
                continue
            if line.startswith("type "):
                dasd_class = words[2]
                if dasd_class == "ECKD" or dasd_class == "CKD":
                    dasd_class = "dasd"
                elif dasd_class == "FBA":
                    dasd_class = "fba"
                elif dasd_class == "DIAG":
                    dasd_class = ""
                continue
            if line.startswith("device type"):
                dasd_type = words[4]
                continue

        # end: if general_section:

        if geometry_section:
            continue
        # end: if geometry_section:

        if extended_section:
            continue
        # end: if extended_section:

    # end: for line in lines: # -----------------------------------------------
    # end: for line in fh: # --------------------------------------------------

    if dasd_dev != '' and cuuu != '':
        vol1 = ''
        mm = ''
        track_s390_dasd(cuuu, dasd_id, vol1, mm, dasd_class, dasd_type, '', fn)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_ls_dasd()
#
# Bus-ID     Status      Name      Device  Type  BlkSz  Size      Blocks
# ==============================================================================
# 0.0.0100   active      dasda     94:0    ECKD  4096   23032MB   5896440
# 0.0.0300   active      dasdb     94:4    FBA   512    64MB      131072
# 0.0.0301   active      dasdc     94:8    FBA   512    256MB     524288
# 0.0.0101   active      dasdd     94:12   ECKD  4096   23032MB   5896440
# 0.0.0102   active      dasde     94:16   ECKD  4096   11516MB   2948220
# 0.0.0104   n/f         dasdf     94:20   ECKD
# 0.0.afe3   alias                         ECKD
#
#
#
# Bus-ID     Status      Name      Device  Type  BlkSz  Size      Blocks
# ==============================================================================
# 0.0.0152   active      dasda     94:0    ECKD  4096   3393MB    868680
# 0.0.0150   active      dasdb     94:4    ECKD  4096   325MB     83340
# 0.0.0151   active      dasdc     94:8    ECKD  4096   125MB     32040
# 0.0.0153   active      dasdd     94:12   ECKD  4096   3315MB    848700
# 0.0.0101   active      dasde     94:16   DIAG  512    256MB     524288
# 0.0.0220   active      dasdf     94:20   ECKD  4096   7042MB    1802880
# 0.0.0102   active      dasdg     94:24   DIAG  512    1024MB    2097152
# 0.0.0221   active      dasdh     94:28   ECKD  4096   3315MB    848880
# 0.0.0103   active      dasdi     94:32   DIAG  512    1024MB    2097152
# 0.0.0100   active      dasdj     94:36   DIAG  512    256MB     524288
#
#
#
# Bus-ID     Status      Name      Device  Type  BlkSz  Size      Blocks
# ==============================================================================
# 0.0.0700   active      dasda     94:0    ECKD  4096   23033MB   5896620
# 0.0.0701   active      dasdb     94:4    ECKD  4096   7042MB    1802880
# 0.0.0702   active      dasdc     94:8    ECKD  4096   7042MB    1802880
# 0.0.0900   active      dasdj     94:36   FBA   512    200MB     409600
# 0.0.0901   active      dasdk     94:40   FBA   512    400MB     819200
# 0.0.0950   active      dasds     94:72   ECKD  4096   1406MB    360000
# 0.0.0191   active(ro)  dasdt     94:76   ECKD  4096   105MB     27000
# 0.0.0712   active      dasdu     94:80   ECKD  4096   11516MB   2948220
# ---------------------------------------------#


def crunch_ls_dasd():

    fn = "sos_commands/s390/lsdasd"
    fh = openfile(fn)
    if fh is None:
        return

    header_found = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "":
            continue

        words = line.split()
        wc = len(words)

        if words[0] == "Bus-ID" and words[1] == "Status":
            header_found = True
            continue

        if not header_found:
            continue

        if wc < 3:
            if not line.startswith("===="):
                error_print('d', line)
            continue

        cuuu = words[0]
        status = words[1]
        dasd_id = ""
        mm = ""
        dasd_class = ""

        if status == "alias":
            dasd_class = words[2]

        if wc > 3:
            dasd_id = words[2]
            mm = words[3]
            dasd_class = words[4]

        blk_size = "0"
        dasd_size = "0"
        block_cnt = "0"

        if wc == 3 and status == "alias":
            pass
        elif wc == 5 and status == "n/f":
            pass
        elif wc == 8 and status == "active":
            pass
        elif wc == 8 and status == "active(ro)":
            pass
        else:
            if not line.startswith("===="):
                error_print('d', line)
            continue

        if wc == 8:
            blk_size = words[5]  # TODO track dasd size
            dasd_size = words[6]
            block_cnt = words[7]

        if dasd_class == "ECKD" or dasd_class == "CKD":
            dasd_class = "dasd"
        elif dasd_class == "FBA":
            dasd_class = "fba"
        elif dasd_class == "DIAG":
            dasd_class = ""

        vol1 = ''
        dasd_type = ''
        track_s390_dasd(cuuu, dasd_id, vol1, mm, dasd_class, dasd_type, status, fn)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_ls_tape()
#
# FICON/ESCON tapes (found 0):
# TapeNo  BusID      CuType/Model DevType/Model   BlkSize State   Op      MedState
#
# SCSI tape devices (found 3):
# Generic Device        Target       Vendor   Model            Type     State
# sg0     IBMtape0      0:0:2:0      IBM      03592E05         tapedrv  running
# sg1     IBMtape1      1:0:3:0      IBM      03592E05         tapedrv  running
# sg2     IBMchanger0   1:0:3:1      IBM      03584L22         changer  running
#
# ---------------------------------------------#


def crunch_ls_tape():

    fn = "sos_commands/s390/lstape"
    fh = openfile(fn)
    if fh is None:
        return

    header_s390_found = False
    header_scsi_found = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        # debug_print(z,line) # REMOVE
        if line == "":
            continue

        words = line.split()
        wc = len(words)

        if wc >= 7 and words[0] == "TapeNo" and words[1] == "BusID":
            header_s390_found = True
            continue

        if line.startswith("SCSI tape devices"):
            header_s390_found = False
            header_scsi_found = True
            continue
        if header_s390_found:

            if wc != 8:
                error_print('d', line)
                continue
            tape_no = words[0]
            cuuu = words[1]
            cu_type = words[2]
            dev_type = words[3]
            block_size = words[4]
            dev_state = words[5]
            op = words[6]
            media_state = words[7]
            if "/" in dev_type:
                tmp = dev_type.split("/")
                dev_type = tmp[0]

            dev_class = "tape"
            track_s390_cuuu(cuuu, dev_class, dev_type, dev_state, fn)

        # end: if header_s390_found:

        if header_scsi_found:

            if line.startswith("Generic Device"):
                continue  # header line

            if wc != 7:
                error_print('d', line)
                continue
            sg_id = words[0]
            dev_id = words[1]
            scsi_adr = words[2]
            mfg = words[3]
            model = words[4]
            dt_long = words[5]
            dt = ''
            if dt_long == "tapedrv":
                dt = "st"
            elif dt_long == "changer":
                dt = "ch"
            else:
                error_print('d', line)
                continue
            dev_status = words[6]

            add_normalized_scsi_data(scsi_adr, dt, dev_id, sg_id, line, fn)
            track_dev_mfgs(scsi_adr, mfg, 1, fn)
            track_dev_models(scsi_adr, model, fn)

        # end: if header_scsi_found:

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_ls_css()
#
# Device   Subchan.  DevType CU Type Use  PIM PAM POM  CHPIDs
# ----------------------------------------------------------------------
# 0.0.0100 0.0.0000  3390/0c 3990/e9 yes  80  80  ff   ff000000 00000000
# 0.0.0101 0.0.0001  3390/0c 3990/e9 yes  80  80  ff   ff000000 00000000
# 0.0.0009 0.0.0002  0000/00 3215/00 yes  80  80  ff   ff000000 00000000
# 0.0.0600 0.0.000b  1732/01 1731/01 yes  80  80  ff   00000000 00000000
# 0.0.0601 0.0.000c  1732/01 1731/01 yes  80  80  ff   00000000 00000000
# 0.0.0602 0.0.000d  1732/01 1731/01 yes  80  80  ff   00000000 00000000
# 0.0.0900 0.0.000e  1732/05 1731/05 yes  80  80  ff   01000000 00000000
# 0.0.0901 0.0.000f  1732/05 1731/05 yes  80  80  ff   01000000 00000000
# 0.0.0902 0.0.0010  1732/05 1731/05 yes  80  80  ff   01000000 00000000
# 0.0.0300 0.0.0011  9336/10 6310/80 yes  80  80  ff   ff000000 00000000
# 0.0.0301 0.0.0012  9336/10 6310/80 yes  80  80  ff   ff000000 00000000
# 0.0.0102 0.0.0013  3390/0c 3990/e9 yes  80  80  ff   ff000000 00000000
# 0.0.0104 n/a       3390/0c 3990/e9 yes
#
# ---------------------------------------------#


def crunch_ls_css():

    fn = "sos_commands/s390/lscss"
    fh = openfile(fn)
    if fh is None:
        return

    header_found = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        # debug_print(z,line) # REMOVE
        if line == "":
            continue

        words = line.split()
        wc = len(words)

        if wc >= 9 and words[0] == "Device" and words[1] == "Subchan.":
            header_found = True
            continue

        if header_found:

            if wc < 4:
                if not line.startswith("-------"):
                    error_print('d', line)
                continue
            cuuu = words[0]
            sub_chan = words[1]
            dev_type = words[2]
            cu_type = words[3]
            word_offset = 0
            use = words[4]

            pim = ""
            pam = ""
            pom = ""
            chpids = ""

            if use != "yes":  # if not 'yes', it's blank
                word_offset = 1
                use = ''

            if wc < 4 and sub_chan == "n/a":
                if not line.startswith("-------"):
                    error_print('d', line)
                continue

            if wc > 5:
                pim = words[5 - word_offset]
                pam = words[6 - word_offset]
                pom = words[7 - word_offset]
                chpids = words[8 - word_offset]
            if dev_type == "0000/00" or dev_type == "0000":
                dev_type = cu_type

            if "/" in dev_type:
                tmp = dev_type.split("/")
                dev_type = tmp[0]

            dev_class = ""
            track_s390_cuuu(cuuu, dev_class, dev_type, '', fn)

        # end: if header_found:

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ---------------------------------------------#
# function: crunch_dumpe2fs_data()
# read the dumpe2fs_-h_.dev....
# files and get the state of each filesystem
# ---------------------------------------------#
def crunch_dumpe2fs_data():

    crunch_dumpe2fs_directory("./sos_commands/filesys/")

    return

# ---------------------------------------------#
# function: crunch_dumpe2fs_directory()
# ---------------------------------------------#


def crunch_dumpe2fs_directory(path):
    global sd_re, dm_re
    global parted_file_spec

    if stat_dir(path, '', 0) is None:
        return

    fn_prefix_list_1 = "dumpe2fs "\
                       ""
    fn_prefixes_1 = fn_prefix_list_1.split()
    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:

        for fn_prefix in fn_prefixes_1:  # dumpe2fs output files
            if fn.startswith(fn_prefix):
                crunch_dumpe2fs_file(path + fn, fn)

    # done: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_dumpe2fs_file()
#
# fn: dumpe2fs_-h_.dev.mapper.VolGroup00-Applied_.Applied
#
# Filesystem state:         clean
# Filesystem state:         clean with error (see case )
# ---------------------------------------------#


def crunch_dumpe2fs_file(path_fn, fn):
    global fs_2_mountpoint        # Key_data()

    tmp = fn.split('.')
    wc = len(tmp)
    fs = ''
    prev_segment = ''
    mountpoint_from_fn = ''
    for i in range(1, wc):
        if prev_segment.endswith("_"):
            if mountpoint_from_fn == '':
                mountpoint_from_fn = "/" + tmp[i]
            prev_segment = tmp[i]
            continue

        if mountpoint_from_fn != '':
            mountpoint_from_fn = mountpoint_from_fn + "/" + tmp[i]
            prev_segment = tmp[i]
            continue
        if fs == '':
            fs = "/" + tmp[i]
        else:
            fs = fs + "/" + tmp[i]
        prev_segment = tmp[i]
    # end: for i in range(1,wc-2):

    if fs.endswith("_"):
        fs = fs.rstrip("_")
    # debug_print(z,"'{0}' {1}".format(fs,fn))

    fh = openfile(path_fn)
    if fh is None:
        return

    fs_status = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == '':
            continue

        words = line.split()
        wc = len(words)

        if line.startswith("Last mounted on:"):
            mountpoint = words[3]
            if mountpoint == "<not":
                mountpoint = words[3] + " " + words[4]
                continue  # <not available>
            if mountpoint_from_fn != "":
                if mountpoint_from_fn != mountpoint:
                    tmp_fs = adjust_fs_name(fs, mountpoint, fn)
                    if fs_2_mountpoint[tmp_fs] == "/export/home":
                        continue
                    if mountpoint != fs_2_mountpoint[tmp_fs]:
                        # this is a relatively rare occurence but it does happen often enough to make it "debug"
                        # error_print('d',"{0} not = {1} or tmp_fs_mountpoint[{2}]  fs={3} tmp_fs={4} ({5})".\
                        debug_print(4, "{0} not = {1} or tmp_fs_mountpoint[{2}]  fs={3} tmp_fs={4} ({5})".
                                    format(mountpoint, mountpoint_from_fn, fs_2_mountpoint[tmp_fs], fs, tmp_fs, fn))
            continue

        if line.startswith("Filesystem state:"):
            fs_status = squeeze(line.replace("Filesystem state:", ""))
            if fs_status == "clean":
                continue
            anomaly_line = "fs {0} mounted at {1} has a status of '{2}', consider running e2fsck ({3})".\
                           format(fs, mountpoint, fs_status, path_fn)
            handle_anomaly("FS", anomaly_line)

    # end: for line in lines:
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return


# ---------------------------------------------#
# function: crunch_parted_udev_data()
# read the parted_-s_.dev.sd*_print
# and the parted_-s_.dev.dm*_print
# files and get the sizes.
# for sd files, set partition sizes and accumulate total sd size
# ---------------------------------------------#
def crunch_parted_udev_data():
    global parted_sd_ul_errors, parted_dm_ul_errors, parted_misc_ul_errors
    global sd_re, dm_re

    crunch_parted_udev_directory("./sos_commands/filesys/")
    crunch_parted_udev_directory("./sos_commands/block/")
    crunch_parted_udev_directory("./sos_commands/devicemapper/")

    if parted_sd_ul_errors > 0:
        do_parted_ul_anom(sd_re, parted_sd_ul_errors)
    if parted_dm_ul_errors > 0:
        do_parted_ul_anom(dm_re, parted_dm_ul_errors)
    if parted_misc_ul_errors > 0:
        do_parted_ul_anom("misc", parted_misc_ul_errors)

    return

# ---------------------------------------------#
# function: do_parted_ul_anom()
# ---------------------------------------------#


def do_parted_ul_anom(type, error_count):
    global parted_file_spec

    anomaly_line = "Found {0} 'Error: Unable to open /dev/{1} - unrecognised disk label.' message{2} ({3}*)".\
                   format(error_count, type, plural(error_count), parted_file_spec)
    handle_anomaly("NOTE", anomaly_line)
    return

# ---------------------------------------------#
# function: crunch_parted_udev_directory()
# ---------------------------------------------#


def crunch_parted_udev_directory(path):
    global sd_re, dm_re
    global parted_file_spec

    if stat_dir(path, '', 0) is None:
        return

    fn_prefix_list_1 = "parted_-s_.dev. "\
                       "fdisk_-l_.dev. "\
                       ""
    fn_prefixes_1 = fn_prefix_list_1.split()
    fn_prefix_list_2 = "udevinfo_-ap_.sys.block. "\
                       "udevadm_info_-ap_.sys.block. "\
                       ""
    fn_prefixes_2 = fn_prefix_list_2.split()

    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:

        for fn_prefix in fn_prefixes_1:  # parted or fdisk output files
            if fn.startswith(fn_prefix):
                dev = fn[len(fn_prefix):]
                dev = dev.replace("_print", '')
                if dev.endswith("_unit_s"):
                    dev = dev.replace("_unit_s", '')
                if dev.endswith("_unit_s_2"):
                    dev = dev.replace("_unit_s_2", '')
                if dev.endswith("_2"):
                    dev = dev[0:len(dev) - 2]
                if re.match(sd_re, dev):
                    crunch_parted_file(dev, path + fn)
                if re.match(dm_re, dev):
                    crunch_parted_file(dev, path + fn)
                parted_file_spec = path + fn_prefix

        for fn_prefix in fn_prefixes_2:  # udev output files
            if fn.startswith(fn_prefix):
                dev = fn[len(fn_prefix):]
                if dev.endswith("_2"):
                    dev = dev[0:len(dev) - 2]
                # if re.match(sd_re,dev): crunch_udev_file(dev,path+fn)
                # TODO: what not for sd_re??
                if re.match(dm_re, dev):
                    crunch_udev_file(dev, path + fn)

    # done: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_udev_file()
# ---------------------------------------------#


def crunch_udev_file(dev, fn):

    if not dev.startswith("dm-"):
        return

    fh = openfile(fn)
    if fh is None:
        return

    mm = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == '':
            continue

        if line.startswith("SYSFS{"):
            end = line.find("}")
            if end == -1:
                error_print("d", line)
                return
            sysfs_parm = line[len("SYSFS{"):end]
            sysfs_value = line[end + 1:]
            sysfs_value = sysfs_value.lstrip("==")
            sysfs_value = sysfs_value.strip('"')
            if sysfs_parm == "size":
                isize = int(sysfs_value)
            elif sysfs_parm == "dev":
                mm = sysfs_value
            # TODO: elif sysfs_parm == "queue_depth": mm = sysfs_value # save for... (case )

    # end: for line in fh:

    add_normalized_mm_data('', '', dev, mm, '', '', fn)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_parted_file()
# parted_-s_.dev.sda_unit_s_print
# fdisk_-l_.dev.sda
# ---------------------------------------------#


def crunch_parted_file_new(dev, fn):
    global sd_re, dm_re

    fh = openfile(fn)
    if fh is None:
        return

    # "Type" aka "Name"
    type_re_list = ''

    # -> see case  for exmaples of the following (Type/Name of 1):
    # Number  Start   End     Size    File system  Name  Flags
    # 1      1049kB  2199GB  2199GB               1     lvm
    #
    # Number  Start    End         Size        File system  Name                          Flags
    # 1      34s      2081s       2048s                    LDM metadata partition
    # 2      2082s    262177s     260096s                  Microsoft reserved partition  msftres
    # 3      262178s  104857566s  104595389s               LDM data partition

    name_re_list = ""\
                   "asm0.*~"\
                   "asmacfs.* 1 ~"\
                   "ASMDEV~"\
                   "block~"\
                   "ceph~"\
                   "data~"\
                   "Disk1~"\
                   "EFI~"\
                   "EFI System~"\
                   "Efi System~"\
                   "EFI System Partitioa~"\
                   "EFI System Partition~"\
                   "extended~"\
                   "GPFS:~"\
                   "LDM metadata partition~"\
                   "LDM data partition~"\
                   "Linux~"\
                   "Linux filesystem~"\
                   "Linux Filesystem Data~"\
                   "Linux LVM ~"\
                   "Linux RAID~"\
                   "Linux Swap~"\
                   "lockbox~"\
                   "logical~"\
                   "LVM~"\
                   "msdp-data~"\
                   "msdp-dd~"\
                   "My Passport ~"\
                   "PART-TYPE~"\
                   "prim~"\
                   "primaria~"\
                   "primary~"\
                   "RHEL-7.2~"\
                   "Server.ppc64le~"\
                   "symc cdsdisk~"\
                   "sun-ufs~"\
                   "swap~"\
                   "Untitled~"\
                   ""

    # Sun disk fdisk file:
    #
    # Disk /dev/sdae (Sun disk label): 16 heads, 545 sectors, 65489 cylinders
    # Units = cylinders of 8720 * 512 bytes
    #
    # Device Flag    Start       End    Blocks   Id  System
    # /dev/sdae3  u          0     65489 285532040    5  Whole disk
    # /dev/sdae8  u          0     65489 285532040    f  Unknown

    # $ cat fdisk_-l_.dev.sdc
    #
    # Disk /dev/sdc: 9663 MB, 9663676416 bytes
    # 64 heads, 32 sectors/track, 9216 cylinders
    # Units = cylinders of 2048 * 512 = 1048576 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk identifier: 0x00000000

    fs_list = ""\
              "btrfs~"\
              "ext2~"\
              "ext3~"\
              "ext4~"\
              "fat16~"\
              "fat32~"\
              "hfs~"\
              "hfs+~"\
              "linux-swap~"\
              "linux-swap(v1)~"\
              "ntfs~"\
              "xfs~"\
              ""

    flag_list = ""\
                "amorce~"\
                "arranque~"\
                "Basic~"\
                "bios_grub~"\
                "boot~"\
                "ceph~"\
                "Cluster~"\
                "data~"\
                "diag~"\
                "esp~"\
                "hidden~"\
                "journal~"\
                "lba~"\
                "legacy~"\
                "lvm~"\
                "Microsoft~"\
                "msftres~"\
                "partition~"\
                "Partition~"\
                "prep~"\
                "raid~"\
                "reserved~"\
                "root~"\
                "partition~"\
                "启动~"\
                ""

    sun_disk = False
    sun_flag_list = "u ."
    sun_id_list = "2 3 4 5 82 83 f e"
    sun_system_list = "Whole_disk Unknown SunOS_root SunOS_swap SunOS_usr"

    disk_ign_list = "Flags: label geometry identifier:"  # ignore these "Disk <word>" lines
    total_size = 0
    total_disk_word = ''
    total_disk_size = 0
    total_calc_size = 0
    total_cylinder_count = 0
    start_line_found = False

    sector_size = 0
    sectors_per_cylinder = 0
    total_calc_size_from_sectors = 0
    block_size = 0
    blocks_per_cylinder = 0
    total_calc_size_from_blocks = 0
    prev_start = ''
    prev_end = ''
    name_pos = 0
    error_line_count = 0
    i = 0

    cc_start = -2
    cc_end = -2
    cc_size = -2
    cc_file_system = -2
    cc_name = -2
    cc_flags = -2

    # Device Flag    Start       End    Blocks   Id  System
    cc_sun_flag = -2
    cc_sun_start = -2
    cc_sun_end = -2
    cc_sun_blocks = -2
    cc_sun_id = -2
    cc_sun_system = -2

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        leading_blanks = count_leading(' ', line)

        orig_line = line
        line = line.strip()
        if line == '':
            continue
        if line.startswith("Error:"):
            crunch_parted_error(dev, fn, line)
            error_line_count += 1
            continue
        if line.startswith("Warning:"):
            continue
        words = line.split()
        wc = len(words)
        # 'Number  Start   End     Size    Type     File system  Flags'
        # 'Number  Start   End     Size    File system  Name           Flags'
        if (words[0] == "Number" and words[1] == "Start" and words[2] == "End") or \
                (words[0] == "Numero" and words[1] == "Inicio" and words[2] == "Fin"):
            start_line_found = True

            cc_start = orig_line.find("Start")
            if cc_start == -1:
                cc_start = orig_line.find("Inicio")

            cc_end = orig_line.find("End")
            if cc_end == -1:
                cc_end = orig_line.find("Fin")

            cc_size = orig_line.find("Size")
            cc_file_system = orig_line.find("File system")
            cc_name = orig_line.find("Name")
            cc_flags = orig_line.find("Flags")
            # if words[6] == "Name": name_pos = line.find("Name")
            continue

        if (words[0] == "Device" and words[1] == "Flag" and words[2] == "Start") and \
                (words[3] == "End" and words[4] == "Blocks" and words[5] == "Id" and words[6] == "System"):
            if not sun_disk:
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue

            cc_sun_flag = orig_line.find("Flag")
            cc_sun_start = orig_line.find("Flag")
            cc_sun_end = orig_line.find("End")
            cc_sun_blocks = orig_line.find("Blocks")
            cc_sun_id = orig_line.find("Id")
            cc_sun_system = orig_line.find("System")

            start_line_found = True
            continue

        # "Disk /dev/sde doesn't contain a valid partition table"
        if "doesn't contain a valid partition table" in line:
            continue

        if words[0] == "Disk":
            if word_in_list(words[1], disk_ign_list):
                continue

            # 'Disk /dev/sdcc (Sun disk label): 16 heads, 545 sectors, 65489 cylinders'
            if "(Sun disk label):" in line:
                sun_disk = True
                sectors_per_cylinder = int(words[5]) * int(words[7])

            if sun_disk:
                expected_dev_id = "/dev/" + dev
            else:
                expected_dev_id = "/dev/" + dev + ":"

            if words[1] != expected_dev_id:
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue

            if sun_disk:
                if wc != 11:
                    error_print("d", "?line='{0} ({1})".format(line, fn))
                    continue
                if not words[9].isdigit():
                    error_print("d", "?line='{0} ({1})".format(line, fn))
                    continue
                # heads           sectors/head
                sectors_per_cylinder = int(words[5]) * int(words[7])
                total_cylinder_count = int(words[9])
            else:
                total_disk_word = words[2].replace(',', '.')
                if total_disk_word.isdigit() or is_float(total_disk_word):
                    mg = words[3].rstrip(',')
                    if mg_conv("0" + mg, False, 1) == 0:  # Valid MB/GB/PB, label ?
                        total_disk_word = total_disk_word + mg

        # 0      1  2              3    4         5
        # 64 heads, 32 sectors/track, 9216 cylinders
        if wc == 6 and words[1] == 'heads,' and words[5] == 'cylinders':
            total_cylinder_count = int(words[4])
            if words[3].rstrip(',') == 'sectors/track':
                sectors_per_cylinder = int(words[0]) * int(words[2])

        if line.startswith("Units = cylinders of"):
            # if not sun_disk:
                # error_print("d","?line='{0} ({1})".format(line,fn))
                # continue
            # 'Units = cylinders of 8720 * 512 bytes'
            if not words[4].isdigit() or not words[6].isdigit():
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue
            blocks_per_cylinder = int(words[4])
            block_size = int(words[6])

        if line.startswith("Units = sectors of"):
            # Units = sectors of 1 * 512 bytes              (wc = 8)
            # Units = sectors of 1 * 512 bytes = 512 bytes  (wc = 11)
            if wc == 11:
                sector_size = int(words[10])
            else:
                sector_size = int(words[4]) * int(words[6])

        if line.startswith("Sector size"):
            # next few lines take line like:
            # Sector size (logical/physical): 512 bytes / 512 bytes
            # and turn it into
            # Sector size (logical/physical): 512B/512B
            line = line.replace(" bytes", "B")  # erase if present
            line = line.replace(" / ", "/")  # bring together
            words = line.split()  # resplit line
            log_phys = words[3]
            tmp = log_phys.split("/")
            if len(tmp) == 2:
                logical_sector_size = tmp[0]
                physical_sector_size = tmp[1]

                if word_in_list(logical_sector_size, "512B 4096B"):
                    pass
                else:
                    error_print("d", "Unrecognized logical sector size: '{0}'".format(line))

                if word_in_list(physical_sector_size, "512B 4096B 8192B 16384B 32768B 131072B"):
                    pass
                else:
                    error_print("d", "Unrecognized physical sector size: '{0}'".format(line))

                sector_size = logical_sector_size.rstrip("B")
                if not sector_size.isdigit():
                    sector_size = "512"
                sector_size = int(sector_size)
                if sector_size != 512 and sector_size != 4096:
                    error_print("d", line)
            else:
                error_print("d", line)
            continue

        if not start_line_found:
            continue

        # Examples:
        #
        # /dev/sdae3  u          0     65489 285532040    5  Whole disk
        #
        # -Disk /dev/sdg (Sun disk label): 255 heads, 63 sectors, 2602 cylinders
        # Units = cylinders of 16065 * 512 bytes
        #
        # Device Flag    Start       End    Blocks   Id  System
        # /dev/sdg1             0    133668 1073688210   83  Linux native
        # /dev/sdg2  u     133668    133674     48195   82  Linux swap
        # /dev/sdg3             0    133674 1073736405    5  Whole disk
        # 0             1         2          3    4  5     6    (word numbers when no flag)
        # 0  1          2         3          4    5  6     7    (word numbers when there is a flag)
        if sun_disk:
            part_id = words[0]
            dev_partition = part_id[len("/dev/"):]  # "/dev/sdae3" -> "sdae3"
            flags_ = words[1]
            if not word_in_list(flags_, sun_flag_list) and flags_.isdigit():
                wo = 1
                flags_ = '.'
            else:
                wo = 0
            start_ = words[2 - wo]
            end_ = words[3 - wo]
            blocks = words[4 - wo]  # 1k blocks
            id_ = words[5 - wo]

            system_ = ' '
            system_ = system_.join(words[6 - wo:])  # remaining word(s)
            if system_ == "Whole disk":
                system_ = "Whole_disk"
            if system_.startswith("SunOS "):
                system_ = system_.replace("SunOS ", "SunOS_")

            blocks = blocks.rstrip("+")  # seen on sos reports from Oracle Linux
            size = int(blocks)
            if prev_start == start_ and prev_end == end_:
                pass
            else:
                total_calc_size += size

            if not word_in_list(flags_, sun_flag_list):
                error_print('d', "{0}? '{1}' ({2})".format(flags_, line, fn))

            if not word_in_list(id_, sun_id_list):
                error_print('d', "{0}? '{1}' ({2})".format(id_, line, fn))

            if not word_in_list(flags_, sun_flag_list):
                error_print('d', "{0}? '{1}' ({2})".format(flags_, line, fn))
            prev_start = start_
            prev_end = end_

        else:

            # debug_print(z,line)
            part_id = words[0]
            dev_partition = dev + part_id
            start_ = words[1].replace(',', '.')
            end_ = words[2].replace(',', '.')
            size_ = words[3].replace(',', '.')
            type_ = ''
            fs_ = ''
            flags_ = ''

            name_ = ''
            if name_pos:
                np = name_pos - leading_blanks  # (because line is stripped above)
                if len(line) > np:
                    tmp_line = line[np:]
                    if tmp_line.startswith("My Passport"):
                        tmp_line = tmp_line.replace("My Passport", "My_Passport")

                    # debug_print(z,tmp_line)
                    if not tmp_line.startswith(" ") and not tmp_line.startswith("EFI") and not tmp_line.startswith("Efi") \
                            and not tmp_line.startswith("Linux"):
                        tmp = tmp_line.split()
                        name_ = tmp[0]
                        # 'Number  Start   End     Size    File system  Name  Flags
                        # ' 1      1049kB  2199GB  2199GB               1     lvm
                        line_beg = line[0:np]
                        blank_name = ' '.ljust(len(name_))
                        line_end = line[np + len(name_):]
                        # line = line.replace(name_,blank_name) # could replace more than was intended
                        line = line_beg + blank_name + line_end
                        words = line.split()  # redo words after removing 'name'

            type_fs_flags = ' '
            type_fs_flags = type_fs_flags.join(words[4:])
            # debug_print(z,type_fs_flags)

            if type_fs_flags.find("EFI System Partition") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System Partition", "EFI_System_Partition")

            if type_fs_flags.find("EFI system partition") != -1:
                type_fs_flags = type_fs_flags.replace("EFI system partition", "EFI_System_Partition")

            if type_fs_flags.find("EFI System Partitioa") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System Partitioa", "EFI_System_Partitioa")

            if type_fs_flags.find("EFI System") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System", "EFI_System")

            if type_fs_flags.find("Efi System") != -1:
                type_fs_flags = type_fs_flags.replace("Efi System", "Efi_System")

            if type_fs_flags.find("Linux filesystem") != -1:
                type_fs_flags = type_fs_flags.replace("Linux filesystem", "Linux_filesystem")

            if type_fs_flags.find("Linux Filesystem Data") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Filesystem Data", "Linux_Filesystem_Data")

            if type_fs_flags.find("Linux LVM") != -1:
                type_fs_flags = type_fs_flags.replace("Linux LVM", "Linux_LVM")

            if type_fs_flags.find("Linux Lvm") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Lvm", "Linux_LVM")

            if type_fs_flags.find("Linux RAID") != -1:
                type_fs_flags = type_fs_flags.replace("Linux RAID", "Linux_RAID")

            if type_fs_flags.find("Linux swap") != -1:
                type_fs_flags = type_fs_flags.replace("Linux swap", "Linux_swap")

            if type_fs_flags.find("Linux Swap") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Swap", "Linux_Swap")

            if type_fs_flags.find("LDM metadata partition") != -1:
                type_fs_flags = type_fs_flags.replace("LDM metadata partition", "LDM_metadata_partition")

            if type_fs_flags.find("LDM data partition") != -1:
                type_fs_flags = type_fs_flags.replace("LDM data partition", "LDM_data_partition")

            type_fs_flags = type_fs_flags.replace(',', ' ')
            type_fs_flags = type_fs_flags.strip()
            tmp = type_fs_flags.split()
            for ty_fs_fl in tmp:  # verify type, file system, and flag
                if word_in_re_list(ty_fs_fl, type_re_list):
                    if type_ == '':
                        type_ = ty_fs_fl
                    else:
                        error_print('d', "'{0}' ({1})".format(line, fn))
                elif word_in_list(ty_fs_fl, fs_list):
                    if fs_ == '':
                        fs_ = ty_fs_fl
                    else:
                        error_print('d', "'{0}' ({1})".format(line, fn))
                elif word_in_list(ty_fs_fl, flag_list):
                    flags_ = flags_ + ' ' + ty_fs_fl
                else:
                    error_print('d', "?{0}? '{1}' ({2})".format(ty_fs_fl, line, fn))
                    continue
            flags_ = flags_.strip()

            size = mg_conv(size_, 0, sector_size)
            if size == -1:
                error_print("d", line)
                continue
            else:
                total_calc_size += size

        # end: else: sun_disk

        if re.match(sd_re, dev):
            set_device_size(dev_partition, size, fn)
            debug_print(3, "{0}: {1} ({2})".format(dev_partition, size, fn))

    # end: for line in fh: # --------------------------------------------------

    if total_cylinder_count:
        if block_size and blocks_per_cylinder:
            total_calc_size_from_blocks = total_cylinder_count * (blocks_per_cylinder * block_size)
        if sector_size and sectors_per_cylinder:
            total_calc_size_from_sectors = total_cylinder_count * (sectors_per_cylinder * sector_size)

    # if re.match(sd_re,dev):
        # debug_print(z,"tcc:{0} * bpc:{1} * bs:{2} = tcsfb:{3} ({4})".\
            # format(total_cylinder_count,blocks_per_cylinder,block_size,total_calc_size_from_blocks,dev))
        # debug_print(z,"tcc:{0} * spc:{1} * ss:{2} = tcsfs:{3} ({4})".\
            # format(total_cylinder_count,sectors_per_cylinder,sector_size,total_calc_size_from_sectors,dev))

    if total_disk_word != '':
        # sector_size only used if tdw is in nnnns format (e.g. 81920s)
        total_disk_size = mg_conv(total_disk_word, 0, sector_size)  # sector_size only used if tdw is in nnnns fmt

    # if True:
    # if re.match(sd_re,dev):
    # if dev == "sda":
        # debug_print(z,"tdw={0} [{1}] ({2})".format(total_disk_word,dev,fn))
        # debug_print(z,"tds__={0}".format(total_disk_size))
        # debug_print(z,"tcsfs={0}".format(total_calc_size_from_sectors))
        # debug_print(z,"tcsfb={0}".format(total_calc_size_from_blocks))
        # debug_print(z,"tcs__={0}".format(total_calc_size))

    total_size_1 = max(total_disk_size, total_calc_size)
    total_size_2 = max(total_calc_size_from_blocks, total_calc_size_from_sectors)
    total_size = max(total_size_1, total_size_2)
    if total_size > 0:
        set_device_size(dev, total_size, fn)
        debug_print(3, "{0}: {1} ({2})".format(dev, total_size, fn))

    # if re.match(sd_re,dev):
        # debug_print(z,"{0} = {1}: {2} ({3})".format(total_size,total_disk_size,total_calc_size,fn))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_parted_file()
# parted_-s_.dev.sda_unit_s_print
# fdisk_-l_.dev.sda
# ---------------------------------------------#


def crunch_parted_file(dev, fn):
    global sd_re, dm_re

    fh = openfile(fn)
    if fh is None:
        return

    # "Type" aka "Name"
    type_re_list = "primary primaria prim extended logical GPFS: msdp-data msdp-dd Linux_filesystem Linux_LVM "\
                   "PART-TYPE symc_cdsdisk Disk1 EFI_System_Partition EFI_System_Partitioa EFI_System ASMDEV LVM asm0.* asmacfs.* 1 "\
                   "Untitled EFI Linux_RAID RHEL-7.2 Server.ppc64le ceph data lockbox block Linux_swap "\
                   "Efi_System Linux_Filesystem_Data Linux_Swap sun-ufs My_Passport "\
                   "LDM_metadata_partition LDM_data_partition metadata_partition"

    # -> see case  for exmaples of the following (Type/Name of 1):
    # Number  Start   End     Size    File system  Name  Flags
    # 1      1049kB  2199GB  2199GB               1     lvm

    # Sun disk fdisk file:
    #
    # Disk /dev/sdae (Sun disk label): 16 heads, 545 sectors, 65489 cylinders
    # Units = cylinders of 8720 * 512 bytes
    #
    # Device Flag    Start       End    Blocks   Id  System
    # /dev/sdae3  u          0     65489 285532040    5  Whole disk
    # /dev/sdae8  u          0     65489 285532040    f  Unknown

    # $ cat fdisk_-l_.dev.sdc
    #
    # Disk /dev/sdc: 9663 MB, 9663676416 bytes
    # 64 heads, 32 sectors/track, 9216 cylinders
    # Units = cylinders of 2048 * 512 = 1048576 bytes
    # Sector size (logical/physical): 512 bytes / 512 bytes
    # I/O size (minimum/optimal): 512 bytes / 512 bytes
    # Disk identifier: 0x00000000

    fs_list = "ext2 ext3 ext4 xfs ntfs linux-swap linux-swap(v1) fat16 fat32 btrfs hfs hfs+"

    flag_list = "bios_grub boot diag hidden lba lvm prep raid ceph data journal arranque esp "\
                "Cluster Partition Microsoft reserved partition  msftres Basic data partition legacy_boot lvm root "\
                "amorce 启动"

    sun_disk = False
    sun_flag_list = "u ."
    sun_id_list = "2 3 4 5 82 83 f e"
    sun_system_list = "Whole_disk Unknown SunOS_root SunOS_swap SunOS_usr"

    disk_ign_list = "Flags: label geometry identifier:"  # ignore these "Disk <word>" lines
    total_size = 0
    total_disk_word = ''
    total_disk_size = 0
    total_calc_size = 0
    total_cylinder_count = 0
    start_line_found = False

    sector_size = 0
    sectors_per_cylinder = 0
    total_calc_size_from_sectors = 0
    block_size = 0
    blocks_per_cylinder = 0
    total_calc_size_from_blocks = 0
    prev_start = ''
    prev_end = ''
    name_pos = 0
    error_line_count = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        leading_blanks = count_leading(' ', line)

        line = line.strip()
        if line == '':
            continue
        if line.startswith("Error:"):
            crunch_parted_error(dev, fn, line)
            error_line_count += 1
            continue
        if line.startswith("Warning:"):
            continue
        words = line.split()
        wc = len(words)
        # 'Number  Start   End     Size    Type     File system  Flags'
        # 'Number  Start   End     Size    File system  Name           Flags'
        if (words[0] == "Number" and words[1] == "Start" and words[2] == "End") or \
                (words[0] == "Numero" and words[1] == "Inicio" and words[2] == "Fin"):
            start_line_found = True
            if words[6] == "Name":
                name_pos = line.find("Name")
            continue

        if (words[0] == "Device" and words[1] == "Flag" and words[2] == "Start") and \
                (words[3] == "End" and words[4] == "Blocks" and words[5] == "Id" and words[6] == "System"):
            if not sun_disk:
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue
            start_line_found = True
            continue

        # "Disk /dev/sde doesn't contain a valid partition table"
        if "doesn't contain a valid partition table" in line:
            continue

        if words[0] == "Disk":
            if word_in_list(words[1], disk_ign_list):
                continue

            # 'Disk /dev/sdcc (Sun disk label): 16 heads, 545 sectors, 65489 cylinders'
            if "(Sun disk label):" in line:
                sun_disk = True
                sectors_per_cylinder = int(words[5]) * int(words[7])

            if sun_disk:
                expected_dev_id = "/dev/" + dev
            else:
                expected_dev_id = "/dev/" + dev + ":"

            if words[1] != expected_dev_id:
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue

            if sun_disk:
                if wc != 11:
                    error_print("d", "?line='{0} ({1})".format(line, fn))
                    continue
                if not words[9].isdigit():
                    error_print("d", "?line='{0} ({1})".format(line, fn))
                    continue
                # heads           sectors/head
                sectors_per_cylinder = int(words[5]) * int(words[7])
                total_cylinder_count = int(words[9])
            else:
                total_disk_word = words[2].replace(',', '.')
                if total_disk_word.isdigit() or is_float(total_disk_word):
                    mg = words[3].rstrip(',')
                    if mg_conv("0" + mg, False, 1) == 0:  # Valid MB/GB/PB, label ?
                        total_disk_word = total_disk_word + mg

        # 0      1  2              3    4         5
        # 64 heads, 32 sectors/track, 9216 cylinders
        if wc == 6 and words[1] == 'heads,' and words[5] == 'cylinders':
            total_cylinder_count = int(words[4])
            if words[3].rstrip(',') == 'sectors/track':
                sectors_per_cylinder = int(words[0]) * int(words[2])

        if line.startswith("Units = cylinders of"):
            # if not sun_disk:
                # error_print("d","?line='{0} ({1})".format(line,fn))
                # continue
            # 'Units = cylinders of 8720 * 512 bytes'
            if not words[4].isdigit() or not words[6].isdigit():
                error_print("d", "?line='{0} ({1})".format(line, fn))
                continue
            blocks_per_cylinder = int(words[4])
            block_size = int(words[6])

        if line.startswith("Units = sectors of"):
            # Units = sectors of 1 * 512 bytes              (wc = 8)
            # Units = sectors of 1 * 512 bytes = 512 bytes  (wc = 11)
            if wc == 11:
                sector_size = int(words[10])
            else:
                sector_size = int(words[4]) * int(words[6])

        if line.startswith("Sector size"):
            # next few lines take line like:
            # Sector size (logical/physical): 512 bytes / 512 bytes
            # and turn it into
            # Sector size (logical/physical): 512B/512B
            line = line.replace(" bytes", "B")  # erase if present
            line = line.replace(" / ", "/")  # bring together
            words = line.split()  # resplit line
            log_phys = words[3]
            tmp = log_phys.split("/")
            if len(tmp) == 2:
                logical_sector_size = tmp[0]
                physical_sector_size = tmp[1]

                if word_in_list(logical_sector_size, "512B 4096B"):
                    pass
                else:
                    error_print("d", "Unrecognized logical sector size: '{0}'".format(line))

                if word_in_list(physical_sector_size, "512B 4096B 8192B 16384B 32768B 131072B"):
                    pass
                else:
                    error_print("d", "Unrecognized physical sector size: '{0}'".format(line))

                sector_size = logical_sector_size.rstrip("B")
                if not sector_size.isdigit():
                    sector_size = "512"
                sector_size = int(sector_size)
                if sector_size != 512 and sector_size != 4096:
                    error_print("d", line)
            else:
                error_print("d", line)
            continue

        if not start_line_found:
            continue

        # Examples:
        #
        # /dev/sdae3  u          0     65489 285532040    5  Whole disk
        #
        # -Disk /dev/sdg (Sun disk label): 255 heads, 63 sectors, 2602 cylinders
        # Units = cylinders of 16065 * 512 bytes
        #
        # Device Flag    Start       End    Blocks   Id  System
        # /dev/sdg1             0    133668 1073688210   83  Linux native
        # /dev/sdg2  u     133668    133674     48195   82  Linux swap
        # /dev/sdg3             0    133674 1073736405    5  Whole disk
        # 0             1         2          3    4  5     6    (word numbers when no flag)
        # 0  1          2         3          4    5  6     7    (word numbers when there is a flag)
        if sun_disk:
            part_id = words[0]
            dev_partition = part_id[len("/dev/"):]  # "/dev/sdae3" -> "sdae3"
            flags_ = words[1]
            if not word_in_list(flags_, sun_flag_list) and flags_.isdigit():
                wo = 1
                flags_ = '.'
            else:
                wo = 0
            start_ = words[2 - wo]
            end_ = words[3 - wo]
            blocks = words[4 - wo]  # 1k blocks
            id_ = words[5 - wo]

            system_ = ' '
            system_ = system_.join(words[6 - wo:])  # remaining word(s)
            if system_ == "Whole disk":
                system_ = "Whole_disk"
            if system_.startswith("SunOS "):
                system_ = system_.replace("SunOS ", "SunOS_")

            blocks = blocks.rstrip("+")  # seen on sos reports from Oracle Linux
            size = int(blocks)
            if prev_start == start_ and prev_end == end_:
                pass
            else:
                total_calc_size += size

            if not word_in_list(flags_, sun_flag_list):
                error_print('d', "{0}? '{1}' ({2})".format(flags_, line, fn))

            if not word_in_list(id_, sun_id_list):
                error_print('d', "{0}? '{1}' ({2})".format(id_, line, fn))

            if not word_in_list(flags_, sun_flag_list):
                error_print('d', "{0}? '{1}' ({2})".format(flags_, line, fn))
            prev_start = start_
            prev_end = end_

        else:

            # debug_print(z,line)
            part_id = words[0]
            dev_partition = dev + part_id
            start_ = words[1].replace(',', '.')
            end_ = words[2].replace(',', '.')
            size_ = words[3].replace(',', '.')
            type_ = ''
            fs_ = ''
            flags_ = ''

            name_ = ''
            if name_pos:
                np = name_pos - leading_blanks  # (because line is stripped above)
                if len(line) > np:
                    tmp_line = line[np:]
                    if tmp_line.startswith("My Passport"):
                        tmp_line = tmp_line.replace("My Passport", "My_Passport")

                    # debug_print(z,tmp_line)
                    if not tmp_line.startswith(" ") and not tmp_line.startswith("EFI") and not tmp_line.startswith("Efi") \
                            and not tmp_line.startswith("Linux"):
                        tmp = tmp_line.split()
                        name_ = tmp[0]
                        # 'Number  Start   End     Size    File system  Name  Flags
                        # ' 1      1049kB  2199GB  2199GB               1     lvm
                        line_beg = line[0:np]
                        blank_name = ' '.ljust(len(name_))
                        line_end = line[np + len(name_):]
                        # line = line.replace(name_,blank_name) # could replace more than was intended
                        line = line_beg + blank_name + line_end
                        words = line.split()  # redo words after removing 'name'

            type_fs_flags = ' '
            type_fs_flags = type_fs_flags.join(words[4:])
            # debug_print(z,type_fs_flags)

            if type_fs_flags.find("EFI System Partition") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System Partition", "EFI_System_Partition")

            if type_fs_flags.find("EFI system partition") != -1:
                type_fs_flags = type_fs_flags.replace("EFI system partition", "EFI_System_Partition")

            if type_fs_flags.find("EFI System Partitioa") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System Partitioa", "EFI_System_Partitioa")

            if type_fs_flags.find("EFI System") != -1:
                type_fs_flags = type_fs_flags.replace("EFI System", "EFI_System")

            if type_fs_flags.find("Efi System") != -1:
                type_fs_flags = type_fs_flags.replace("Efi System", "Efi_System")

            if type_fs_flags.find("Linux filesystem") != -1:
                type_fs_flags = type_fs_flags.replace("Linux filesystem", "Linux_filesystem")

            if type_fs_flags.find("Linux Filesystem Data") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Filesystem Data", "Linux_Filesystem_Data")

            if type_fs_flags.find("Linux LVM") != -1:
                type_fs_flags = type_fs_flags.replace("Linux LVM", "Linux_LVM")

            if type_fs_flags.find("Linux Lvm") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Lvm", "Linux_LVM")

            if type_fs_flags.find("Linux RAID") != -1:
                type_fs_flags = type_fs_flags.replace("Linux RAID", "Linux_RAID")

            if type_fs_flags.find("Linux swap") != -1:
                type_fs_flags = type_fs_flags.replace("Linux swap", "Linux_swap")

            if type_fs_flags.find("Linux Swap") != -1:
                type_fs_flags = type_fs_flags.replace("Linux Swap", "Linux_Swap")

            if type_fs_flags.find("LDM metadata partition") != -1:
                type_fs_flags = type_fs_flags.replace("LDM metadata partition", "LDM_metadata_partition")

            if type_fs_flags.find("metadata partition") != -1:
                type_fs_flags = type_fs_flags.replace("metadata partition", "metadata_partition")

            if type_fs_flags.find("LDM data partition") != -1:
                type_fs_flags = type_fs_flags.replace("LDM data partition", "LDM_data_partition")

            type_fs_flags = type_fs_flags.replace(',', ' ')
            type_fs_flags = type_fs_flags.strip()
            tmp = type_fs_flags.split()
            for ty_fs_fl in tmp:  # verify type, file system, and flag
                if word_in_re_list(ty_fs_fl, type_re_list):
                    if type_ == '':
                        type_ = ty_fs_fl
                    else:
                        error_print('d', "'{0}' ({1})".format(line, fn))
                elif word_in_list(ty_fs_fl, fs_list):
                    if fs_ == '':
                        fs_ = ty_fs_fl
                    else:
                        error_print('d', "'{0}' ({1})".format(line, fn))
                elif word_in_list(ty_fs_fl, flag_list):
                    flags_ = flags_ + ' ' + ty_fs_fl
                else:
                    error_print('d', "?{0}? '{1}' ({2})".format(ty_fs_fl, line, fn))
                    continue
            flags_ = flags_.strip()

            size = mg_conv(size_, 0, sector_size)
            if size == -1:
                error_print("d", line)
                continue
            else:
                total_calc_size += size

        # end: else: sun_disk

        if re.match(sd_re, dev):
            set_device_size(dev_partition, size, fn)
            debug_print(3, "{0}: {1} ({2})".format(dev_partition, size, fn))

    # end: for line in fh: # --------------------------------------------------

    if total_cylinder_count:
        if block_size and blocks_per_cylinder:
            total_calc_size_from_blocks = total_cylinder_count * (blocks_per_cylinder * block_size)
        if sector_size and sectors_per_cylinder:
            total_calc_size_from_sectors = total_cylinder_count * (sectors_per_cylinder * sector_size)

    # if re.match(sd_re,dev):
        # debug_print(z,"tcc:{0} * bpc:{1} * bs:{2} = tcsfb:{3} ({4})".\
            # format(total_cylinder_count,blocks_per_cylinder,block_size,total_calc_size_from_blocks,dev))
        # debug_print(z,"tcc:{0} * spc:{1} * ss:{2} = tcsfs:{3} ({4})".\
            # format(total_cylinder_count,sectors_per_cylinder,sector_size,total_calc_size_from_sectors,dev))

    if total_disk_word != '':
        # sector_size only used if tdw is in nnnns format (e.g. 81920s)
        total_disk_size = mg_conv(total_disk_word, 0, sector_size)  # sector_size only used if tdw is in nnnns fmt

    # if True:
    # if re.match(sd_re,dev):
    # if dev == "sda":
        # debug_print(z,"tdw={0} [{1}] ({2})".format(total_disk_word,dev,fn))
        # debug_print(z,"tds__={0}".format(total_disk_size))
        # debug_print(z,"tcsfs={0}".format(total_calc_size_from_sectors))
        # debug_print(z,"tcsfb={0}".format(total_calc_size_from_blocks))
        # debug_print(z,"tcs__={0}".format(total_calc_size))

    total_size_1 = max(total_disk_size, total_calc_size)
    total_size_2 = max(total_calc_size_from_blocks, total_calc_size_from_sectors)
    total_size = max(total_size_1, total_size_2)
    if total_size > 0:
        set_device_size(dev, total_size, fn)
        debug_print(3, "{0}: {1} ({2})".format(dev, total_size, fn))

    # if re.match(sd_re,dev):
        # debug_print(z,"{0} = {1}: {2} ({3})".format(total_size,total_disk_size,total_calc_size,fn))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: crunch_parted_error()
# ---------------------------------------------#


def crunch_parted_error(dev, fn, line):
    global sd_re, dm_re
    global parted_sd_ul_errors, parted_dm_ul_errors, parted_misc_ul_errors
    global all_unrecognised_disk_label_devices  # ''

    if 'unrecognised disk label' in line:
        tmp = line.split()
        # "Error: Unable to open /dev/sda - unrecognised disk label."
        # "Error: /dev/dm-12: unrecognised disk label"
        if line.startswith("Error: Unable to open "):
            wn = 4
        else:
            wn = 1
        dev_id = tmp[wn].rstrip(":")
        all_unrecognised_disk_label_devices = unique_list(all_unrecognised_disk_label_devices, dev_id)
        dev_id = dev_id.replace("/dev/", '')
        if re.match(sd_re, dev_id):
            if not is_dev_a_pv(dev_id):
                parted_sd_ul_errors += 1
        elif re.match(dm_re, dev_id):
            parted_dm_ul_errors += 1
        else:
            parted_misc_ul_errors += 1
        return

    return

# ---------------------------------------------#
# function: is_dev_a_pv(dev):
# ---------------------------------------------#


def is_dev_a_pv(dev):
    global all_vg_names
    global vg_2_all_pvs

    vgs = all_vg_names.split()
    for vg in vgs:
        pvs = vg_2_all_pvs[vg]
        pvs = pvs.split()
        for pv in pvs:
            if dev == pv:
                return(True)
            # else check sub devs for pv..?
    # end: for vg in vgs:
    return(False)

# ---------------------------------------------#
# function: crunch_ls_dev()
# crunch data in ls_-laR_.dev
# ---------------------------------------------#


def crunch_ls_dev(pass_no):
    global dev_2_lun  # Key_data
    global all_hd_ids  # ""
    global all_dev_aliases  # ""
    global dasd_re, dasd_re_p
    global hda_re, hda_re_p, ccd_re, ccd_re_p, mdn_re
    global dm_re, sd_re, vd_re, vd_re_p, pp_re, sddl_re, sddl_re_p, xvd_re, xvd_re_p, dfa_re
    global st_re, nst_re, lt_re, lt_ch_re, tsm_re, rmt_re
    global ls_dev_dm_major  # -1
    global yyyy_mm_dd_re, hhmm_re
    global sw_debug_level  # 5 # REMOVE

    ls_file = "sos_commands/devicemapper/ls_-laR_.dev"
    if not file_exists_with_data(ls_file):
        ls_file = "sos_commands/block/ls_-lanR_.dev"
    fh = openfile(ls_file)
    if fh is None:
        return

    ign_blck_fn_prefixs = "archive.* "\
                          "inbound.* "\
                          "ram[0-9]{1,2} "\
                          ""
    ign_blck_fn_words = ign_blck_fn_prefixs.split()

    ign_char_fn_prefixs = "tty[0-9]{1,2} "\
                          "amf "\
                          "cpu.* "\
                          "hfcldd[0-9]{1,2} "\
                          "ipmi[0-9] "\
                          "lp[0-9] "\
                          "mem "\
                          "mice "\
                          "mouse[0-9] "\
                          "msr "\
                          "ptp[0-9] "\
                          "usb.* "\
                          "vcs[0-9] "\
                          "vcsa[0-9] "\
                          "001 "\
                          "002 "\
                          "\.tmp-.* "\
                          ""
    ign_char_fn_words = ign_char_fn_prefixs.split()

    # Partitioned device regex patterns:
    re_xx_p_list = \
        sd_re_p + " " +\
        xvd_re_p + " " +\
        vd_re_p + " " +\
        ccd_re_p + " " +\
        dasd_re_p + " " +\
        hda_re_p + " " +\
        sddl_re_p + " " +\
        "nvme[0-9]n[0-9]{1,2} "\
        "fio[a-z]n[0-9]{1,2} "\
        ""
    re_p_words = re_xx_p_list.split()

    # Device regex patterns:
    # need more examples of 'fio' -- (Fusion IO) - so far have seen only 'fioa'
    re_xx_list = \
        sd_re + " " +\
        xvd_re + " " +\
        vd_re + " " +\
        mdn_re + " " +\
        dfa_re + " " +\
        ccd_re + " " +\
        pp_re + " " +\
        dasd_re + " " +\
        hda_re + " " +\
        sddl_re + " " +\
        "loop[0-9]{1,2} "\
        "fio[a-z]{1,2} "\
                 "cvfsctl[0-9]{1,2} "\
                 "btibm[0-9]{1,2} "\
                 "\.asm_ctl_spec "\
                 "\.asm_ctl_v.* "\
                 ""
    re_words = re_xx_list.split()

    #
    # /dev/.udev/links/disk\x2fby-id\x2fdm-name-vg00-lv_root:
    # /dev/.udev/links/disk\x2fby-id\x2fdm-uuid-LVM-gQpdKXtTC6VPJJ0tStNFvSSImTY3iAEz2PpukazOUPWfFachTyrZA4FEx5adz9UI:
    # /dev/.udev/links/disk\x2fby-id\x2fscsi-36000144000000010300042a8c554efea:
    # /dev/.udev/links/disk\x2fby-id\x2fscsi-3600508b1001c31c471805c6564fa2ede-part1:
    # /dev/.udev/links/disk\x2fby-id\x2fwwn-0x6000144000000010300042a8c554efea:
    # /dev/.udev/links/disk\x2fby-id\x2fwwn-0x6000144000000010300042a8c554efea-part1:
    # /dev/.udev/links/disk\x2fby-id\x2fcciss-3600508b100104a395354503256480000:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:00:1f.2-scsi-0:0:0:0:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:05:00.0-scsi-0:0:0:0:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:05:00.0-scsi-0:0:0:0-part1:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:0b:00.0-fc-0x5000144280004203-lun-0:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:0b:00.0-fc-0x5000144280004203-lun-0-part1:
    # /dev/.udev/links/disk\x2fby-path\x2fpci-0000:0b:00.0-fc-0x5000144280004203-lun-0-part2:
    # /dev/.udev/links/disk\x2fby-uuid\x2f0d743882-728e-484a-8696-94d32f19d421:
    # /dev/.udev/links/disk\x2fby-uuid\x2f1da2b00d-281f-48e0-93a2-640fe5522b16:
    #
    udev_dirs = ""\
                ".udev/links/disk\\x2fby-id\\x2fdm-name- "\
                ".udev/links/disk\\x2fby-id\\x2fscsi- "\
                ".udev/links/disk\\x2fby-id\\x2fdm-uuid-LVM- "\
                ".udev/links/disk\\x2fby-id\\x2fdm-uuid-mpath- "\
                ".udev/links/disk\\x2fby-id\\x2fwwn- "\
                ".udev/links/disk\\x2fby-id\\x2fccw-IBM "\
                ".udev/links/disk\\x2fby-id\\x2fcciss "\
                ".udev/links/disk\\x2fby-path\\x2f "\
                ".udev/links/disk\\x2fby-uuid\\x2f "\
                ""
    udev_dwds = udev_dirs.split()

    udev_tape_dirs = ""\
        ".udev/links/st "\
        ".udev/links/nst "\
        ".udev/links/tape\\x2fby-id\\x2fscsi- "\
        ""
    udev_tape_dwds = udev_tape_dirs.split()

    curr_dir = ""
    subdir = ""
    major_minor = ""
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "":
            continue
        words = line.split()
        wc = len(words)
        word1 = words[0]

        if wc == 1:
            # new subdir
            # reset state variables

            udb = False
            udb_tape = False
            mpathb = False
            by_id = False
            by_label = False
            by_uuid = False
            by_path = False
            by_partuuid = False
            udnm = ""
            udid = ""

            if word1.startswith("/dev"):
                curr_dir = word1
                tmp = curr_dir.split("/")  # NB leading slash means tmp[0] = ""
                subdir = word1[5:].rstrip(":")  # remove leading "/dev/" and trailing ":". e.g.: /dev/cpu: --> cpu

                for udev_dir in udev_dwds:
                    if subdir.startswith(udev_dir):
                        udb = True
                        udnm = udev_dir
                        udid = subdir[len(udev_dir):].rstrip(':')

                for udev_tape_dir in udev_tape_dwds:
                    if subdir.startswith(udev_tape_dir):
                        remainder = "(n/a)"
                        if udev_tape_dir == ".udev/links/st" or udev_tape_dir == ".udev/links/nst":
                            # debug_print(0,subdir)
                            remainder = subdir[len(udev_tape_dir):]
                            if remainder == '' or remainder.isdigit():
                                pass
                            else:
                                # debug_print(0,"{0} should not be tape dir remainder='{1}'".format(subdir,remainder))
                                break
                        # debug_print(0,"{0} is tape dir remainder='{1}'".format(subdir,remainder))
                        udb_tape = True
                        udnm = subdir
                        utmp = subdir.split('/')
                        uwc = len(utmp)
                        udid = utmp[uwc - 1]

                if not udb and not udb_tape:
                    if subdir == "mpath":
                        mpathb = True
                    elif subdir == "disk/by-id":
                        by_id = True
                    elif subdir == "disk/by-label":
                        by_label = True
                    elif subdir == "disk/by-uuid":
                        by_uuid = True
                    elif subdir == "disk/by-path":
                        by_path = True
                    elif subdir == "disk/by-partuuid":
                        by_partuuid = True
            else:
                debug_print(2, "({0} {1}) first word?: {2}".format(i, ls_file, word1))
            continue
        # end: if wc == 1:

        if wc == 2:
            # usually "total 0"
            if word1 != "total":
                if words[1] != "0":  # occasionaly non 0
                    debug_print(2, "({0} {1}) not 'total 0': {2}".format(i, ls_file, line))
            continue
        # end: if wc == 2:
        word_adj = 0
        if wc > 6:
            if re.match(yyyy_mm_dd_re, words[5]) and re.match(hhmm_re, words[6]):
                word_adj = -1
            # this means that the date format is 'yyyy-mm-dd hh:mm' (2 tokens) rather than 'Mon dd hh:mm' (3 tokens)

        if wc == (9 + word_adj):
            perm = words[0]
            fn = words[8 + word_adj]

            if subdir == "cpu":
                perm = words[0]
                fn = words[8 + word_adj]
                if fn.isdigit():
                    cpu = int(fn)
                    set_cpu_count(cpu, ls_file)
            # end: if subdir == "cpu":

            # /dev:
            # ...
            # drwxr-xr-x   2 root root         680 Mar  3 13:14 vg_bi
            # drwxr-xr-x   2 root root         200 Mar  3 13:14 vg_biqa
            if curr_dir == "/dev:":  # top level
                if perm.startswith("drw") and fn.startswith("vg"):
                    update_vg(fn, '', ls_file)
            # end: if curr_dir == "/dev:": # top level

            continue
        # end: if wc == 9:

        # brw-------  1 root       root     8,   3 Sep  9 00:05 root
        # crw-------  1 root       root   246,   0 Aug 10 20:07 amf
        if wc == (10 + word_adj):
            perm = words[0]
            fn = words[9 + word_adj]

            if perm.startswith("brw") or perm.startswith("crw") or perm.startswith("b--"):
                major = words[4].rstrip(",")
                minor = words[5]
                if major.isdigit() and minor.isdigit():
                    major_minor = major + ":" + minor
                else:
                    error_print('d', "{0}:'{1}' ({2})".format(i, line, ls_file))
                    major_minor = ''
                    continue

                if fn == "root" and pass_no < 2:
                    continue  # allow vgscan alias to be created...

                ignore = False

                # brw-------  1 root       root     8,   3 Sep  9 00:05 root
                if perm.startswith("brw") or perm.startswith("b--"):
                    for ign_blck_fn in ign_blck_fn_words:
                        if ign_blck_fn != '' and re.match(ign_blck_fn, fn):
                            ignore = True
                            break
                # end: if perm.startswith("brw"):

                # crw-------  1 root       root   246,   0 Aug 10 20:07 amf
                if perm.startswith("crw"):
                    for ign_char_fn in ign_char_fn_words:
                        if ign_char_fn != '' and re.match(ign_char_fn, fn):
                            ignore = True
                            break
                # end: if perm.startswith("crw"):

                if ignore:
                    continue

                # crw-------  1 root       root   246,   0 Aug 10 20:07 amf
                if perm.startswith("crw"):
                    if subdir == "" and fn.startswith("sg"):
                        add_mm_cd(fn, major_minor, ls_file)  # scsi generic
                    if subdir == "" and is_tape(int(major)):
                        if re.match(st_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # std scsi tape
                        elif re.match(nst_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # std scsi tape
                        elif re.match(lt_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # lintape
                        elif re.match(lt_ch_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # lintape changer
                        elif re.match(tsm_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # TSMtape
                        elif re.match(rmt_re, fn):
                            add_mm_cd(fn, major_minor, ls_file)  # rmt0,..
                        elif re.match('fct[0-9]', fn):
                            add_mm_cd(fn, major_minor, ls_file)  # fct0,..
                        else:
                            add_mm_cd(fn, major_minor, ls_file)  # just add it anyway
                        # else: error_print("l","unknown char dev: '{0}' fn?".format(line))

                        debug_print(3, "tape char dev {0}".format(line))
                        # could do additional tracking on char tape devices if needed
                    continue  # don't need other char devices at this point..
                # end: if perm.startswith("crw"):

                # /dev/block
                #
                # brw-------  1 root       root     8,   3 Sep  9 00:05 root
                #
                # Fusion io char/block devices
                # crw-------.  1   0   0  10,  57 Jun  8 19:58 fct0
                # crw-------.  1   0   0  10,  56 Jun  8 19:58 fct1
                #
                # brw-rw----.  1   0   6 252,   0 Jun  8 19:58 fioa
                # brw-rw----.  1 101 101 252,   1 Jun  9 14:30 fioa1
                # brw-rw----.  1 101 101 252,   2 Jun  9 14:30 fioa2
                # brw-rw----.  1 101 101 252,   3 Jun  9 14:30 fioa3
                # brw-rw----.  1 101 101 252,   4 Jun  9 14:30 fioa4
                # brw-rw----.  1   0   6 252,  16 Jun  8 19:58 fiob
                # brw-rw----.  1 101 101 252,  17 Jun  9 14:30 fiob1
                # brw-rw----.  1 101 101 252,  18 Jun  9 14:30 fiob2
                # brw-rw----.  1 101 101 252,  19 Jun  9 14:30 fiob3
                # brw-rw----.  1 101 101 252,  20 Jun  9 14:30 fiob4
                #
                debug_print(4, "fn='{0}' mm='{1}' line {2} '{3}' ({4})".format(fn, major_minor, i, line, ls_file))

                vg_name = ''
                if subdir == "bsg" and fn[0:1].isdigit():
                    scsi_adr = fn
                    add_normalized_mm_data(scsi_adr, "", "", major_minor, line, "", ls_file)

                elif subdir == "mapper":
                    # vg_name = check_vg_prefix(fn,ls_file)
                    vg_name = split_valid_vg_name(fn, ls_file)
                    if vg_name != "":
                        lv_name = split_lv_name(fn, ls_file)
                        add_normalized_mm_data("", "", build_vg_lv(vg_name, lv_name, ls_file), major_minor, line, "", ls_file)

                elif subdir == "oracleasm/disks" or subdir == "asm":
                    if pass_no == 3:
                        check_oracle_dev_status(major, major_minor, fn, subdir, ls_file)
                        # exit(RC_OKAY)
                else:
                    pass
                # end: if ...

                if subdir == '':
                    add_mm_bd(fn, major_minor, ls_file)
                else:
                    if subdir == "mapper" and vg_name != '':
                        pass
                    else:
                        add_mm_bd(subdir + '/' + fn, major_minor, ls_file)
                check_dev_partition(fn, ls_file)

        # end: if wc == 10:

        # process links under /dev/block:
        # /dev/block:
        # lrwxrwxrwx  1 root root     8 Jan  9 09:28 128:1040 -> ../sdarj
        # lrwxrwxrwx  1 root root     9 Jan  9 09:28 128:1041 -> ../sdarj1
        # lrwxrwxrwx  1 root root     7 Jan  9 14:09 252:0 -> ../dm-0
        # lrwxrwxrwx  1 root root     7 Jan  9 14:09 252:1 -> ../dm-1
        #
        # process ls lines under /dev/.udev/links/disk...
        # lrwxrwxrwx   1 root root   28 Jul 17 12:35 b253:20 -> /devices/virtual/block/dm-20
        #
        # /dev/.udev/links/disk\x2fby-id\x2fscsi-36001405d3cd66ebfc3b4607aa09e71d7:
        # lrwxrwxrwx   1 0 0   94 Oct 24 05:11 b65:224 -> /devices/pci0000:00/0000:00:01.1/0000:02:00.0/host0/rport-0:0-2/target0:0:0/0:0:0:3/block/sdae
        # lrwxrwxrwx   1 0 0   93 Oct 24 05:11 b65:80 -> /devices/pci0000:00/0000:00:01.1/0000:02:00.1/host1/rport-1:0-4/target1:0:2/1:0:2:3/block/sdv
        #
        # process ls lines under /dev/.udev/links/st*|nst*
        # lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
        # lrwxrwxrwx   1 0 0    99 Jul 17 21:13 c9:1025 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/st129
        # lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
        # lrwxrwxrwx   1 0 0    99 Jul 17 21:13 c9:1025 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/st129
        # lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
        #
        # lrwxrwxrwx.  1 root root   15 2013-01-18 06:02 252:0 -> ../bsg/0:0:32:0 <<--- this date fmt has only 2 token, not 3
        #
        # process ls lines under /dev/mpath:
        # lrwxrwxrwx   1 root root    9 Dec  2 2014 asm-acfs1 -> ../dm-172
        #
        # lrwxrwxrwx   1 root root    43 Aug 17 02:37 b94:80 -> /devices/css0/0.0.0036/0.0.0830/block/dasdu
        # lrwxrwxrwx   1 root root    50 Aug 17 02:37 b94:81 -> /devices/css0/0.0.0036/0.0.0830/block/dasdu/dasdu1
        #
        # /dev/disk/by-label:
        # lrwxrwxrwx 1 root root  10 Jul 18 16:28 boot -> ../../sda1
        #
        if wc == (11 + word_adj):
            perm = words[0]
            fn = words[8 + word_adj]
            if perm.startswith("lrw"):
                lit_arrow = words[9 + word_adj]
                path = words[10 + word_adj]
                major_minor = ''
                if lit_arrow != "->":
                    error_print('d', "({0} {1}) lit_arrow?: {2}".format(i, ls_file, lit_arrow))
                    continue

                p_words = path.split("/")
                pwc = len(p_words)  # path word count
                p_fn = p_words[pwc - 1]

                if pass_no == 1 and ("/pci" in line and "/host" in line):
                    crunch_pci_and_host(i, line, words, path, p_words, ls_file)

                if subdir == "block":
                    if re.match(mm_re, fn) and (re.match(sd_re, p_fn) or re.match(dm_re, p_fn)):
                        add_mm_bd(p_fn, fn, ls_file)

                pass_action = 2
                pass_action = 1  # this will expedite an issue where uuids aren't known earlier in the sumsos process
                # but could break something else

                if fn.startswith("dvd") or fn.startswith("cd"):
                    alias = fn
                    # dev_2_aliases[path] = unique_list(dev_2_aliases[path],alias)
                    all_dev_aliases = unique_list(all_dev_aliases, alias)
                    # debug_print(z,"{0} {1}".format(fn,path))
                    mm = bd_2_mm[p_fn]
                    if mm != '':
                        add_mm_bd(fn, mm, ls_file)

                if pass_no == pass_action and udb:
                    b_or_c = fn[0:1]  # 'b' (or 'c')
                    major_minor = fn[1:]  # remove 'b' at the front
                    if p_fn.startswith("cciss!"):
                        p_fn = p_fn[len("cciss!"):]
                        track_cciss_devs(p_fn, major_minor, ls_file)
                    # p_lit_block = p_words[pwc-2]
                    # p_lit_virtual = p_words[pwc-3]
                    # p_lit_devices = p_words[pwc-4]

                    if s390 and "x2fccw-IBM" in udnm:
                        if "block" != p_words[5]:
                            continue  # Should Not Occur
                        cuuu = p_words[4]
                        dasdid = p_words[pwc - 1]  # last word in path, some are ../block/dasda - some are ../block/dasda/dasda1
                        vol1 = ''
                        track_s390_dasd(cuuu, dasdid, vol1, major_minor, '', '', '', ls_file)
                        continue

                    _dm = ''
                    _sd = ''
                    if re.match(dm_re, p_fn):
                        _dm = p_fn
                    if re.match(sd_re, p_fn):
                        _sd = p_fn
                    add_normalized_mm_data("", _sd, _dm, major_minor, line, "", ls_file)
                    crunch_udev_data(i, udnm, udid, curr_dir, pwc, p_words, p_fn, b_or_c, major_minor, line, ls_file)

                # end: if pass_no == 1 and udb:

                # lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
                if pass_no == pass_action and udb_tape:

                    u_mm = words[8 + word_adj]
                    if re.match("c" + n3_re + ":" + n4_re, u_mm):
                        u_mm = u_mm.strip("c")
                        major_minor = u_mm
                    crunch_udev_tape_data(i, udnm, udid, curr_dir, pwc, p_words, p_fn, b_or_c, major_minor, line, ls_file)
                # end: if pass_no == pass_action and udb_tape:

                if pass_no == pass_action and by_id:
                    p_fn = p_words[pwc - 1]   # last word of path: ../../sde
                    crunch_by_id_data(i, fn, curr_dir, p_fn, major_minor, line, ls_file)
                # end: if pass_no == pass_action and  by_id:

                if pass_no == pass_action and by_label:
                    p_fn = p_words[pwc - 1]   # last word of path: ../../sda1
                    # crunch_by_label_data(i,fn,curr_dir,p_fn,major_minor,line,ls_file)
                    # /dev/disk/by-label:
                    # lrwxrwxrwx 1 root root  10 Sep  9 00:06 SWAP-sda2 -> ../../sda2
                    # lrwxrwxrwx 1 root root  10 Sep  9 00:06 boot -> ../../sda1
                    # lrwxrwxrwx 1 root root  10 Sep  9 00:06 u2 -> ../../sdb1
                    # lrwxrwxrwx 1 root root  10 Sep  9 00:06 u3 -> ../../sdc1
                    label = fn
                    if label.startswith("\\x2f"):
                        label = label[len("\\x2f"):]  # remove \x2f
                    if label == '':
                        label = '/'
                    dev_id = p_fn
                    track_label(label, dev_id, ls_file)
                # end: if pass_no == pass_action and  by_label:

                if pass_no == pass_action and (by_uuid or by_partuuid):
                    p_fn = p_words[pwc - 1]   # last word of path: ../../sda1
                    if p_words[pwc - 2] == "cciss":
                        track_cciss_devs(p_fn, major_minor, ls_file)
                    # /dev/disk/by-uuid:
                    # lrwxrwxrwx 1 root root   9 May  8 01:04 16c2bc24-e465-49a5-9cd7-8b7e91a68552 -> ../../sda
                    # lrwxrwxrwx 1 root root   9 May  8 01:04 49ffd8b4-b2b7-468c-8ad4-545f9cefdc95 -> ../../sdd
                    # lrwxrwxrwx 1 root root   9 May  8 01:04 90ed0bf7-9ee7-48c6-b410-d6f766a180f6 -> ../../sdb
                    # lrwxrwxrwx 1 root root   9 May  8 01:04 a39a8a2a-aaff-4eea-9cc8-407d437a94f0 -> ../../sdc
                    # lrwxrwxrwx 1 root root  18 May  8 01:04 d0f60ab1-4eda-4f68-9f3d-ffd364df8379 -> ../../cciss/c0d0p3
                    # lrwxrwxrwx 1 root root  18 May  8 01:04 df7b3b8a-713a-41a5-9291-85d9f57f2e0c -> ../../cciss/c0d0p1
                    #
                    # lrwxrwxrwx. 1 0 0   9 Sep 25 08:50 2017-09-20-06-24-36-0 -> ../../sr0 (case )
                    uuid = fn
                    dev_id = p_fn
                    # debug_print(z,"{0} {1} ({2})".format(uuid,dev_id,ls_file))
                    if len(uuid) >= len("yyyy-mm-dd"):
                        if re.match(yyyy_mm_dd_re, uuid[0:len("yyyy-mm-dd")]):
                            continue
                    u_type = ''
                    if by_partuuid:
                        u_type = "partition"
                    track_uuid(clean_uuid(uuid), dev_id, u_type, ls_file)
                # end: if pass_no == pass_action and  by_uuid:

                if pass_no == pass_action and by_path:
                    p_fn = p_words[pwc - 1]   # last word of path: ../../sda1

                    # look for these types of lines:
                    # lrwxrwxrwx 1 root root   9 Mar 28 20:07 ip-149.191.38.107:3260-iscsi-iqn.1992-08.com.netapp:sn.0e8f9ab19e3611e396dc123478563412:vs.5-lun-0 -> ../../sde
                    # lrwxrwxrwx 1 root root   9 Mar 20 17:53 pci-0000:00:1f.2-scsi-4:0:0:0 -> ../../sr0
                    # lrwxrwxrwx 1 root root   9 Mar 20 17:53 pci-0000:02:00.0-scsi-0:2:0:0 -> ../../sda
                    # lrwxrwxrwx 1 root root  10 Mar 20 17:53 pci-0000:02:00.0-scsi-0:2:0:0-part1 -> ../../sda1

                    if re.match(sd_re, p_fn) or re.match(sd_re_p, p_fn) or re.match(sr_re, p_fn) or re.match(st_re, p_fn):
                        if fn.startswith("pci-") and "-scsi-" in fn:
                            tmp = fn.split("-")
                            # "pci"  = tmp[0]
                            # pci_adr = tmp[1][5:] # minus leading "0000:"
                            pci_adr = tmp[1]  # full pci address
                            # "scsi" = tmp[2]
                            lt = len(tmp)
                            for tkn in range(2, lt):
                                if tmp[tkn] == "scsi":
                                    # scsi_adr = dev_2_lun[p_fn] # trust proc/scsi/scsi over ls for now
                                    scsi_adr = tmp[tkn + 1]
                            # if scsi_adr == "": scsi_adr = tmp[3]
                            tmp = scsi_adr.split(":")
                            scsi_host = tmp[0]
                            # debug_print(z,"{0} '{1}' {2} ({3})".format(i,line,scsi_adr,ls_file))
                            #
                            # these lines seem to be inaccurate in that they usually have a host and bus of 0 (0:0:t:l)
                            # the target and lun match up with other instances of the device, but 0:0 gives us DUP-1 anomalies...
                            # so commenting out.
                            # track_pci_address_and_host(pci_adr,'',scsi_host,ls_file)
                        # end: if fn.startswith("pci-") and "-scsi-" in fn:
                        if fn.startswith("ip-"):
                            scsi_adr = dev_2_lun[p_fn]
                            debug_print(4, "'{0}' '{1}' '{2}'".format(p_fn, fn, scsi_adr))
                            if scsi_adr != '':
                                tmp = scsi_adr.split(":")
                                scsi_host = tmp[0]
                                track_hba(scsi_host, "iscsi", ls_file)
                            # end: if scsi_adr != '':
                        # end: if fn.startswith("ip-"):

                    # end: if re.match(sd_re,p_fn) or re.match(sd_re_p,p_fn) or re.match(sr_re,p_fn)  or re.match(st_re,p_fn):
                # end: if pass_no == pass_action and  by_path:

                if pass_no == pass_action and mpathb:
                    p_fn = p_words[1]  # .. / dm-nn
                    crunch_mpath_data(i, fn, curr_dir, p_fn, major_minor, line, ls_file)
                # end: if pass_no == pass_action and  mpathb:

                # TODO - process x2fby-id/s2fscsi-36...
                # 01502342/cclprddwora4c-2015090212411441212104/sos_commands/devicemapper/ls_-laR_.dev

        # end: if wc == 11: # link line
    # end: for line in fh:
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ls_file))
    return

# ---------------------------------------------#
# function: check_oracle_dev_status()
# produce ORACLE Anomalies if the associated Oracle device;
# 1) does not have a "dm" type major number
# 2) not associated with an iscsi host
# ---------------------------------------------#


def check_oracle_dev_status(major, mm, dev_id, sub_dir, source):
    global all_oracle_sd_devices  # ''
    global all_oracle_sd_device_subdirs  # ''
    global all_oracle_sd_device_sources  # ''

    debug_print(3, "check_oracle_dev_status({0},{1},{2},{3},({4})".format(major, mm, dev_id, sub_dir, source))

    if not is_sd(int(major)):
        return  # all is well, not sd type major number

    dev_id2 = conv_mm_2_bd(mm)
    debug_print(3, "check_oracle_dev_status: {0}=get_mm_2_id({1},'')".format(dev_id2, mm))

    last_char = dev_id2[len(dev_id2) - 1:]
    if last_char.isdigit():
        dev_id2 = dev_id2[0:len(dev_id2) - 1]

    scsi_adr = dev_2_lun[dev_id2]
    debug_print(3, "check_oracle_dev_status: {0}=dev_2_lun[{1}]".format(scsi_adr, dev_id2,))

    if scsi_adr != '':
        tmp = scsi_adr.split(':')
        host = tmp[0]
        if "iscsi" in scsi_host[host]:
            # iscsi is effective multipathing
            return

    all_oracle_sd_devices = unique_list(all_oracle_sd_devices, dev_id)
    all_oracle_sd_device_subdirs = unique_list(all_oracle_sd_device_subdirs, sub_dir)
    all_oracle_sd_device_sources = unique_list(all_oracle_sd_device_sources, source)
    return

# ---------------------------------------------#
# function: check_for_oracle_sd_anomalies()
# ---------------------------------------------#


def check_for_oracle_sd_anomlaies():
    global all_oracle_sd_devices  # ''
    global all_oracle_sd_device_subdirs  # ''
    global all_oracle_sd_device_sources  # ''
    global Virtual_guest
    global all_dev_mfgs  # ''
    global major_block_type  # Key_data() # key major number, data block type description

    if all_oracle_sd_devices == '':
        return

    tmp = all_oracle_sd_devices.split()
    wc = len(tmp)

    anomaly_line = "Warning: {0} oracle disk{1} {2} sd major/minor number{3} [see {4}] ({5})".\
                   format(wc, plural(wc), has_have(wc), plural(wc), all_oracle_sd_device_subdirs, all_oracle_sd_device_sources)
    handle_anomaly_with_points("ORACLE", anomaly_line, 'configuration', 1)

    # TODO: check case

    needed_SO_setting = "dm"
    needed_SE_setting = "sd"
    emcpower_present = False
    if word_in_list('EMC', all_dev_mfgs) or word_in_list('DGC', all_dev_mfgs):
        for maj in range(0, 1024 + 1):
            if 'power' in major_block_type[maj]:
                emcpower_present = True
        # end: for maj in range(0,1024+1):
        if emcpower_present:
            needed_SO_setting = "emcpower"

    vm_blurb = ""
    if Virtual_guest:
        vm_blurb = "(mitigated by virtualization)"

    anomaly_line = squeeze('prior ORACLE anomaly may be caused by incorrect or missing settings in /etc/sysconfig/oracleasm, {0} {1}'.
                           format(vm_blurb, cfa_kcs("88573")))
    handle_anomaly("ORACLE", anomaly_line)

    anomaly_line = 'ORACLEASM_SCANORDER should be "{0}", currently set to "{1}"'.\
                   format(needed_SO_setting, OracleASM["ORACLEASM_SCANORDER"])
    handle_anomaly("ORACLE", anomaly_line)

    anomaly_line = 'ORACLEASM_SCANEXCLUDE should be "{0}", currently set to "{1}"'.\
                   format(needed_SE_setting, OracleASM["ORACLEASM_SCANEXCLUDE"])
    handle_anomaly("ORACLE", anomaly_line)
    return

# ---------------------------------------------#
# function: crunch_by_id_data()
# /dev/disk/by-id:
# lrwxrwxrwx 1 root root   9 Jul 18 16:28 scsi-36006016009403b00e7049178410fe511 -> ../../sde
# ---------------------------------------------#


def crunch_by_id_data(i, fn, curr_dir, p_fn, major_minor, line, source):
    global scsi_id_2_devs  # Key_data()
    global dev_2_scsi_id  # Key_data()
    global dev_2_wwn_id  # Key_data()
    # global scsi_id_2_dev_origin # Key_data()

    if fn.startswith("scsi-"):
        # print("@crunch by_id({0} {1}) fn:{2} cd:{3} pfn:{4} line:'{5}'".format(i,source,fn,curr_dir,p_fn,line))
        scsi_id = fn[len("scsi-"):]

        if is_scsi_id(scsi_id):
            track_scsi_id(scsi_id, p_fn, source)
        else:
            return  # most likely alternative scsi id such as: SHITACHI_OPEN-V_50450328
        # else: error_print('d',"invalid scsi id: '{0}'".format(scsi_id))

        parent_dev_id = get_dev_from_part_id(p_fn, source)
        if parent_dev_id != '':
            add_partition_2_dev(parent_dev_id, p_fn, source)
        return
        # end of> if fn.startswith("scsi-")
    elif fn.startswith("wwn-0x"):
        # debug_print(z,"({0} {1}) fn:{2} cd:{3} pfn:{4} line:'{5}'".format(i,source,fn,curr_dir,p_fn,line))
        wwn_id = fn[len("wwn-0x"):]

        # scsi_id = dev_2_scsi_id[p_fn]
        # if scsi_id != '':
        # if scsi_ids_equal(wwn_id,scsi_id):
        # debug_print(4,'{0} = {1}'.format(wwn_id,scsi_id))
        # return

        if is_wwn_id(wwn_id):
            track_wwn_id(wwn_id, p_fn, source)
        else:
            error_print('d', "line {0}, invalid wwn id: '{1}' ({2})".format(i, wwn_id, source))

        parent_dev_id = get_dev_from_part_id(p_fn, source)
        if parent_dev_id != '':
            add_partition_2_dev(parent_dev_id, p_fn, source)

        return
        # end of> if fn.startswith("wwn-")

    return

# ---------------------------------------------#
# function: track_scsi_id()
# ---------------------------------------------#


def track_scsi_id(scsi_id, dev_id, source):
    global dev_2_scsi_id  # Key_data()
    global dev_2_scsi_id_origin  # Key_data()
    global scsi_id_2_devs  # Key_data()
    global scsi_id_2_parts  # Key_data()
    global all_scsi_ids
    global max_scsi_id  # 0
    global len_std_scsi_id  # 33

    debug_print(4, "{0} '{1}' ({2})".format(scsi_id, dev_id, source))

    # if scsi_id == dev_id: return # case  sos_commands/devicemapper/dmsetup_info_-ck
    # strange but true - not a bug

    if dev_id == '' and "vgscan" in source:
        # debug_print(z,"{0} {1} ({2})".format(scsi_id,dev_id,source))
        # print 444 / 0
        return  # sometimes the scsi id is found before the mm_2_bd relationship is set

    debug_print(3, "{0} {1} ({2})".format(scsi_id, dev_id, source))
    if not is_scsi_id(scsi_id):
        error_print("d", "{0} {1} ({2})".format(scsi_id, dev_id, source))
        errorprint(0 / 0)
        return

    true_scsi_id = get_dev_from_part_id(scsi_id, source)
    if true_scsi_id == '':
        true_scsi_id = scsi_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_scsi_ids = unique_list(all_scsi_ids, true_scsi_id)
    if dev_2_scsi_id[true_dev_id] == "":
        dev_2_scsi_id[true_dev_id] = true_scsi_id
        dev_2_scsi_id_origin[true_dev_id] = source
    else:
        # if dev_2_scsi_id[true_dev_id] != true_scsi_id:
        if not scsi_ids_equal(dev_2_scsi_id[true_dev_id], true_scsi_id):
            anomaly_line = "device id {0} already set to scsi id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_scsi_id[true_dev_id], dev_2_scsi_id_origin[true_dev_id], scsi_id, source)
            handle_anomaly("DUP-1", anomaly_line)
            # https://access.redhat.com/solutions/319453  -- explains scsi and wwn ids
    if true_scsi_id == scsi_id:
        scsi_id_2_devs[true_scsi_id] = unique_list(scsi_id_2_devs[true_scsi_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(scsi_id, dev_id)
        scsi_id_2_parts[true_scsi_id] = unique_list(scsi_id_2_parts[true_scsi_id], part_and_dev_id)

    max_scsi_id = max(max_scsi_id, len(scsi_id))

    return


# ---------------------------------------------#
# function: scsi_ids_equal()
# allow equality when two scsi ids are the same
# but one or both has additional partition text appended to it:
# e.g.:  360002ac0000000000000012a0001276fp2 == 360002ac0000000000000012a0001276fp1
# ---------------------------------------------#
def scsi_ids_equal(scsi_id1, scsi_id2):
    global len_std_scsi_id  # 33

    if scsi_id1 == scsi_id2:
        return(True)

    s1 = scsi_id1
    s2 = scsi_id2

    s1 = scsi_strip(s1)
    s2 = scsi_strip(s2)
    if s1 == s2:
        return(True)

    if is_partition_id(s1, ''):
        s1 = get_dev_from_part_id(s1, '')
    if is_partition_id(s2, ''):
        s2 = get_dev_from_part_id(s2, '')
    # debug_print(z,'{0} {1}'.format(s1,s2))
    if s1 == s2:
        return(True)

    l1 = len(scsi_id1)
    l2 = len(scsi_id2)

    if l1 == l2 == len_std_scsi_id:
        return(False)

    if (l1 < len_std_scsi_id) or (l2 < len_std_scsi_id):
        return(False)

    if scsi_id1[0:len_std_scsi_id] != scsi_id1[0:len_std_scsi_id]:
        return(False)

    extra1 = ''
    extra2 = ''

    if l1 > len_std_scsi_id and get_len_partition_suffix(scsi_id1) == 0:
        return(False)
    if l2 > len_std_scsi_id and get_len_partition_suffix(scsi_id2) == 0:
        return(False)

    return(True)

# ---------------------------------------------#
# function scsi_strip()
# ---------------------------------------------#


def scsi_strip(s):

    if s.startswith("0x"):
        return(s[2:])
    # if s.startswith("3"): return(s[1:]) # why would this be done??
    return(s)


# ---------------------------------------------#
# function: track_iscsi_id()
# ---------------------------------------------#
def track_iscsi_id(iscsi_id, dev_id, source):
    global dev_2_iscsi_id  # Key_data()
    global dev_2_iscsi_id_origin  # Key_data()
    global iscsi_id_2_devs  # Key_data()
    global iscsi_id_2_parts  # Key_data()
    global all_iscsi_ids
    global max_iscsi_id  # 0
    global len_std_scsi_id  # 33

    debug_print(3, "{0} {1} ({2})".format(iscsi_id, dev_id, source))
    if not is_iscsi_id(iscsi_id):
        error_print("d", "{0} {1} ({2})".format(iscsi_id, dev_id, source))
        return

    true_iscsi_id = get_dev_from_part_id(iscsi_id, source)
    if true_iscsi_id == '':
        true_iscsi_id = iscsi_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_iscsi_ids = unique_list(all_iscsi_ids, true_iscsi_id)
    if dev_2_iscsi_id[true_dev_id] == "":
        dev_2_iscsi_id[true_dev_id] = true_iscsi_id
        dev_2_iscsi_id_origin[true_dev_id] = source
    else:
        if dev_2_iscsi_id[true_dev_id] != true_iscsi_id:
            anomaly_line = "device id {0} already set to iscsi id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_iscsi_id[true_dev_id], dev_2_iscsi_id_origin[true_dev_id], iscsi_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_iscsi_id == iscsi_id:
        iscsi_id_2_devs[true_iscsi_id] = unique_list(iscsi_id_2_devs[true_iscsi_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(iscsi_id, dev_id)
        iscsi_id_2_parts[true_iscsi_id] = unique_list(iscsi_id_2_parts[true_iscsi_id], part_and_dev_id)

    max_iscsi_id = max(max_iscsi_id, len(iscsi_id))

    return

# ---------------------------------------------#
# function: track_sata_id()
# ---------------------------------------------#


def track_sata_id(sata_id, dev_id, source):
    global dev_2_sata_id  # Key_data()
    global dev_2_sata_id_origin  # Key_data()
    global sata_id_2_devs  # Key_data()
    global sata_id_2_parts  # Key_data()
    global all_sata_ids
    global max_sata_id  # 0
    global len_std_sata_id  # 13

    debug_print(3, "{0} {1} ({2})".format(sata_id, dev_id, source))
    if not is_sata_id(sata_id):
        error_print("d", "{0} {1} ({2})".format(sata_id, dev_id, source))
        return

    true_sata_id = get_dev_from_part_id(sata_id, source)
    if true_sata_id == '':
        true_sata_id = sata_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_sata_ids = unique_list(all_sata_ids, true_sata_id)
    if dev_2_sata_id[true_dev_id] == "":
        dev_2_sata_id[true_dev_id] = true_sata_id
        dev_2_sata_id_origin[true_dev_id] = source
    else:
        if dev_2_sata_id[true_dev_id] != true_sata_id:
            anomaly_line = "device id {0} already set to sata id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_sata_id[true_dev_id], dev_2_sata_id_origin[true_dev_id], sata_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_sata_id == sata_id:
        sata_id_2_devs[true_sata_id] = unique_list(sata_id_2_devs[true_sata_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(sata_id, dev_id)
        sata_id_2_parts[true_sata_id] = unique_list(sata_id_2_parts[true_sata_id], part_and_dev_id)

    max_sata_id = max(max_sata_id, len(sata_id))

    return

# ---------------------------------------------#
# function: track_ata_id()
# ---------------------------------------------#


def track_ata_id(ata_id, dev_id, source):
    global dev_2_ata_id  # Key_data()
    global dev_2_ata_id_origin  # Key_data()
    global ata_id_2_devs  # Key_data()
    global ata_id_2_parts  # Key_data()
    global all_ata_ids
    global max_ata_id  # 0
    global len_std_ata_id  # 13
    global n_dot_m_re

    debug_print(3, "{0} {1} ({2})".format(ata_id, dev_id, source))
    if not is_ata_id(ata_id):
        error_print("d", "{0} {1} ({2})".format(ata_id, dev_id, source))
        return

    true_ata_id = get_dev_from_part_id(ata_id, source)
    if true_ata_id == '':
        true_ata_id = ata_id
    # debug_print(z,"true ata:{0} ata:{1}".format(true_ata_id,ata_id))

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_ata_ids = unique_list(all_ata_ids, true_ata_id)
    if dev_2_ata_id[true_dev_id] == "":
        dev_2_ata_id[true_dev_id] = true_ata_id
        dev_2_ata_id_origin[true_dev_id] = source
    else:
        if dev_2_ata_id[true_dev_id] != true_ata_id:
            if re.match(n_dot_m_re, ata_id):
                pass  # secondary ata ids often given in n.m or n.m-partn format -- ok
            else:
                anomaly_line = "device id {0} already set to ata id {1} ({2}) while trying to set to {3} ({4})".\
                    format(true_dev_id, dev_2_ata_id[true_dev_id], dev_2_ata_id_origin[true_dev_id], ata_id, source)
                handle_anomaly("DUP-1", anomaly_line)
    if true_ata_id == ata_id:
        ata_id_2_devs[true_ata_id] = unique_list(ata_id_2_devs[true_ata_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(ata_id, dev_id)
        ata_id_2_parts[true_ata_id] = unique_list(ata_id_2_parts[true_ata_id], part_and_dev_id)

    max_ata_id = max(max_ata_id, len(ata_id))

    return

# ---------------------------------------------#
# function: track_usb_id()
# ---------------------------------------------#


def track_usb_id(usb_id, dev_id, source):
    global dev_2_usb_id  # Key_data()
    global dev_2_usb_id_origin  # Key_data()
    global usb_id_2_devs  # Key_data()
    global usb_id_2_parts  # Key_data()
    global all_usb_ids
    global max_usb_id  # 0
    global len_std_usb_id  # -1

    debug_print(3, "{0} {1} ({2})".format(usb_id, dev_id, source))
    if not is_usb_id(usb_id):
        error_print("d", "{0} {1} ({2})".format(usb_id, dev_id, source))
        return

    true_usb_id = get_dev_from_part_id(usb_id, source)
    if true_usb_id == '':
        true_usb_id = usb_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_usb_ids = unique_list(all_usb_ids, true_usb_id)
    if dev_2_usb_id[true_dev_id] == "":
        dev_2_usb_id[true_dev_id] = true_usb_id
        dev_2_usb_id_origin[true_dev_id] = source
    else:
        if dev_2_usb_id[true_dev_id] != true_usb_id:
            anomaly_line = "device id {0} already set to usb id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_usb_id[true_dev_id], dev_2_usb_id_origin[true_dev_id], usb_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_usb_id == usb_id:
        usb_id_2_devs[true_usb_id] = unique_list(usb_id_2_devs[true_usb_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(usb_id, dev_id)
        usb_id_2_parts[true_usb_id] = unique_list(usb_id_2_parts[true_usb_id], part_and_dev_id)

    max_usb_id = max(max_usb_id, len(usb_id))

    return

# ---------------------------------------------#
# function: track_sas_id()
# ---------------------------------------------#


def track_sas_id(sas_id, dev_id, source):
    global dev_2_sas_id  # Key_data()
    global dev_2_sas_id_origin  # Key_data()
    global sas_id_2_devs  # Key_data()
    global sas_id_2_parts  # Key_data()
    global all_sas_ids
    global max_sas_id  # 0
    global len_std_sas_id  # -1

    debug_print(3, "{0} {1} ({2})".format(sas_id, dev_id, source))
    if not is_sas_id(sas_id):
        error_print("d", "{0} {1} ({2})".format(sas_id, dev_id, source))
        return

    # check for sas_id of this type: exp0x500304801eded5bf-phy0-lun-0  (expansion chasis id) e.g.:
    #
    # case:
    # /dev/disk/by-path/pci-0000:03:00.0-sas-0x5000cca2510173b1-lun-0: Aliased to /dev/sdb in device cache (8:16)
    # /dev/disk/by-path/pci-0000:03:00.0-sas-exp0x500304801eded63f-phy0-lun-0: Aliased to /dev/sdb in device cache (8:16)
    # /dev/disk/by-path/pci-0000:03:00.0-sas-0x5000cca25101d945-lun-0: Aliased to /dev/sdc in device cache (8:32)
    # /dev/disk/by-path/pci-0000:03:00.0-sas-exp0x500304801eded63f-phy1-lun-0: Aliased to /dev/sdc in device cache (8:32)
    # Note the hex portion of the sas id does not change for 'exp'ansion ids.
    if sas_id.startswith("exp0x5"):
        return

    true_sas_id = get_dev_from_part_id(sas_id, source)
    if true_sas_id == '':
        true_sas_id = sas_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_sas_ids = unique_list(all_sas_ids, true_sas_id)
    if dev_2_sas_id[true_dev_id] == "":
        dev_2_sas_id[true_dev_id] = true_sas_id
        dev_2_sas_id_origin[true_dev_id] = source
    else:
        if not sas_ids_equal(dev_2_sas_id[true_dev_id], true_sas_id):
            anomaly_line = "device id {0} already set to sas id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_sas_id[true_dev_id], dev_2_sas_id_origin[true_dev_id], sas_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_sas_id == sas_id:
        sas_id_2_devs[true_sas_id] = unique_list(sas_id_2_devs[true_sas_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(sas_id, dev_id)
        sas_id_2_parts[true_sas_id] = unique_list(sas_id_2_parts[true_sas_id], part_and_dev_id)

    max_sas_id = max(max_sas_id, len(sas_id))

    return

# ---------------------------------------------#
# function: sas_ids_equal()
# helper function to determine sis id equality.
# not sure why we end up seeing some sas ids as 'phy3-lun-0'
# rather than something like 0x5000c5009e7d43f9-lun-0 (expected)
# ---------------------------------------------#


def sas_ids_equal(sas_id1, sas_id2):
    if sas_id1 == sas_id2:
        return(True)
    if sas_id1.startswith("0x5") and sas_id2.startswith("0x5"):
        return(False)
    if sas_id1.startswith("0x5") and sas_id2.startswith("phy"):
        return(True)  # allow
    if sas_id1.startswith("phy") and sas_id2.startswith("0x5"):
        return(True)  # allow
    return(False)

# ---------------------------------------------#
# function: track_virtio_id()
# ---------------------------------------------#


def track_virtio_id(virtio_id, dev_id, source):
    global dev_2_virtio_id  # Key_data()
    global dev_2_virtio_id_origin  # Key_data()
    global virtio_id_2_devs  # Key_data()
    global virtio_id_2_parts  # Key_data()
    global all_virtio_ids
    global max_virtio_id  # 0
    global len_std_virtio_id  # -1

    debug_print(4, "'{0}' '{1}' ({2})".format(virtio_id, dev_id, source))
    if not is_virtio_id(virtio_id):
        error_print("d", "{0} {1} ({2})".format(virtio_id, dev_id, source))
        return

    if dev_id == '' and "vgscan" in source:
        # debug_print(z,"{0} {1} ({2})".format(virtio_id,dev_id,source))
        # print 444 / 0
        return  # sometimes the virtio_id id is found before the mm_2_bd relationship is set

    true_virtio_id = get_dev_from_part_id(virtio_id, source)
    if true_virtio_id == '':
        true_virtio_id = virtio_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_virtio_ids = unique_list(all_virtio_ids, true_virtio_id)
    if dev_2_virtio_id[true_dev_id] == "":
        dev_2_virtio_id[true_dev_id] = true_virtio_id
        dev_2_virtio_id_origin[true_dev_id] = source
    else:
        if dev_2_virtio_id[true_dev_id] != true_virtio_id:
            anomaly_line = "device id {0} already set to virtio id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_virtio_id[true_dev_id], dev_2_virtio_id_origin[true_dev_id], virtio_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_virtio_id == virtio_id:
        virtio_id_2_devs[true_virtio_id] = unique_list(virtio_id_2_devs[true_virtio_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(virtio_id, dev_id)
        virtio_id_2_parts[true_virtio_id] = unique_list(virtio_id_2_parts[true_virtio_id], part_and_dev_id)

    max_virtio_id = max(max_virtio_id, len(virtio_id))

    return


# ---------------------------------------------#
# function: track_other_id()
# ---------------------------------------------#
def track_other_id(other_id, dev_id, source):
    global dev_2_other_id  # Key_data()
    global dev_2_other_id_origin  # Key_data()
    global other_id_2_devs  # Key_data()
    global other_id_2_parts  # Key_data()
    global all_other_ids
    global max_other_id  # 0
    global len_std_other_id  # ??

    debug_print(0, "{0} {1} ({2})".format(other_id, dev_id, source))
    # if not is_other_id(other_id):
    # error_print("d","{0} {1} ({2})".format(other_id,dev_id,source))
    # return
    errorprint(999 / 0)

    true_other_id = get_dev_from_part_id(other_id, source)
    if true_other_id == '':
        true_other_id = other_id

    all_other_ids = unique_list(all_other_ids, true_other_id)
    if dev_2_other_id[dev_id] == "":
        dev_2_other_id[dev_id] = true_other_id
        dev_2_other_id_origin[dev_id] = source
    else:
        if dev_2_other_id[dev_id] != true_other_id:
            anomaly_line = "device id {0} already set to other id {1} ({2}) while trying to set to {3} ({4})".\
                format(dev_id, dev_2_other_id[dev_id], dev_2_sata_id_origin[dev_id], other_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_other_id == other_id:
        other_id_2_devs[true_other_id] = unique_list(other_id_2_devs[true_other_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(other_id, dev_id)
        other_id_2_parts[true_other_id] = unique_list(other_id_2_parts[true_other_id], part_and_dev_id)

    max_other_id = max(max_other_id, len(other_id))

    return
# ---------------------------------------------#
# function: track_fc_id()
# ---------------------------------------------#


def track_fc_id(fc_id, dev_id, source):
    global dev_2_fc_id  # Key_data()
    global dev_2_fc_id_origin  # Key_data()
    global fc_id_2_devs  # Key_data()
    global all_fc_ids
    global max_fc_id  # 0

    if dev_id == '':
        debug_print(4, "{0} {1} ({2})".format(fc_id, dev_id, source))
        errorprint(333 / 0)  # REMOVE
    if not is_fc_id(fc_id):
        error_print("d", "{0} {1} ({2})".format(fc_id, dev_id, source))
        return

    true_fc_id = get_dev_from_part_id(fc_id, source)
    if true_fc_id == '':
        true_fc_id = fc_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_fc_ids = unique_list(all_fc_ids, fc_id)
    if dev_2_fc_id[true_dev_id] == "":
        dev_2_fc_id[true_dev_id] = true_fc_id
        dev_2_fc_id_origin[true_dev_id] = source
    else:
        if dev_2_fc_id[true_dev_id] != true_fc_id:
            anomaly_line = "device id {0} already set to fc id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_fc_id[true_dev_id], dev_2_fc_id_origin[true_dev_id], fc_id, source)
            handle_anomaly("DUP-1", anomaly_line)
    if true_fc_id == fc_id:
        fc_id_2_devs[true_fc_id] = unique_list(fc_id_2_devs[true_fc_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(fc_id, dev_id)
        fc_id_2_parts[true_fc_id] = unique_list(fc_id_2_parts[true_fc_id], part_and_dev_id)

    max_fc_id = max(max_fc_id, len(fc_id))

    return

# ---------------------------------------------#
# function: track_wwn_id()
# ---------------------------------------------#


def track_wwn_id(wwn_id, dev_id, source):
    global dev_2_wwn_id  # Key_data()
    global dev_2_wwn_id_origin  # Key_data()
    global wwn_id_2_devs  # Key_data()
    global all_wwn_ids
    global max_wwn_id

    # debug_print(z,"'{0}' '{1}' ({2})".format(wwn_id,dev_id,source))

    if dev_id == '' and "vgscan" in source:
        # debug_print(z,"{0} {1} ({2})".format(scsi_id,dev_id,source))
        # print 444 / 0
        return  # sometimes the wwn id is found before the mm_2_bd relationship is set

    if not is_wwn_id(wwn_id):
        error_print("d", "invalid wwn id: '{0}' '{1}' ({2})".format(wwn_id, dev_id, source))

    true_wwn_id = get_dev_from_part_id(wwn_id, source)
    if true_wwn_id == '':
        true_wwn_id = wwn_id

    true_dev_id = get_dev_from_part_id(dev_id, source)
    if true_dev_id == '':
        true_dev_id = dev_id

    all_wwn_ids = unique_list(all_wwn_ids, true_wwn_id)
    if dev_2_wwn_id[true_dev_id] == "":
        dev_2_wwn_id[true_dev_id] = true_wwn_id
        dev_2_wwn_id_origin[true_dev_id] = source
    else:
        if dev_2_wwn_id[true_dev_id] != true_wwn_id:
            anomaly_line = "device id {0} already set to wwn id {1} ({2}) while trying to set to {3} ({4})".\
                format(true_dev_id, dev_2_wwn_id[true_dev_id], dev_2_wwn_id_origin[true_dev_id], wwn_id, source)
            handle_anomaly("DUP-1", anomaly_line)
            if (dev_id.endswith("1") or dev_id.endswith("2")) and "-part" not in wwn_id:
                errorprint(9999 / 0)

    if true_wwn_id == wwn_id:
        wwn_id_2_devs[true_wwn_id] = unique_list(wwn_id_2_devs[true_wwn_id], dev_id)
    else:
        part_and_dev_id = "{0}:{1}".format(wwn_id, dev_id)
        wwn_id_2_parts[true_wwn_id] = unique_list(wwn_id_2_parts[true_wwn_id], part_and_dev_id)

    max_wwn_id = max(max_wwn_id, len(wwn_id))

    return

# ---------------------------------------------#
# function: track_md_id()
# ---------------------------------------------#


def track_md_id(md_id, dev_id, md_uuid, md_dev_uuid, source):
    global dev_2_md_id  # Key_data()
    global dev_2_md_id_origin  # Key_data()
    global md_id_2_devs  # Key_data()
    global md_id_2_uuid  # Key_data()
    global md_id_2_dev_uuid  # Key_data()
    global all_md_ids
    global max_md_id  # 0

    all_md_ids = unique_list(all_md_ids, md_id)
    if dev_id != '':
        if dev_2_md_id[dev_id] == "":
            dev_2_md_id[dev_id] = md_id
            dev_2_md_id_origin[dev_id] = source
        else:
            dev_2_md_id[dev_id] = unique_list(dev_2_md_id[dev_id], md_id)
            dev_2_md_id_origin[dev_id] = unique_list(dev_2_md_id_origin[dev_id], source)
            # if dev_2_md_id[dev_id] != md_id:
            # anomaly_line = "device id {0} already set to md id {1} ({2}) while trying to set to {3} ({4})".\
            # format(dev_id,dev_2_md_id[dev_id],dev_2_md_id_origin[dev_id],md_id,source)
            # handle_anomaly("DUP-1",anomaly_line)
        md_id_2_devs[md_id] = unique_list(md_id_2_devs[md_id], dev_id)

    if md_uuid != '':
        md_id_2_uuid[md_id] = md_uuid
    if md_dev_uuid != '':
        md_id_2_dev_uuid[md_id] = md_dev_uuid

    max_md_id = max(max_md_id, len(md_id))

    return


# ---------------------------------------------#
# function: track_label()
# /dev/disk/by-label:
# lrwxrwxrwx 1 root root  10 Jul 18 16:28 boot -> ../../sda1
# ---------------------------------------------#
def track_label(label, dev_id, source):
    global dev_2_label          # Key_data()
    global dev_2_label_origin   # Key_data()
    global label_2_devs         # Key_data()
    global all_label_ids  # ""
    global all_dev_aliases  # ""
    global max_label

    debug_print(4, "label:{0} dev_id:{1} ({2})".format(label, dev_id, source))
    # TODO handle label: 'var\x2fcrash' -- apparently we should change \ to / and lose 'x2f' .. check more data
    # see 01679240

    if "\\x2f" in label:
        label = label.replace("\\x2f", "/")

    # skip tracking if dev_id is an alias ??
    # tmp_dev_id = dev_id
    # if dev_id.startswith("/dev/"): tmp_dev_id = dev_id[len("/dev/"):]
    if dev_id.startswith("/dev/"):
        dev_id = dev_id[len("/dev/"):]

    # if word_in_list(tmp_dev_id,all_dev_aliases): return()
    if word_in_list(dev_id, all_dev_aliases):
        return()

    all_label_ids = unique_list(all_label_ids, label)

    if dev_2_label[dev_id] == "":
        dev_2_label[dev_id] = label
        dev_2_label_origin[dev_id] = source
    else:
        if not equal_labels(dev_2_label[dev_id], label):
            anomaly_line = "device id {0} already set to label {1} ({2}) while trying to set to {3} ({4})".\
                format(dev_id, dev_2_label[dev_id], dev_2_label_origin[dev_id], label, source)
            handle_anomaly("DUP-1", anomaly_line)
    label_2_devs[label] = unique_list(label_2_devs[label], dev_id)

    max_label = max(max_label, len(label))

    return


# ---------------------------------------------#
# function equal_labels()
# ---------------------------------------------#
def equal_labels(label1, label2):

    if label1 == label2:
        return(True)
    if label2.startswith("SW-cciss/c"):
        tmp_label2 = label2.replace("/", '')
        if label1 == tmp_label2:
            return(True)
    if list_in_list(label1 + " " + label2, "/ root"):
        return(True)
    if list_in_list(label1 + " " + label2, "/boot boot"):
        return(True)
    # TODO: further label equality checks mpath/vg-lv,..
    return(False)


# ---------------------------------------------#
# function: get_devs_in_label()
# return devices found for label (if label found, and if devices exist for label)
# ---------------------------------------------#
def get_devs_in_label(label_id):
    global all_label_ids  # ''
    global label_2_devs  # Key_data()

    if not word_in_list(label_id, all_label_ids):
        return('')

    tmp = label_2_devs[label_id].split()
    wc = len(tmp)
    if wc == 0:
        return('')

    dev_list = ''

    for dev in tmp:
        if re.match(sd_re_p, dev):
            dev_list = unique_list(dev_list, "/dev/" + dev)
        elif re.match(sd_re, dev):
            dev_list = unique_list(dev_list, "/dev/" + dev)
        # lif ... others?
    # end: for dev in tmp:

    return(dev_list)

# ---------------------------------------------#
# function equal_vg_lvs()
# made necessary becausee of double dash rules...
# ---------------------------------------------#


def equal_vg_lvs(vg_lv1, vg_lv2, source):
    global dm_re
    if re.match(dm_re, vg_lv2):
        return(False)  # commonly called w/vg_lv2 passed as dm-n
    # debug_print(z,"'{0}' '{1}' ({2})".format(vg_lv1,vg_lv2,source))
    if vg_lv1.startswith("mapper/"):
        vg_lv1 = vg_lv1.replace("mapper/", '')
    if vg_lv2.startswith("mapper/"):
        vg_lv2 = vg_lv2.replace("mapper/", '')
    vg1 = split_valid_vg_name(vg_lv1, source)
    # if vg1 == '': return(False)
    vg2 = split_valid_vg_name(vg_lv2, source)
    # if vg2 == '': return(False)
    # debug_print(z,vg1)
    # debug_print(z,vg2)
    if vg1 == '':
        return(False)
    if vg2 == '':
        return(False)
    if vg1 != vg2:
        return(False)

    lv1 = split_valid_lv_name(vg_lv1, source)
    # if lv1 == '': return(False)
    lv2 = split_valid_lv_name(vg_lv2, source)
    # debug_print(z,lv1)
    # debug_print(z,lv2)
    if lv1 == '':
        return(False)
    if lv2 == '':
        return(False)
    # debug_print(z,lv1)
    # debug_print(z,lv2)
    if lv1 != lv2:
        return(False)
    # debug_print(z,"true")
    return(True)

# ---------------------------------------------#
# function list_in_list(l1,l2):
# is list1 in list2?
# ---------------------------------------------#


def list_in_list(l1, l2):
    if l1 == l2:
        return(True)

    words1 = l1.split()
    # wc1    = len(words1)
    # words2 = l2.split()
    # wc2    = len(words2)
    # if wc1 != wc2: return(False)

    for ele in words1:
        if not word_in_list(ele, l2):
            return(False)
    # end: for ele in words1:
    return(True)

# ---------------------------------------------#
# function: track_uuid()
#
# track regular device uuids and partition uuids
# Note: a partition device can appear as both (see sda1 in case )
# ---------------------------------------------#


def track_uuid(uuid, dev_id, u_type, source):
    global dev_2_uuid  # Key_data()
    global dev_2_uuid_origin  # Key_data()
    global uuid_2_dev  # Key_data()
    global uuid_2_dev_origin  # Key_data()

    global pdev_2_uuid  # Key_data()
    global pdev_2_uuid_origin  # Key_data()
    global uuid_2_pdev  # Key_data()
    global uuid_2_pdev_origin  # Key_data()

    global max_uuid
    global all_uuids  # ''
    global yyyy_mm_dd_re  # yyyy-mm-dd
    global hex_re
    hhmmssnn_re = "[0-9]{2}-[0-9]{2}-[0-9]{2}-[0-9]{2}"
    xxxx_xxxx_re = hex_re + "{4}-" + hex_re + "{4}"
    x_16_re = hex_re + "{16}"

    debug_print(3, "uuid:{0},dev_id:{1},({2})".format(uuid, dev_id, source))

    if not is_uuid(uuid):
        if re.match(yyyy_mm_dd_re + "-" + hhmmssnn_re, uuid):
            pass
        elif re.match(xxxx_xxxx_re, uuid):
            pass
        elif re.match(x_16_re, uuid):
            pass
        else:
            error_print('d', "invalid uuid {0} {1} ({2})".format(uuid, dev_id, source))
            return

    all_uuids = unique_list(all_uuids, uuid)

    if u_type.startswith("p"):
        track_uuid_part(uuid, dev_id, u_type, source)
    else:
        track_uuid_reg(uuid, dev_id, u_type, source)

    max_uuid = max(max_uuid, len(uuid))

    return

# ---------------------------------------------#
# function: track_uuid_reg()
# /dev/disk/by-uuid:
# lrwxrwxrwx 1 root root   9 May  8 01:04 16c2bc24-e465-49a5-9cd7-8b7e91a68552 -> ../../sda
#
# /dev/disk/by-uuid: # (case )
# lrwxrwxrwx. 1 0 0  10 Mar 28 13:42 2017-03-28-13-29-31-00 -> ../../sda3
# lrwxrwxrwx. 1 0 0  10 Mar 28 14:34 4b08ab69-05dc-47fa-b0fe-a3d44c975c12 -> ../../sdb1
#
# /dev/disk/by-uuid: # (case )
# lrwxrwxrwx. 1 0 0  10 May  1 10:13 D445-04B0 -> ../../sda1
#
# /dev/disk/by-uuid:
# lrwxrwxrwx 1 0 0  10 Apr 18 20:51 1C704466704448AA -> ../../sdb1
# ---------------------------------------------#


def track_uuid_reg(uuid, dev_id, u_type, source):
    if dev_2_uuid[dev_id] == "":
        dev_2_uuid[dev_id] = uuid
        dev_2_uuid_origin[dev_id] = source
    else:
        if dev_2_uuid[dev_id] != uuid:
            anomaly_line = "device id {0} already set to uuid {1} ({2}) while trying to set to {3} ({4})".\
                format(dev_id, dev_2_uuid[dev_id], dev_2_uuid_origin[dev_id], uuid, source)
            handle_anomaly("DUP-1", anomaly_line)
    if uuid_2_dev[uuid] == "":
        uuid_2_dev[uuid] = dev_id
        uuid_2_dev_origin[uuid] = source
    else:
        if uuid_2_dev[uuid] != dev_id:
            anomaly_line = "uuid {0} already set to device id {1} ({2}) while trying to set to {3} ({4})".\
                format(uuid, uuid_2_dev[uuid], uuid_2_dev_origin[uuid], dev_id, source)
            handle_anomaly("DUP-2", anomaly_line)

    return

# ---------------------------------------------#
# function: track_uuid_part()
# /dev/disk/by-partuuid:
# lrwxrwxrwx. 1 0 0  11 May  1 10:12 088d5ddf-3d80-4862-ae2e-a47abb56b217 -> ../../sdlj1
# lrwxrwxrwx. 1 0 0  10 May  1 10:13 1159c8c9-0f39-4c2a-8e82-cee03c145f46 -> ../../sda2
# lrwxrwxrwx. 1 0 0  11 May  1 10:12 1db6034c-dbb1-4409-8f6f-a3c70477dd99 -> ../../sdiz1
# ---------------------------------------------#


def track_uuid_part(uuid, dev_id, u_type, source):
    if pdev_2_uuid[dev_id] == "":
        pdev_2_uuid[dev_id] = uuid
        pdev_2_uuid_origin[dev_id] = source
    else:
        if pdev_2_uuid[dev_id] != uuid:
            anomaly_line = "device id {0} already set to uuid {1} ({2}) while trying to set to {3} ({4})".\
                format(dev_id, pdev_2_uuid[dev_id], pdev_2_uuid_origin[dev_id], uuid, source)
            handle_anomaly("DUP-1", anomaly_line)
    if uuid_2_pdev[uuid] == "":
        uuid_2_pdev[uuid] = dev_id
        uuid_2_pdev_origin[uuid] = source
    else:
        if uuid_2_pdev[uuid] != dev_id:
            anomaly_line = "uuid {0} already set to device id {1} ({2}) while trying to set to {3} ({4})".\
                format(uuid, uuid_2_dev[uuid], uuid_2_dev_origin[uuid], dev_id, source)
            handle_anomaly("DUP-2", anomaly_line)

    return

# ---------------------------------------------#
# function: dump_uuid_devs()
# ---------------------------------------------#


def dump_uuid_devs():
    global dev_2_uuid  # Key_data()
    global dev_2_uuid_origin  # Key_data()
    global uuid_2_dev  # Key_data()
    global uuid_2_dev_origin  # Key_data()
    global all_uuids  # ''

    words = all_uuids.split()
    wc = len(words)
    errorprint("dump_uuid_devs(): {0} uuids".format(wc))

    if wc == 0:
        return

    for uuid in words:
        dev_id = uuid_2_dev[uuid]
        source = uuid_2_dev_origin[uuid]
        errorprint("{0} [{1}] ({2})".format(uuid, dev_id, source))
    # end: for uuid in words:


# ---------------------------------------------#
# function: crunch_mpath_data()
# /dev/mpath:
# lrwxrwxrwx  1 root root    7 Jul 18 16:28 36006016009403b001544e1b1970ee511 -> ../dm-7  (scsi disk id)
#
# /dev/mpath:
# lrwxrwxrwx  1 root root     9 Dec  2  2014 asm-acfs1 -> ../dm-172
# ---------------------------------------------#
def crunch_mpath_data(i, fn, curr_dir, p_fn, major_minor, line, source):
    global scsi_id_2_devs  # Key_data()
    global mm_2_bd_aliases  # Key_data()

    mm = bd_2_mm[p_fn]

    # if fn.startswith("3600507680180872d780000000000008e"):
    # debug_print(z,"{0} {1} {2} {3} [{4}] [{5}] '{6}' ({7})".format(i,fn,curr_dir,p_fn,major_minor,mm,line,source))
    debug_print(4, "{0} {1} {2} {3} [{4}] [{5}] '{6}' ({7})".format(i, fn, curr_dir, p_fn, major_minor, mm, line, source))

    if word_in_list(fn, mm_2_bd_aliases[mm]):
        return  # all is well

    dev_ids = scsi_id_2_devs[fn]
    if dev_ids != "":
        tmp = dev_ids.split()
        for dev_id in tmp:
            if word_in_list(dev_id, dm_2_devs[p_fn]):
                # ?? needs further investigation...
                debug_print(0, "{0} {1} '{2}' ({3})".format(fn, p_fn, line, source))
                return  # all is well

    # TODO: if is_scsi_id() then check of related device...and...?

    if check_mpath_mm(fn, mm, source):
        return

    if is_scsi_id(fn) or curr_dir == "/dev/mpath:":
        name = curr_dir[len("/dev/"):len(curr_dir) - 1] + "/" + fn  # e.g. mpath/360....
        # debug_print(z,"{0} {1}".format(mm,name))
        add_mm_bd(name, mm, source)
        return

    anomaly_line = "mpath entry '{0}' links to {1}({2}) but has no corresponding block file - check udev rules ({3})".\
                   format(fn, p_fn, mm, source)
    handle_anomaly("MULTIPATHCONF", anomaly_line)
    # print("@cmd mpath[{0}] to od[{1}] or mp[{2}] mm[{3}] dm:{4}".format(fn,major_minor_2_od[mm],major_minor_2_mp[mm],mm,p_fn))
    # print("@cmd '{0}' ({1})".format(line,source))
    # print 9/0

    return

# ---------------------------------------------#
# function: check_mpath_mm()
# ---------------------------------------------#


def check_mpath_mm(fn, mm, source):
    # mp_max_minor = hi_block_minor[get_device_mapper_major()]

    if mm != '':
        if fn == mm_2_bd[mm]:
            return(True)
        if word_in_list(fn, mm_2_bd_aliases[mm]):
            return(True)
        if word_in_list("mapper/" + fn, mm_2_bd_aliases[mm]):
            return(True)
        if word_in_list("mpath/" + fn, mm_2_bd_aliases[mm]):
            return(True)

    dm_maj = get_device_mapper_major()
    minor = get_first_block_minor_no(dm_maj)
    i = 0
    debug_print(3, "{0} '{1}' ({2})".format(fn, mm, source))

    # for minor in range(0,mp_max_minor+1):
    while minor != -1:
        mm = "{0}:{1}".format(dm_maj, minor)
        dm_fn = "dm-{0}".format(minor)

        if fn == mm_2_bd[mm]:
            return(True)
        if word_in_list(fn, mm_2_bd[mm]):
            return(True)
        # if fn.startswith("mpath"):
        #    if word_in_list("mapper/"+fn,mm_2_bd_aliases[mm]): return(True)
        if word_in_list("mapper/" + fn, mm_2_bd_aliases[mm]):
            return(True)
        if word_in_list("mpath/" + fn, mm_2_bd_aliases[mm]):
            return(True)

        i += 1
        minor = get_next_block_minor_no(dm_maj, i)

    # end: while minor != -1:
    # end: for minor in range(0,mp_max_minor+1):

    return False


# ---------------------------------------------#
# function: crunch_udev_tape_data()
# see sfdc case
#
# lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
# lrwxrwxrwx   1 0 0    99 Jul 17 21:13 c9:1025 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/st129
# lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
# lrwxrwxrwx   1 0 0    99 Jul 17 21:13 c9:1025 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/st129
# lrwxrwxrwx   1 0 0   100 Jul 17 21:13 c9:1153 -> /devices/pci0000:80/0000:80:09.0/0000:84:00.0/host7/rport-7:0-2/target7:0:2/7:0:2:1/scsi_tape/nst129
#
# (example w/no 'rport-n:n-n')
# lrwxrwxrwx  1 0 0   88 Jul  2 11:00 c21:5 -> /devices/pci0000:00/0000:00:1c.0/0000:0a:00.0/host5/target5:2:0/5:2:0:1/scsi_generic/sg5
# lrwxrwxrwx  1 0 0   85 Jul  2 11:00 c9:0 -> /devices/pci0000:00/0000:00:1c.0/0000:0a:00.0/host5/target5:2:0/5:2:0:0/scsi_tape/st0
# lrwxrwxrwx  1 0 0   86 Jul  2 11:00 c9:128 -> /devices/pci0000:00/0000:00:1c.0/0000:0a:00.0/host5/target5:2:0/5:2:0:0/scsi_tape/nst0
#
#
#
#
# ---------------------------------------------#
def crunch_udev_tape_data(i, udnm, udid, curr_dir, pwc, p_words, p_fn, b_or_c, major_minor, line, source):
    global sd_re, sd_re_p, dm_re

    debug_print(4, "uf:'{0}' uv:'{1}' cd:'{2}' pfn:{3} mm:{4} ({5} {6})".
                format(udnm, udid, curr_dir, p_fn, major_minor, i, source))

    if p_words[pwc - 2] == "scsi_tape":
        if not is_tape_id(p_fn):
            error_print('l', "'scsi_tape' line but not is_tape_id({0}) '{1}' ({2})".format(p_fn, line, source))
        add_mm_cd(p_fn, major_minor, source)
        scsi_adr = normalize_scsi_adr(p_words[pwc - 3])
        add_normalized_scsi_data(scsi_adr, "st", p_fn, '', line, source)
        # debug_print(4,"{0} {1}".format(scsi_adr,p_fn))
    elif p_words[pwc - 2] == "scsi_generic":
        if not major_minor.startswith("21:"):
            error_print('l', "'scsi_generic' line mm != '21:..'  '{1}' ({2})".format(major_minor, line, source))
        scsi_adr = normalize_scsi_adr(p_words[pwc - 3])
        add_dev_sgn(scsi_adr, p_fn, source)
        # debug_print(4,"{0} {1}".format(scsi_adr,p_fn))
    else:
        error_print("d", "'scsi_tape' or 'scsi_generic' not found where expected: ['{0}'] '{1}' ({2})".format(p_words[pwc - 2], line, source))
        return

    return


# ---------------------------------------------#
# function: crunch_udev_data()
#
# /dev/.udev/links/disk\x2fby-id\x2fdm-name-:
# lrwxrwxrwx    1 0 0     29 May 11 10:45 b253:200 -> /devices/virtual/block/dm-200
# lrwxrwxrwx    1 0 0     29 May 11 10:45 b253:201 -> /devices/virtual/block/dm-201
# lrwxrwxrwx    1 0 0     29 May 11 10:45 b253:202 -> /devices/virtual/block/dm-202
# .
# .
#
# /dev/.udev/links/disk\x2fby-id\x2fdm-name-VolGroup00-LVdata01:
# lrwxrwxrwx    1 0 0     30 May 11 10:36 b253:1123 -> /devices/virtual/block/dm-1123
#
# /dev/.udev/links/disk\x2fby-id\x2fdm-name-test_lun1023:
# lrwxrwxrwx    1 0 0     29 May 11 10:35 b253:564 -> /devices/virtual/block/dm-564
#
# /dev/.udev/links/disk\x2fby-id\x2fdm-name-test_lun1023p1:
# lrwxrwxrwx    1 0 0     29 May 11 10:35 b253:954 -> /devices/virtual/block/dm-954
#
# ---------------------------------------------#
def crunch_udev_data(i, udnm, udid, curr_dir, pwc, p_words, p_fn, b_or_c, major_minor, line, source):
    global sd_re, sd_re_p, dm_re

    debug_print(4, "uf:'{0}' uv:'{1}' cd:'{2}' pfn:{3} mm:{4} ({5} {6})".
                format(udnm, udid, curr_dir, p_fn, major_minor, i, source))

    tmp = udnm.split("\\")
    x2_a = tmp[1]
    x2_b = tmp[2].rstrip("-")

    # udnm------------------------------------+ udid--+
    # /dev/.udev/links/disk\x2fby-id\x2fdm-name-mpathiw:
    # lrwxrwxrwx   1 0 0   27 Oct 24 09:12 b253:8 -> /devices/virtual/block/dm-8
    #
    # /dev/.udev/links/disk\x2fby-id\x2fdm-name-VDB_DATA_1:
    # lrwxrwxrwx    1 root root    29 Nov 13 04:54 b253:143 -> /devices/virtual/block/dm-143

    if x2_a == "x2fby-id" and x2_b == "x2fdm-name":
        # TODO: lots of data samples to make it easier to understand the flow
        # if udid != '': vg_name = check_vg_prefix(udid,source)
        if udid != '':
            vg_name = split_valid_vg_name(udid, source)
        else:
            vg_name = ''
        if vg_name != "":
            lv_name = split_lv_name(udid, source)
            vg_name = update_vg(vg_name, "", source)
            update_lv(vg_name, lv_name, "", "", "", source)
            # print("@@@@ (line {0}) {1}-> vg:'{2}' lv:{3}".format(i,p_fn,vg_name,lv_name))
        elif udid.startswith("mpath"):
            add_mm_bd(udid, major_minor, source)
        else:
            tmp = major_minor.split(':')
            maj = tmp[0]
            min = tmp[1]
            # maj_type = get_major_type(int(maj),"b")
            # if maj_type == "dm":
            if re.match(dm_re, p_fn):
                dm_dev = "dm-{0}".format(min)
                if dm_dev == p_fn:  # should always be the case...
                    # debug_print(z,"{0}: '{1}' ({2})".format(i,line,source))
                    track_ufn(udid, major_minor, dm_dev, source)
                    # add_mm_bd(udid,major_minor,source)
                else:
                    error_print('l', "uf:'{0}' uv:'{1}' cd:'{2}' pfn:{3} mm:{4} ({5} {6})".
                                format(udnm, udid, curr_dir, p_fn, major_minor, i, source))
            else:
                error_print('l', "uf:'{0}' uv:'{1}' cd:'{2}' pfn:{3} mm:{4}[{5}] ({6} {7})".
                            format(udnm, udid, curr_dir, p_fn, major_minor, maj_type, i, source))
        # TODO: new assoc arrays go here dm- to uuid, foo to wwn, bar to scsi id...etc

    # udnm------------------------------------------+ udid----------------------------+
    # /dev/.udev/links/disk\x2fby-id\x2fdm-uuid-mpath-360014051c0b2982c633453a805898857:
    # lrwxrwxrwx   1 0 0   27 Oct 24 09:12 b253:5 -> /devices/virtual/block/dm-5
    if x2_a == "x2fby-id" and x2_b == "x2fdm-uuid-mpath":
        if re.match(dm_re, p_fn):
            if is_scsi_id(udid):
                track_scsi_id(udid, p_fn, source)

    # udnm---------------------------------+ udid----------------------------+
    # /dev/.udev/links/disk\x2fby-id\x2fscsi-360014051925a04851624fffaa60d4126:
    # p_words/line
    # lrwxrwxrwx   1 0 0   93 Oct 24 05:11 b65:16 -> /devices/pci0000:00/0000:00:01.1/0000:02:00.1/host1/rport-1:0-4/target1:0:2/1:0:2:7/block/sdr
    #
    if x2_a == "x2fby-id" and x2_b.startswith("x2fscsi"):
        scsi_adr_word = 0
        if re.match(sd_re_p, p_fn):
            # if sd partition, scsi address is 4th from end
            # '.../host2/rport-2:0-1/target2:0:0/2:0:0:0/block/sdb/sdb1'
            scsi_adr_word = 4
            p_devid = p_words[pwc - 2]
        elif re.match(sd_re, p_fn):
            # if sd device, scsi address is 3rd from end
            # '.../host2/rport-2:0-1/target2:0:0/2:0:0:0/block/sdb'
            scsi_adr_word = 3
            p_devid = p_fn

        if scsi_adr_word > 0 and "/host" in line and "/block/" in line:
            scsi_adr = p_words[pwc - scsi_adr_word]
            debug_print(3, "{0} '{1}' scsi_adr/dev=[{2}/{3}] ({4})".format(i, line, scsi_adr, p_fn, source))
            dev_type = p_fn[0:2]  # sd, sr, etc.
            debug_print(4, "{0} {1} {2} '{3}' ({4})".format(scsi_adr, dev_type, p_fn, line, source))
            if p_devid != p_fn:
                add_partition_2_dev(p_devid, p_fn, source)
            add_normalized_scsi_data(scsi_adr, dev_type, p_devid, '', line, source)
            if is_scsi_id(udid):
                track_scsi_id(udid, p_fn, source)
    # if path.startswith("/devices/pci") and "/host" in line: crunch_pci_and_host(i,line,words,path,p_words,source)
    return


# ---------------------------------------------#
# function: crunch_md_data()
# ---------------------------------------------#
#
# md file w/data:
#
# Personalities: [raid1]
# md1: active raid1 sdb2[1] sda2[0]
# 16779776 blocks [2/2] [UU]
#
# md2: active raid1 sdb3[2](S) sda3[0]
# 10482304 blocks [2/1] [U_]
#
# md3: active raid1 sdb4[1] sda4[0]
# 104832064 blocks [2/2] [UU]
#
# md0: active raid1 sdb1[1] sda1[0]
# 10482304 blocks [2/2] [UU]
#
# unused devices: <none>
#
# without data:
#
# Personalities:
# unused devices: <none>
def crunch_md_data():
    global mdn_re

    md_file = "proc/mdstat"
    fh = openfile(md_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        line = line.strip()
        i += 1
        if line == "":
            continue  # skip header or ending blank line

        if re.match(mdn_re + ": active ", line):
            tk = line.split()
            tkc = len(tk)
            md_id = tk[0]
            for rd in range(2, tkc):
                token = tk[rd]
                # if token.startswith("raid"): continue

                dev_id = ''
                rd_num = ''
                lb = token.find("[")
                if lb != -1:
                    rd_num = token[lb:]
                    rd_num = rd_num.strip("[]")
                    token = token[0:lb]

                if token.startswith("sd"):
                    dev_id = token
                elif token.startswith("cciss/"):
                    dev_id = token[len("cciss/"):]
                    track_cciss_devs(dev_id, '', md_file)
                if dev_id != '':
                    track_md_id(md_id, dev_id, '', '', md_file)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, md_file))
    return

# ---------------------------------------------#
# function: crunch_mdadm_data()
# ---------------------------------------------#
#
# mdadm.conf file:
#
# # mdadm.conf written out by anaconda
# MAILADDR root
# AUTO +imsm +1.x -all
# ARRAY /dev/md/0 level=raid1 num-devices=2 UUID=6e4c4246:2ca934e9:04ea4100:01fccf42
# ARRAY /dev/md/1 level=raid1 num-devices=2 UUID=488aa9ff:20610621:ce8a491d:56768e4b
# ARRAY /dev/md/2 level=raid1 num-devices=2 UUID=dd9d05a0:685d616b:ab8d7ee8:5df2f983
# ARRAY /dev/md/3 level=raid1 num-devices=2 UUID=47d0eb79:9eaa1e60:b7f11804:621a8eed
#


def crunch_mdadm_data():
    global mdn_re
    md_file = "etc/mdadm.conf"
    fh = openfile(md_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        line = line.strip()
        i += 1
        if line == "" or line.startswith('# '):
            continue  # skip header or ending blank line

        words = line.split()
        wc = len(words)
        w0 = words[0]

        if w0 == "MAILADDR":
            continue
        elif w0 == "AUTO":
            continue
        elif w0 == "ARRAY":
            md_id = ''
            md_uuid = ''
            dev_tmp = words[1]  # /dev/md/n
            tmp = dev_tmp.split('/')
            wct = len(tmp)
            if wct == 3:
                md_id = tmp[2]  # /dev/'mdn'
                if not re.match(mdn_re, md_id):
                    continue
            if wct == 4:
                md_id = tmp[2] + tmp[3]  # 'md'+n
                if not re.match(mdn_re, md_id):
                    continue
            if wc >= 3 and words[2].startswith('level='):
                md_level = words[2][len('level='):]
                # may want to track at some point
            if wc >= 4 and words[3].startswith('num-devices='):
                md_num_dev = words[3][len('num-devices='):]
                # may want to track at some point
            if wc >= 5 and words[4].startswith('UUID='):
                md_uuid = words[4][len('UUID='):]
            if wc >= 5 and words[4].startswith('uuid='):
                md_uuid = words[4][len('uuid='):]
            track_md_id(md_id, '', md_uuid, '', md_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, md_file))
    return


# ---------------------------------------------#
# function: crunch_blkid()
# ---------------------------------------------#
def crunch_blkid():

    blkid_files = "sos_commands/filesys/blkid " \
                  "sos_commands/block/blkid_-c_.dev.null " \
                  ""

    tmp = blkid_files.split()
    for fn in tmp:
        if fn == '' or fn.startswith('# '):
            continue
        crunch_blkid_file(fn)
    # end: for fn in tmp:
    return

# ---------------------------------------------#
# function: crunch_blkid_file()
#
# /dev/cciss/c0d0p3: LABEL="/" UUID="..." TYPE="ext3" SEC_TYPE="ext2"
# /dev/sdk1: LABEL="ASMDISK0004" TYPE="oracleasm"
# /dev/emcpowerv: LABEL="ASMDISK0004" TYPE="oracleasm"
# ---------------------------------------------#


def crunch_blkid_file(blkid_file):

    fh = openfile(blkid_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        line = line.strip()
        i += 1
        if line == "" or line.startswith('# '):
            continue  # skip header or ending blank line

        words = line.split()
        wc = len(words)
        w0 = words[0]

        if wc < 2:
            continue  # SNO

        rem_str = line[len(w0) + 1:]
        dev = w0.rstrip(":")

        uuid = get_kw_value('UUID=', rem_str)  # uuid is filesystem uuid
        label = get_kw_value('LABEL=', rem_str)
        type = get_kw_value('TYPE=', rem_str)

        if type == "oracleasm" and label != '':
            track_label(label, dev, blkid_file)
        # if uuid  != '': track_uuid(uuid,dev,blkid_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, blkid_file))
    return

# ---------------------------------------------#
# function kw_eq_string(str)
# return the value portion of kw=value or kw="val1 val2"
# ---------------------------------------------#


def get_kw_value(kw, str):
    kw_beg = str.find(kw)
    if kw_beg == -1:
        return('')
    kw_eq = str.find('=', kw_beg)

    kw = str[kw_beg:kw_eq]  # kw without '='
    val = str[kw_eq + 1:]  # kw value
    if val.startswith('"'):
        end_quote = val.find('"', 1)  # look for next double quote after the 1st
        if end_quote == -1:
            return(val)  # badly formed value??
        val = val[1:end_quote]
        debug_print(3, "{0} = '{1}'".format(kw, val))
        return(val)
    words = val.split()
    wc = len(words)
    if wc == 0:
        return('')
    return(words[0])

# ---------------------------------------------#
# function: crunch_scsi_scsi()
# ---------------------------------------------#
#
# Attached devices:
# Host: scsi1 Channel: 00 Id: 00 Lun: 00
# Vendor: NECVMWar Model: VMware IDE CDR10 Rev: 1.00
# Type:   CD-ROM                           ANSI  SCSI revision: 05
# Host: scsi2 Channel: 00 Id: 00 Lun: 00
# Vendor: VMware   Model: Virtual disk     Rev: 1.0
# Type:   Direct-Access                    ANSI  SCSI revision: 02
# Host: scsi2 Channel: 00 Id: 01 Lun: 00
# Vendor: VMware   Model: Virtual disk     Rev: 1.0
# Type:   Direct-Access                    ANSI  SCSI revision: 02


def crunch_scsi_scsi():
    global nf2_re

    scsi_file = "proc/scsi/scsi"
    fh = openfile(scsi_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 1 or line == "":
            continue  # skip header or ending blank line

        tk = line.split()
        tkc = len(tk)
        if tk[0] == "Host:":
            host = tk[1]
            host = host[4:]
            bus = tk[3]
            target = tk[5]
            lun = tk[7]
            continue

        # seen in case:
        # Vendor:          Model:                  Rev:
        if tk[0] == "Vendor:":
            mfg = ''
            model = ''
            if tkc <= 3:
                continue
            mfg = tk[1]
            model = ""
            if tk[2] == "Model:":
                model = tk[3]
            if tk[4] != "Rev:":
                model = model + " " + tk[4]
            if tkc > 5:
                if tk[4] != "Rev:" and tk[5] != "Rev:":
                    model = model + " " + tk[5]
            continue

        if tk[0] == "Type:":
            # This was seen in case , lun # : 49409 (used to send 'report-luns' to)
            #
            # Host: scsi1 Channel: 00 Id: 01 Lun: 49409
            # Vendor: IBM      Model: 2107900          Rev: 1.69
            # Type:   Well-known LUN                   ANSI  SCSI revision: 05
            #
            if tk[1] == "Well-known" and tk[2] == "LUN":
                continue
            #
            scsi_type = tk[1]
            if tk[2] != "ANSI":
                if tk[2] == "Changer" or tk[2] == "Device":
                    scsi_type = scsi_type + " " + tk[2]
                else:
                    debug_print(0, "tk[2] != ANSI: {0}".format(line))  # REVISIT
            # manufacture a scsi line and pass it off to add_scsi_info()
            scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
            scsi_info_line = "scsi {0} {1} {2} {3}".format(scsi_adr, scsi_type, mfg, model)
            debug_print(4, scsi_info_line)
            add_scsi_info(scsi_info_line, scsi_file)
            line = squeeze(line)
            if re.match("Type: Direct-Access ANSI SCSI revision: " + nf2_re, line):
                rev_level = tk[tkc - 1]  # revision no. is last token
                track_scsi_rev_level(scsi_adr, rev_level, scsi_file)
            if re.match("Type: Sequential-Access ANSI SCSI revision: " + nf2_re, line):
                rev_level = tk[tkc - 1]  # revision no. is last token
                track_scsi_rev_level(scsi_adr, rev_level, scsi_file)
            continue

    # end: for line in fh:
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, scsi_file))
    return

# ---------------------------------------------#
# function: track_scsi_rev_level()
# ---------------------------------------------#


def track_scsi_rev_level(scsi_adr, rev_level, source):
    global scsi_lun_rev_level        # Key_data()   # key: scsi_adr        data: "02", "03", "04", etc
    global scsi_lun_rev_level_origin  # Key_data()   # key: scsi_adr        data: proc/scsi/scsi

    rev_level = rev_level.lstrip("0")
    scsi_adr = normalize_scsi_adr(scsi_adr)

    # debug_print(z,"{0},{1} ({2})".format(scsi_adr,rev_level,source))

    if scsi_lun_rev_level[scsi_adr] == "":
        scsi_lun_rev_level[scsi_adr] = rev_level
        scsi_lun_rev_level_origin[scsi_adr] = source
        # debug_print(z,"scsi_lun_rev_level[{0}] now = {1} ({2})".format(scsi_adr,scsi_lun_rev_level[scsi_adr],source))
    else:
        if scsi_lun_rev_level[scsi_adr] != rev_level:
            action = file_check(scsi_lun_rev_level_origin[scsi_adr], source)
            if do_anomaly(action):
                anomaly_line = "scsi adr {0} already set to rev level {1} ({2}) while trying to set to {3} [{4}] ({5})".\
                    format(scsi_adr, scsi_lun_rev_level[scsi_adr], scsi_lun_rev_level_origin[scsi_adr],
                           rev_level, action, source)
                handle_anomaly("DUP-1", anomaly_line)
            if action == "overridden":
                scsi_lun_rev_level[scsi_adr] = rev_level
                scsi_lun_rev_level_origin[scsi_adr] = source
                # debug_print(z,"scsi_lun_rev_level[{0}] now = {1}".format(scsi_adr,scsi_lun_rev_level[scsi_adr]))
    return


# ---------------------------------------------#
# function: crunch_scsi_sg_devices()
#
# this file is written out in sgn order so line 1 is for sg0, line 2 for sg1, etc.
#
# host    chan    id      lun     type    opens   qdepth  busy    online [*]
# 1       0       0       1       0       1       32      0       1
# 0       0       0       1       0       1       32      0       1
# 4       0       2       0       1       1       1       0       1
# 4       0       45      0       1       1       1       0       1
#
# -1      -1      -1      -1      -1      -1      -1      -1      -1 <<<--- if info for the sgn device is unavailable
#
# [*] header line is in a separate file, device_hdr
# ---------------------------------------------#
def crunch_scsi_sg_devices():
    global sgn_2_lun  # Key_data()              # key: sgn,                 data: scsi address;     e.g. sg1,     0:0:0:0
    global sgn_2_lun_origin  # Key_data()       # key: sgn,                 data: file origin       e.g. sg1,     var/log/dmesg
    global lun_2_sgn  # Key_data()              # key: scsi address,        data: sgn;              e.g. 0:0:0:0, sg1
    global lun_2_sgn_origin  # Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg

    this_file = "proc/scsi/sg/devices"
    fh = openfile(this_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 1 or line == "":
            continue  # skip header or ending blank line

        words = line.split()
        wc = len(words)

        if wc != 9:
            error_print("d", "{0} '{1}'".format(wc, line))
            continue

        if words[0] == "-1":
            continue

        host = words[0]
        chan = words[1]
        id = words[2]
        lun = words[3]
        type = words[4]
        opens = words[5]
        qdepth = words[6]
        busy = words[7]
        online = words[8]

        scsi_adr = host + ":" + chan + ":" + id + ":" + lun
        scsi_adr = normalize_scsi_adr(scsi_adr)
        if scsi_adr == "":
            error_print("d", "'{0}' '{1}'".format(scsi_adr, line))
            continue

        sg_dev = "sg{0}".format(i - 1)

        add_normalized_scsi_data(scsi_adr, '', '', sg_dev, line, this_file)
        # bld_ha_bus_tgt_lun(scsi_adr,this_file)
        # type, opens, qdepth, busy, online can be tracked by scsi_adr

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, this_file))
    return


# ---------------------------------------------#
# function: crunch_lsscsi() # slurp up scsi/scsi data
#
#
# scsi_adr     type    vendor   model        revision  device
# [0:0:0:0]    disk    IBM      2145             0000  /dev/sda
# [0:0:0:1]    disk    IBM      2145             0000  /dev/sdb
# [0:0:0:29]   disk    IBM      2145             0000  /dev/sdc
#
# [1:0:0:0]    mediumx IBM      03584L32         0100  -
# [1:0:0:1]    tape    IBM      ULT3580-TD3      5AT0  -
# [1:0:0:2]    tape    IBM      ULT3580-TD3      5AT0  -
#
# [5:0:0:0]    cd/dvd  NECVMWar VMware SATA CD00 1.00  /dev/sr0
#
# [0:3:0:0]    storage HP       P220i            6.00  -
# [7:0:4:0]    storage IBM      2810XIV-LUN-0    0000  -
#
# [0:0:0:254]  enclosu 3PARdata SES              3212  -
#
# [0:0:2:0]    type?   vendor?  model?           rev?  -
# [1:0:0:0]    disk    ATA      WDC WD6000BLHX-0 04.0  /dev/sde
#
# [1:0:1:49409]wlun    IBM      2107900          1.69  -
#
# [6:0:0:1312] disk    HP       OPEN-V           6008  /dev/sdad
# [6:0:1:0]    process EMC      DataDomain DFC   1.0   -
# [6:0:1:1]    process EMC      DataDomain DFC   1.0   -
# [6:0:2:0]    tape    IBM      ULT3580-HH6      E6R3  /dev/st0

# [0:3:0:0]    no dev  IBM      57D7001SISIOA    0150  -
#
# case
# [0:0:0:0]    disk    SEAGATE  ST3300657SS      ES68  -
# [0:0:1:0]    disk    SEAGATE  ST3300657SS      ES68  -
# [0:1:0:0]    disk    Dell     Virtual Disk     1028  /dev/sdb
# [1:0:0:0]    disk                                    /dev/sda  <-- no mfg/model
#
# ---------------------------------------------#
def crunch_lsscsi():

    lsscsi_file = "sos_commands/scsi/lsscsi"
    fh = openfile(lsscsi_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 1 or line == "":
            continue  # skip header or ending blank line

        words = line.split()
        wc = len(words)
        scsi_adr = words[0]
        if not scsi_adr.endswith("]"):
            if "]" in scsi_adr:
                line = line.replace("]", "] ")
                words = line.split()
                wc = len(words)
                scsi_adr = words[0]
        scsi_adr = scsi_adr.strip("[]")
        scsi_adr = normalize_scsi_adr(scsi_adr)
        if scsi_adr == "":
            errorprint(line)
        if scsi_adr == "":
            errorprint(8 / 0)  # REMOVE
        if scsi_adr == "":
            error_print("d", "'{0}' '{1}'".format(scsi_adr, line))
            continue

        dev_type = ""
        if words[1] == "disk":
            dev_type = "sd"
        elif words[1] == "storage":
            dev_type = "sd"
        elif words[1] == "tape":
            dev_type = "st"
        elif words[1] == "mediumx":
            dev_type = "ch"
        elif words[1] == "enclosu":
            dev_type = "esd"
        elif words[1] == "cd/dvd":
            dev_type = "sr"
        elif words[1] == "process":
            dev_type = "pr"  # see DataDomain example above
        elif words[1] == "type?":
            dev_type = ""
        elif words[1] == "wlun" and scsi_adr.endswith(":49409"):
            continue  # see comment in crunch_scsi_scsi
        elif words[1] == "no" and words[2] == "dev":  # see case
            line = line.replace("no dev", "no_dev")
            words = line.split()
            wc = len(words)
        else:
            error_print("d", "{0} '{1}'".format(dev_type, line))

        if wc == 3 and words[wc - 1].startswith("/dev/"):
            mfg = ""
            model = ""
        else:
            if words[2] == "vendor?":
                mfg = ""
            else:
                mfg = words[2]
            if words[3] == "model?":
                model = ""
            else:
                model = words[3]
                if words[4] == "0000":
                    pass
                else:
                    model = model + " " + words[4]
        # end: else

        dev_id = words[wc - 1]  # device id is last word
        if dev_id == "-":
            dev_id = ''
        if dev_id.startswith("/dev/"):
            dev_id = dev_id[len("/dev/"):]

        add_normalized_scsi_data(scsi_adr, dev_type, dev_id, '', line, lsscsi_file)
        track_dev_mfgs(scsi_adr, mfg, 1, lsscsi_file)
        track_dev_models(scsi_adr, model, lsscsi_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lsscsi_file))
    return

# ---------------------------------------------#
# function: crunch_sgmap()
#
# this routine has little value if the sgn device can be correlated to a lun.
# the only way to do this (so far) is via var/log/dmesg or var/log/messages message data
# which can be unreliable if rescanning has occured or if the discovery messages are not present.
# Depending on where crunch_sgmap is called, the var/log/dmesg/messages crunch routines may not have been called yet.
# ---------------------------------------------#


def crunch_sgmap():
    global sgn_2_lun  # Key_data()              # key: sgn,                 data: scsi address;     e.g. sg1,     0:0:0:0
    global sgn_2_lun_origin  # Key_data()       # key: sgn,                 data: file origin       e.g. sg1,     var/log/dmesg
    global lun_2_sgn  # Key_data()              # key: scsi address,        data: sgn;              e.g. 0:0:0:0, sg1
    global lun_2_sgn_origin  # Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg

    sgmap_file = "sos_commands/scsi/sg_map"
    fh = openfile(sgmap_file)
    if fh is None:
        return

    flush = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 1 or line == "":
            continue  # skip header or ending blank line

        if line == "Stopping because no sg devices found":
            flush = True
        if flush:
            continue

        if line.startswith("Strange, could not find device"):
            continue  # probably started with "Stopping.." msg above

        if "could not find device" in line:
            continue  # occasionally the "Strange," word in the above message is truncated

        if line.startswith("Error opening /dev/"):
            continue

        if "Error opening /dev/" in line:
            continue  # more variations on garbled lines...

        if re.match("Device /dev/.* is busy", line):
            continue

        if line.startswith("Stopping because there are too many error"):
            continue

        # device /dev/nst0 failed on scsi ioctl(idlun), skip: Input/output error (case )
        if "failed on scsi ioctl" in line:
            continue

        words = line.split()
        wc = len(words)

        sg_dev = ""
        dev_id = ""
        dev_type = ""
        sg_scsi_adr = ""

        if wc == 0:
            continue  # sno
        if wc >= 1:
            sg_dev = words[0]
        if wc == 2:
            dev_id = words[1]
        if wc > 2:
            error_print("d", "{0} '{1}' ({2})".format(wc, line, sgmap_file))

        if sg_dev.startswith("/dev/sg"):
            sg_dev = sg_dev[len("/dev/"):]
        else:
            error_print("d", "{0} '{1}'".format(sg_dev, line))
            continue

        sg_scsi_adr = sgn_2_lun[sg_dev]
        sg_mm = "21:" + sg_dev[len("sg"):]  # nn portion of sgnn

        if dev_id != "":
            if dev_id.startswith("/dev/sd") or dev_id.startswith("/dev/st") or dev_id.startswith("/dev/sr"):
                dev_id = dev_id[len("/dev/"):]
                dev_type = dev_id[0:2]  # sd, st, etc.
            elif dev_id.startswith("/dev/nst"):
                dev_id = dev_id[len("/dev/"):]
                dev_type = "st"
            elif dev_id.startswith("/dev/scd"):
                dev_id = dev_id[len("/dev/"):]
                dev_type = "sr"
            elif dev_id == "busy":
                dev_id = ""
                dev_type = ""
            else:
                error_print("d", "{0} '{1}'".format(dev_id, line))
                continue
        if sg_scsi_adr == "":
            continue

        add_normalized_scsi_data(sg_scsi_adr, dev_type, dev_id, sg_dev, line, sgmap_file)
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, sgmap_file))
    return

# ---------------------------------------------#
# function: crunch_hw_lshal()
# ---------------------------------------------#


def crunch_hw_lshal():

    lshal_file = "sos_commands/hardware/lshal"
    fh = openfile(lshal_file)
    if fh is None:
        return

    found_udi_section = False
    dev_id = ''
    dev_type = ''
    major = -1
    minor = -1
    mfg = ''
    model = ''
    scsi_adr = ''
    serial = ''
    size = -1
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 1 or line == "":
            continue  # skip header or ending blank line

        words = line.split()
        wc = len(words)

        if line == '':
            found_udi_section = False

        if line.startswith("udi = '/"):
            found_udi_section = True
            if dev_id != '':  # data from previous block device?
                # call rtns with the prev info, then reset vars...
                if dev_id.startswith("cciss/"):
                    dev_id = dev_id[len("cciss/"):]
                debug_print(3, "{0}, {1}:{2}, {3}, {4}, {5}, {6}, {7}".format(dev_id, major, minor, mfg, model, scsi_adr, serial, size))
                dev_sgn = ''
                if scsi_adr != '':
                    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, dev_sgn, line, lshal_file)
                mm = "{0}:{1}".format(major, minor)
                dm_dev = ''
                hint = ''
                add_normalized_mm_data(scsi_adr, dev_id, dm_dev, mm, line, hint, lshal_file)
                if serial != '':
                    pass
                    # TODO: is it a scsi serial number? if so process
            # end: if found_udi_block_device_section: # data from previous block device?

            # re-init variables
            dev_id = ''
            dev_type = ''
            major = -1
            minor = -1
            mfg = ''
            model = ''
            scsi_adr = ''
            serial = ''
            size = -1
            continue
        # end: if line.startswith("udi = '/"):

        if found_udi_section:
            if line.startswith("  block.device = '/dev/"):
                dev_id = words[2].strip("'")
                dev_id = dev_id[len("/dev/"):]  # everything past /dev/
                dev_type = dev_id[0:2]
                continue
            if line.startswith("  block.major = "):
                major = int(words[2])
                continue
            if line.startswith("  block.minor = "):
                minor = int(words[2])
                continue
            if line.startswith("  info.vendor = "):
                mfg = words[2].strip("'")
                mfg = mfg.upper()
                continue
            if line.startswith("  linux.sysfs_path = "):
                tmp = words[2]
                tmp = tmp.split('/')
                lt = len(tmp)
                scsi_adr = tmp[lt - 3]
                if not is_scsi_adr(scsi_adr):
                    scsi_adr = tmp[lt - 3]
                if not is_scsi_adr(scsi_adr):
                    scsi_adr = ''
                continue
            if line.startswith("  storage.model = "):
                model = " ".join(words[2:wc - 1])
                model = model.strip("'")
                continue
            if line.startswith("  storage.vendor = "):
                mfg = words[2].strip("'")
                mfg = mfg.upper()
                continue
            if line.startswith("  storage.size = "):
                size = int(words[2])
                continue
            if line.startswith("  storage.serial = "):
                serial = words[2].strip("'")
                continue

    # end: for line in fh:
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lshal_file))
    return


# ---------------------------------------------#
# function: crunch_fstab()
# ---------------------------------------------#
def crunch_fstab(pass_no):
    global dm_re
    global fstab_redo_lines  # ""

    if pass_no == 2:
        if fstab_redo_lines == '':
            return
        debug_print(1, "redo for lines: {0}".format(fstab_redo_lines))

    fstab_file = "etc/fstab"
    fh = openfile(fstab_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue
        track_fstab_line = False
        try_mountpoint = False
        if pass_no == 2:
            line_no = "{0}".format(i)
            if not word_in_list(line_no, fstab_redo_lines):
                continue

        words = line.split()
        wc = len(words)

        fs_device = ''
        fs_dev_alias = ''
        mount_point = ''
        fs_type = ''
        fs_mntops = ''
        fs_freq = '0'
        fs_pass = '0'

        invalid_fstab_line = False
        reason = ''

        #
        # Normal fstab entry has 6 items:
        # word[0]: file system device or id
        # word[1]: file system mount point
        # word[2]: file system type [ext4, nfs, etc.]
        # word[3]: file system mount options ['str1(,str2(,str3))']
        # word[4]: file system dump frequency (normally 0)
        # word[5]: file system fsck pass number (0|1|2)
        #
        if wc >= 1:
            fs_device = clean_fs_token(words[0])
        if wc >= 2:
            mount_point = words[1]
        if wc >= 3:
            fs_type = words[2]
        if wc >= 4:
            fs_mntops = words[3]
        if wc >= 5:
            fs_freq = words[4]
        if wc >= 6:
            fs_pass = words[5]

        if fs_device.startswith("dev/"):
            fs_device = "/" + fs_device  # case
        if ignore_filesystem(fs_device):
            continue

        if fs_type != '':
            if not valid_fs_type(fs_type, fstab_file):
                if wc == 5 and '' == valid_fs_mntops(fs_type, ''):
                    # fs_type is not a valid file system type but it is a valid mount option
                    invalid_fstab_line = True
                    reason = csp(reason, "fs_type missing")
                    # shift parms right one
                    fs_pass = fs_freq
                    fs_freq = fs_mntops
                    fs_mntops = fs_type
                    fs_type = '(missing)'
                    wc = 6
                else:
                    invalid_fstab_line = True
                    reason = csp(reason, "fs_type invalid:" + fs_type)

        if fs_mntops != '':
            bad_mntop = valid_fs_mntops(fs_mntops, fs_type)
            if bad_mntop != '':
                invalid_fstab_line = True
                reason = csp(reason, "fs_mntops:" + bad_mntop)

        if wc < 4:
            if fs_type != "nfs":
                invalid_fstab_line = True
                reason = csp(reason, "too few parameters")

        # 0: do not fsck at all
        # 1: root fs, fsck first
        # 2: non-root fs, fsck after root
        pass_blurb = "fs_passno={0}".format(fs_pass)
        if fs_pass.isdigit():
            if int(fs_pass) < 0 or int(fs_pass) > 2:
                invalid_fstab_line = True
                reason = csp(reason, pass_blurb + "[not 0-2]")
        else:
            invalid_fstab_line = True
            reason = csp(reason, pass_blurb + "[not numeric]")

        # if /dev/sda and not /dev/sda1
        if re.match("/dev/" + sd_re, fs_device) and not re.match("/dev/" + sd_re_p, fs_device):
            sd_dev = fs_device[5:]
            # if this device has partitions then the base device should not appear in fstab as a mountable device
            # dev_2_parts = Key_data()            # key: device id,           data: partion id(s)     e.g. sda,     sda1, sda2, ...
            if dev_2_parts[sd_dev] != '':
                twc = wordcount(dev_2_parts[sd_dev])
                invalid_fstab_line = True
                reason = csp(reason, "device {0} contains partition{1}: {2}".
                             format(fs_device, plural(twc), dev_2_parts[sd_dev]))
        if invalid_fstab_line:
            if "fs_passno" in reason:
                ref_blurb = "see SFDC {0}".format(sfdc_url("01482355"))
            else:
                ref_blurb = ''
            anomaly_line = "line {0} of {1} is invalid [reason: {2}] {3}".format(i, fstab_file, reason, ref_blurb)
            handle_anomaly("FS", anomaly_line)
            if "too few parameters" in reason:
                continue  # don't track incomplete / bogus data

        if fs_device.startswith("LABEL="):
            label = fs_device[len("LABEL="):]  # remainder of string beyond 'LABEL='
            if label.startswith("SW-cciss/"):
                track_label(label, "/dev/" + label[len("SW-"):], fstab_file)
            label_dev = adjust_fs_LABEL(label, line, fstab_file)
            if label_dev != '':
                fs_dev_alias = fs_device
                fs_device = label_dev
            else:
                if pass_no == 1:
                    track_fstab_line = True  # first pass and can't resolve LABEL=...
                else:
                    try_mountpoint = True

        if fs_device.startswith("UUID=") or fs_device.startswith("uuid="):
            uuid = fs_device[len("uuid="):]  # remainder of string beyond 'uuid/UUID='
            uuid = clean_uuid(uuid)
            uuid_dev = adjust_fs_UUID(uuid, line, fstab_file)
            if uuid_dev != '':
                fs_dev_alias = fs_device
                fs_device = uuid_dev
            else:
                if pass_no == 1:
                    track_fstab_line = True  # first pass and can't resolve UUID=...
                else:
                    try_mountpoint = True

        if fs_device.startswith("/dev/disk/by-id/wwn-0x"):
            wwn = fs_device[len("/dev/disk/by-id/wwn-0x"):]  # remainder of string beyond prefix
            wwn_dev = adjust_fs_wwn(wwn, line, fstab_file)
            if wwn_dev != '':
                fs_dev_alias = fs_device
                fs_device = wwn_dev
            else:
                if pass_no == 1:
                    track_fstab_line = True  # first pass and can't resolve UUID=...
                else:
                    try_mountpoint = True

        if track_fstab_line:
            line_no = "{0}".format(i)
            fstab_redo_lines = unique_list(fstab_redo_lines, line_no)  # remember this line and redo it
            continue

        if try_mountpoint:
            existing_fs = find_fs_by_mountpoint(mount_point, '')
            if existing_fs != '':
                fs_dev_alias = fs_device
                fs_device = existing_fs

        # check for /dev/mapper, /dev/cciss, etc
        # this allows data from mountab, fstab and df to coallesce under the same "Filesystem"
        fs_device = adjust_fs_name(fs_device, mount_point, fstab_file)

        track_fs_data(fs_device, fs_dev_alias, mount_point, fs_type, fs_mntops, fstab_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fstab_file))
    return


# ---------------------------------------------#
# function adjust_fs_LABEL()
# turn LABEL=label into a device name so that later coalescing works
# ---------------------------------------------#
def adjust_fs_LABEL(label, line, source):
    global label_2_devs

    label_dev = ''
    label_devs = label_2_devs[label]

    if label_devs == '' and label != "/":
        if label.startswith("/"):
            label = label[len("/"):]
            label_devs = label_2_devs[label]

    words = label_devs.split()

    # this will return the last word in label_2_devs[label]
    # however, generally there should only be one word for the fs LABELS
    for label_dev in words:

        if re.match(dm_re, label_dev):
            label_dev = adjust_fs_dm(label_dev, line, source)

        if label_dev != '':
            if not label_dev.startswith("/dev/"):
                label_dev = "/dev/" + label_dev

    # end: for label_dev in words:

    debug_print(3, "[{0}] '{1}'".format(label_dev, line))

    return(label_dev)
# ---------------------------------------------#
# function: adjust_fs_UUID()
# turn UUID=uuid into a device name so that later coalescing works
# ---------------------------------------------#


def adjust_fs_UUID(uuid, line, source):
    global all_md_ids  # ''
    global md_id_2_uuid  # Key_data()
    global uuid_2_dev  # Key_data()
    global dm_re

    uuid_dev = ''

    cln_uuid = clean_uuid(uuid)
    words = all_md_ids.split()
    for md_id in words:
        if md_id_2_dev_uuid[md_id] == uuid or md_id_2_dev_uuid[md_id] == cln_uuid:
            uuid_dev = "/dev/" + md_id
            break
    # end: for md_id in words:
    if uuid_dev == '':
        uuid_dev = uuid_2_dev[cln_uuid]
        if uuid_dev != '':
            if re.match(dm_re, uuid_dev):
                uuid_dev = adjust_fs_dm(uuid_dev, line, source)
    if uuid_dev == '':
        uuid_dev = uuid_2_dev[uuid]
        if uuid_dev != '':
            if re.match(dm_re, uuid_dev):
                uuid_dev = adjust_fs_dm(uuid_dev, line, source)

    if uuid_dev != '':
        if not uuid_dev.startswith("/dev/"):
            uuid_dev = "/dev/" + uuid_dev

    debug_print(3, "[{0}] '{1}'".format(uuid_dev, line))
    return(uuid_dev)

# ---------------------------------------------#
# function: adjust_fs_wwn()
# turn /dev/disk/by-id/wwn-0x....  into a device name so that later coalescing works
# ---------------------------------------------#


def adjust_fs_wwn(wwn, line, source):
    global all_wwn_ids  # ''
    global dev_2_wwn_id  # Key_data()
    global wwn_id_2_devs  # Key_data()
    global dm_re

    wwn_dev = ''

    if word_in_list(wwn, all_wwn_ids):
        devs = wwn_id_2_devs[wwn]
        tmp = devs.split()
        wwn_dev = tmp[0]
        if wwn_dev != '':
            wwn_dev = "/dev/" + wwn_dev

    debug_print(3, "[{0}] '{1}'".format(wwn_dev, line))
    return(wwn_dev)


# ---------------------------------------------#
# function: adjust_fs_dm()
# turn dm_nn dev name into a mpath or vg/lv device name so that later coalescing works
# ---------------------------------------------#
def adjust_fs_dm(dm, line, source):
    global mm_2_bd_aliases  # Key_data()

    rval = ''
    mm = conv_id_2_mm(dm, '')
    vg_lv = conv_mm_2_vg_lv(mm, source)
    if vg_lv == '':
        mpath = mm_2_bd_aliases[mm]
        if mpath != '':
            tmp = mpath.split()
            mpath = "mapper/" + tmp[0]  # in case of situation like dm-50 -> "mpathap5 root" case
        rval = mpath
    else:
        vg = split_vg_name(vg_lv, source)
        lv = split_lv_name(vg_lv, source)
        rval = vg + "/" + lv

    return(rval)

# ---------------------------------------------#
# function: valid_fs_mntops()
# "mntop(,mntop(,...))"
# ---------------------------------------------#


def valid_fs_mntops(fs_mntops, fs_type):

    debug_print(2, "mount options passed in: '{0}', fs type:{1}".format(fs_mntops, fs_type))

    valid_mntop_words_fs = Key_data()  # any fs specific keywords

    valid_mntop_words_fs["fuse"] = ""\
                                   "no_check_certificate "\
                                   "nocopyapi "\
                                   "nomultipart "\
                                   "nonempty "\
                                   "sigv2 "\
                                   "use_path_request_style "\
                                   ""

    valid_mntop_words_fs["gpfs"] = ""\
                                   "nomtime "\
                                   ""

    valid_mntop_words_fs["vxfs"] = ""\
                                   "largefiles "\
                                   "nolargefiles "\
                                   ""

    valid_mntop_words = "" \
        "ac "\
        "acl "\
        "allow_other "\
        "allow_root "\
        "async "\
        "async_read "\
        "atime "\
        "attr2 "\
        "auto "\
        "auto_cache "\
        "bg "\
        "bind "\
        "bootfail "\
        "cifsacl "\
        "cto "\
        "datavolume "\
        "defaults "\
        "delaylog "\
        "dev "\
        "directio "\
        "direct_io "\
        "dirsync "\
        "discard "\
        "dynperm "\
        "exec "\
        "fg "\
        "fsc "\
        "forceuid "\
        "forcegid "\
        "groupt "\
        "grpquota "\
        "guest "\
        "hard "\
        "hard_remove "\
        "ignorecase "\
        "inode64 "\
        "intr "\
        "iocharset "\
        "iversion "\
        "kernel_cache "\
        "kudzu "\
        "largeio "\
        "large_read "\
        "lazytime "\
        "lock "\
        "loop "\
        "loud "\
        "lofs "\
        "managed "\
        "mand "\
        "mapchars "\
        "mtime "\
        "multiuser "\
        "noac "\
        "noacl "\
        "noatime "\
        "noauto "\
        "nobarrier "\
        "nobh "\
        "nobootwait "\
        "nobrl "\
        "nocase "\
        "nocto "\
        "nodelalloc "\
        "nodev "\
        "nodiratime "\
        "noexec "\
        "nofail "\
        "nofsc "\
        "nointr "\
        "noiversion "\
        "nolargeio "\
        "nolazytime "\
        "nolock "\
        "nomand "\
        "nomapchars "\
        "nomount "\
        "none "\
        "noperm "\
        "noposixpaths "\
        "noquota "\
        "norealtime "\
        "noresvport "\
        "noserverino "\
        "nosharecache "\
        "nostrictatime "\
        "nosuid "\
        "nounix "\
        "nouser "\
        "nouser_xattr "\
        "nouuid "\
        "owner "\
        "pamconsole "\
        "perm "\
        "posix "\
        "posixpaths "\
        "rbind "\
        "relatime "\
        "remount "\
        "resvport "\
        "ro "\
        "rw "\
        "rwpidforward "\
        "seclabel "\
        "serverino "\
        "sfu "\
        "sharecache "\
        "silent "\
        "soft "\
        "strictatime "\
        "strictcache "\
        "suid "\
        "sw "\
        "swalloc "\
        "swap "\
        "sync "\
        "sync_read "\
        "tcp "\
        "user "\
        "user_ino "\
        "user_xattr "\
        "usrquota "\
        "wallet "\
        "x-gvfs-show "\
        "x-initrd.mount "\
        "_netdev "\
        "_rnetdev "\
        ""

    valid_mntop_num_kwds_fs = Key_data()  # any fs specific numeric keywords
    # haven't confirmed 'retry=' yet...
    # namelen XFS only?
    # direct_io only valid for 'fuse' type filesystems (98% confident)
    # allow_other only valid for 'fuse' type filesystems (98% confident)
    valid_mntop_num_kwds = "" \
        "acdirmax= "\
        "acdirmin= "\
        "acregmax= "\
        "acregmin= "\
        "actimeo= "\
        "barrier= "\
        "commit= "\
        "dir_mode= "\
        "dir_umask= "\
        "dmask= "\
        "dmode= "\
        "file_mode= "\
        "file_umask= "\
        "fmask= "\
        "fmode= "\
        "fix_control= "\
        "inode_readahead_blks= "\
        "logbufs= "\
        "max_read= "\
        "max_readahead= "\
        "max_write= "\
        "minorversion= "\
        "mode= "\
        "mountport= "\
        "namelen= "\
        "namlen= "\
        "nfsvers= "\
        "port= "\
        "posix= "\
        "pri= "\
        "quota_quantum= "\
        "retrans= "\
        "retry= "\
        "rsize= "\
        "stripe= "\
        "timeo= "\
        "umask= "\
        "vers= "\
        "wsize= "\
        "x-systemd.device-timeout= "\
        ""
    valid_mntop_str_kwds_fs = Key_data()  # any fs specific string keywords

    valid_mntop_str_kwds_fs["gluster"] = "" \
        "backupvolfile-server= "\
        "direct-io-mode= "\
        "log-file= "\
        "log-level= "\
        "transport= "\
        "user-readdirp= "\
        "volfile-max-fetch-attempts= "\
        ""

    valid_mntop_str_kwds_fs["fuse"] = "" \
        "passwd_file= "\
        "url= "\
        ""

    # addr/clientaddr='ip.address'
    valid_mntop_str_kwds = "" \
        "addr= "\
        "backupuid= "\
        "backupgid= "\
        "clientaddr= "\
        "codepage= "\
        "comment= "\
        "context= "\
        "convosync= "\
        "credentials= "\
        "cruid= "\
        "data= "\
        "data_err= "\
        "dev= "\
        "domain= "\
        "errors= "\
        "fscontext= "\
        "fsname= "\
        "gid= "\
        "grpjquota= "\
        "heartbeat= "\
        "iocharset= "\
        "idmap= "\
        "ip= "\
        "jqfmt= "\
        "ldev= "\
        "local_lock= "\
        "logdev= "\
        "lookupcache= "\
        "mincache= "\
        "mountaddr= "\
        "mounthost= "\
        "mountport= "\
        "mountproto= "\
        "mountvers= "\
        "netbiosname= "\
        "passwd= "\
        "password= "\
        "prefixpath= "\
        "proto= "\
        "quota= "\
        "sec= "\
        "servernetbiosname= "\
        "servern= "\
        "shortname= "\
        "subtype= "\
        "transport= "\
        "uid= "\
        "useNSDserver= "\
        "user= "\
        "username= "\
        "usrjquota= "\
        "verbose= "\
        "workgroup= "\
        "wrkgrp= "\
        "xlator-option= "\
        "x-gvfs-name= "\
        ""

    valid_mntop_siz_kwds_fs = Key_data()

    valid_mntop_siz_kwds = "" \
        "allocsize= "\
        "cachebufsize= "\
        "buffercachecap= "\
        "dircachesize= "\
        "logbsize= "\
        "size= "\
        ""

    if fs_type != '':
        if valid_mntop_words_fs[fs_type] != "":
            valid_mntop_words = valid_mntop_words + " " + valid_mntop_words_fs[fs_type]
        if valid_mntop_num_kwds_fs[fs_type] != "":
            valid_mntop_num_kwds = valid_mntop_num_kwds + " " + valid_mntop_num_kwds_fs[fs_type]
        if valid_mntop_str_kwds_fs[fs_type] != "":
            valid_mntop_str_kwds = valid_mntop_str_kwds + " " + valid_mntop_str_kwds_fs[fs_type]
        if valid_mntop_siz_kwds_fs[fs_type] != "":
            valid_mntop_siz_kwds = valid_mntop_siz_kwds + " " + valid_mntop_siz_kwds_fs[fs_type]
    # end: if fs_type != '':

    words = fs_mntops.split(",")

    for mntop in words:
        debug_print(2, "evaluating mount option: '{0}'".format(mntop))
        if mntop == '' or word_in_list(mntop, valid_mntop_words):
            continue

        eq_loc = mntop.find('=')  # find first '=' sign
        if eq_loc == -1:
            return(mntop + "[unrecognized keyword]")

        kweq = mntop[0:eq_loc + 1]  # kw plus '=' sign
        value = mntop[eq_loc + 1:]  # everything to the right of the '=' sign

        if word_in_list(kweq, valid_mntop_num_kwds):
            if value.isdigit() or is_float(value):
                continue
            else:
                return(mntop + "[data value not numeric]")

        if word_in_list(kweq, valid_mntop_str_kwds):
            if value != '':
                continue
            else:
                return(mntop + "[no data found]")
        if word_in_list(kweq, valid_mntop_siz_kwds):
            if mg_conv(value, 0, 0) != -1:
                continue
            else:
                return(mntop + "[data value invalid]")

        # if word_in_list(kweq,valid_mntop_gluser_str_kwds):
            # if value != '': continue
            # else: return(mntop+"[no data found]")

        return(mntop + "[unrecognized keyword]")
    # end: for mntop in words:

    return('')


# ---------------------------------------------#
# function: crunch_df_data()
# ---------------------------------------------#
# ---------------------------------------------#
# df: '/proc/sys/fs/binfmt_misc': No such device  <<<--- first seen in 7.1
# Filesystem                 1K-blocks    Used Available Use% Mounted on
# rootfs                       1548144  610820    921608  40% /
# proc                               0       0         0    - /proc
# sysfs                              0       0         0    - /sys
# devtmpfs                   131908372       0 131908372   0% /dev
# securityfs                         0       0         0    - /sys/kernel/security
# tmpfs                      131927836      12 131927824   1% /dev/shm
# devpts                             0       0         0    - /dev/pts
# tmpfs                      131927836 1960392 129967444   2% /run
# tmpfs                      131927836       0 131927836   0% /sys/fs/cgroup
# cgroup                             0       0         0    - /sys/fs/cgroup/systemd
# pstore                             0       0         0    - /sys/fs/pstore
# cgroup                             0       0         0    - /sys/fs/cgroup/cpuset
# cgroup                             0       0         0    - /sys/fs/cgroup/cpu,cpuacct
# cgroup                             0       0         0    - /sys/fs/cgroup/memory
# cgroup                             0       0         0    - /sys/fs/cgroup/devices
# cgroup                             0       0         0    - /sys/fs/cgroup/freezer
# cgroup                             0       0         0    - /sys/fs/cgroup/net_cls
# cgroup                             0       0         0    - /sys/fs/cgroup/blkio
# cgroup                             0       0         0    - /sys/fs/cgroup/perf_event
# cgroup                             0       0         0    - /sys/fs/cgroup/hugetlb
# configfs                           0       0         0    - /sys/kernel/config
# /dev/sda3                    4133360  228988   3694404   6% /run/initramfs/live
# /dev/mapper/live-rw          1548144  610820    921608  40% /
# rpc_pipefs                         0       0         0    - /var/lib/nfs/rpc_pipefs
# selinuxfs                          0       0         0    - /sys/fs/selinux
# mqueue                             0       0         0    - /dev/mqueue
# hugetlbfs                          0       0         0    - /dev/hugepages
# debugfs                            0       0         0    - /sys/kernel/debug
# none                       131927836  671200 131256636   1% /var/lib/stateless/writable
# none                       131927836  671200 131256636   1% /var/cache/man
# none                         1998672  516892   1360540  28% /var/log
# none                       131927836  671200 131256636   1% /var/lib/dbus
# none                       131927836  671200 131256636   1% /tmp
#
# (see case  for gpfs example)
# IMPAX_DCM_10             536870912    530537664     6333248  99% /gpfs/IMPAX_DCM_10
# IMPAX_DCM_100            536870912    518223744    18647168  97% /gpfs/IMPAX_DCM_100
# ---------------------------------------------#
def crunch_df_data():
    global fs_2_pctused  # Key_data()
    global fs_2_blocks  # Counter()
    global fs_2_block_size  # Counter()
    global fs_2_type  # Key_data()
    global fs_2_alias  # Key_data()
    global fs_full_anom_lines  # ''
    global all_label_ids  # ''

    df_file = "sos_commands/filesys/df_-al"
    if not file_exists_with_data(df_file):
        df_file = "df"
    fh = openfile(df_file)
    if fh is None:
        return

    found_hdr = False
    bsize = kb
    l = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line.startswith("/bin/df"):
            continue  # line starting with /bin/df is as in note in readline1()
        debug_print(4, "'{0}' ({1} {2})".format(line, i, df_file))
        words = line.split()
        first_word = words[0]
        # /bin/df: `/dev/shm': No such file or directory
        # /bin/df: `/opt/IBM/db2': No such file or directory
        # Filesystem ...
        if first_word == "/bin/df:" or first_word == "df:":
            continue

        l += 1
        if first_word == "Filesystem":
            found_hdr = True
            bsize = words[1]
            if bsize[0:2] == "1K":
                bsize = kb
            elif bsize[0:2] == "1M":
                bsize = mb
            elif bsize[0:2] == "1G":
                bsize = gb
            else:
                bsize = 1  # ??

        if l == 1 or first_word == "Filesystem":  # nls translation broke above test
            continue  # 1st line (header)

        if squeeze(line) == "rootfs - - - - /":
            continue

        wc = len(words)
        # normally 6 but >= catches this case where blanks in mnt pt increase word count:
        # /dev/sr0                607752    607752         0 100% /media/RHEL-Supplementary_6.5 x86_64 1
        if wc >= 6:
            filesystem = words[0]
            blocks = words[1]
            pct_used = words[4]
            mount_point = words[5]
        elif wc == 1:
            filesystem = words[0]
            mount_point = ""  # on next line
            continue
        elif wc == 5:
            if first_word.isdigit():
                blocks = words[0]
                pct_used = words[3]
                mount_point = words[4]
            else:
                anomaly_line = "unhandled line: {0} ({1})".format(line, df_file)
                handle_anomaly("DATA-1", anomaly_line)
        if filesystem == "" or mount_point == "":
            anomaly_line = "null data: fs={0} mp={1} ({2})".format(filesystem, mount_point, df_file)
            handle_anomaly("DATA-2", anomaly_line)
            continue
        if ignore_filesystem(filesystem):
            continue

        first_char = filesystem[0:1]
        if first_char != "/" and filesystem != "rootfs" and not word_in_list(filesystem, all_label_ids):
            if first_char == "\\":
                continue  # cifs
            elif fs_2_type[filesystem].startswith("nfs"):
                continue
            elif fs_2_type[filesystem] == "gpfs":
                pass  # fs device name non-std, but size available
            elif fs_2_type[filesystem] == "fuse":
                pass  # fs device name non-std, but size available
            else:
                anomaly_line = "unrecognized built-in fs: {0} mount point {1} ({2})".format(filesystem, mount_point, df_file)
                handle_anomaly("FS", anomaly_line)
                continue

        # if filesystem.endswith("HostVG-Config"): filesystem = "{0}({1})".format(filesystem,mountpoint)
        # /dev/mapper/HostVG-Config /etc/passwd -> /dev/mapper/HostVG-Config(/etc/passwd) /etc/passwd

        # when necessary, change '/dev/mapper/VolGroupName-LogVolName' to '/dev/VolGroupName/LogVolName'
        # this allows data from mountab, fstab and df to coallesce under the same "Filesystem"
        adjusted_fs = adjust_fs_name(filesystem, mount_point, df_file)
        # debug_print(z,"{0} {1}".format(filesystem,adjusted_fs))

        if adjusted_fs == filesystem:
            existing_fs = find_fs_by_mountpoint(mount_point, '')
            # debug_print(z,"{0} {1}".format(filesystem,existing_fs))
            if existing_fs != '' and filesystem != existing_fs:
                # debug_print(z,'{0} {1}'.format(filesystem,existing_fs))
                # TODO: should filesystem always be set to existing_fs in this case??
                if mount_point == "/":
                    fs_2_alias[existing_fs] = unique_list(fs_2_alias[existing_fs], filesystem)
                    filesystem = existing_fs
                elif fs_names_equal(filesystem, existing_fs, mount_point):
                    filesystem = existing_fs
        else:
            filesystem = adjusted_fs

        track_fs_data(filesystem, "", mount_point, "", "", df_file)

        fs_2_pctused[filesystem] = pct_used
        if not blocks.isdigit():
            blocks = "0"
        fs_2_blocks[filesystem] = int(blocks)
        fs_2_block_size[filesystem] = bsize
        pct_used = pct_used.rstrip("%")
        if pct_used == "" or not pct_used.isdigit():
            pct_used = 0

        if mount_point == "/":
            pct_threshold = 90
        elif mount_point == "/boot":
            pct_threshold = 90
        else:
            pct_threshold = 95

        if int(pct_used) > pct_threshold:
            if filesystem.endswith(".iso") or filesystem == "/dev/sr0":
                pass
            else:
                anomaly_line = "fs {0} mounted at {1} is over {2}% full ({3}%) ({4})".\
                               format(filesystem, mount_point, pct_threshold, pct_used, df_file)
                if fs_full_anom_lines == '':
                    fs_full_anom_lines = anomaly_line
                else:
                    fs_full_anom_lines = fs_full_anom_lines + "\n" + anomaly_line
                # handle_anomaly("FS",anomaly_line)

        debug_print(4, "{0} mounted on {1}".format(filesystem, mount_point))

    # end: for line in fh:
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, df_file))
    return


# ---------------------------------------------#
# function: clean_fs_token()
# see case:
# line 118 of etc/fstab:
# s3fs# plw-suspense-non-prod /ab_s3fs_pi_02/fs fuse nocopyapi,use_path_request_style,nomultipart,sigv2,url=https://cloud.hcpnorn1.travp.net/,allow_other,gid=4800474,uid=4901156,passwd_file=/etc/passwd-s3fs-plw-suspense,no_check_certificate,nonempty,umask=0000 0 0
# df amd mount commands both reference s3fs (without the '# plw-suspense-non-prod')
# ---------------------------------------------#
def clean_fs_token(fs_token):

    sp = fs_token.find('# ')
    if sp == -1:
        return(fs_token)
    return(fs_token[0:sp])


# ---------------------------------------------#
# function: crunch_proc_mounts()
# ---------------------------------------------#
def crunch_proc_mounts():
    global fs_2_opts  # Key_data()
    global fs_types_ign

    mount_file = "proc/mounts"
    fh = openfile(mount_file)
    if fh is None:
        return

    skip_cnt = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "":
            continue

        # if line == "warning: can't open /etc/mtab: No such file or directory": continue

        if skip_cnt > 0:
            skip_cnt -= 1
            continue
        words = line.split()
        wc = len(words)

        if "mount: warning:" in line:
            anomaly_line = "'{0}' ({1})".format(line, mount_file)
            handle_anomaly("FS", anomaly_line)
            skip_cnt = 3
            continue

        if "[mntent]:" in line:
            anomaly_line = "'{0}' ({1})".format(line, mount_file)
            handle_anomaly("FS", anomaly_line)
            continue
        # debug_print(z,"{0}:'{1}'".format(i,line))
        filesystem = words[0]

        mount_point = ''
        fs_type = ''
        fs_opts = ''
        fs_alias_data = ''

        # rootfs / rootfs rw 0 0
        # /dev/mapper/mpathep1 /boot ext4 rw,seclabel,nodev,relatime,barrier=1,data=ordered 0 0
        # /dev/mapper/vg_root-lv_home /home ext4 rw,seclabel,nodev,relatime,barrier=1,data=ordered 0 0

        if wc > 1:
            mount_point = words[1]
        if wc > 2:
            fs_type = words[2]
        if wc > 3:
            fs_opts = words[3]
        # if wc > 4: fs_.. = words[4]
        # if wc > 5: fs_.. = words[5]
        if ignore_filesystem(filesystem):
            continue

        if word_in_list(fs_type, fs_types_ign):
            continue

        #
        # if filesystem == mountpoint: continue

        original_fs = filesystem
        # when necessary, change '/dev/mapper/VolGroupName-LogVolName' to '/dev/VolGroupName/LogVolName'
        # this allows data from mountab, fstab and df to coallesce under the same "Filesystem"
        adjusted_fs = adjust_fs_name(filesystem, mount_point, mount_file)
        # if "clusternfslv" in mount_point: debug_print(z,"{0} '{1}' '{2}'".format(filesystem,adjusted_fs,line))
        # if "loop0" in filesystem: debug_print(z,"{0} '{1}' '{2}'".format(filesystem,adjusted_fs,line))

        if adjusted_fs == filesystem:
            existing_fs = find_fs_by_mountpoint(mount_point, '')
            if existing_fs != '' and filesystem != existing_fs:
                debug_print(3, '{0} {1}'.format(filesystem, existing_fs, mount_point))
                if fs_names_equal(filesystem, existing_fs, mount_point):
                    filesystem = existing_fs
        else:
            filesystem = adjusted_fs

        if word_in_list_sep("ro", fs_opts, ",", False, False) and word_in_list_sep("rw", fs_2_opts[filesystem], ",", False, False):
            anomaly_line = "Filesystem {0} is mounted ro but should be rw ({1})".format(filesystem, mount_file)
            handle_anomaly("FS", anomaly_line)

        # if original_fs == "rootfs" and mount_point == "/" and fs_type == "rootfs":
        if mount_point == "/":
            if fs_type == "rootfs":
                fs_type = ''
                # debug_print(z,"'{0}'".format(fs_type))
            tfs = find_fs_by_mountpoint("/", '')
            if tfs != '':
                if filesystem != tfs:
                    fs_alias_data = filesystem
                    filesystem = tfs

        if original_fs == "rootfs":
            continue

        # if filesystem.endswith("LV_root") or mount_point == "/":
        #    debug_print(z,"{0} '{1}'".format(filesystem,fs_type))
        fs_opts = fs_opts.replace(",data=ordered", '')
        track_fs_data(filesystem, fs_alias_data, mount_point, fs_type, fs_opts, mount_file)
    # end: for line in fh:

    # process filesys info
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, mount_file))
    return


# ---------------------------------------------#
# function: crunch_mount_data()
# called w/True or False to control whether
# the purpose is to only gather vg_names or not.
# ---------------------------------------------#
def crunch_mount_data(vg_names_only):

    mount_file = "sos_commands/filesys/mount_-l"
    if not file_exists_with_data(mount_file):
        mount_file = "mount"
    fh = openfile(mount_file)
    if fh is None:
        return

    skip_cnt = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line.startswith("/bin/mount"):
            continue  # line starting with /bin/mount is as noted in readline1()

        if line == "warning: can't open /etc/mtab: No such file or directory":
            continue

        if skip_cnt > 0:
            skip_cnt -= 1
            continue
        if "mount: warning:" in line:
            anomaly_line = "'{0}' ({1})".format(line, mount_file)
            handle_anomaly("FS", anomaly_line)
            skip_cnt = 3
            continue

        if "[mntent]:" in line:
            anomaly_line = "'{0}' ({1})".format(line, mount_file)
            handle_anomaly("FS", anomaly_line)
            continue

        words = line.split()
        wc = len(words)
        filesystem = words[0]

        lit_on = ''
        mount_point = ''
        lit_type = ''
        fs_type = ''
        fs_opts = ''

        # usually output from the mount command has the literals "on" and "type" ahead of the actual values for those attributes.
        # however, this is not always the case. Look for these literals and remove them if present and then resplit the line
        #
        # v        v
        # 0                     1  2     3    4   5
        # example with literals: /dev/mapper/vg00-home on /home type xfs (rw,relatime,attr2,inode64,noquota)
        #
        # after clean up:        0                     1     2   3
        # /dev/mapper/vg00-home /home xfs (rw,relatime,attr2,inode64,noquota)

        if wc > 1:
            lit_on = words[1]
        if wc > 3:
            lit_type = words[3]

        if lit_on == "on":
            line = line.replace(' on ', ' ')

        if lit_type == "type":
            line = line.replace(' type ', ' ')

        if lit_on == "on" or lit_type == "type":  # need to resplit?
            words = line.split()
            wc = len(words)

        # "if wc > n" prompted by case  which left a partial file 69 lines in...
        if wc > 1:
            mount_point = words[1]
        if wc > 2:
            fs_type = words[2]
        if wc > 3:
            fs_opts = words[3]

        if vg_names_only:
            if not filesystem.startswith("/dev/mapper/"):
                continue
            tmp = filesystem.split("/")
            name = tmp[3]  # [0]/[1]/[2]/[3]
            if not possible_vg_lv_name(name, 'crunch_mount_data', mount_file):
                continue
            vg_name = split_vg_name(name, mount_file)
            if vg_name == '':
                continue
            lv_name = split_lv_name(name, mount_file)
            update_vg(vg_name, "", mount_file)
            update_lv(vg_name, lv_name, "", "", "", mount_file)
            continue  # << -- done with harvesting vg/lv names

        if ignore_filesystem(filesystem):
            continue

        # when necessary, change '/dev/mapper/VolGroupName-LogVolName' to '/dev/VolGroupName/LogVolName'
        # this allows data from mountab, fstab and df to coallesce under the same "Filesystem"
        orig_fs = filesystem
        adjusted_fs = adjust_fs_name(filesystem, mount_point, mount_file)
        existing_fs = find_fs_by_mountpoint(mount_point, '')
        if adjusted_fs == filesystem:
            if existing_fs != '' and filesystem != existing_fs:
                debug_print(3, '{0} {1}'.format(filesystem, existing_fs, mount_point))
                if fs_names_equal(filesystem, existing_fs, mount_point):
                    filesystem = existing_fs
        else:
            filesystem = adjusted_fs

        debug_print(3, "filesystem={0} orig_fs={1} adj_fs={2} existing_fs={3}".format(filesystem, orig_fs, adjusted_fs, existing_fs))

        track_fs_data(filesystem, "", mount_point, fs_type, fs_opts, mount_file)
    # end: for line in fh:

    # process filesys info
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, mount_file))
    return

# ---------------------------------------------#
# function: ignore_filesystem()
# check filesystem versus the ignore list, etc. and if it matches, return True, else return False
# ---------------------------------------------#


def ignore_filesystem(fs):
    global fs_ign  # "..."

    if word_in_list(fs, fs_ign):
        return(True)

    if fs.startswith("/etc/auto."):
        return(True)
    if fs.startswith("auto."):
        return(True)
    if fs.startswith("AUTO."):
        return(True)
    if fs.startswith("auto_"):
        return(True)
    if fs.startswith("ou=auto."):
        return(True)
    if fs.startswith("ldap:cn="):
        return(True)

    if fs == "/proc/bus/usb":
        return(True)
    # if fs == "tracefs": return(True)

    return(False)

# ---------------------------------------------#
# function: adjust_fs_name()
# ---------------------------------------------#


def adjust_fs_name(fs, mount_point, source):

    debug_print(3, "{0} {1} {2}".format(fs, mount_point, source))

    if fs.startswith("/dev/mapper/"):
        fs = adjust_fs_dev_mapper_name(fs, mount_point, source)
    elif fs.startswith("/dev/dm-"):
        fs = adjust_fs_dev_mapper_name(fs, mount_point, source)
    elif fs.startswith("/dev/cciss/"):
        fs = fs.replace("/dev/cciss/", "/dev/")
    elif fs.startswith("/dev/disk/by-path/ccw-"):
        # 0 1   2    3       4
        # TODO: check for /dev/disk/by-path/ccw-0.0.cuuu-partn
        # if so, check device cuuu
        tmp = fs.split("/")
        cuuu = tmp[4]
        p = cuuu.find("-part")
        part = ''
        if p != -1:
            part = cuuu[p + len("part-"):]
        x = len("ccw-n.n.")
        cuuu = cuuu[x:x + 4]
        dasdid = cuuu_2_dasd[cuuu]
        if dasdid != '' and part != '':
            dasdid = dasdid + part
        mm = ''
        if dasdid != '':
            mm = conv_id_2_mm(dasdid, "bd")
        if mm != '':
            fs = "/dev/" + dasdid

    # debug_print(z,"{0} {1} {2}".format(fs,mount_point,source))

    fs = adjust_fs_name_concat(fs, mount_point, source)

    debug_print(3, "{0} {1} {2}".format(fs, mount_point, source))
    return(fs)

# ---------------------------------------------#
# function: adjust_fs_name_concat()
# some file systems, such as /dev/mapper/HostVG-Config have multiple mount points,
# typically in the /etc directory, to create a unique fs name, we concatenate the mountpoint to the name here.
# ---------------------------------------------#


def adjust_fs_name_concat(fs, mount_point, source):
    concat_list = "HostVG-Config HostVG-Logging HostVG-Data ovirt-crypt-config ovirt-crypt-data -luks"
    # oncat_list = "HostVG/Config HostVG/Logging HostVG/Data ovirt-crypt-config ovirt-crypt-data -luks"
    concat_words = concat_list.split()

    for concat_word in concat_words:
        if fs.endswith(concat_word):
            fs = "{0}({1})".format(fs, mount_point)
            break
        if '-' in concat_word:
            concat_word = concat_word.replace('-', '/')
            if fs.endswith(concat_word):
                fs = "{0}({1})".format(fs, mount_point)
                break
    # end: for concat_word in concat_words:
    return(fs)

# ---------------------------------------------#
# function: adjust_fs_dev_mapper_name()
#
# The point of this function (and the other adjust_fs_...) functions is to
# coalesce all the fs data from fstab, and the output of the df and mount commands into
# a single display. Due to the nature of things, some of the file system names (i.e. the device names)
# are different from (or aliases of) one another.
# This routine tries to anticipate those differences and come up with a fs name that will be consistent
# with all 3 files.
# Otherwise the filesystem display will show more than one line with the same mountpoint (but different fs devices).
# ---------------------------------------------#


def adjust_fs_dev_mapper_name(fs, mount_point, source):
    global all_vg_names  # ''
    global vg_2_all_lvs  # Key_data()
    global lv_2_path    # Key_data()
    # global hi_block_minor # Key_data_m1()
    global mm_2_bd_aliases  # Key_data()
    global dm_re

    debug_print(3, "{0} {1}".format(fs, source))
    words = fs.split('/')
    wc = len(words)

    # +------------------------------- words[0] (null string)
    # | +----------------------------- words[1] ('dev')
    # | |   +------------------------- words[2] ('dm-2')
    # | |   |
    # | |   |
    # /dev/dm-2     (might be converted to something like /dev/mpath/mpath1)
    if wc == 3 and re.match(dm_re, words[2]):
        dm_dev = words[2]
        mm = conv_id_2_mm(dm_dev, 'dm')
        if mm == '':
            return(fs)

        # mapper_dev = major_minor_2_mp[mm] # changed mapper_dev to alias_dev
        alias_dev = mm_2_bd_aliases[mm]
        fs_matching_mountpoint = find_fs_by_mountpoint(mount_point, '')

        vg = split_valid_vg_name(alias_dev, '')
        lv = ''
        if vg != '':
            lv = split_valid_lv_name(alias_dev, '')

        # if "dm-13" in fs: debug_print(z,vg)
        if vg != "" and fs_matching_mountpoint.startswith("/dev/"):
            ex_vg_lv = fs_matching_mountpoint[len("/dev/"):]
            ex_vg_lv = ex_vg_lv.replace("/", "-")
            ex_vg = split_valid_vg_name(ex_vg_lv, '')
            if ex_vg == vg and lv == split_valid_lv_name(ex_vg_lv, ''):
                return(fs_matching_mountpoint)

        if fs_matching_mountpoint.endswith(alias_dev):
            return(fs_matching_mountpoint)
        fs_vg_lv = ''
        if vg != '':
            fs_vg_lv = vg + "-" + lv
        fs_matching_vg_lv = find_fs_by_vg_lv(fs_vg_lv, '')
        if fs_matching_vg_lv != '':
            return(fs_matching_vg_lv)
        return(fs)

    # end: if wc == 3 and re.match(dm_re,words[2]):

    if wc != 4:
        return(fs)

    # +------------------------------- words[0] (null string)
    # | +----------------------------- words[1] ('dev')
    # | |   +------------------------- words[2] ('mapper')
    # | |   |      +------------------ words[3] ('Vg-Lv', or scsi id(p1))
    # | |   |      |
    # /dev/mapper/VolGroupName-LogVolume
    mapper_name = words[3]
    # hi_dm_minor = hi_block_minor[253]
    dm_major = get_device_mapper_major()
    # hi_dm_minor = hi_block_minor[dm_major]
    debug_print(3, "{0} {1} {2}".format(fs, source, mapper_name))

    if mapper_name.find('-') == -1:  # Not a vg-lv ?
        if fs_2_mountpoint[fs] != '':
            return(fs)  # already registered, use it
        if not is_scsi_id(mapper_name):
            return(fs)  # not, a scsi id, out
        minor = get_first_block_minor_no(dm_major)
        i = 0
        # for i in range(0,hi_dm_minor+1):
        while minor != -1:
            mm = "{0}:{1}".format(dm_major, i)
            # if major_minor_2_mp[mm] == vg_lv: return("/dev/dm-{0}".format(i))
            # if mm_2_bd_aliases[mm] == mapper_name: return("/dev/dm-{0}".format(i)) # <-- not sure when dm-nn was a good idea??
            if mm_2_bd_aliases[mm] == mapper_name:
                return(fs)  # return /dev/mapper/scsi-id
            # TODO: dm-nn -> /deb/<vgname>/<lvname> return that instead of of dm-nn see: 01702045

            i += 1
            minor = get_next_block_minor_no(dm_major, i)

        # end: while minor != -1:
        # end: for i in range(0,hi_dm_minor+1):
        return(fs)

    # if mapper_name == "msc01dg-apps--oracle": dl = 0
    # else: dl = 4
    # debug_print(dl,mapper_name)
    vg = split_valid_vg_name(mapper_name, source)
    if vg == '':
        return(fs)
    # debug_print(dl,vg)

    lv = split_lv_name(mapper_name, source)  # in case of '--' in vg or lv
    # debug_print(dl,lv)

    lvs = vg_2_all_lvs[vg]
    # debug_print(dl,lvs)
    normalized_vg_lv = vg + '-' + lv
    # debug_print(dl,normalized_vg_lv)
    # debug_print(z,"{0} {1} {2} {3} '{4}'".format(fs,source,vg,vg_lv,lvs))

    # if not word_in_list(normalized_vg_lv,lvs): return(fs)
    # if not word_in_list(vg_lv,lvs): return(fs)
    if word_in_list(normalized_vg_lv, lvs) or word_in_list(mapper_name, lvs):
        pass
    else:
        return(fs)

    lv_dev = lv_2_path[normalized_vg_lv]
    # debug_print(dl,lv_dev)
    # debug_print(dl,lv_2_path[mapper_name])
    # lv_dev = lv_2_path[vg_lv]
    # debug_print(z,"{0} {1} {2} {3} '{4}'".format(fs,source,vg,vg_lv,lv_dev))
    # if lv_dev == '': return(fs)
    if lv_dev == '':
        lv_dev = "/dev/" + vg + "/" + lv

    # debug_print(z,"{0}".format(lv_dev))
    # debug_print(dl,lv_dev)
    return(lv_dev)

# ---------------------------------------------#
# function: fs_names_euqal(fs1,fs2)
# are two filesystem names equivalent?
#
# E.g.:
# /dev/mapper/uat_srq_slave_vg01-zdotcms_assets_lv01
# /dev/uat_srq_slave_vg01/webapps_assets_lv01
# ---------------------------------------------#


def fs_names_equal(fs1, fs2, mount_point):
    global fs_2_opts  # Key_data()
    global dm_re

    if fs1 == fs2:
        return(True)

    if mount_point == "/" and "root" in fs1 and "root" in fs2:
        if ":" not in fs1 and ":" not in fs2:
            return(True)  # not equal if ':' (nfs) in either one

    # Account for /dev/loopn where this case exists:
    #
    # df:  /omni_idbcopy/Software_HP_DP_8.1_for_Linux_TD586-15014.iso
    # mount:  /omni_idbcopy/Software_HP_DP_8.1_for_Linux_TD586-15014.iso on /mnt type iso9660 (rw,loop=/dev/loop0) [DP81_LINUX]
    # proc/mounts:  /dev/loop0                                                    /mnt iso9660 ro,relatime 0 0

    fs_opts_1 = fs_2_opts[fs1]
    fs_opts_2 = fs_2_opts[fs2]
    if fs1 in fs_opts_2:
        return(True)
    if fs2 in fs_opts_2:
        return(True)

    if re.match("/dev/" + dm_re, fs1) or re.match("/dev/" + dm_re, fs2):
        mm1 = conv_id_2_mm(fs1, '')
        mm2 = conv_id_2_mm(fs2, '')
        # debug_print(z,"{0}:{1} {2}:{3}".format(fs1,mm1,fs2,mm2))
        if mm1 == mm2:
            return(True)

    vg_fs1 = fs_2_vg(fs1)
    if vg_fs1 == '':
        return(False)

    vg_fs2 = fs_2_vg(fs2)
    if vg_fs2 == '':
        return(False)

    if vg_fs1 == vg_fs2:
        return(True)

    return(False)

# ---------------------------------------------#
# function: fs_2_vg(fs):
# if the device is a volume group / logical volume
# return vg+" "+lv
# ---------------------------------------------#


def fs_2_vg(fs):
    if not fs.startswith("/dev/"):
        return('')

    if fs.startswith("/dev/mapper/"):
        fs = fs[len("/dev/mapper/"):]  # remainder of fs name

    if fs.startswith("/dev/"):
        fs = fs[len("/dev/"):]        # remainger of fs name
        if fs.count("/") != 1:
            return('')
        fs = fs.replace('/', '-')

    if fs.count("-") != 1:
        return('')
    vg = split_vg_name(fs, '')
    if vg == '':
        return('')

    lv = split_lv_name(fs, '')
    if lv == '':
        return('')
    return(vg + " " + lv)
# ---------------------------------------------#
# function: find_fs_by_mountpoint(mount_point,fs_type):
# find a file system by mount point and optionally by file system type (e.g. ext4, gfs)
# return fs name
# ---------------------------------------------#


def find_fs_by_mountpoint(mount_point, fs_type):
    global all_filesystems        # ""
    global fs_2_mountpoint        # Key_data()
    global fs_2_type              # Key_data()

    if mount_point == '':
        return('')

    words = all_filesystems.split()
    for fs in words:
        # if "sterling2/sedaredi/edi" in mount_point: debug_print(z,"moutpoint[{0}] {1} <-> {2}".format(fs,fs_2_mountpoint[fs],mount_point))
        if fs_2_mountpoint[fs] == mount_point:
            if fs_type == '':
                return(fs)
            if fs_2_type[fs] == fs_type:
                return(fs)
            if fs_2_type[fs] == "none" or fs_type == "none":
                return(fs)
    # end: for fs in words:
    return('')

# ---------------------------------------------#
# function: find_fs_by_vg_lv(vg_lv,fs_type):
# find a file system by volume group & logical volume and optionally by file system type (e.g. ext4, gfs)
# return fs name
# ---------------------------------------------#


def find_fs_by_vg_lv(vg_lv, fs_type):
    global all_filesystems        # ""
    global fs_2_type              # Key_data()

    if vg_lv == '':
        return('')

    words = all_filesystems.split()
    for fs in words:
        # if "sterling2/sedaredi/edi" in mount_point: debug_print(z,"moutpoint[{0}] {1} <-> {2}".format(fs,fs_2_mountpoint[fs],mount_point))
        fs_vg_lv = ''
        if fs.startswith("/dev/"):
            fs_vg_lv = fs[len("/dev/"):]
        if fs.startswith("/dev/mapper/"):
            fs_vg_lv = fs[len("/dev/mapper/"):]

        if fs_vg_lv == '':
            continue
        fs_vg_lv = fs_vg_lv.replace("/", "-")

        if fs_vg_lv == vg_lv:
            if fs_type == '':
                return(fs)
            if fs_2_type[fs] == fs_type:
                return(fs)
    # end: for fs in words:
    return('')

# ---------------------------------------------#
# function: track_fs_data()
# ---------------------------------------------#


def track_fs_data(fs_dev, fs_dev_alias, fs_mount_pt, fs_type, fs_opts, source):
    global all_filesystems        # ""
    global all_fs_types           # ""
    global all_nfs_servers        # ''          # names of all nfs servers encountered
    # global fs_netdev_opt_cnt      # 0           # number of times '_netdev' fs option seen

    global fs_2_alias             # Key_data()  # alias; UUID=..,LABEL=..,alt lvm name
    global fs_2_mountpoint        # Key_data()
    global fs_2_mountpoint_origin  # Key_data()
    global fs_2_type              # Key_data()
    global fs_2_type_origin       # Key_data()
    # global fs_2_pctused           # Key_data()
    global fs_2_opts              # Key_data()
    # global fs_2_blocks            # Counter()
    # global fs_2_block_size        # Counter()

    debug_print(3, "{0},{1},{2},{3},{4},({5})".format(fs_dev, fs_dev_alias, fs_mount_pt, fs_type, fs_opts, source))

    all_filesystems = unique_list(all_filesystems, fs_dev)

    # changed to list as root often has a LABEL= in fstab and a "/dev/root" in proc/mounts
    if fs_dev_alias != '':
        fs_2_alias[fs_dev] = unique_list(fs_2_alias[fs_dev], fs_dev_alias)

    if fs_type != '':
        if valid_fs_type(fs_type, source):
            all_fs_types = unique_list(all_fs_types, fs_type)
        else:
            anomaly_line = "filesystem {0} has an unrecognized type: {1} ({2})".\
                format(fs_dev, fs_type, source)
            handle_anomaly("FS", anomaly_line)
            pass  # add anom

    if fs_mount_pt != "/":
        # get rid of trailing '/' if present
        if fs_mount_pt.endswith("/"):
            fs_mount_pt = fs_mount_pt[0:len(fs_mount_pt) - 1]

    # TODO: override mountpoint with incoming info if set to anything in list: "/export .. "
    # if fs_2_mountpoint[fs_dev] == "" or fs_2_mountpoint[fs_dev] == "/export"
    if fs_2_mountpoint[fs_dev] == "":
        fs_2_mountpoint[fs_dev] = fs_mount_pt
        fs_2_mountpoint_origin[fs_dev] = source
    elif not fs_mountpoints_equal(fs_2_mountpoint[fs_dev], fs_mount_pt):
        # # #
        # DONE: check existing mountpoint to see if it is already known as a filesystem too,
        # if so, don't generate a DUP-1 anomaly like the one that follows:
        #
        # 1 unique instance of anomaly type DUP-1 found:
        # [1] filesystem /dev/vg00/tmp already set to mountpoint /tmp (etc/fstab), while trying to set to /var/tmp (proc/mounts)
        #
        # grep 'tmp ' etc/fstab
        # /dev/vg00/tmp           /tmp                    ext3    nodev,nosuid        1 2
        # /tmp                    /var/tmp                none    bind            0 0 <<-+
        # |
        # grep 'tmp ' proc/mounts                                                        |
        # /dev/vg00/tmp /tmp ext3 rw,nosuid,nodev,data=ordered 0 0                       |
        # /dev/vg00/tmp /var/tmp ext3 rw,nosuid,nodev,data=ordered 0 0 >>----------------+ (/tmp is a known re-mount fs)
        #
        tfs = find_fs_by_mountpoint(fs_2_mountpoint[fs_dev], fs_2_type[fs_dev])
        if tfs == '':
            anomaly_line = "filesystem {0} already set to mountpoint {1} ({2}), while trying to set to {3} ({4})".\
                format(fs_dev, fs_2_mountpoint[fs_dev], fs_2_mountpoint_origin[fs_dev], fs_mount_pt, source)
            handle_anomaly("DUP-1", anomaly_line)

    if fs_type != "":
        if fs_2_type[fs_dev] == "" or word_in_list(fs_2_type[fs_dev], "none unknown auto"):
            fs_2_type[fs_dev] = fs_type
            fs_2_type_origin[fs_dev] = source
        elif not fs_types_equal(fs_2_type[fs_dev], fs_type):
            anomaly_line = "filesystem {0} already set to type {1} ({2}), while trying to set to {3} ({4})".\
                format(fs_dev, fs_2_type[fs_dev], fs_2_type_origin[fs_dev], fs_type, source)
            handle_anomaly("DUP-2", anomaly_line)

    if fs_type.startswith("nfs"):
        words = fs_dev.split(":")
        wc = len(words)
        if wc == 2 or wc == 3:
            nfs_server = words[0]
            all_nfs_servers = unique_list(all_nfs_servers, nfs_server)
        else:
            error_print("d", "no colon in {0} mounted on {1} but fs type={2} {3} ({4})".format(fs_dev, fs_mount_pt, fs_type, fs_opts, source))
            # print 4 / 0

    if fs_opts != "":
        new_options = fs_opts.strip("()")
        nwords = new_options.split(",")
        for new_opt in nwords:
            # if new_opt == "_netdev": fs_netdev_opt_cnt+=1 # could write a general rtn to count any option...
            fs_2_opts[fs_dev] = unique_list_sep(fs_2_opts[fs_dev], new_opt, ',', False)

    return

# ---------------------------------------------#
# function: fs_types_equal()
# ---------------------------------------------#


def fs_types_equal(fs1, fs2):

    if fs1 == fs2:
        return True
    if fs2 == "none":
        return True
    if fs1.startswith("nfs") and fs2.startswith("nfs"):
        return True

    fs_equal_type_groups = ""\
                           "nfs fuse.glusterfs glusterfs~"\
                           "fuse fuse.s3fs~"\
                           "ext4 rootfs~"\
                           ""
    tmp = fs_equal_type_groups.split('~')
    for fsg in tmp:
        if word_in_list(fs1, fsg) and word_in_list(fs2, fsg):
            return True
    # end: for fsg in tmp:

    # if fs1 == "fuse.glusterfs" and fs2 == "glusterfs": return True
    # if fs2 == "fuse.glusterfs" and fs1 == "glusterfs": return True

    return False

# ---------------------------------------------#
# function: valid_fs_type()
# ---------------------------------------------#


def valid_fs_type(fs_type, source):
    global fs_type_ptrns
    for ptrn in fs_type_ptrns:
        if re.match(ptrn, fs_type):
            return(True)
    # end: for ptrn in fs_type_ptrns:

    debug_print(3, "invalid fs_type: {0} ({1})".format(fs_type, source))
    return(False)

# ---------------------------------------------#
# function: fs_mountpoints_equal()
# ---------------------------------------------#


def fs_mountpoints_equal(mpt1, mpt2):

    if mpt1 == mpt2:
        return True

    list_h = "/etc/resolv.conf /etc/hosts /etc/hostname"
    if word_in_list(mpt1, list_h) and word_in_list(mpt2, list_h):
        return True

    debug_print(3, "{0} {1}".format(mpt1, mpt2))
    if mpt1.startswith("/export/") and "/export" + mpt2 == mpt1:
        return True

    if mpt2.startswith("/export/") and "/export" + mpt1 == mpt2:
        return True

    return False


# ---------------------------------------------#
# function: scan_dmesg_files()
# ---------------------------------------------#
def scan_dmesg_files():
    global sw_n
    global dmesg_files  # "var/log/dmesg "...

    files = dmesg_files.split()
    for fn in files:
        if file_exists_with_data(fn):
            scan_dmesg_data(fn)

    return

# ---------------------------------------------#
# function: scan_dmesg_data()
# early scan to pick some key data if available.
# ---------------------------------------------#


def scan_dmesg_data(dmesg_file):

    line_cnt = initial_file_check(dmesg_file)
    if line_cnt == 0:
        return  # nothing to process

    fh = openfile(dmesg_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove the ending \n
        i += 1
        if line == "":
            continue

        if line.startswith("Kernel command line:") or line.startswith("Command line:"):
            cp = line.find(":")
            tmp = line[cp + 1:]  # remaider of line without <Kernel Command>/<Command> line:
            tmp = tmp.strip()
            crunch_cmdline_data(tmp, dmesg_file)

        if line.startswith("Linux version "):
            crunch_linux_version_line(line, dmesg_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dmesg_file))
    return


# ---------------------------------------------#
# function: crunch_dmesg_files()
# ---------------------------------------------#
def crunch_dmesg_files(pass_no):
    global sw_n
    global dmesg_files  # "var/log/dmesg "...

    # typically, but not always, dmesg_now will contain messages that are also in var/log/messages

    files = dmesg_files.split()

    for fn in files:
        if file_exists_with_data(fn):
            crunch_dmesg_data(fn, pass_no)
            if not sw_n:
                break  # if sw_n, look at all possible dmesg variants
    # end: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_dmesg_data()
# ---------------------------------------------#


def crunch_dmesg_data(dmesg_file, pass_no):
    global this_script_name
    global count_of_times_do_scan_block_called  # 0
    global match_log_msg_match_calls  # 0
    global match_log_msg_matches  # 0
    global prev_msg_line
    global prev_scan_msg

    line_cnt = initial_file_check(dmesg_file)
    if line_cnt == 0:
        return  # nothing to process

    fh = openfile(dmesg_file)
    if fh is None:
        return

    esc_cleanup_count = 0
    prev_msg_line = ''
    prev_scan_msg = ''
    i = 0

    for dl in fh:
        dl = dl[0:len(dl) - 1]  # remove the ending \n
        i += 1
        if dl == "":
            continue

        # Warning!, Warning!: Ugly hack:
        # Some dmesg files have kernel level in the message (i.e. in the form of <n>, where n is the level))
        # example:
        # E<5>sd 5:0:2:19: Attached scsi disk sdpe
        # T<5>sd 4:0:2:16: Attached scsi disk sdpg
        # X<5>sd 1:0:2:17: Attached scsi disk sdph
        # <5>sd 4:0:2:17: Attached scsi disk sdpk
        # <5>sd 2:0:2:20: Attached scsi disk sdpl
        # <5>sd 6:0:2:12: Attached scsi disk sdpn
        # <5>sd 4:0:2:18: Attached scsi disk sdpp
        #
        # We will try to adjust for this  on the fly but it may be imperfect
        cm = re.search("<[0-9]>", dl)
        if cm:
            esc_str = cm.group()
            debug_print(4, "({0} {1}) pre-esc: {2}".format(i, dmesg_file, dl))

            esc_cleanup_count += 1
            tmp = dl.split(esc_str)
            p0 = tmp[0]  # throw away tmp[0] (i.e. whatever was on the left)
            dl = tmp[1]  # throw away tmp[0] (i.e. whatever was on the left)

            p0 = tmp[0].strip()  # +'text on left of <n>'
            p1 = tmp[1].strip()  # +'text on right of <n>'

            debug_print(4, "({0} {1}) post-esc: '{2}' '{3}'".format(i, dmesg_file, p0, p1))

            dl = p0 + '\n' + p1
        sub_lines = dl.split('\n')
        for sl in sub_lines:  # almost always 1 line, only if the <n> search above finds something are there 2 lines
            # dummy up dmesg line with 'kernel: ' to make it look like a msg from var/log/messages
            # this lets us have one set of scan patterns.
            check_log_msg(0, pass_no, "kernel: " + sl, i, dmesg_file)  # go check for matches...
            prev_msg_line = sl

        # end of "for sl in sub_lines:" ----------------------------------
    # end of "for dl in dmesg_lines:" ------------------------------------
    # end of "for dl in fh:" ---------------------------------------------

    if esc_cleanup_count > 0:
        anomaly_line = "{0}: attempted to clean up {1} lines containing escape sequences '<[0-9]>' ({2})".\
                       format(this_script_name, esc_cleanup_count, dmesg_file)
        handle_anomaly("DATA-3", anomaly_line)
    esc_cleanup_count = 0

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dmesg_file))

    debug_print(1, "match checks: {0} matches: {1}".format(match_log_msg_match_calls, match_log_msg_matches))
    debug_print(1, "count of times do_scan_block_called {0}".format(count_of_times_do_scan_block_called))
    match_log_msg_match_calls = 0
    match_log_msg_matches = 0
    count_of_times_do_scan_block_called = 0

    return


# ---------------------------------------------#
# function: set_cpu_count()
# key hole setting of cpu count in order to trace how it was set if needed.
# ---------------------------------------------#
def set_cpu_count(count, source):
    global cpu_count  # 0

    debug_print(2, "current count:{0} new count:{1} ({2})".format(cpu_count, count, source))
    cpu_count = max(cpu_count, count)
    return

# ---------------------------------------------#
# function: do_intel_cpu()
# Intel pstate controlling: cpu 18
# Intel pstate controlling: cpu 19
# ---------------------------------------------#


def do_intel_cpu(line, words, line_no, source):

    # words = sl.split()
    cpu = words[5]
    if not cpu.isdigit():
        debug_print("cpu='{0}'? '{1}' ({2})".format(cpu, line, source))
        return
    cpu = int(words[5])
    set_cpu_count(cpu, source)
    return

# ---------------------------------------------#
# function: do_dmi_line
# ---------------------------------------------#


def do_dmi_line(line, words, line_no, source):
    global dmi_sys_data
    if line.startswith("kernel: DMI:"):
        dmi_sys_data = " "
        dmi_sys_data = dmi_sys_data.join(words[2:])  # cut off 'kernel: DMI:'
        dmi_sys_data = dmi_sys_data.strip()
        debug_print(3, "sys: {0}".format(dmi_sys_data))
        check_virtual_status(dmi_sys_data, source)
        return

    if line.startswith("kernel: Hypervisor detected:"):
        check_virtual_status(line, source)
        return

    return


# ---------------------------------------------#
# function: check_virtual_status()
# ---------------------------------------------#
def check_virtual_status(line, source):
    global Virtual_guest, Virtual_type
    global dmi_sys_data
    default_guest_type = ""

    debug_print(3, "'{0} ({1})".format(line, source))

    if "VMware" in line:
        set_virtual_type("VMware", line, source)

    elif "Red Hat KVM" in line or "Red Hat RHEV" in line:
        set_virtual_type("RHEV", line, source)

    elif "Red Hat OpenStack Compute" in line:
        set_virtual_type("OpenStack", line, source)

    elif "Xen HVM" in line or "Xen version: " in line:
        set_virtual_type("Xen HVM", line, source)
        # Xen HVM machines will often have one or more QEMU devices which will cause Virtual_type to have an initial setting of RHEV
        # if Virtual_type != '' and Virtual_type != "Xen HVM" and Virtual_type != "RHEV": error_print("d","[{0}] '{1}' ({2})".format(Virtual_type,line,source))
        # Virtual_type  = "Xen HVM"

    elif "QEMU" in line:
        set_virtual_type("RHEV", line, source)
        Virtual_guest = True
        # if Virtual_type != '' and (Virtual_type != "RHEV" and Virtual_type != "Xen HVM" and Virtual_type != "OpenStack"):
        # error_print("d","[{0}] '{1}'".format(Virtual_type,line))
        # if Virtual_type == '': Virtual_type  = "RHEV"

    elif "VirtualBox" in line or "VBOX" in line:
        set_virtual_type("VirtualBox", line, source)

    elif "Microsoft" in line and "Virtual" in line:
        set_virtual_type("HyperV", line, source)

    elif "kernel: Hypervisor detected: KVM" == line:
        set_virtual_type("RHEV", line, source)

    elif "kernel: Hypervisor detected:" in line:

        Virtual_guest = True
        words = line.split()
        wc = len(words)
        if wc > 2:
            default_guest_type = " "
            default_guest_type = default_guest_type.join(words[3:])
            default_guest_type = default_guest_type.strip()
        set_virtual_type(default_guest_type, line, source)

    elif "z/VM guest operating system" in line or \
         "z/VM virtual unit record device" in line:
        set_virtual_type("z/VM", line, source)

    if Virtual_guest:
        debug_print(3, "[{0}] '{1}' ({2})".format(Virtual_type, line, source))

    return
# ---------------------------------------------#
# function: set_virtual_type()
# if already set, check that it's equivalent, if not error_print
# ---------------------------------------------#


def set_virtual_type(guest_type, line, source):
    global Virtual_guest, Virtual_type, Virtual_type_source

    if guest_type == Virtual_type:
        return  # same value that has already been set

    if Virtual_type == "":
        Virtual_guest = True
        Virtual_type = guest_type
        Virtual_type_source = source
        return

    if guest_type in Virtual_type:
        return

    action = file_check(Virtual_type_source, source)
    if do_anomaly(action):
        anom_lne = "Virtual type already set to '{0}' ({1}), while trying set trying to set to '{2}' ({3}) '{4}'".\
                   format(Virtual_type, Virtual_type_source, guest_type, source, line)
        add_anomaly("DUP-1", anom_line)

    return

# ---------------------------------------------#
# function: check_hypervisor_status()
# check if this linux machine hosting virtual machines
# ---------------------------------------------#


def check_hypervisor_status(line, source):
    global Hypervisor, Hypervisor_type
    if "Red Hat" in line and "Hypervisor" in line and "release" in source:
        Hypervisor = True
        if "RHEV" in line:
            Hypervisor_type = "RHEV"
        elif "KVM" in line:
            Hypervisor_type = "KVM"
        else:
            Hypervisor_type = "RHEV"

    if not Hypervisor and "/usr/libexec/qemu-kvm" in line and "process" in source:
        Hypervisor = True
        Hypervisor_type = "qemu-kvm"

    return

# ---------------------------------------------#
# function: get_active_cpu_count()
# line -> "kernel: Brought up nnn CPUs"
# ---------------------------------------------#


def get_active_cpu_count(line, words, line_no, source):
    global cpus_active

    cpus_active = int(words[3])
    debug_print(2, "cpus active:{0} '{1} ({2})".format(cpus_active, line, source))
    return

# ---------------------------------------------#
# function: check_s390_dasd()
# ---------------------------------------------#


def check_s390_dasd(line, words, line_no, source):
    global s390
    global prev_dasd_cuuu
    global prev_dasd_eckd_line

    # kernel: dasd-fba 0.0.0301: New FBA DASD 9336/10 (CU 6310/80) with 512 MB and 512 B/blk
    # kernel: dasd-eckd 0.0.0221: New DASD 3390/0C (CU 3990/01) with 10016 cylinders, 15 heads, 224 sectors
    # kernel: dasd-eckd 0.0.0221: DASD with 4 KB/block, 7211520 KB total size, 48 KB/track, compatible disk layout
    # kernel: dasdv:VOL1/  0X0221: dasdv1
    if not s390:
        return  # SHOULD NOT OCCUR

    # debug_print(z,line) # REMOVE
    if words[1] == "dasd-eckd":
        cuuu = words[2].rstrip(':')
        type = ''
        if '3390' in line:
            type = '3390'
        track_s390_cuuu(cuuu, "dasd", type, '', source)
        prev_dasd_eckd_line = line_no
        prev_dasd_cuuu = cuuu
        return

    # debug_print(z,line) # REMOVE
    if words[1] == "dasd-fba":
        cuuu = words[2].rstrip(':')
        type = ''
        if '9336' in line:
            type = '9336'
        track_s390_cuuu(cuuu, "fba", type, '', source)
        prev_dasd_eckd_line = line_no
        prev_dasd_cuuu = cuuu
        return

    # Take the vol1 data with a grain of salt...the relationship, as derived from this msg,
    # between cuuu and dasdid/vol1 is tenuous at best.
    if "VOL1" in words[1]:
        dasdid = words[1].rstrip(':VOL1/')
        vol1 = words[2][0:6]
        cuuu = dasd_2_cuuu[dasdid]
        if cuuu != '':
            track_s390_dasd(cuuu, dasdid, vol1, '', '', '', '', source)
        elif prev_dasd_eckd_line == (line_no - 1) and prev_dasd_cuuu != '':
            track_s390_dasd(prev_dasd_cuuu, dasdid, vol1, '', '', '', '', source)
        elif vol1.startswith("0X"):
            cuuu = vol1[2:].lower()
            if is_hex(cuuu):
                track_s390_dasd(cuuu, dasdid, vol1, '', '', '', '', source)

    return
# ---------------------------------------------#
# function: track_s390_cuuu()
# ---------------------------------------------#


def track_s390_cuuu(cuuu, s390_class, s390_type, s390_status, source):
    global cuuu_2_class  # Key_data()
    global cuuu_2_class_origin  # Key_data()
    global cuuu_2_type  # Key_data()
    global cuuu_2_type_origin  # Key_data()
    global cuuu_2_status  # Key_data()
    global cuuu_2_status_origin  # Key_data()
    global class_2_cuuus  # Key_data()
    global type_2_cuuus  # Key_data()
    global max_hlq1  # 0
    global max_hlq2  # 0
    global high_cuuu  # 0
    global low_cuuu  # big_num
    global s390_device_count  # 0

    debug_print(3, "{0} '{1}' '{2}' '{3}' ({4})".format(cuuu, s390_class, s390_type, s390_status, source))

    hlq1 = '0'
    hlq2 = '0'
    if '.' in cuuu:
        tmp = cuuu.split('.')
        hlq1 = tmp[0]
        hlq2 = tmp[1]
        cuuu = tmp[2]

    max_hlq1 = max(max_hlq1, int(hlq1))
    max_hlq2 = max(max_hlq2, int(hlq2))

    _cuuu = int(cuuu, 16)
    if _cuuu > high_cuuu:
        high_cuuu = _cuuu
    if _cuuu < low_cuuu:
        low_cuuu = _cuuu

    if s390_class == '':
        s390_class = get_class_from_type(s390_type)

    if s390_class != "":
        if cuuu_2_class[cuuu] == "":
            cuuu_2_class[cuuu] = s390_class
            cuuu_2_class_origin[cuuu] = source
            s390_device_count += 1
        elif cuuu_2_class[cuuu] != s390_class:
            anomaly_line = "cuuu {0} already has class set to {1} ({2}), attempting to set to {3} ({4})".\
                format(cuuu, cuuu_2_class[cuuu], cuuu_2_class_origin[cuuu], s390_class, source)
            handle_anomaly("DUP-3", anomaly_line)
        class_2_cuuus[s390_class] = unique_list(class_2_cuuus[s390_class], cuuu)
    # end: if s390_class != "":

    if s390_type != "":
        if cuuu_2_type[cuuu] == "":
            cuuu_2_type[cuuu] = s390_type
            cuuu_2_type_origin[cuuu] = source
        elif cuuu_2_type[cuuu] != s390_type:
            anomaly_line = "cuuu {0} already has type set to {1} ({2}), attempting to set to {3} ({4})".\
                format(cuuu, cuuu_2_type[cuuu], cuuu_2_type_origin[cuuu], s390_type, source)
            handle_anomaly("DUP-3", anomaly_line)
        type_2_cuuus[s390_type] = unique_list(type_2_cuuus[s390_type], cuuu)
    # end: if s390_type != "":

    if s390_status != "":
        if cuuu_2_status[cuuu] == "":
            cuuu_2_status[cuuu] = s390_status
            cuuu_2_status_origin[cuuu] = source
        elif cuuu_2_status[cuuu] != s390_status:
            anomaly_line = "cuuu {0} already has status set to {1} ({2}), attempting to set to {3} ({4})".\
                format(cuuu, cuuu_2_status[cuuu], cuuu_2_status[cuuu], s390_status, source)
            handle_anomaly("DUP-3", anomaly_line)
        # status[s390_status] = unique_list(status[s390_status],cuuu)
    # end: if s390_status != "":

    return

# ---------------------------------------------#
# function: get_class_from_type():
# ---------------------------------------------#


def get_class_from_type(s390_type):

    class_types = ""\
                  "dasd:3390 3380 3350 3330~"\
                  "fba:9336 9335 9332 3370 3310~"\
                  "tape:3480 3490~"\
                  "ur:2540~"\
                  "prt:1403~"\
                  "cons:3215~"\
                  "graf:3270 3277 3278 3279~"\
                  "osa:1731 1732~"\
                  ""
    if s390_type == '':
        return('')

    classes = class_types.split("~")
    for _class in classes:
        if _class == '':
            continue
        tmp = _class.split(":")
        s390_class = tmp[0]
        type_list = tmp[1]
        if word_in_list(s390_type, type_list):
            return(s390_class)
    # end: for _class in classes:

    return('')


def normalize_cuuu(cuuu):

    if len(cuuu) < 4:
        cuuu = cuuu.rjust(4, "0")
    if len(cuuu) == 4:
        cuuu = "0.0." + cuuu

    return(cuuu)

# ---------------------------------------------#
# function: track_s390_dasd()
# ---------------------------------------------#


def track_s390_dasd(cuuu, dasdid, vol1, mm, s390_class, s390_type, s390_status, source):
    global cuuu_2_dasd  # Key_data()
    global cuuu_2_dasd_origin  # Key_data()
    global dasd_2_cuuu  # Key_data()
    global dasd_2_cuuu_origin  # Key_data()
    global cuuu_2_vol1  # Key_data()
    global cuuu_2_vol1_origin  # Key_data()

    debug_print(3, "{0} {1} {2} {3} {4} {5} {6}".format(cuuu, dasdid, vol1, mm, s390_class, s390_type, source))
    track_s390_cuuu(cuuu, s390_class, s390_type, s390_status, source)

    if '.' in cuuu:
        tmp = cuuu.split('.')
        cuuu = tmp[2]

    if cuuu_2_dasd[cuuu] == "":
        cuuu_2_dasd[cuuu] = dasdid
        cuuu_2_dasd_origin[cuuu] = source
    elif cuuu_2_dasd[cuuu] != dasdid:
        p_dasdid = cuuu_2_dasd[cuuu]
        if dasdid.startswith(p_dasdid) and dasdid[len(dasdid) - 1:].isdigit():
            dasd_2_parts[p_dasdid] = unique_list(dasd_2_parts[p_dasdid], dasdid)
        else:
            action = file_check(cuuu_2_dasd_origin[cuuu], source)
            if do_anomaly(action):
                anomaly_line = "cuuu {0} already has id set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                    format(cuuu, cuuu_2_dasd[cuuu], cuuu_2_dasd_origin[cuuu], dasdid, action, source)
                handle_anomaly("DUP-1", anomaly_line)
            if action == "overridden":
                cuuu_2_dasd[cuuu] = dasdid
                cuuu_2_dasd_origin[cuuu] = source

    if dasd_2_cuuu[dasdid] == "":
        dasd_2_cuuu[dasdid] = cuuu
        dasd_2_cuuu_origin[dasdid] = source
    elif dasd_2_cuuu[dasdid] != cuuu:
        action = file_check(dasd_2_cuuu_origin[dasdid], source)
        if do_anomaly(action):
            anomaly_line = "id {0} already has cuuu set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                format(dasdid, dasd_2_cuuu[dasdid], dasd_2_cuuu_origin[dasdid], cuuu, action, source)
            handle_anomaly("DUP-1", anomaly_line)
        if action == "overridden":
            dasd_2_cuuu[dasdid] = cuuu
            dasd_2_cuuu_origin[dasdid] = source

    if vol1 != '':
        if cuuu_2_vol1[cuuu] == "":
            cuuu_2_vol1[cuuu] = vol1
            cuuu_2_vol1_origin[cuuu] = source
        elif cuuu_2_vol1[cuuu] != vol1:
            action = file_check(cuuu_2_vol1_origin[cuuu], source)
            if do_anomaly(action):
                anomaly_line = "cuuu {0} already has vol1id set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                    format(cuuu, cuuu_2_vol1[cuuu], cuuu_2_vol1_origin[cuuu], vol1, action, source)
                handle_anomaly("DUP-1", anomaly_line)
            if action == "overridden":
                cuuu_2_vol1[cuuu] = vol1
                cuuu_2_vol1_origin[cuuu] = source
    # end: if vol1 != '':

    if mm != '':
        add_mm_bd(dasdid, mm, source)

    return


# ---------------------------------------------#
# function: crunch_cpuinfo()
# process cpu info, look for processor instance number and type
# ---------------------------------------------#
def crunch_cpuinfo():
    global dmi_cpu_data

    if file_exists_with_data("cpuinfo"):
        cpu_file = "cpuinfo"
    else:
        cpu_file = "proc/cpuinfo"
    fh = openfile(cpu_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.replace("\t", '')
        line = line.strip()
        if line == "":
            continue

        words = line.split()
        wc = len(words)
        if wc == 0:
            continue
        if line.startswith("processor: ") and wc > 1:
            cpu_no = words[1]
            if cpu_no.isdigit():
                set_cpu_count(int(cpu_no), cpu_file)

        if line.startswith("model name: "):
            dmi_cpu_data = " "
            dmi_cpu_data = dmi_cpu_data.join(words[2:])

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, cpu_file))
    return

# ---------------------------------------------#
# function: crunch_ps_l_info()
# check for real time processes and other rare items.
#
# F   UID   PID  PPID PRI  NI    VSZ   RSS WCHAN  STAT TTY        TIME COMMAND
# 4     0     1     0  20   0  19364  1548 poll_s Ss   ?          0:02 /sbin/init
# 1     0     2     0  20   0      0     0 kthrea S    ?          0:00 [kthreadd]
# 1     0     3     2 -100  -      0     0 migrat S    ?          0:00 [migration/0]
# 1     0     4     2  20   0      0     0 ksofti S    ?          0:00 [ksoftirqd/0]
#
# words:
# 0     1     2     3  4    5      6     7 8      9   10         11   12
#
#
# ---------------------------------------------#


def crunch_ps_l_info():
    global total_rt_procs  # 0
    global rt_procs  # ''
    global rt_proc_count  # Counter()

    ps_file = "sos_commands/process/ps_alxwww"
    fh = openfile(ps_file)
    if fh is None:
        return

    # process ps info, look for real time info, etc.
    sys_rt_names = "migration stopper watchdog"
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "":
            continue

        words = line.split()
        wc = len(words)
        # debug_print(4,"({0} {1}) word cnt {2}".format(i,ps_file,wc))

        if wc < 13:
            continue  # in case ps killed and output truncated

        proc_name = ""
        proc_flag = words[0]
        proc_uid = words[1]
        proc_pid = words[2]
        proc_ppid = words[3]
        proc_pri = words[4]
        proc_ni = words[5]
        proc_vsz = words[6]
        proc_rss = words[7]
        proc_wchan = words[8]
        proc_stat = words[9]
        proc_tty = words[10]
        proc_time = words[11]
        proc_name = words[12]

        if proc_name.startswith("["):
            proc_name = proc_name.strip("[]")
            if proc_name.find("/") != -1:
                tmp = proc_name.split("/")
                twc = len(tmp)
                if proc_name.startswith("/"):
                    proc_name = tmp[twc - 1]  # last word /dir/dir/proc
                else:
                    proc_name = tmp[0]  # first word in [deamon/nn]
        elif proc_name.startswith("/"):
            tmp = proc_name.split("/")
            twc = len(tmp)
            proc_name = tmp[twc - 1]  # last word in /dir/dir/proc

        if proc_ni == "-":
            if word_in_list(proc_name, sys_rt_names):
                continue
            total_rt_procs += 1
            rt_procs = unique_list(rt_procs, proc_name)
            rt_proc_count[proc_name] += 1

    # end: for line in ps_lines:
    # end: for line in fh:
    # ============================================================

    tmp = rt_procs.split()
    wc = len(tmp)
    debug_print(3, "{0} rt procs found [{1} unique] ({2})".format(total_rt_procs, wc, ps_file))
    for rt_proc in tmp:
        debug_print(3, "{0} count: {1}".format(rt_proc, rt_proc_count[rt_proc]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ps_file))
    return


# ---------------------------------------------#
# function: crunch_ps_slot_info()
# process ps info, check vs kernel restraints
#
# USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
# root         1  0.0  0.0 406716 221396 ?       -     2016  36:47 /usr/lib/systemd/systemd --switched-root --system --deserialize 21
# root         -  0.0    -      -     - -        Ss    2016  36:47 -
# root         2  0.0  0.0      0     0 ?        -     2016   0:04 [kthreadd]
# root         -  0.0    -      -     - -        S     2016   0:04 -
# root         3  0.0  0.0      0     0 ?        -     2016   5:25 [ksoftirqd/0]
# root         -  0.0    -      -     - -        S     2016   5:25 -
# root         5  0.0  0.0      0     0 ?        -     2016   0:00 [kworker/0:0H]
# root         -  0.0    -      -     - -        S<    2016   0:00 -
# root         8  0.0  0.0      0     0 ?        -     2016   5:32 [migration/0]
#
# words:
# 0            1  2    3    4      5    6        7    8       9    10
#
# ---------------------------------------------#
def crunch_ps_slot_info():
    global sysctl  # Key_data

    ps_file = "sos_commands/process/ps_auxwwwm"
    fh = openfile(ps_file)
    if fh is None:
        return

    total_proc_slots = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line.startswith("USER "):
            continue

        words = line.split()
        wc = len(words)
        # debug_print(4,"({0} {1}) word cnt {2}".format(i,ps_file,wc))

        if wc < 11:
            continue  # in case ps killed and output truncated

        total_proc_slots += 1

    # end: for line in ps_lines:
    # ============================================================

    pid_max = sysctl["kernel.pid_max"]
    if total_proc_slots > pid_max and pid_max != -1:
        anomaly_line = "Found {0} processes, but pid max is set to {1}, increase pid max ({2})".\
                       format(total_proc_slots, pid_max, ps_file)
        handle_anomaly_with_points("PROC", anomaly_line, 'performance', 100)

    # if total_proc_slots > 40000: debug_print(z,"{0} lines read, {1} process slots counted, pid max {2}".format(i,total_proc_slots,pid_max))
    debug_print(3, "{0} lines read, {1} process slots counted, pid max {2}".format(i, total_proc_slots, pid_max))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ps_file))
    return

# ---------------------------------------------#
# function: crunch_ps_info()
# process ps info, look for various process info and save it
#
# USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
# root         1  0.0  0.0  19364  1548 ?        Ss   17:59   0:02 /sbin/init
# root         2  0.0  0.0      0     0 ?        S    17:59   0:00 [kthreadd]
# root         3  0.0  0.0      0     0 ?        S    17:59   0:00 [migration/0]
# root         4  0.0  0.0      0     0 ?        S    17:59   0:00 [ksoftirqd/0]
#
# words:
# 0            1  2    3    4      5    6        7    8       9    10
#
# ---------------------------------------------#


def crunch_ps_info():
    global Oracle  # False
    global service_time  # Counter()
    global service_procs  # Counter()
    global all_services
    global mp_services
    global total_d_state_procs  # 0
    global d_state_procs  # ''                    # list of unique process names in 'D' state
    global d_state_proc_count  # Counter()      # key: 'D' state proc name  date: proc count
    global total_z_state_procs  # 0
    global z_state_procs  # ''                    # list of unique process names in 'Z' state
    global z_state_proc_count  # Counter()      # key: 'Z' state proc name  date: proc count
    global sysctl  # Key_data
    global proc_cpu_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file
    global proc_mem_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file
    global proc_tim_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file
    global total_procs  # 0                     # total number of processes at time of sos report

    ps_file = "sos_commands/process/ps_auxwww"
    if not file_exists_with_data(ps_file):
        ps_file = "ps"
    fh = openfile(ps_file)
    if fh is None:
        return

    # process ps info, look for various process info and save it
    service_words = all_services.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line.startswith("USER "):
            if line.startswith("USER "):
                proc_cpu_line[0] = line
                proc_mem_line[0] = line
                proc_tim_line[0] = line
            continue

        words = line.split()
        wc = len(words)
        # debug_print(4,"({0} {1}) word cnt {2}".format(i,ps_file,wc))

        if wc < 11:
            continue  # in case ps killed and output truncated

        if "XXX.XXX.XXX.XXX" in line:
            continue  # case

        total_procs += 1
        proc_name = ""
        proc_user = words[0]
        # proc_pid = words[1]
        proc_cpu = words[2]
        proc_mem = words[3]
        # proc_vsz = words[4]
        # proc_rss = words[5]
        # proc_tty = words[6]
        proc_stat = words[7]
        # proc_date = words[8]
        proc_time = words[9]
        if proc_time == "0:00":
            total_proc_seconds = 0
        else:
            tmp = proc_time.split(':')
            twc = len(tmp)
            if twc == 2:
                total_proc_seconds = int(tmp[0]) * 60
                total_proc_seconds += int(tmp[1])
            else:
                debug_print(0, "WTF_PROCTIME {0}".fomat(proc_time))
        track_top_cpu_procs(float(proc_cpu), line, ps_file)
        track_top_mem_procs(float(proc_mem), line, ps_file)
        track_top_tim_procs(total_proc_seconds, line, ps_file)

        if wc >= 11:
            proc_name = words[10]

        if proc_name.startswith("["):
            proc_name = proc_name.strip("[]")
            if proc_name.find("/") != -1:
                if proc_name.startswith("/"):
                    if proc_stat.startswith("Z"):
                        tmp = proc_name.split("/")
                        twc = len(tmp)
                        proc_name = tmp[twc - 1]  # last word in /dir/dir/proc
                    else:
                        error_print("d", line)
                else:
                    tmp = proc_name.split("/")
                    twc = len(tmp)
                    proc_name = tmp[0]  # first word in [deamon/nn]
        elif proc_name.startswith("/"):
            tmp = proc_name.split("/")
            twc = len(tmp)
            proc_name = tmp[twc - 1]  # last word in /dir/dir/proc
        if proc_user == 'oracle' or \
           proc_name.startswith('asm_') or \
           proc_name.startswith('oracle_') or \
           proc_name.startswith('oracle+') or \
           proc_name.startswith('ora_') or \
           proc_name.startswith('oraag') or \
           proc_name.startswith('oraroot') or \
           proc_name.startswith('ologger') or \
           proc_name.startswith('osysmond') or \
           proc_name.startswith('octssd') or \
           proc_name.startswith('ocssd') or \
           proc_name.startswith('ohasd') or \
           proc_name.startswith('cssdagent') or \
           proc_name.startswith('cssdmonitor') or \
           proc_name.startswith('mdb_ckpt') or \
           proc_name.startswith('tnslsnr'):
            Oracle = True
            track_db_servers("Oracle", proc_name, line)
        elif "db2" in proc_name:
            track_db_servers("Db2", proc_name, line)
        elif "mysql" in proc_name or "mySQL" in proc_name:
            track_db_servers("MySQL", proc_name, line)
        elif "Postgres" in proc_name or "postgres" in proc_name:
            track_db_servers("PostgreSQL", proc_name, line)
        elif "sybase" in proc_name or "sybase" == proc_user:
            track_db_servers("sybase", proc_name, line)
        if proc_name.startswith("/"):
            tmp = proc_name.split("/")
            twc = len(tmp)
            proc_name = tmp[twc - 1]  # last word in /d1/d2/miscd

        # if "sbin/libvirtd" in line: check_hypervisor_status(line,ps_file)
        if proc_name == "qemu-kvm":
            check_hypervisor_status(line, ps_file)

        for service in service_words:  # service_words = all_services.split() [ list of services we want to track for possible later use ]
            if service == proc_name:
                service_procs[service] += 1
                service_time[service] += total_proc_seconds
        # end: for service in service_words: # service_words = all_services.split() [ list of services we want to track for possible later use ]
        #
        # PROCESS STATE CODES: Here are the different values that the s, stat and state output specifiers
        # (header "STAT" or "S") will display to describe the state of a process:
        # [more that one character can be displayed per process]
        #
        # D    uninterruptible sleep (usually IO)
        # R    running or runnable (on run queue)
        # S    interruptible sleep (waiting for an event to complete)
        # T    stopped by job control signal
        # t    stopped by debugger during the tracing
        # W    paging (not valid since the 2.6.xx kernel)
        # X    dead (should never be seen)
        # Z    defunct ("zombie") process, terminated but not reaped by its parent
        #
        # For BSD formats and when the stat keyword is used, additional characters may be displayed:
        #
        # <    high-priority (not nice to other users)
        # N    low-priority (nice to other users)
        # L    has pages locked into memory (for real-time and custom IO)
        # s    is a session leader
        # l    is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)
        # +    is in the foreground process group
        #

        if proc_stat == "D" or proc_stat.startswith("D"):
            total_d_state_procs += 1
            d_state_procs = unique_list(d_state_procs, proc_name)
            d_state_proc_count[proc_name] += 1

        if proc_stat == "Z" or proc_stat.startswith("Z"):
            total_z_state_procs += 1
            z_state_procs = unique_list(z_state_procs, proc_name)
            z_state_proc_count[proc_name] += 1

    # end: for line in ps_lines:
    # ============================================================

    if service_procs["multipathd"]:
        words = mp_services.split()
        for tmp in words:
            tmp2 = tmp.split(',')
            vendor = tmp2[0]
            daemon = tmp2[1]
            if daemon == "multipathd":
                continue
            if service_procs[daemon]:
                anomaly_line = "Both multipathd and {0} {1} appear to be running, but only one should be, see KCS {2} & SFDC {3} ({4})".\
                    format(vendor, daemon, kcs_url("358783"), sfdc_url("01628200"), ps_file)
                handle_anomaly_with_points("SERVICE", anomaly_line, 'configuration', 5)

    if service_procs["mmfsd"]:
        cpu_rank = find_cpu_rank("mmfsd")
        mem_rank = find_mem_rank("mmfsd")
        time_rank = find_time_rank("mmfsd")
        if cpu_rank or mem_rank or time_rank:
            cpu_blurb = ''
            mem_blurb = ''
            time_blurb = ''
            cats = 0
            if cpu_rank:
                cpu_blurb = "(# {0} in %CPU)".format(cpu_rank)
                cats += 1
            if mem_rank:
                mem_blurb = "(# {0} in %MEM)".format(mem_rank)
                cats += 1
            if time_rank:
                time_blurb = "(# {0} in TIME)".format(time_rank)
                cats += 1
            blurb = squeeze(cpu_blurb + " " + mem_blurb + " " + time_blurb)
            anomaly_line = "Found mmfsd in the top 10 of {0} categories [{1}], {2} ({3})".\
                           format(cats, blurb, cfa_kcs('1522253'), ps_file)
            handle_anomaly_with_points("GPFS", anomaly_line, 'performance', 20)

    if total_d_state_procs > 0:
        procword = 'process'
        if total_d_state_procs > 1:
            procword = 'processes'
        anomaly_line = "Found {0} {1} in 'D' state [{2}], {3} ({4})".\
                       format(total_d_state_procs, procword, d_state_procs, info_kcs('59989'), ps_file)
        handle_anomaly_with_points("HUNG", anomaly_line, 'performance', total_d_state_procs * 10)

    cnt = d_state_proc_count['elxhbamgrd']
    if cnt > 0:
        anomaly_line = "Found {0} instance{1} of 'elxhbamgrd' in 'D' state, {2}".\
                       format(cnt, plural(cnt), cfa_kcs("489243"))
        handle_anomaly("HUNG", anomaly_line)

    if total_z_state_procs > 4:
        procword = 'process'
        if total_z_state_procs > 1:
            procword = 'processes'
        anomaly_line = "Found {0} zombie {1} [{2}], ({3})".\
                       format(total_z_state_procs, procword, z_state_procs, ps_file)
        handle_anomaly_with_points("PROC", anomaly_line, 'performance', total_z_state_procs * 3)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ps_file))
    return

# ---------------------------------------------#
# function track_top_cpu_procs()
# ---------------------------------------------#


def track_top_cpu_procs(pct_cpu, line, source):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_cpu      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %CPU
    global proc_cpu_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    # if pct_cpu == 0.0: return
    if pct_cpu < 1.0:
        return
    if pct_cpu < proc_cpu[proc_slots]:
        return

    insert = False
    for i in range(1, proc_slots + 1):
        if insert:
            prv_cpu = proc_cpu[i]
            prv_cpu_line = proc_cpu_line[i]

            proc_cpu[i] = tmp_cpu
            proc_cpu_line[i] = tmp_cpu_line

            tmp_cpu = prv_cpu
            tmp_cpu_line = prv_cpu_line
            continue
        if pct_cpu > proc_cpu[i]:
            tmp_cpu = proc_cpu[i]
            tmp_cpu_line = proc_cpu_line[i]
            insert = True
            proc_cpu[i] = pct_cpu
            proc_cpu_line[i] = line
    # end: for i in range(1,proc_slots+1):
    return

# ---------------------------------------------#
# function track_top_mem_procs()
# ---------------------------------------------#


def track_top_mem_procs(pct_mem, line, source):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_mem      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %MEM
    global proc_mem_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    # if pct_mem == 0.0: return
    if pct_mem < 1.0:
        return
    if pct_mem < proc_mem[proc_slots]:
        return

    insert = False
    for i in range(1, proc_slots + 1):
        if insert:
            prv_mem = proc_mem[i]
            prv_mem_line = proc_mem_line[i]

            proc_mem[i] = tmp_mem
            proc_mem_line[i] = tmp_mem_line

            tmp_mem = prv_mem
            tmp_mem_line = prv_mem_line
            continue
        if pct_mem > proc_mem[i]:
            tmp_mem = proc_mem[i]
            tmp_mem_line = proc_mem_line[i]
            insert = True
            proc_mem[i] = pct_mem
            proc_mem_line[i] = line
    # end: for i in range(1,proc_slots+1):
    return

# ---------------------------------------------#
# function track_top_tim_procs()
# ---------------------------------------------#


def track_top_tim_procs(tot_tim, line, source):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_tim      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for TIME
    global proc_tim_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    if tot_tim == 0.0:
        return
    if tot_tim < proc_tim[proc_slots]:
        return

    insert = False
    for i in range(1, proc_slots + 1):
        if insert:
            prv_tim = proc_tim[i]
            prv_tim_line = proc_tim_line[i]

            proc_tim[i] = tmp_tim
            proc_tim_line[i] = tmp_tim_line

            tmp_tim = prv_tim
            tmp_tim_line = prv_tim_line
            continue
        if tot_tim > proc_tim[i]:
            tmp_tim = proc_tim[i]
            tmp_tim_line = proc_tim_line[i]
            insert = True
            proc_tim[i] = tot_tim
            proc_tim_line[i] = line
    # end: for i in range(1,proc_slots+1):
    return


# ---------------------------------------------#
# function: find_cpu_rank()
# ---------------------------------------------#
def find_cpu_rank(proc_name):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_cpu      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %CPU
    global proc_cpu_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    for i in range(1, proc_slots + 1):
        if proc_name in proc_cpu_line[i]:
            return(i)
    # end: for i in range(1,proc_slots+1):

    return(0)

# ---------------------------------------------#
# function: find_mem_rank()
# ---------------------------------------------#


def find_mem_rank(proc_name):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_mem      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for %MEM
    global proc_mem_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    for i in range(1, proc_slots + 1):
        if proc_name in proc_mem_line[i]:
            return(i)
    # end: for i in range(1,proc_slots+1):

    return(0)
# ---------------------------------------------#
# function: find_time_rank()
# ---------------------------------------------#


def find_time_rank(proc_name):
    global proc_slots  # 10                     # track this many instances of proc data in proc_xxxxx arrays
    global proc_tim      # Counter()           # 'proc_slots' count ordered array (highest->lowest) for TIME
    global proc_tim_line  # Key_data()          # 'proc_slots' count ordered array  of data line from ps file

    for i in range(1, proc_slots + 1):
        if proc_name in proc_tim_line[i]:
            return(i)
    # end: for i in range(1,proc_slots+1):

    return(0)

# ---------------------------------------------#
# function: track_lockup_processes()
# Jan 16 23:38:58 ryelxdwpdb1 kernel: BUG: soft lockup - CPU# 43 stuck for 10s! [oracle:13008]
# Jun  1 12:08:16 lctcvp6523 kernel: NMI watchdog: BUG: soft lockup - CPU# 2 stuck for 21s! [java:8058]
# ---------------------------------------------#


def track_lockup_processes(line, words, source):
    global all_lockup_processes  # ""
    global lock_process_pids  # Key_data() # key: process name: data process id instances

    wc = len(words)
    locked_process = words[wc - 1].strip("[]")  # last word
    tmp = locked_process.split(':')
    proc_name = tmp[0]
    proc_pid = tmp[1]
    all_lockup_processes = unique_list(all_lockup_processes, proc_name)
    lock_process_pids[proc_name] = unique_list(lock_process_pids[proc_name], proc_pid)

    return

# ---------------------------------------------#
# function: issue_lockup_summary()
# ---------------------------------------------#


def issue_lockup_summary():
    global all_lockup_processes  # ""
    global lock_process_pids  # Key_data() # key: process name: data process id instances

    if all_lockup_processes == '':
        return

    blurb = ''
    total_proc_cnt = 0
    all_lockup_processes = sort_list(all_lockup_processes)
    words = all_lockup_processes.split()

    for proc_name in words:
        pids = lock_process_pids[proc_name]
        tmp = pids.split()
        proc_cnt = len(tmp)
        total_proc_cnt += proc_cnt
        proc_name_cnt = "{0}({1})".format(proc_name, proc_cnt)
        if blurb == '':
            blurb = proc_name_cnt
        else:
            blurb = blurb + " " + proc_name_cnt

    # end: for proc_name in words:
    anomaly_line = "Summary of soft lockup processes: {0}".format(blurb)
    handle_anomaly_with_points("LOCKUP", anomaly_line, 'performance', 10 * total_proc_cnt)
    return


# ---------------------------------------------#
# function: track_db_servers()
# ---------------------------------------------#
def track_db_servers(dbv, proc_name, line):
    global database_procs  # Counter()
    global database_server  # False
    global database_vendors  # ''
    global database_vendors_found  # ''

    debug_print(3, "Vendor:{0} proc:{1} '{2}'".format(dbv, proc_name, line))

    database_procs[dbv] += 1
    database_server = True
    database_vendors_found = unique_list(database_vendors_found, dbv)
    return


# ---------------------------------------------#
# function: crunch_dmsetup_info()
# ---------------------------------------------#
# TODO: dmsetup_info_-c has "asm'n'" names w/mpath uuids...hmmm
# also has vg_name"-"lv_name ...hmmmm
# see 01447637/essorasir06-2015051915291432042158/sos_commands/devicemapper
#
# TODO: read dmsetup_info_-c correlate names and major/minor number id_2_maj_min, maj_min_2_pv
# TODO: add /dev/mapper to above info or remove from vgdisplay pv data??
def crunch_dmsetup_info():

    dm_file = "sos_commands/devicemapper/dmsetup_info_-c"
    fh = openfile(dm_file)
    if fh is None:
        return

    flush = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line == "No devices found" or line == "Device does not exist." or line == "Command failed":
            continue

        if "timeout:" in line or "warning:" in line:
            continue

        if line == "/proc/devices: fopen failed: No such file or directory":
            flush = True
        if flush:
            continue

        words = line.split()
        wc = len(words)
        if wc < 3:
            continue
        dm_dev = words[0]
        dm_major = words[1]
        dm_minor = words[2]
        if dm_dev == "Name" and dm_major == "Maj":  # header line?
            continue

        dm_major_minor = dm_major + ":" + dm_minor

        dm_UUID = ""
        hint = ""
        if wc >= 8:
            # dm_Stat = words[3]
            # TODO: parse stat as per case  (suspended state anom)
            # dm_Open = words[4]
            # dm_Targ = words[5]
            # dm_Event = words[6]
            dm_UUID = words[7]
            if dm_UUID.startswith("mpath-"):
                hint = "mp"
                dm_UUID = dm_UUID[len("mpath-"):]
            elif re.match("part[0-9]{1,2}-mpath-.*", dm_UUID):
                hint = "mp"
                x = dm_UUID.find("mpath-")
                dm_UUID = dm_UUID[x + len("mpath-"):]
            elif dm_UUID.startswith("LVM-"):
                hint = "lv"
                dm_UUID = dm_UUID[len("LVM-"):]
            elif "CRYPT-" in dm_UUID:
                # hint = "lv"
                # dm_UUID = dm_UUID[4:]
                debug_print(4, "({0} {1}) - CRYPT -- TODO: {2}".format(i, dm_file, line))
                continue
            else:
                debug_print(4, "({0} {1}) - dm_UUID?: {2} '{3}'".format(i, dm_file, dm_UUID, line))
                continue

        if hint == "":
            if hint == "" and dm_dev.startswith("dm-"):
                hint = "dm"
            elif "-" in dm_dev:
                hint = "lv"

        if hint == "mp":
            if dm_dev.startswith("ASM-") or dm_dev.startswith("asm-") or re.match('asm[0-9]{1,2}', dm_dev):
                hint = "od"

        if hint == "lv":
            # vg_name = check_vg_prefix(dm_dev,dm_file)
            vg_name = split_valid_vg_name(dm_dev, dm_file)
            if vg_name != "":
                lv_name = split_lv_name(dm_dev, dm_file)
                vg_uuid = ""
                if len(dm_UUID) == 64:
                    vg_uuid = dm_UUID[0:32]
                vg_name = update_vg(vg_name, vg_uuid, dm_file)
                update_lv(vg_name, lv_name, "", dm_UUID, dm_major_minor, dm_file)
                add_mm_bd(build_vg_lv(vg_name, lv_name, dm_file), dm_major_minor, dm_file)
            else:
                hint = ""
                # print 11 / 0
            # # vg_name = check_vg_prefix(dm_dev,dm_file)
            # vg_name = split_valid_vg_name(dm_dev,dm_file)
            # if vg_name == "":
                # hint = ""
            # else:
                # lv_name = split_lv_name(dm_dev,dm_file)
                # vg_name = update_vg(vg_name,"",dm_file)
                # update_lv(vg_name,lv_name,"",dm_UUID,dm_major_minor,dm_file)
        else:
            # print("({0} {1}) {2} {3} {4} {5}".format(i,dm_file,dm_dev,dm_major_minor,hint,line))
            add_mm_bd(dm_dev, dm_major_minor, dm_file)
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dm_file))
    return

# ---------------------------------------------#
# function: crunch_dmsetup_table()
# ---------------------------------------------#


def crunch_dmsetup_table(pass_no):
    global dm_mp_types

    dm_file = "sos_commands/devicemapper/dmsetup_table"
    fh = openfile(dm_file)
    if fh is None:
        return

    vg_name = ""
    vg_uuid = ""
    pv_name = ""
    pv_uuid = ""
    lv_path = ""
    lv_name = ""
    lv_uuid = ""
    flush = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1

        line = line.strip()
        if line == "" or line == "No devices found":
            continue
        if "timeout:" in line or "warning:" in line:
            continue

        if line == "/proc/devices: fopen failed: No such file or directory":
            flush = True  # there are 3 or 4 more error lines, but no data

        if flush:
            continue

        words = line.split()
        wc = len(words)
        # this next check is due to one dmsetup_table line having 1 token.. see case
        if wc < 5:
            if words[wc - 1] != "error":
                # allow short line if it ends in 'error':
                # 'vgSGINF-lvorabd1-missing_1_0: 0 54525952 error'

                if wc == 4 and words[wc - 1] == "secvm":
                    pass
                else:
                    if pass_no == 1:
                        error_print('d', "wc < 5, line shorter than expected: '{0}' ({1} {2})".format(line, i, dm_file))
            continue

        name = words[0]
        if name == "INTEL":
            # See case: "INTEL SSDPE2ME020T4_CVMD520400D42P0JGN: 0 3907029168 multipath 0 0 1 1 service-time 0 1 2 259:0 1 1"
            line = line.replace("INTEL ", '')
            words = line.split()
            wc = len(words)

        b_start = words[1]
        b_end = words[2]
        lit_type = words[3]

        if word_in_list(lit_type, dm_mp_types):
            crunch_multipath_line(i, line, pass_no, dm_file)
            continue
        else:
            # dump out error
            if pass_no == 1:
                error_print('d', "lit_type[{0}] not in '{1}' '{2}' ({3} {4})".format(lit_type, dm_mp_types, line, i, dm_file))
            return

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dm_file))
    return


# ---------------------------------------------#
# function: crunch_multipath_line()
#
# vg_system-root: 0 14680064 linear 9:2 2048
# 3600507680c8081f5c000000000000228: 0 2147483648 multipath 1 queue_if_no_path 0 2 1 round-robin 0 4 1 65:3472 1 132:3344 1 68:3392 1 65:3664 1 round-robin 0 4 1 135:3072 1 129:3456 1 70:3536 1 134:3520 1
# 3600507680c8081f5c000000000000228p1: 0 2147470762 linear 253:1704 2048
#
# 360000970000195702626533035364133: 0 2147481600 multipath 1 queue_if_no_path 0 1 1 round-robin 0 4 1 133:3136 1 133:3296 1 133:3216 1 134:3120 1
#
# glustervg-glusterlv: 0 4000808960 striped 2 128 8:16 2048 8:0 2048
#
# TODO:
# if no vendor/product entries in a device stanza, flag as error; see case
# ---------------------------------------------#
def crunch_multipath_line(i, line, pass_no, dm_file):
    global dev_2_mp  # Key_data()               # key: device id,           data: mp id;            e.g. sdab,    mpathe
    global dm_mp_types  # alua, linear, multipath, etc.
    global all_failing_path_mm  # ''

    dm_mp_type = ''  # dm mp type for this line; alua, linear, roundrobin, etc
    vg_name = ""
    lv_name = ""
    scsi_id = False
    lv_id = False
    found_sw = False
    mm_list = ""  # list of major:minor numbers found in line

    words = line.split()
    wc = len(words)

    name = words[0].rstrip(":")

    if is_scsi_id(name):
        scsi_id = True
    else:
        # vg_name = check_vg_prefix(name,dm_file)
        vg_name = split_valid_vg_name(name, dm_file)
        if vg_name != "":
            lv_name = split_lv_name(name, dm_file)
            lv_id = True
            if pass_no == 1:
                update_vg(vg_name, "", dm_file)            # should already have been found in other files, but just in case
                update_lv(vg_name, lv_name, "", "", "", dm_file)  # (don't pass mm at this point, may be be for mpath dev)

    debug_print(4, "({0}:'{1}' ({2})".format(i, line, dm_file))
    for word in words:
        if re.match(mm_re, word):
            mm_list = unique_list(mm_list, word)
        if word_in_list(word, dm_mp_types):
            found_sw = True
            dm_mp_type = word
    # end: for word in words:
    if found_sw is False:
        if pass_no == 1:
            error_print('d', "none of '{0}' found in: '{1}' ({2} {3})".format(dm_mp_types, line, i, dm_file))
        return

    mms = mm_list.split()
    for mm in mms:

        check_dm_mm(name, lv_id, vg_name, lv_name, scsi_id, dm_mp_type, mm, pass_no, i, line, dm_file)

    # end: for mm in mms:

    debug_print(3, "pass_no:{0} mm_list[{1}]/{2} name:{3}, lv_id:{4}".
                   format(pass_no, mm_list, dm_mp_type, name, lv_id))

    return

# ---------------------------------------------#
# function: check_dm_mm()
# process one of the major/minor numbers found on dmsetup line
# ---------------------------------------------#


def check_dm_mm(name, lv_id, vg_name, lv_name, scsi_id, dm_mp_type, mm, pass_no, i, line, dm_file):
    global all_failing_path_mm  # ''
    global n1_re

    debug_print(3, "'{0}' '{1}' '{2}' '{3}' '{4}' '{5}' '{6}' '{7}' {8}' '{9}' ({10})".
                format(name, lv_id, vg_name, lv_name, scsi_id, dm_mp_type, mm, pass_no, i, line, dm_file))
    types_2_check = "sd dm cciss cciss majblock_253"
    dev_id = ""
    major = -1
    minor = -1
    major_type = ""

    tmp = mm.split(":")
    if len(tmp) == 2 and tmp[0].isdigit() and tmp[1].isdigit():
        major = int(tmp[0])
        minor = int(tmp[1])
    else:
        errorprint(8 / 0)

    major_type = get_major_type(major, 'block')

    dev_id = conv_mm_2_bd(mm)

    if dev_id == "" and not word_in_list(mm, all_failing_path_mm):
        if pass_no == 2:
            debug_print(3, "no dev_id for mm[{0}], type({1}) '{2}' ({3} {4})".format(mm, major_type, line, i, dm_file))
            anomaly_line = "No device found for major-minor number {0} ({1}/{2}) associated with {3} ({4} {5})".\
                           format(mm, major_type, dm_mp_type, name, i, dm_file)
            handle_anomaly_with_points("DMSETUP", anomaly_line, 'hardware', 10)
        return

    if scsi_id and dev_id != "":
        if word_in_list(major_type, types_2_check) or re.match("cciss" + n1_re, major_type):
            track_scsi_id(name, dev_id, dm_file)
        else:
            if pass_no == 1:
                error_print('d', "maj type {0} not in list '{1}' for dev_id[{2}] for mm[{3}] '{4}' ({5} {6})".
                            format(major_type, types_2_check, dev_id, mm, line, i, dm_file))
            return

    if dev_id != "" and not lv_id:
        track_mp_id(dev_id, name, dm_file)

    if lv_id:
        if pass_no == 2:
            check_dm_devid_vs_pvs(name, dev_id, mm, vg_name, major_type, dm_mp_type, i, line, dm_file)

    return

# ---------------------------------------------#
# function: check_dm_devid_vs_pvs()
# ensure that a logical volume's device id (or its alias) is listed in the the physical volumes for its volume group
# ---------------------------------------------#


def check_dm_devid_vs_pvs(vg_lv_name, dev_id, mm, vg_name, major_type, dm_mp_type, i, line, source):
    global vg_2_all_pvs  # Key_data()
    global dev_2_scsi_id  # Key_data()          # key: device id,           data: scsi id;          e.g. sde,     ~33 char hex string
    global dm_re, sd_re
    global mm_2_bd_aliases  # Key_data()
    global dm_2_devs

    pvs = vg_2_all_pvs[vg_name]

    # debug_print(4,'{0} {1} {2} {3} {4} {5} {6} {7}'.format(vg_lv_name,dev_id,mm,vg_name,major_type,dm_mp_type,i,pvs))

    if pvs == '':
        return  # different problem...vg has no pvs associated w/it

    # if word_in_list(dev_id,pvs): return # all is well... # CHG_MM
    if dev_id_in_pvs(dev_id, pvs, mm):
        return  # all is well...

    if re.match(dm_re, dev_id):
        # DONE: if dev_id is dm-n, resolve it to its mpath name and check that in pvs also... (see case )
        # aliases = major_minor_2_mp[mm]
        aliases = mm_2_bd_aliases[mm]
        if aliases != "":
            debug_print(3, "search mp aliases='{0}' for matching pvs:[{1}]".format(aliases, pvs))  # REMOVE
        tmp = aliases.split()
        for alias in tmp:
            if word_in_list(alias, pvs):
                return  # all is well...
        # end: for alias in tmp:
        aliases = dm_2_devs[mm]
        if aliases != "":
            debug_print(3, "search dm aliases='{0}' for matching pvs:[{1}]".format(aliases, pvs))  # REMOVE
        tmp = aliases.split()
        for alias in tmp:
            if word_in_list(alias, pvs):
                return  # all is well...
        # end: for alias in tmp:

        # if aliases != "": debug_print(3,"search ufn aliases='{0}' for matching pvs:[{1}]".format(aliases,pvs)) # REMOVE
        # Do we need to search ufns?...

        #
        return  # assume that this dm-nn device is mapped to the vg/lv (otherwise false positive LVM anomalies are issued)

    if re.match(sd_re, dev_id):
        # DONE: if dev_id is sdcc, resolve it to its scsi id and check that in pvs also... (see case )
        scsi_id = dev_2_scsi_id[dev_id]
        # debug_print(z,'{0} -> {1}'.format(dev_id,scsi_id))
        if word_in_list(scsi_id, pvs):
            return

    if word_in_list(dev_id, dm_2_devs[conv_id_2_mm(vg_lv_name, "lvm")]):
        return  # all is well

    # if vg_lv_name == "u02-p":
        # debug_print(z,dm_2_devs[conv_id_2_mm(vg_lv_name,"lvm")])
        # debug_print(z,'{0} {1} {2} {3} {4} {5} {6} {7}'.format(vg_lv_name,dev_id,mm,vg_name,major_type,dm_mp_type,i,pvs))

    # DONE: dmsetup_table lists a 8:nn device but vg/lv info differs (see case )
    debug_print(4, "lvm:{0} lists dev_id:{1}/{2} but not found in pvs[{3}] for vg {4}".format(vg_lv_name, dev_id, mm, pvs, vg_name))
    if "emcpower" in pvs and "root" in vg_lv_name:
        blurb = cfa_sfdc("01756597")
    else:
        blurb = ''
    anomaly_line = "lvm {0} lists device {1} [{2}] ({3}/{4}) but it was not found in the list of pvs for the vg {5} [{6}] ({7} {8}) {9}".\
                   format(vg_lv_name, mm, dev_id, major_type, dm_mp_type, vg_name, pvs, i, source, blurb)
    handle_anomaly_with_points("LVM", anomaly_line, 'configuration', 10)

    return

# ---------------------------------------------#
# function:  dev_id_in_pvs()
# ---------------------------------------------#


def dev_id_in_pvs(dev_id, pvs, mm):
    global scsi_id_2_devs
    global scsi_id_2_parts
    global all_scsi_ids

    if word_in_list(dev_id, pvs):
        return(True)  # all is well...

    if '/' in dev_id:
        tmp = dev_id.split('/')
        wc = len(tmp)
        tmp_dev_id = tmp[wc - 1]  # dev_id without leading subdir
        if word_in_list(tmp_dev_id, pvs):
            return(True)  # all is well...
    # end: if '/' in dev_id:

    # debug_print(z,"{0} {1} {2} {3}".format(dev_id,pvs,mm,word_count(all_scsi_ids)))
    words = pvs.split()
    for pv in words:
        if pv.startswith("scsi-"):
            scsi_id = pv[len("scsi-"):]
            ps = scsi_id.find("-part")
            if ps != -1:
                scsi_id_w_part = scsi_id
                scsi_id = scsi_id[0:ps]
                s_parts = scsi_id_2_parts[scsi_id]
                tmp = scsi_id_w_part + ":" + dev_id
                # debug_print(z,"{0} {1} '{2}' '{3}'".format(scsi_id,tmp,scsi_id_2_devs[scsi_id],s_parts))
                if word_in_list(tmp, s_parts):
                    return(True)
            else:
                devs = scsi_id_2_devs[scsi_id]
                if word_in_list(dev_id, devs):
                    return(True)
            # end: if ps != -1:
        # end: if pv.startswith("scsi-"):
    # end: for pv in words:

    return(False)

# ---------------------------------------------#
# function: track_mp_id()
# ---------------------------------------------#


def track_mp_id(dev_id, mp_id, source):
    global dev_2_mp  # Key_data()               # key: device id,           data: mp id;            e.g. sdab,    mpathe
    global mp_2_devs  # Key_data()              # key: mp id,               data: device id(s);     e.g. mpathe,  sdab,...
    global mp_2_parts  # Key_data()             # key: mp id,               data: mp part_id(s);    e.g. mpathe,  mpathep1,mpathep2,...

    debug_print(3, "'{0}' '{1}' ({2})".format(dev_id, mp_id, source))
    _mp_id = mp_id
    if is_partition_id(mp_id, source):
        _mp_id = get_dev_from_part_id(mp_id, source)

    if dev_id == _mp_id:
        return

    if dev_2_mp[dev_id] == "":
        dev_2_mp[dev_id] = _mp_id
        dev_2_mp_origin[dev_id] = source
    else:
        if dev_2_mp[dev_id] != _mp_id:
            anomaly_line = "device id {0} already set to mpath id {1} ({2}) while trying to set to {3} ({4})".\
                format(dev_id, dev_2_mp[dev_id], dev_2_mp_origin[dev_id], _mp_id, source)
            handle_anomaly("DUP-1", anomaly_line)

    if _mp_id != mp_id:
        mp_2_parts[_mp_id] = unique_list(mp_2_parts[_mp_id], mp_id)

    mp_2_devs[mp_id] = unique_list(mp_2_devs[mp_id], dev_id)

    return


# ---------------------------------------------#
# function: crunch_linear_line()
# ---------------------------------------------#
def crunch_linear_line(i, dm_file, line):
    words = line.split()
    wc = len(words)

    name = words[0].rstrip(":")
    mm = words[4]
    if not valid_major_minor(mm, False, dm_file):
        error_print('d', "didn't find valid maj/min {0} '{1}' ({2} {3})".format(mm, line, i, dm_file))
        return

    # is name a lv?
    # vg_name = check_vg_prefix(name,dm_file)
    vg_name = split_valid_vg_name(name, dm_file)
    if vg_name == "":  # not an lv
        add_mm_bd(name, mm, dm_file)
        return
    pv_name = conv_mm_2_bd(mm)
    lv_name = split_lv_name(name, dm_file)
    vg_name = update_vg(vg_name, "", dm_file)
    update_lv(vg_name, lv_name, "", "", "", dm_file)

    if pv_name == "":
        error_print('d', "didn't find pv dev for maj/min {0} '{1}' ({2} {3})".format(mm, line, i, dm_file))
    else:
        update_pv(vg_name, pv_name, "", "", mm, dm_file)

    return


# ---------------------------------------------#
# function: crunch_dmsetup_tree()
# ---------------------------------------------#
def crunch_dmsetup_tree():
    global mm_pa_re
    global rr_tracks, rr_tracks_exterior

    dm_file = "sos_commands/devicemapper/dmsetup_ls_--tree"
    fh = openfile(dm_file)
    if fh is None:
        return

    vg_name = ""
    vg_uuid = ""
    lv_path = ""
    lv_name = ""
    lv_uuid = ""

    mm_ptrn = re.compile(mm_pa_re)
    rrts = rr_tracks.split()

    #
    # vg_kdump-lvol1 (253:91)
    # ├─Kdump_DB_1A_1 (253:65)
    # │  ├─ (67:384)
    # │  ├─ (8:352)
    # │  ├─ (134:16)
    # │  └─ (128:240)
    # └─Kdump_DB_1A (253:64)
    # ├─ (134:0)
    # ├─ (128:224)
    # ├─ (67:368)
    # └─ (8:320)

    prev_line = ''
    flush = False
    level = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1

        debug_print(4, "{0}: '{1}' ({2})".format(i, line, dm_file))
        if line == "" or line == "No devices found":
            continue
        if "timeout:" in line or "warning:" in line:
            continue

        if line == "Incorrect number of arguments":
            prev_line = line
            continue

        if line == "Usage:":
            if prev_line == "Incorrect number of arguments":
                flush = True
            continue

        if line == "/proc/devices: fopen failed: No such file or directory":
            flush = True  # there are 3 or 4 more error lines, but no data
        if flush:
            continue

        words = line.split()
        wc = len(words)
        if wc == 1:  # commmand output truncated?
            if not line.endswith("..."):
                error_print('d', "'{0}' ({1})".format(line, dm_file))
            # 5a5d6381--61c5--4e8c--ab71--31e1d1cdc6c1-c2e33b70--9bee--4ee4--a2c8--4f2b7a4d1e...
            continue

        if line.endswith("..."):
            continue  # 2nd token can also be truncated:
        # |  `-2b1dd242--a966--43b9--9128--6518744caab9-641ee894--6a40--46be--9584--9c44...

        if "INTEL " in line:
            # see case: " `-INTEL SSDPE2ME020T4_CVMD520400D42P0JGN (253:9)"
            line = line.replace("INTEL ", '')
            words = line.split()
            wc = len(words)

        char1 = line[0:1]  # reset level when new parent device seen
        if char1.isalpha() or char1.isdigit():
            level = 0

        match = False
        word_offset = 0
        j = 0
        for word in words:
            for rrt in rrts:
                if word == rrt:
                    match = True
                    word_offset += 1
                    if word in rr_tracks_exterior:
                        level += 1
                        # TODO - better analysis of levels
                    break  # for rrt in rrts
            if not match:
                break  # for word in words

        name = words[0 + word_offset]

        for rrt in rrts:
            if name.startswith(rrt):
                name = name[len(rrt):]
                if name == "":   # this is not uncommon:  '`- (m:m)'
                    continue
        m = mm_ptrn.match(name)
        if m:
            major_minor = name
            name = ""
        else:
            major_minor = words[1 + word_offset]

        if ":" in major_minor:
            major_minor = major_minor.strip("()")

        # Truncated output seen in RHEL 7:
        # vg_tdaf--di01osp06_cinder-volume--d2da79dc--2a1c--4f8c--8c27--70f66d31b1b8 (253...
        # `-eql-8-661fc6-81a2ba6be-1fca8aed7955563a-esx-cl1-alc-sata-datastore-1 (253:10...
        # if major_minor.startswith("(") and major_minor.endswith("..."):
        if major_minor.endswith("..."):
            major_minor = ''

        if name == "":
            # TODO can we do more when all we have is this type of data: (i.e. no name, just major:minor)?
            # rootvg-usrlv (253:6)
            # └─ (8:17)
            # rootvg-tmplv (253:5)
            # └─ (8:17)
            continue

        if is_scsi_id(name):
            track_scsi_id(name, conv_mm_2_bd(major_minor), dm_file)
            continue
        else:
            # debug_print(z,name)
            # vg_name = check_vg_prefix(name,dm_file)
            vg_name = split_valid_vg_name(name, dm_file)
            if vg_name != "":
                lv_name = split_lv_name(name, dm_file)
                vg_name = update_vg(vg_name, "", dm_file)
                update_lv(vg_name, lv_name, "", "", major_minor, dm_file)
                continue

        if major_minor == '':
            continue

        add_mm_bd(name, major_minor, dm_file)

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dm_file))
    return


# ---------------------------------------------#
# function: crunch_fdisk_data()
# ---------------------------------------------#
def crunch_fdisk_data():
    global dev_2_lun  # Key_data()

    fdisk_file = "sos_commands/cluster/fdisk_-l"
    fh = openfile(fdisk_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if line == "":
            continue
        if line.startswith("/dev/sd"):
            words = line.split()
            dev_id = words[0]
            dev_id = dev_id[5:]  # /dev/sda2 -> sda2
            last_char = dev_id[len(dev_id) - 1:]
            while last_char.isdigit():          # remove numeric portion
                dev_id = dev_id[0:len(dev_id) - 1]
                last_char = dev_id[len(dev_id) - 1:]
            scsi_adr = dev_2_lun[dev_id]
            if scsi_adr != "":
                debug_print(3, "line dev_2_lun[{0}] = {1}".format(dev_id, scsi_adr))
                add_normalized_scsi_data(scsi_adr, "sd", dev_id, "", line, fdisk_file)
        continue

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fdisk_file))
    return

# ---------------------------------------------#
# function: scan_messages_files()
# locate a syslog file and then call scan_messages_data() to
# determine syslog format, etc.
# ---------------------------------------------#


def scan_messages_files():
    global syslog_msg_fn_array  # Key_data()
    global syslog_fn_format_yyyymmdd  # False
    global syslog_fn_format_n  # False
    global syslog_fn_max_n  # 0
    global syslog_fn_min_n  # big_num
    global syslog_fn_cnt_n  # 0
    global messages_file_list
    global first_message_file_read  # ''

    words = messages_file_list.split()
    for messages_file in words:
        if syslog_format == '' and file_exists_with_data(messages_file):
            scan_messages_data(messages_file)
            if first_message_file_read == '':
                first_message_file_read = os.path.basename(messages_file)
    # end: for messages_file in words:

    if syslog_format == '':  # (only happens if var/log/messages is really corrupt or more likely, 0 bytes)

        build_messages_file_array()

        if syslog_fn_cnt_n > 0:
            if syslog_fn_format_n:
                # go in reverse order (oldest to newest)
                for n in range(syslog_fn_max_n, syslog_fn_min_n - 1, -1):
                    fn = syslog_msg_fn_array[n]
                    if fn == "":
                        continue
                    scan_messages_data("var/log/" + fn)
                    if syslog_format != '':
                        break

            if syslog_fn_format_yyyymmdd:
                # go from smallest to largest value (oldest to newest)
                for n in range(syslog_fn_min_n, syslog_fn_max_n + 1, 1):
                    fn = syslog_msg_fn_array[n]
                    if fn == "":
                        continue
                    scan_messages_data("var/log/" + fn)
                    if syslog_format != '':
                        break

        # end: if syslog_fn_cnt_n > 0:

    # end: if syslog_format == '':

    debug_print(1, "done")
    return


# ---------------------------------------------#
# function: scan_messages_data()
# determine syslog format and set messages_start_line
#
# var/log/messages has several formats such as:
#
# 'Mon dd hh:mm:ss nodename ....' <<<-- most common
# 'yyyy-mm-ddThh:mm:ss.nnnnnn+hh:mm nodename ...'
# 'yyyy-mm-dd hh:mm:ss.nnn nodename ...'
# ---------------------------------------------#
def scan_messages_data(messages_file):
    global messages_start_line  # 0
    global messages_start_line_ref  # 0

    global syslog_format
    global syslog_hdr_fp_word_num   # -1
    global syslog_hdr_nn_word_num   # -1
    global syslog_hdr_rep_char  # ''
    global syslog_hdr_length  # 0
    global syslog_hdr_and_nodename_length  # 0
    global syslog_hdr_xnnxn_cruft  # False
    global syslog_hdr_nn_word_num_expected   # -1

    global sw_r
    global OracleLinux_lines
    global last_timestamp
    global last_reboot_timestamp

    global last_nodename  # ''
    global last_nodename_matches_this_host  # False

    global syslog_nodenames_match  # needed here?
    global syslog_nodenames_found  # '' # unique list of all syslog nodenames encountered
    global syslog_nodename_count  # Counter() # key: nodename date: count of that nodename in syslog lines
    global syslog_nodenames_match_words  # syslog_nodenames_match.split()
    global syslog_nodename_word_count  # len(syslog_nodename_words)
    global last_msg_rptd  # "last message repeated"
    global total_esc_messages_count  # 0
    global syslog_hdr_fp_cleanup_style  # -1

    linux_scan_ptrn = re.compile('kernel: Linux version .* \(gcc version .*')
    klogd_scan_ptrn = re.compile('kernel: (klogd|imklog) [0-9]{1,2}\.[0-9]{1,3}\.[0-9]{1,3}, log source = /proc/kmsg started')
    syslogd_scan_ptrn = re.compile('syslogd [0-9]{1,2}\.[0-9]{1,3}\.[0-9]{1,3}: restart')
    rsyslogd_scan_ptrn = re.compile('rsyslogd: \[origin software="rsyslogd" .*\] start')

    line_cnt = initial_file_check(messages_file)
    if line_cnt == 0:
        return  # nothing to process

    fh = openfile(messages_file)
    if fh is None:
        return

    data_read = False
    oline = ''
    format_not_det_line = ''
    last_nodename = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove ending \n
        i += 1
        if line == "":
            continue

        # often the first line of a message file will be corrupt.
        # typically some portion of the beginning of the line will have been lost.
        # so when scanning for the format of the messages file skip the first line.
        # (unless it's the only line)
        if i == 1 and line_cnt != 1:
            continue

        data_read = True

        if last_msg_rptd in line:
            continue  # node name may or may not be in place for lmr messages...

        if syslog_hdr_xnnxn_cruft:
            sp = line.find(" ")
            if sp != -1:
                line = line[sp + 1:]  # remove '<nn>n '

        if syslog_format == '':
            format_not_det_line = line
            # debug_print(z,"{0}: '{1}' {2}".format(i,syslog_format,syslog_hdr_nn_word_num))
            determine_format(line, messages_file)
            debug_print(1, line)
            if syslog_format == '':
                continue  # occasionaly the first line(s) is/are truncated...
            # if not no_host_data() and syslog_hdr_nn_word_num == -1: continue # occasionaly the first line(s) is/are truncated...
        oline = line
        if syslog_hdr_fp_word_num == 0:
            pos = line.find(':')
            if pos != -1:  # should not occur..
                line = line[pos + 1:].lstrip()
                oline = line

        if syslog_hdr_rep_char != '':
            # TODO - does the number of character replacements need to be a variable?
            line = line.replace(syslog_hdr_rep_char, ' ', 3)
            oline = line

        if syslog_hdr_fp_word_num > 0:
            # debug_print(z,"{0} '{1}'".format(syslog_hdr_fp_word_num,line))
            words = line.split()
            wc = len(words)
            if (syslog_hdr_fp_word_num + 1) > wc:
                continue  # incomplete / partial line
            fac_pri = words[syslog_hdr_fp_word_num]
            if fac_pri.startswith("[kern."):
                if wc >= (syslog_hdr_fp_word_num + 2):
                    if words[syslog_hdr_fp_word_num + 1] == "kernel:":
                        line = line.replace(' ' + fac_pri, '')  # disappear it
                    else:
                        line = line.replace(' ' + fac_pri, ' kernel:')  # no 'kernel:' word, replace '[kern.(info|debug|warning|etc)]' to kernel:
            else:
                line = line.replace(' ' + fac_pri, '')  # disappear it
            oline = line

        if not valid_hdr(line):
            # debug_print(z,"inv hdr '{0}'".format(line))
            continue

        words = line.split()
        wc = len(words)
        if syslog_hdr_nn_word_num != -1:
            nn_word_num = syslog_hdr_nn_word_num
        else:
            nn_word_num = syslog_hdr_nn_word_num_expected
        if wc >= (nn_word_num + 1):
            if syslog_hdr_fp_word_num != -1 and syslog_hdr_fp_word_num < nn_word_num:
                nn_word_num -= 1  # adjust down as we disappeared the fac/pri token above
            tmp_nodename = words[nn_word_num]
        else:
            debug_print(0, "wc:{0} syslwn:{1} syslwnex:{2}".format(wc, syslog_hdr_nn_word_num, syslog_hdr_nn_word_num_expected))
            debug_print(0, line)
            debug_print(0, messages_file)
            continue
        # debug_print(z,"{0}: '{1}' '{2}' '{3}".format(i,tmp_nodename,last_nodename,syslog_nodenames_found))
        if tmp_nodename != last_nodename:
            last_nodename = tmp_nodename
            syslog_nodenames_found = unique_list(syslog_nodenames_found, tmp_nodename)
            # debug_print(z,tmp_nodename)
            # debug_print(z,"{0} {1}".format(syslog_hdr_fp_word_num,nn_word_num))   # -1
        syslog_nodename_count[tmp_nodename] += 1

        # TODO - account for possible change in nodename lengths
        line = adjust_log_message(syslog_hdr_length + len(tmp_nodename) + 1, line, messages_file)
        if syslogd_scan_ptrn.match(line) or \
           rsyslogd_scan_ptrn.match(line) or  \
           klogd_scan_ptrn.match(line) or  \
           linux_scan_ptrn.match(line):
            debug_print(3, "{0} ({1} {2})".format(i, messages_file, line))

            if linux_scan_ptrn.match(line):
                crunch_linux_version_line(line, messages_file)

            if sw_r:
                messages_start_line = i
            messages_start_line_ref = i  # remember regardless of whether it is used to restrict msg evaluation
            last_reboot_timestamp = oline[0:syslog_hdr_length]

        if line.startswith("kernel: Command line:"):
            cp = line.find(":")
            tmp = line[len("kernel: Command line:") + 1:]  # remaider of line without kernel: command line:
            tmp = tmp.strip()
            crunch_cmdline_data(tmp, messages_file)

        if '<' in line:
            cm1 = re.search("<[0-9]>", line)
            cm2 = re.search("<>", line)
            if cm1 or cm2:
                total_esc_messages_count += 1

    # end: for line in messages_lines
    # end: for line in fh

    # if syslog_format == 'mdt' and syslog_hdr_nn_word_num == -1:
        # syslog_hdr_nn_word_num = 3 # set typical default (most likely syslog node name not = hostname)

    if no_host_data():
        if syslog_hdr_nn_word_num == -1:
            syslog_hdr_nn_word_num = syslog_hdr_nn_word_num_expected

    if oline != '':
        last_timestamp = oline[0:syslog_hdr_length]

    if data_read:
        if syslog_format == '':
            error_print("d", "unable to determine syslog prefix format, last line: '{0}' ({1})".format(format_not_det_line, messages_file))
        else:
            check_syslog_nodenames()
            if syslog_nodenames_found == '':
                error_print("d", "unable to locate node name(s) in syslog prefix area, last line: '{0}' ({1})".format(format_not_det_line, messages_file))
    syslog_nodename = "(unknown)"
    syslog_nodenames_match_words = syslog_nodenames_match.split()
    syslog_nodename_word_count = len(syslog_nodenames_match_words)
    # debug_print(z,"{0}: {1}".format(syslog_nodename_word_count,syslog_nodenames_match_words))
    if syslog_nodename_word_count >= 1:
        syslog_nodename = syslog_nodenames_match_words[0]

    hostname1_file = "hostname"
    hostname2_file = "sos_commands/general/hostname"
    if not stat_file('', hostname1_file, 0) and not stat_file('', hostname2_file, 0):
        nodename_line = syslog_nodename
        # don't write files...derive info when necessary
        # writefile(hostname1_file,nodename_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, messages_file))
    debug_print(1, "messages_start_line set to {0}".format(messages_start_line))
    debug_print(1, "total_esc_messages_count {0}".format(total_esc_messages_count))

    debug_print(1, "syslog_format='{0}' "
                "syslog_hdr_length={1} "
                "syslog_hdr_and_nodename_length={2} "
                "syslog_hdr_nn_word_num={3} "
                "syslog_hdr_fp_word_num={4} "
                "syslog_hdr_fp_cleanup_style={5}".
                format(syslog_format,
                       syslog_hdr_length,
                       syslog_hdr_and_nodename_length,
                       syslog_hdr_nn_word_num,
                       syslog_hdr_fp_word_num,
                       syslog_hdr_fp_cleanup_style))
    return


# ---------------------------------------------#
# function: initial_file_check(file_name):
# Check for null file (actual or logical)
# returns:
# -1: file size > 1k, line cnt not determined
# 0: no data in file, (could be 'no_data_message_lines')
# 1 and above: actual line count
# ---------------------------------------------#
def initial_file_check(file_name):
    global no_data_message_lines  # "No journal files were found.\n-- No entries --\n"

    line_cnt = 0
    msg_file_size = file_size(file_name)
    if msg_file_size == -1:
        return(0)  # -1 means stat(file_name) failed

    # 750,000,000: 750 million bytes: initial trigger point
    # 482,003,149: 482 million bytes (6,277,622 lines) - see case  kernel: 2,500,068 lines, multipathd: 2,896,782 lines
    # 200,000,000: 200 million bytes: new trigger point
    # note that the size alone does not dictate processing time, a huge file containing mostly lines that are "skipped" will be
    # processed quickly, while a much smaller message file containing almost entirely kernel: and multipathd: messages can take a long time.
    if msg_file_size > 200000000:
        print_stderr("** Warning: could take a while to process large message file: {0} ({1})".
                     format(mg_disp(msg_file_size, 1), file_name))

    if msg_file_size > 1024:
        return(-1)

    fh = openfile(file_name)
    if fh is None:
        return(0)  # an open failure here is usually due to permission failure

    file_string = ''
    for line in fh:
        # leave linefeed on end of line
        line_cnt += 1
        if file_string == '':
            file_string = line
        else:
            file_string = file_string + line
    closefile(fh, line_cnt)

    if file_string == no_data_message_lines:
        # debug_print(z,"{0} = {1}".format(file_name,file_string))
        return(0)  # nothing to process

    # Empty CentOS journal message files don't have the "-- No entries --" portion
    if len(no_data_message_lines) > len(file_string) and file_string == no_data_message_lines[0:len(file_string)]:
        # debug_print(z,"{0} = {1}".format(file_name,file_string))
        return(0)  # nothing to process

    tmp_string = file_string.replace("\n", '')
    if tmp_string == '':
        # debug_print(z,"{0} = all null lines".format(file_name))
        return(0)  # nothing to process

    return(line_cnt)

# ---------------------------------------------#
# function: check_syslog_nodenames()
# ---------------------------------------------#


def check_syslog_nodenames():
    global hostname, uname_nodename
    global syslog_hdr_length  # 0
    global syslog_hdr_and_nodename_length  # 0
    global syslog_hdr_nn_word_num  # -1
    global syslog_nodename_count  # Counter() # key: nodename date: count of that nodename in syslog lines
    global syslog_nodenames_found  # '' # unique list of all syslog nodenames encountered
    global syslog_nodenames_match  # = ''
    global syslog_matching_nodename_count  # 0 # number of matching nodenames in syslog_nodenames_match (usually 1)
    global multiple_syslog_nodenames  # False
    global multiple_syslog_nodenames_with_different_lengths  # False
    global syslog_nodename_status  # '' # sentence describing which syslog nodename(s) are being used

    tmp = syslog_nodenames_found.split()
    count_of_nodenames = len(tmp)

    if count_of_nodenames == 0:
        syslog_nodename_status = "Error: Unable to determine nodename with syslog prefix area {0} {1}".format(count_of_nodenames, syslog_hdr_nn_word_num)
        return

    if count_of_nodenames == 1:
        syslog_nodenames_match = tmp[0]  # one and only nodename
        syslog_matching_nodename_count = 1
        syslog_hdr_and_nodename_length = syslog_hdr_length + len(syslog_nodenames_match) + 1
        syslog_nodename_status = "Found only 1 unique nodename, {0} selected as syslog nodename based on this.".\
                                 format(syslog_nodenames_match)
        if hostnames_differ(hostname, syslog_nodenames_match):
            syslog_nodename_status = "{0} [Warning: syslog nodename not equal hostname {1}]".format(syslog_nodename_status, hostname)
        return

    multiple_syslog_nodenames = True

    # exact_nn_match = False
    # fuzzy_nn_match = False
    # localhost_match = False
    max_nn_count = 0
    nax_nn_name = ''
    prev_nn = ''

    # short_hostname = ''
    # pos = hostname.find('.')
    # if pos != -1:
    # short_tmp = hostname.split('.')
    # short_hostname = short_tmp[0]

    # short_uname = ''
    # pos = uname_nodename.find('.')
    # if pos != -1:
    # short_tmp = uname_nodename.split('.')
    # short_uname = short_tmp[0]

    for nn in tmp:
        if prev_nn != '':
            if len(nn) != len(prev_nn):
                multiple_syslog_nodenames_with_different_lengths = True
        prev_nn = nn
    # end: for nn in tmp:

    why_blurb = ''
    if not no_host_data():  # there is hostname, uname, or ip_addr data available
        for nn in tmp:
            if word_matches_hostname(nn, ''):
                syslog_nodenames_match = unique_list(syslog_nodenames_match, nn)
        # end: for nn in tmp:
        if syslog_nodenames_match != "":  # did host_data help match node names in the syslog file?
            why_blurb = syslog_why(why_blurb, "based on matching hostname/uname/ip_addr data")
        else:
            debug_print(0, 'host data avail, syslog nodenames match = ""')
    # end: if not no_host_data(): # there is hostname, uname, or ip_addr data available

    if no_host_data() or syslog_nodenames_match == "":
        for nn in tmp:
            if syslog_nodename_count[nn] > max_nn_count:
                max_nn_count = syslog_nodename_count[nn]
                max_nn_name = nn
        # end: for nn in tmp:
        why_blurb = syslog_why(why_blurb, "based on greater frequency in messages ({0})".format(syslog_nodename_count[max_nn_name]))
        syslog_nodenames_match = unique_list(syslog_nodenames_match, max_nn_name)
    # end: if no_host_data() or syslog_nodenames_match == "":

    # for nn in tmp:

        # if hostname != '':
        # if nn.lower() == hostname.lower():
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # exact_nn_match = True

        # if uname_nodename != '':
        # if nn.lower() == uname_nodename.lower():
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # exact_nn_match = True

        # if short_hostname != '':
        # if nn.lower() == short_hostname.lower():
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # exact_nn_match = True

        # if short_uname != '':
        # if nn.lower() == short_uname.lower():
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # exact_nn_match = True

        # if nn == "localhost" or nn == "localhost.localdomain" or nn == "default":
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # localhost_match = True

        # if len(hostname)       > len(nn) and nn in hostname:
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # fuzzy_nn_match = True

        # if len(uname_nodename) > len(nn) and nn in uname_nodename:
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,nn)
        # fuzzy_nn_match = True

        # if syslog_nodename_count[nn] > max_nn_count:
        # max_nn_count = syslog_nodename_count[nn]
        # max_nn_name  = nn

        # if prev_nn != '':
        # if len(nn) != len(prev_nn): multiple_syslog_nodenames_with_different_lengths = True
        # prev_nn = nn
    # end: for nn in tmp:

    # if not exact_nn_match and not fuzzy_nn_match:
        # syslog_nodenames_match = unique_list(syslog_nodenames_match,max_nn_name)

    blurb1 = "Found {0} unique nodename{1} in syslog file: [{2}].".format(count_of_nodenames, plural(count_of_nodenames), syslog_nodenames_found)

    tmp = syslog_nodenames_match.split()
    match_cnt = len(tmp)

    blurb2 = "Selected [{0}] as syslog nodename{1}".format(syslog_nodenames_match, plural(match_cnt))

    # why_blurb = ''
    # if  exact_nn_match: why_blurb = syslog_why(why_blurb,"based on exact match with hostname/uname")
    # if  fuzzy_nn_match: why_blurb = syslog_why(why_blurb,"based on fuzzy match with hostname/uname")
    # if  localhost_match: why_blurb = syslog_why(why_blurb,"based on finding default 'localhost' used")
    # if not exact_nn_match and not fuzzy_nn_match and max_nn_name != '':
    # why_blurb = syslog_why(why_blurb,"based on greater frequency in messages ({0})".format(syslog_nodename_count[max_nn_name]))

    if match_cnt == 0:
        why_blurb = syslog_why(why_blurb, "none selected...")
    syslog_nodename_status = "{0} {1}, {2}".format(blurb1, blurb2, why_blurb)
    if not multiple_syslog_nodenames_with_different_lengths:
        tmp = syslog_nodenames_match.split()
        syslog_hdr_and_nodename_length = syslog_hdr_length + len(tmp[0]) + 1

    return

# ---------------------------------------------#
# function: syslog_why()
# ---------------------------------------------#


def syslog_why(blurb, why):

    if blurb == '':
        return(why)
    return(blurb + " and " + why)


# ---------------------------------------------#
# function: hotnames_differ()
# if hostname differs from syslogname return True otherwise return False
# ---------------------------------------------#
def hostnames_differ(hostname, syslogname):
    if hostname == syslogname:
        return(False)
    if hostname.lower() == syslogname.lower():
        return(False)
    if hostname == '' or hostname == "<unknown>":
        return(False)

    lh = len(hostname)
    ls = len(syslogname)

    if (ls - lh) >= 3:
        if syslogname.startswith(hostname):          # names are the same at the shorter length
            domain = syslogname[len(hostname):]       # remainder of syslogname - hostname (e.g. foo.bar.com -> .bar.com)
            if domain.startswith("."):
                return(False)  # names don't differ, syslogname contains domain name

    if (lh - ls) >= 3:
        if hostname.startswith(syslogname):          # names are teh same at the shorter length
            domain = hostname[len(syslogname):]       # remainder of hostname - syslogname (e.g. foo.bar.com -> .bar.com)
            if domain.startswith("."):
                return(False)  # names don't differ, hostname contains domain name

    return(True)  # names differ

# ---------------------------------------------#
# function: determine_format()
# see prolog in scan_messages_data() above for a description of the various syslot prefix formats
# ---------------------------------------------#


def determine_format(line, source):
    global syslog_hdr_fp_word_num   # 0
    global syslog_format       # ''
    global syslog_year         # '' # set if syslog_format = 'yyyy[n]'
    global syslog_next_year    # '' # set to syslog_year+1 if syslog_format = 'yyyy[n]'
    global syslog_last_year    # '' # set to syslog_year-1 if syslog_format = 'yyyy[n]'
    global syslog_hdr_length   # 0
    global syslog_hdr_rep_char  # ''
    global syslog_hdr_nn_word_num_expected   # -1
    global syslog_hdr_xnnxn_cruft  # False
    global xnnxn_re  # "<"+n4_re+">"+n1_re
    global hhmmss_re           # "[0-9]{2}:[0-9]{2}:[0-9]{2}"
    global Mon_re              # "(Jan|Feb etc.)"
    global yyyy_mm_dd_re       #
    global yyyy_mon_dd_hhmmss_re
    global n2_re, var_spaces
    global facility_ptrn  # "(auth|daemon|kern|local[0-9]|mail|syslog|user)"
    global priority_ptrn  # "(alert|crit|emerg|err|info|notice|warning|debug)"
    global syslog_hdr_fp_cleanup_style  # -1

    facility_priority_ptrn_1 = re.compile('^' + facility_ptrn + '[\., ]' + priority_ptrn + ':')  # 'facility.priority:' 'f,p:'
    # facility_priority_ptrn_2 = re.compile('<'+facility_ptrn+'[\.]'+priority_ptrn+'>')    # '<facility.priority>'
    # facility_priority_ptrn_3 = re.compile('<[0-9]{1,2}[\.][0-9]{1,2}>')                  # numeric version of facility_priority_ptrn_2
    # facility_priority_ptrn_4 = re.compile('\['+facility_ptrn+'[\.]'+priority_ptrn+'\]')  # '[facility.priority]'
    # facility_priority_ptrn_5 = re.compile(facility_ptrn+'[\.]'+priority_ptrn)            # 'facility.priority'
    # facility_priority_ptrn_6 = re.compile(facility_ptrn+'[,]'+priority_ptrn+'[,]')       # 'facility,priority,'

    words = line.split()
    wc = len(words)
    if wc < 3:
        return

    line_format = ''
    line_hdr_length = 0
    line_hdr_rep_char = ''

    if line[0:1] == '<' and re.match(xnnxn_re, line):
        syslog_hdr_xnnxn_cruft = True
    if syslog_hdr_xnnxn_cruft:
        sp = line.find(" ")
        if sp != -1:
            line = line[sp + 1:]  # remove '<nn>n '

    if facility_priority_ptrn_1.match(line):
        syslog_hdr_fp_word_num = 0

    if syslog_hdr_fp_word_num == 0:
        pos = line.find(':')
        if pos != -1:  # should not occur..
            line = line[pos + 1:].lstrip()
            # debug_print(z,line)
            words = line.split()
            wc = len(words)
            if wc < 3:
                return

    if re.match("^" + yyyy_mm_dd_re + "T" + hhmmss_re + ".[0-9]{6}[+|-][0-9]{2}:[0-9]{2}.*", line):
        tmp_sep_char = line[32:33]
        if tmp_sep_char == ' ':
            pass
        elif tmp_sep_char == ',':
            # 1       2                3
            # 2016-12-12T06:14:29.034861+01:00,xtt2016,nfsidmap[71438]:,daemon,err, Failed to add child keyring: Operation not permitted
            # 0 (words)                        1       2                3           4+
            line_hdr_rep_char = tmp_sep_char
        else:
            return  # ?? different seperator? bad match?
        line_format = 'yyyy1'
        syslog_hdr_nn_word_num_expected = 1
        # "yyyy-mm-ddThh:mm:ss.nnnnnn+hh:mm nodename"
        line_hdr_length = len("yyyy-mm-ddThh:mm:ss.nnnnnn+hh:mm") + 1
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + hhmmss_re + ".[0-9]{6}[+|-][0-9]{2}:[0-9]{2}.*", line):
        tmp_sep_char = line[32:33]
        if tmp_sep_char == ' ':
            pass
        elif tmp_sep_char == ',':
            # 1       2                3

            # 2017-07-09 09:34:43.624720-04:00 jacketst kernel:show_signal_msg: 3 callbacks suppressed
            # 0 (words)                        1       2                3           4+
            line_hdr_rep_char = tmp_sep_char
        else:
            return  # ?? different seperator? bad match?
        line_format = 'yyyy6'
        syslog_hdr_nn_word_num_expected = 2
        # "yyyy-mm-dd hh:mm:ss.nnnnnn+hh:mm nodename"
        line_hdr_length = len("yyyy-mm-dd hh:mm:ss.nnnnnn+hh:mm") + 1
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + hhmmss_re + " [+|-][0-9]{2}:[0-9]{2} ", line):
        line_format = 'yyyy3'
        line_hdr_length = len("yyyy-mm-dd hh:mm:ss +hh:mm") + 1  # followed by nodename and possibly fac.pri
        syslog_hdr_nn_word_num_expected = 3
        #
    elif re.match("^" + yyyy_mon_dd_hhmmss_re, line):
        line_format = 'yyyy2'
        line_hdr_length = len("yyyy Mon dd hh:mm:ss") + 1
        syslog_hdr_nn_word_num_expected = 4
        #
    elif re.match("^" + Mon_re + "(\s+)[0-9]{1,2} " + hhmmss_re + " ", line):
        line_format = 'mdt'
        line_hdr_length = len("Mon dd hh:mm:ss") + 1
        syslog_hdr_nn_word_num_expected = 3
        #
    elif re.match("^" + Mon_re + "(\s+)[0-9]{1,2} " + hhmmss_re + "-" + yyyy_re + " ", line):
        line_format = 'mdty'
        line_hdr_length = len("Mon dd hh:mm:ss-yyyy") + 1
        syslog_hdr_nn_word_num_expected = 3
        #
    #
    # seen on puppet syslogs (single numeric digit leads off severity?)
    elif re.match("^[0-9] " + Mon_re + "(\s+)[0-9]{1,2} " + hhmmss_re + " ", line):
        line_format = 'nmdt'
        line_hdr_length = len("n Mon dd hh:mm:ss") + 1
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + hhmmssnnn_re, line):
        line_format = 'yyyy4'
        line_format = 'nmdt'
        line_hdr_length = len("n Mon dd hh:mm:ss") + 1
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + hhmmssnnn_re, line):
        line_format = 'yyyy4'
        line_hdr_length = len("yyyy-mm-dd hh:mm:ss.nnn") + 1  # followed by nodename and possibly fac.pri
        syslog_hdr_nn_word_num_expected = 2
        #
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + hhmmss_re + " \(" + hhmmssnnn_re + "\)", line):
        line_format = 'yyyy5'
        line_hdr_length = len("yyyy-mm-dd hh:mm:ss (hh:mm:ss.nnn)") + 1  # followed by nodename and possibly fac.pri
        syslog_hdr_nn_word_num_expected = 3
        #
    elif re.match("^" + yyyy_mm_dd_re + " " + Day_short_re + " " + hhmmss_re, line):
        line_format = 'yyyy7'
        line_hdr_length = len("yyyy-mm-dd Day hh:mm:ss") + 1  # followed by nodename and possibly fac.pri
        syslog_hdr_nn_word_num_expected = 3
    else:
        debug_print(1, "??-> '{0}'".format(line))
        return

    do_syslog_consistency_check(line_format, line_hdr_length, line_hdr_rep_char, line)

    if line_hdr_rep_char != '':
        # debug_print(z,line)
        # TODO - does the number of character replacements need to be a variable?
        line = line.replace(line_hdr_rep_char, ' ', 3)
        # debug_print(z,line)

    if line_format != '':
        determine_fp_and_nn_positions(line, source)

    debug_print(1, "{0} {1} {2} {3} '{4}'".
                format(line_format, syslog_hdr_fp_word_num, syslog_hdr_nn_word_num, syslog_hdr_fp_cleanup_style, line))
    return

# ---------------------------------------------#
# function: do_syslog_consistency_check()
# ensure that we are getting consistent syslog data
# ---------------------------------------------#


def do_syslog_consistency_check(line_format, line_hdr_length, line_hdr_rep_char, line):
    global syslog_format       # ''
    global syslog_year         # '' # set if syslog_format = 'yyyy[n]'
    global syslog_next_year    # '' # set to syslog_year+1 if syslog_format = 'yyyy[n]'
    global syslog_last_year    # '' # set to syslog_year-1 if syslog_format = 'yyyy[n]'
    global syslog_hdr_length   # 0
    global syslog_hdr_rep_char  # ''
    global syslog_hdr_fp_word_num   # -1
    global syslog_hdr_nn_word_num   # -1
    global n1_re

    if syslog_format == "":
        syslog_format = line_format
        # debug_print(0,line_format)
    else:
        do_syslog_change_check('syslog_format', syslog_format, line_format, line)

    if syslog_hdr_length == 0:
        syslog_hdr_length = line_hdr_length
    else:
        do_syslog_change_check('syslog_hdr_length', syslog_hdr_length, line_hdr_length, line)

    if syslog_hdr_rep_char == "":
        syslog_hdr_rep_char = line_hdr_rep_char
    else:
        do_syslog_change_check('syslog_hdr_rep_char', syslog_hdr_rep_char, line_hdr_rep_char, line)

    # if line_format == 'yyyy1' or line_format == 'yyyy2' or line_format == 'yyyy3' or line_format == 'yyyy4':
    if re.match("yyyy" + n1_re, line_format) or line_format == "mdty":
        #
        tmp_year = line[0:4]
        if line_format == "mdty":
            tmp_year = line[16:20]
        if tmp_year.isdigit():
            tmp = int(tmp_year) + 1
            tmp_next_year = "{0}".format(tmp)
            tmp = int(tmp_year) - 1
            tmp_last_year = "{0}".format(tmp)

            if syslog_year == "":
                syslog_year = tmp_year
            else:
                do_syslog_change_check('syslog_year', syslog_year, tmp_year, line)

            if syslog_next_year == "":
                syslog_next_year = tmp_next_year
            else:
                do_syslog_change_check('syslog_next_year', syslog_next_year, tmp_next_year, line)

            if syslog_last_year == "":
                syslog_last_year = tmp_last_year
            else:
                do_syslog_change_check('syslog_last_year', syslog_last_year, tmp_last_year, line)

    return

# ---------------------------------------------#
# function: do_syslog_change_check()
# if a setting has changed, issus error_print() for it
# ---------------------------------------------#


def do_syslog_change_check(label, old, new, line):
    if old == new:
        return
    error_print('d', "{0} previously set to '{1}' while trying to set it to '{2}', line:'{3}'".
                format(label, old, new, line))
    return


# ---------------------------------------------#
# function: determine_fp_and_nn_positions(line):
# set word number of nodename in syslog prefix area
# set word number of facility/priority in syslog prefix area if present
# ---------------------------------------------#
def determine_fp_and_nn_positions(line, source):
    global syslog_hdr_fp_word_num   # -1
    global syslog_hdr_nn_word_num   # -1
    global syslog_hdr_nn_word_num_expected   # -1
    global syslog_hdr_token_to_delete  # -1
    global syslog_nodenames_found  # '' # unique list of all syslog nodenames encountered
    global syslog_hdr_fp_cleanup_style  # -1
    global facility_ptrn  # "(auth|daemon|kern|local[0-9]|mail|syslog|user)"
    global daemon_nk_ptrn  # "(|.*)" # daemon(name) or null (kernel), usually followed by priority
    global priority_ptrn  # "(alert|crit|emerg|err|info|notice|warning|debug)"
    global syslog_separate_first_token  # False # True/False: need to separate 1st token from rest of msg line: 'kernel:foo...'
    global syslog_first_msg_token  # -1 # position of first token in msg line (word no.)
    global syslog_check_words  # syslog_check_list.split("~")

    # Examples of various facility-priority formats:
    #
    # facility.priority:
    # facility,priority:
    # facility priority:
    # <facility.priority>
    # <n.n>
    # [facility.priority]
    # facility.priority
    # facility,priority,
    #
    fac_pri_br_re = '\[' + facility_ptrn + '[\.]' + priority_ptrn + '\]'

    dnk_pri_br_re = '\[' + daemon_nk_ptrn + '[\.]' + priority_ptrn + '\]'

    fp_ptrn_list = facility_ptrn + '[\., ]' + priority_ptrn + ':~'\
        '<' + facility_ptrn + '[\.]' + priority_ptrn + '>~'\
        '<[0-9]{1,2}[\.][0-9]{1,2}>~'\
        '' + fac_pri_br_re + '~'\
        '' + dnk_pri_br_re + '~'\
        '' + facility_ptrn + '[\.]' + priority_ptrn + '~'\
        '' + facility_ptrn + '[,]' + priority_ptrn + '[,]~'\
        '<.*:' + priority_ptrn + '>'

    words = line.split()
    wc = len(words)
    if wc < 3:
        return

    i = 0

    fps = fp_ptrn_list.split('~')
    # debug_print(z,line)

    range_beg = 0
    range_end = min(7, wc - 1)
    if syslog_hdr_nn_word_num_expected != -1:
        range_beg = syslog_hdr_nn_word_num_expected
        range_end = min(wc - 1, syslog_hdr_nn_word_num_expected + 3)

    for i in range(range_beg, range_end):

        word = words[i]
        # debug_print(z,word)

        if re.match("\[" + n1_re + "\]", word):
            if syslog_hdr_token_to_delete == -1:
                debug_print(1, "token {0} will be deleted from each line ({1})".format(i, source))
            syslog_hdr_token_to_delete = i
            continue

        # see if we can find a facility/priority string,
        # and if found(infrequent), remember the word position
        for fp_ptrn in fps:
            # debug_print(z,'{0}'.format(fp_ptrn))
            # debug_print(z,'{0}'.format(word))
            if re.match(fp_ptrn, word):
                debug_print(1, "**match** '{0}' -> {1}'".format(fp_ptrn, word))
                if syslog_hdr_fp_word_num == -1:
                    # debug_print(z,"{0} '{1}'".format(syslog_hdr_fp_word_num,fp_ptrn))
                    syslog_hdr_fp_word_num = i
                    if fp_ptrn.startswith("<.*:"):
                        syslog_hdr_fp_cleanup_style = 1
                    elif fac_pri_br_re == fp_ptrn:
                        syslog_hdr_fp_cleanup_style = 2
                    # debug_print(z,'{0} {1}'.format(word,fp_ptrn))
                    elif dnk_pri_br_re == fp_ptrn:
                        syslog_hdr_fp_cleanup_style = 3
                    # debug_print(z,'{0} {1}'.format(word,fp_ptrn))
                elif syslog_hdr_fp_word_num == i:
                    pass
                else:
                    error_print('l', "syslog facility/priority matched at different points. Prev: {0}, current: {1} '{2}'".
                                format(syslog_hdr_fp_word_num, i, line))
            # end: if re.match(fp_ptrn,word):
        # end: for fp_ptrn in fps:

        if no_host_data():
            pass
        else:
            if word_matches_hostname(word, source):
                syslog_nodenames_found = unique_list(syslog_nodenames_found, word)
                # debug_print(z,"nn match-> {0} {1} {2}".format(word,i,syslog_hdr_nn_word_num))
                if syslog_hdr_nn_word_num == -1:  # if we haven't set where the nodename lives yet, do it now
                    syslog_hdr_nn_word_num = i
                elif syslog_hdr_nn_word_num == i:
                    pass
                else:
                    error_print('l', "syslog nodename found at different points. Prev: {0}, current: {1} '{2}'".
                                format(syslog_hdr_nn_word_num, i, line))
            # end: if word_matches_hostname(word):
        # else: (if no_host_data())
    # end: for word in range(range_beg,range_end):

    if syslog_hdr_fp_word_num != -1:
        if syslog_hdr_fp_word_num == syslog_hdr_nn_word_num_expected:
            syslog_hdr_nn_word_num_expected += 1  # assume word after 'fac,pri'
        # elif syslog_hdr_fp_word_num < syslog_hdr_nn_word_num_expected:
            # syslog_hdr_nn_word_num_expected-=1 # since the fp word will be removed, the nn will come 1 word sooner

    if syslog_first_msg_token == -1 and syslog_hdr_nn_word_num != -1:
        syslog_first_msg_token = syslog_hdr_nn_word_num + 1
        if syslog_hdr_fp_word_num != -1 and syslog_hdr_fp_word_num > syslog_hdr_nn_word_num:
            syslog_first_msg_token = syslog_hdr_fp_word_num + 1

    # case  introduced a messages file in which ~98% of the messages had the first two msg tokens joined.
    # this bit of code tries to identify that situation and remember it (syslog_separate_first_msg_token).
    if syslog_first_msg_token != -1 and wc > syslog_first_msg_token:
        mt1 = words[syslog_first_msg_token]
        for token in syslog_check_words:
            if token == '':
                continue
            if mt1.startswith(token) and mt1 != token:
                # debug_print(z,"'{0}' '{1}'".format(mt1,token))
                syslog_separate_first_token = True
            # <token>                  <mt1>
            # e.g.:  "kernel:"   compared to  "kernel:Initializing"
            # "systemd:"  compared to  "systemd:Starting"
        # end: for token in syslog_check_words:
    return

# ---------------------------------------------#
# function: no_host_data()
# return true/false depending on whether or not there is any host data
# ---------------------------------------------#


def no_host_data():
    global hostname, hostname_short
    global uname_nodename, uname_nodename_short
    global all_host_ip_names  # ''
    global localhostname  # ''
    if hostname != '':
        return(False)
    if uname_nodename != '':
        return(False)
    if localhostname != '':
        return(False)
    if all_host_ip_names != '':
        return(False)
    return(True)  # no host name data to work with

# ---------------------------------------------#
# function: word_matches_hostname()
# if word matches hostname/uname return True otherwise return False
# ---------------------------------------------#


def word_matches_hostname(word, source):
    global hostname, hostname_short
    global uname_nodename, uname_nodename_short
    global all_host_ip_names  # ''
    global localhostname  # ''

    debug_print(1, "{0} -> '{1}' '{2}' '{3}' '{4}' '{5}'".format(word, hostname, hostname_short, uname_nodename, uname_nodename_short, localhostname))
    if word.lower() == hostname.lower():
        return(True)
    if word.lower() == uname_nodename.lower():
        return(True)

    word_short = domain_strip(word, source)
    if word_short == '':
        if hostname_short != '':
            if word.lower() == hostname_short.lower():
                return(True)
        if uname_nodename_short != '':
            if word.lower() == uname_nodename_short.lower():
                return(True)
    else:  # word_short != '':
        if word_short.lower() == hostname.lower():
            return(True)
        if word_short.lower() == uname_nodename.lower():
            return(True)
        if hostname_short != '':
            if word_short.lower() == hostname_short.lower():
                return(True)
        if uname_nodename_short != '':
            if word_short.lower() == uname_nodename_short.lower():
                return(True)

    if word_in_list(word, all_host_ip_names):
        return(True)

    if word == "localhost":
        return(True)
    if word == "localhost.localdomain":
        return(True)
    if word == localhostname:
        return(True)  # from etc/rsyslog.conf

    return(False)  # word doesn't match actual version(s) of local host name or defacto local host name

# ---------------------------------------------#
# function: domain_strip()
# if word has domain info, return the the string without it
# if word does not have domain info return null string
# ---------------------------------------------#


def domain_strip(word, source):
    global tld_domain_ptrn  # "(com|org|..."
    global cc_domain_ptrn  # "(ae|au|br|ca|..."

    if '.' not in word:
        return('')

    tmp = word.split('.')
    wc = len(tmp)
    last_segment = tmp[wc - 1]
    word_short = ''
    # debug_print(z,"'{0}' '{1}' '{2}'".format(word,word_short,last_segment))
    if re.match(tld_domain_ptrn, last_segment.lower()):
        pass
    elif re.match(cc_domain_ptrn, last_segment.lower()):
        pass
    elif source == "hostname" or source == "uname":
        anomaly_line = "hostname '{0}' ends with non-standard segment '{1}' ({2})".format(word, last_segment, source)
        handle_anomaly("NOTE", anomaly_line)
    else:
        return('')

    word_short = tmp[0]
    # debug_print(z,"'{0}' '{1}' '{2}'".format(word,word_short,last_segment))
    return(word_short)

# ---------------------------------------------#
# function: get_general_data()
#
# Read files such as hostname, date, and uptime
# Normally these files are symlinks to the actual versions on sos_commands/general
# but sometimes they are real and little or nothing exists in sos_commands/general
# ---------------------------------------------#


def get_general_data(fn):

    fid = "sos_commands/general/" + fn
    data = readline1(fid)
    if data != "":
        return(data)

    # try non-symlink
    data = readline1(fn)
    return(data)


# ---------------------------------------------#
# function: crunch_messages_files()
# previous messages files are named using one of the 2 following formats:
# messages.n(.gz/.bz2) where 1 is the most
# recent messages file
# (other than messages itself).
# So the oldest file has the
# the numerically largest value.
# messages-yyyymmdd(.gz/.bz2) where a given messages
# file can contain mulitple days of messages.
# In this case the oldest file has the
# the numerically lower value.
# N.B. any other naming schemes
# (or non-numeric suffixes) will be kicked out in in the
# error_print and the user will have to rename the files
# manually in order for sumsos to process them.
# ---------------------------------------------#
def crunch_messages_files(pass_no):
    global sw_msg_level  # 0

    global syslog_msg_fn_array  # Key_data()
    global syslog_fn_format_yyyymmdd  # False
    global syslog_fn_format_n  # False
    global syslog_fn_max_n  # 0
    global syslog_fn_min_n  # big_num
    global syslog_fn_cnt_n  # 0
    global messages_file_list

    n = 0

    if sw_msg_level > 0:  # do we want to analyze older syslog files ?

        if syslog_fn_cnt_n == 0:
            build_messages_file_array()

        if syslog_fn_cnt_n > 0:
            i = syslog_fn_cnt_n
            if syslog_fn_format_n:
                # go in reverse order (oldest to newest)
                for n in range(syslog_fn_max_n, syslog_fn_min_n - 1, -1):
                    fn = syslog_msg_fn_array[n]
                    if fn == "":
                        continue
                    if i <= sw_msg_level:
                        crunch_messages_data(pass_no, "var/log/" + fn)
                    i -= 1

            if syslog_fn_format_yyyymmdd:
                # go from smallest to largest value (oldest to newest)
                for n in range(syslog_fn_min_n, syslog_fn_max_n + 1, 1):
                    fn = syslog_msg_fn_array[n]
                    if fn == "":
                        continue
                    if i <= sw_msg_level:
                        crunch_messages_data(pass_no, "var/log/" + fn)
                    i -= 1
    # end of 'if sw_msg_level > 0:'

    tmp = messages_file_list.split()
    for messages_file in tmp:
        if file_exists_with_data(messages_file):
            crunch_messages_data(pass_no, messages_file)
            break
    # end: for messages_file in tmp:

    debug_print(1, "requested to process {0} messages file{1}, {2} found".
                format(sw_msg_level + 1, plural(sw_msg_level + 1), messages_file_count))
    return

# ---------------------------------------------#
# function: crunch_messages_data()
# var/logline_count/messages
# ---------------------------------------------#


def crunch_messages_data(pass_no, messages_file):
    global this_script_name
    global scsi_adr_re, hhmmss_re
    global total_blocked_task_count
    global messages_start_line  # 0
    global prev_dasd_eckd_line  # 0
    global prev_dasd_cuu  # ''
    global count_of_times_do_scan_block_called
    global match_log_msg_match_calls  # 0
    global match_log_msg_matches  # 0
    global count_of_times_add_scsi_info_called  # 0 # (per calling routine)
    global sw_debug_level
    global sw_timeline
    global timeline_increment  # 'd|h|m|s'
    global timeline_hdr_reduction  # big_num
    global big_num
    global curr_anom_timestamp
    global prev_msg_line
    global prev_scan_msg
    global messages_file_count  # 0
    global messages_line_count  # 0
    global messages_skipped  # 0
    global messages_skipped_mark_or_repeat  # 0
    global messages_skipped_inv_hdr  # 0
    global messages_skipped_not_this_nodename  # 0
    global first_message_timestamp  # ''
    global last_message_timestamp  # ''

    global syslog_hdr_length  # 0
    global syslog_hdr_rep_char  # ''
    global syslog_hdr_fp_word_num
    global syslog_hdr_nn_word_num
    global syslog_hdr_nn_word_num_expected
    global syslog_hdr_token_to_delete  # -1:
    global syslog_hdr_fp_cleanup_style  # -1 # if fac and/or pri are intermingled in a token requiring clean up,
    global syslog_nodenames_match_words  # syslog_nodenames_match.split()
    global syslog_nodename_word_count  # len(syslog_nodenames_match_words)
    global last_msg_rptd  # "last message repeated"
    global rsyslogd_mark  # "rsyslogd: -- MARK --"

    global syslog_hdr_xnnxn_cruft  # False
    global skip_same_last_non_match  # 0

    esc_cleanup_count = 0
    line_cnt = 0

    line_cnt = initial_file_check(messages_file)
    if line_cnt == 0:
        return  # nothing to process

    fh = openfile(messages_file)
    if fh is None:
        return

    prev_dasd_eckd_line = 0

    if pass_no == 1:
        messages_file_count += 1
    count_of_times_add_scsi_info_called = 0  # (per calling routine)
    prev_msg_line = ''
    prev_scan_msg = ''
    i = 0

    for ml in fh:
        ml = ml[0:len(ml) - 1]  # remove ending \n
        i += 1
        # if (i % 1000) == 0: debug_print(1,"timing..")

        if syslog_format == '':
            determine_format(ml, messages_file)
            # keep looking if if format not determined or nodename word number not yet known (occasionaly the first line(s) is/are truncated).
            if syslog_format == '':
                continue

        if i < messages_start_line:
            continue

        if ml == "":
            continue

        if last_msg_rptd in ml or rsyslogd_mark in ml or ratelimit_msg in ml:  # node name may or may not be in place for lmr messages...
            if pass_no == 1:
                messages_skipped += 1
                messages_skipped_mark_or_repeat += 1
                messages_line_count += 1
            continue

        if syslog_hdr_xnnxn_cruft:
            sp = ml.find(" ")
            if sp != -1:
                ml = ml[sp + 1:]  # remove '<nn>n '

        if syslog_hdr_fp_word_num == 0:  # if f/p the first word?
            pos = ml.find(':')
            if pos != -1:  # should not occur..
                ml = ml[pos + 1:].lstrip()

        if not valid_hdr(ml):
            if pass_no == 1:
                messages_skipped += 1
                messages_skipped_inv_hdr += 1
                # debug_print(z,"inv hdr '{0}".format(ml))
            continue

        if syslog_hdr_rep_char != '':
            # debug_print(z,"'{0}'".format(ml))
            ml = ml.replace(syslog_hdr_rep_char, ' ', 3)  # TODO - does the number of character replacements need to be a variable?
            # debug_print(z,"'{0}'".format(ml))

        if syslog_hdr_fp_word_num > 0:  # f/p in the msg prefix area?
            # debug_print(z,"'{0}'".format(ml))
            words = ml.split()
            wc = len(words)
            fac_pri = words[syslog_hdr_fp_word_num]
            if syslog_hdr_fp_cleanup_style == 1:  # fac and/or pri are intermingled in a token requiring clean up,
                fac_pri_new = fac_pri.replace("<", '')  # "<kernel:warning>" remove leading '<'
                tmp = fac_pri_new.split(':')  # split on colon
                fac_pri_new = tmp[0] + ":"  # take first word and add colon back
                ml = ml.replace(fac_pri, fac_pri_new)  # swap orig word w/new one so matches work
            elif syslog_hdr_fp_cleanup_style == 2:  # fac-pri in '[fac.pri]' format and no kernel: word for [kern.(info|warning|...)]
                repl_str = ''
                if fac_pri.startswith("[kern."):                          # fac.pri = [kern.*] ?
                    if wc >= (syslog_hdr_fp_word_num + 2):                  # another word to check?
                        if words[syslog_hdr_fp_word_num + 1] != "kernel:":      # is it kernel: ?
                            repl_str = ' kernel:'                                # if not, replace fac.pri w/' kernel:'
                ml = ml.replace(' ' + fac_pri, repl_str)  # disappear fac_pri or replace w/" kernel:" if [kern.*] and kernel: not next parm
            elif syslog_hdr_fp_cleanup_style == 3:  # daemon name or null (kernel) and pri are intermingled in a token requiring clean up,
                dnk_pri_new = fac_pri.strip("[]")     # "[snmpd.err]" remove leading and trailing '[]'
                tmp = dnk_pri_new.split('.')  # split on .
                if tmp[0] == '':
                    dnk = "kernel:"  # if [.warning] or [.err] etc, dnk is null kernel
                else:
                    dnk = tmp[0] + ":"  # else it is daemon name
                ml = ml.replace(fac_pri, dnk)  # swap orig word w/new one so matches work
            else:
                ml = ml.replace(' ' + fac_pri, '')  # disappear it
            # debug_print(z,"'{0}' removed->'{1}'".format(ml,fac_pri))

        if syslog_hdr_token_to_delete != -1:
            words = ml.split()
            word_to_delete = words[syslog_hdr_token_to_delete]
            ml = ml.replace(' ' + word_to_delete, '')  # disappear it (e.g. "[2]", "[5]", ..)
        this_nodename_matches = True
        if multiple_syslog_nodenames:
            words = ml.split()
            wc = len(words)
            if syslog_hdr_nn_word_num != -1:
                nn_word_num = syslog_hdr_nn_word_num
            else:
                nn_word_num = syslog_hdr_nn_word_num_expected
            if syslog_hdr_fp_word_num > 0 and (nn_word_num > syslog_hdr_fp_word_num):
                nn_word_num -= 1  # disappeared a word above
            if wc >= (nn_word_num + 1):
                this_nodename = words[nn_word_num]
                this_nodename_matches = False  # assume no match
                # debug_print(z,syslog_nodenames_match_words)
                for nn in syslog_nodenames_match_words:
                    if this_nodename == nn:
                        this_nodename_matches = True
            else:
                debug_print(0, "'{0}' {1} ({2})".format(ml, nn_word_num, messages_file))
                continue

        if this_nodename_matches is False:
            if pass_no == 1:
                messages_skipped += 1
                messages_skipped_not_this_nodename += 1
                # if messages_skipped_not_this_nodename == 1: debug_print(z,"'{0}' '{1}'".format(syslog_nodenames_match_words,this_nodename))
                # debug_print(z,"nn doesn't match '{0}".format(ml))
            continue

        if multiple_syslog_nodenames_with_different_lengths:
            this_syslog_hdr_and_nodename_length = syslog_hdr_length + len(this_nodename) + 1
        else:
            this_syslog_hdr_and_nodename_length = syslog_hdr_and_nodename_length
        hdr = ml[0:this_syslog_hdr_and_nodename_length]  # just hdr
        if sw_timeline:
            if timeline_increment != '' and timeline_hdr_reduction == big_num:
                # currently only "Mon nn hh:mm:ss" format is supported for -b=d|m|h|s
                tmp_timestamp = hdr[syslog_hdr_length - len("hh:mm:ss "):]  # verify timestampt end in hh:mm:ss format
                if re.match(hhmmss_re, tmp_timestamp.rstrip()):
                    if timeline_increment == "s":
                        timeline_hdr_reduction = 0
                    elif timeline_increment == "m":
                        timeline_hdr_reduction = len(":ss ")
                    elif timeline_increment == "h":
                        timeline_hdr_reduction = len(":mm:ss ")
                    elif timeline_increment == "d":
                        timeline_hdr_reduction = len(" hh:mm:ss ")
                    else:
                        timeline_hdr_reduction = 0  # should not occur
                else:
                    error_print('d', "option -b={0} specified but log timestamp [{1}] not in supported format (Mon nn hh:mm:ss)".
                                format(timeline_increment, hdr[0:syslog_hdr_length]))
                    sw_timeline = False
            if timeline_hdr_reduction == big_num:
                timeline_hdr_reduction = 0
            if sw_timeline:
                curr_anom_timestamp = hdr[0:syslog_hdr_length - timeline_hdr_reduction]
            # debug_print(z,curr_anom_timestamp)

        txt = ml[this_syslog_hdr_and_nodename_length:]  # line w/o header

        if pass_no == 1:
            messages_line_count += 1
            if first_message_timestamp == '':
                first_message_timestamp = hdr
            last_message_timestamp = hdr

        nml = ml  # assume no line splitting...

        if '<' in txt:
            # TODO: could also consider looking for '<>' and splitting on this as well.
            # however, anecdotally, it appears that when '<>' sequences are found there can be
            # multiple instances per line and there would be little to be gained from splitting and
            # attempting to match with them.
            cm = re.search("<[0-9]>", txt)
            if cm:
                # The "Mon dd hh:mm:ss hostname source:" is intact, but the message
                # has '<n>' artifacts in it. Using the same process as is found in crunch_dmesg_data();
                # namely break what is on the left and right of the <n> into two separate lines.
                esc_str = cm.group()
                debug_print(4, "({0} {1}) pre-esc: {2}".format(i, messages_file, ml))
                esc_cleanup_count += 1
                tmp = txt.split(esc_str)
                p0 = hdr + tmp[0].strip()  # +'text on left of <n>'
                p1 = hdr + tmp[1].strip()  # +'text on right of <n>'

                debug_print(4, "({0} {1}) post-esc: '{2}' '{3}'".format(i, messages_file, p0, p1))
                nml = p0 + '\n' + p1
        sub_lines = nml.split('\n')
        for sl in sub_lines:  # almost always 1 line, only if the <n> search above finds something are there 2 lines

            # <||Developer Note||>
            # each msg from various message files is check for a match with the following call:
            match = check_log_msg(this_syslog_hdr_and_nodename_length, pass_no, sl, i, messages_file)  # go check for matches...
            prev_msg_line = sl

        # end of for sl in sub_lines    ----------------------------------------------------------------------
    # end of for line in messages_lines ----------------------------------------------------------------------
    # end of for line in fh ----------- ----------------------------------------------------------------------

    curr_anom_timestamp = ''  # anomalies no longer eligible to be collected in timestamp array
    # sw_debug_level = 1 # REMOVE

    if corrupt_scsi_error_lines > 0:
        anomaly_line = "{0}: encountered {1} scsi error line{2} in {3} with corrupt/overwritten data.".\
                       format(this_script_name, corrupt_scsi_error_lines, plural(corrupt_scsi_error_lines), messages_file)
        handle_anomaly("DATA-5", anomaly_line)

    if esc_cleanup_count > 0:
        anomaly_line = "{0}: attempted to clean up {1} line{2} containing escape sequences <[0-9]> ({3})".\
                       format(this_script_name, esc_cleanup_count, plural(esc_cleanup_count), messages_file)
        handle_anomaly("DATA-3", anomaly_line)

    esc_cleanup_count = 0

    # debug_print(z,"skipped {0} check_log_msg() calls based on last_non_match_line".format(skip_same_last_non_match))
    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, messages_file))
    if messages_start_line > 1:
        debug_print(1, "scanning started at line {0}".format(messages_start_line))

    debug_print(1, "match checks: {0} matches: {1}".format(match_log_msg_match_calls, match_log_msg_matches))
    debug_print(1, "count of times do_scan_block called {0}".format(count_of_times_do_scan_block_called))
    debug_print(1, "count of times add_scsi_info called {0}".format(count_of_times_add_scsi_info_called))
    count_of_times_add_scsi_info_called = 0  # (per calling routine)
    match_log_msg_match_calls = 0
    match_log_msg_matches = 0
    count_of_times_do_scan_block_called = 0

    return

# ---------------------------------------------#
# function: valid_hdr()
# ---------------------------------------------#


def valid_hdr(line):
    global Mon_re, n1_re
    global hhmmss_re, hhmmssnnn_re, yyyy_re
    global syslog_format
    global syslog_year, syslog_next_year, syslog_last_year
    global Day_short_re

    if len(line) < 20:
        return(False)

    if syslog_format == 'mdt' or syslog_format == 'mdty':
        # 5   10   15   20   25   30   35
        # 01234 6789 1234 6789 1234 6789 1234
        # mdt   format: "mon dd hh:mm:ss nodename .."
        # mdty  format: "mon dd hh:mm:ss-yyyy nodename .."
        if line[3:4] != ' ':
            return(False)
        month = line[0:3]
        if not re.match(Mon_re, month):
            return(False)
        d_1 = line[4:5]
        if d_1 != ' ' and not d_1.isdigit():
            return(False)
        d_2 = line[5:6]
        if not d_2.isdigit():
            return(False)
        time = line[7:15]
        if not re.match(hhmmss_re, time):
            return(False)
        if syslog_format == 'mdt':
            if line[15:16] == ' ':
                return(True)
            else:
                return(False)
        if syslog_format == 'mdty':
            if line[15:16] != '-':
                return(False)
        year = line[16:20]
        # if year != syslog_year and year != syslog_last_year and year != syslog_next_year: return(False)
        if not re.match(yyyy_re, year):
            return(False)
        if line[20:21] != ' ':
            return(False)
        return(True)

    # 5   10   15   20   25   30   35
    # 01234 6789 1234 6789 1234 6789 1234
    # yyyy1 -> "yyyy-mm-ddThh:mm:ss.nnnnnn...
    # yyyy2 -> "yyyy Mon dd hh:mm:ss
    # yyyy3 -> "yyyy-mm-dd hh:mm:ss +hh:mm
    # yyyy4 -> "yyyy-mm-dd hh:mm:ss.nnn ...
    # yyyy5 -> "yyyy-mm-dd hh:mm:ss (hh:mm:ss.nnn) ...
    # yyyy6 -> "yyyy-mm-dd hh:mm:ss.nnnnnn...
    # yyyy7 -> "yyyy-mm-dd Day hh:mm:ss ...
    # 01234 6789 1234 6789 1234 6789 1234
    # 5   10   15   20   25   30   35
    # if syslog_format == 'yyyy1' or syslog_format == 'yyyy2' or syslog_format == 'yyyy3' == syslog_format == 'yyyy4':
    if re.match('yyyy' + n1_re, syslog_format):
        year = line[0:4]
        if not year.isdigit():
            return(False)
        if year != syslog_year and year != syslog_last_year and year != syslog_next_year:
            return(False)
        if syslog_format == 'yyyy1' or syslog_format == 'yyyy6':
            time = line[11:19]
            if not re.match(hhmmss_re, time):
                return(False)
        if syslog_format == 'yyyy2':
            if line[4:5] != ' ':
                return(False)
            if line[8:9] != ' ':
                return(False)
            month = line[5:8]
            if not re.match(Mon_re, month):
                return(False)
        if syslog_format == 'yyyy3':
            if line[10:11] != ' ':
                return(False)
            if line[19:20] != ' ':
                return(False)
            time = line[11:19]
            if not re.match(hhmmss_re, time):
                return(False)
            tz = line[20:27]
            if not re.match("[+|-][0-9]{2}:[0-9]{2}", tz):
                return(False)
        if syslog_format == 'yyyy4':
            if line[10:11] != ' ':
                return(False)
            if line[23:24] != ' ':
                return(False)
            time = line[11:23]
            if not re.match(hhmmssnnn_re, time):
                return(False)
        if syslog_format == 'yyyy5':
            if line[10:11] != ' ':
                return(False)
            if line[19:20] != ' ':
                return(False)
            if line[34:35] != ' ':
                return(False)
            time = line[11:19]
            if not re.match(hhmmss_re, time):
                return(False)
            time = line[21:33]
            if not re.match(hhmmssnnn_re, time):
                return(False)
        if syslog_format == 'yyyy7':
            if line[10:11] != ' ':
                return(False)
            if line[14:15] != ' ':
                return(False)
            if line[23:24] != ' ':
                return(False)
            day = line[11:14]
            if not re.match(Day_short_re, day):
                return(False)
            time = line[15:23]
            if not re.match(hhmmss_re, time):
                return(False)

        return(True)

    if syslog_format == 'nmdt':
        # rarely seen format? "n mon dd hh:mm:ss nodename .."
        if line[1:2] != ' ':
            return(False)
        if line[5:6] != ' ':
            return(False)
        month = line[2:5]
        if re.match(Mon_re, month):
            return(True)
        return(False)

    return(False)  # should not get here
# ---------------------------------------------#
# function: build_messages_file_array()
# ---------------------------------------------#


def build_messages_file_array():
    global syslog_msg_fn_array  # Key_data()
    global syslog_fn_format_yyyymmdd  # False
    global syslog_fn_format_n  # False
    global syslog_fn_max_n  # 0
    global syslog_fn_min_n  # big_num
    global syslog_fn_cnt_n  # 0
    global messages_fn  # "messages"

    n = 0

    fn_list = get_messages_file_names()
    fns = fn_list.split()

    for fn in fns:
        num_portion = fn[len(messages_fn + "."):]
        if not num_portion.isdigit():
            if num_portion.endswith(".gz"):
                num_portion = num_portion.replace(".gz", '')
            if num_portion.endswith(".bz2"):
                num_portion = num_portion.replace(".bz2", '')

        if not num_portion.isdigit():
            error_print("d", "fn has non-numeric suffix ({0}) ({1})".format(fn, num_portion))
            continue

        if len(num_portion) > 3 and len(num_portion) != 8:
            error_print("d", "fn has invalid numeric suffix ({0}) ({1})".format(fn, num_portion))
            continue

        if len(num_portion) == 8:
            syslog_fn_format_yyyymmdd = True
        else:
            syslog_fn_format_n = True

        n = int(num_portion)
        syslog_msg_fn_array[n] = fn  # <<<-------  build array of names
        syslog_fn_max_n = max(syslog_fn_max_n, n)
        syslog_fn_min_n = min(syslog_fn_min_n, n)
        syslog_fn_cnt_n += 1

    # end: for fn in fns:

    if syslog_fn_format_yyyymmdd and syslog_fn_format_n:
        error_print("d", "both fn formats in use - rename manually")
        syslog_fn_format_yyyymmdd = False
        syslog_fn_format_n = False

    return


# ---------------------------------------------#
# function: get_messages_file_names()
# ---------------------------------------------#
def get_messages_file_names():

    path = "var/log"

    if stat_dir(path, '', 0) is None:
        return ''

    files = [f for f in listdir(path) if isfile(join(path, f))]

    msg_files = ''
    for fn in files:
        if fn.startswith(messages_fn + ".") or fn.startswith(messages_fn + "-"):
            msg_files = unique_list(msg_files, fn)

    return msg_files


# ---------------------------------------------#
# function: adjust_log_message()
# helper routine to strip off the syslog header (if necessary)
# and any data in "kernel:" messages that might confuse later regex checks.
# (see below for more details)
# ---------------------------------------------#
def adjust_log_message(header_length, line, source):
    global br_time_1_ptrn  # re.compile("\[[0-9]{1,7}\.[0-9]{1,7}\]")
    global br_time_2_ptrn  # re.compile("[0-9]{1,7}\.[0-9]{1,7}\]")
    global kernel_no_space_ptrn  # re.compile("kernel:[A-Z,a-z,\[].*")
    global pid_br_re

    nl = line

    if header_length:
        nl = nl[header_length:]  # line w/o header

    if nl.startswith("iscsid["):  # iscsid[pid]: ...
        words = nl.split()
        wc = len(words)
        if re.match("iscsid" + pid_br_re + ":", words[0]):
            nl = nl.replace(words[0], "iscsid:")
        return(nl)
    if not nl.startswith("kernel:"):
        return(nl)

    # if nl.startswith("kernel:["): nl = nl.replace("kernel:[","kernel: [")
    # seen in case  where "kernel:" prefix had no space between the ':' and the next char.
    if kernel_no_space_ptrn.match(nl):
        nl = nl.replace("kernel:", "kernel: ")

    words = nl.split()
    wc = len(words)

    if wc <= 2:
        return(nl)
    word1 = words[1]
    word2 = words[2]

    # is line in one of the following forms: ?
    # "kernel: [123456.654321] ..."
    # "kernel: [12345.654321] ..."
    # "kernel:: ..."
    # such as: "kernel [123456.654321] sd 0:0:3:2 [sdu] ..." or "kernel:: lpfc..."
    # if so, standardize them (i.e. remove the intermediate data)

    beg = 0
    # use 'nl.find(wordn)'  instead 'len(..)' to avoid match issues where,
    # for some reason there are 2 spaces after the timing info
    if ':' == word1:
        beg = nl.find(word2)  # len("kernel:: ")
    elif br_time_1_ptrn.match(word1):
        beg = nl.find(word2)  # len("kernel: ") + len(word1) + 1
    elif '[' == word1 and wc > 3 and br_time_2_ptrn.match(word2):
        # these are dmesg lines (either direct or that have been migrated to var/log/messages)
        # beg = nl.find(word2) + len(word2) + 1
        word3 = words[3]
        beg = nl.find(word3)

    # standardize line above if 'beg' set:
    # "kernel:: ..."                 -> "kernel: ..."
    # "kernel: [123456.654321] ..."   -> "kernel: ..."
    # "kernel: [    7.984508] ..."    -> "kernel: ..."
    if beg:
        nl = "kernel: " + nl[beg:]

    return(nl)


# ---------------------------------------------#
# function: check_log_msg()
# called by crunch_dmesg and crunch_messages
# ---------------------------------------------#
def check_log_msg(hl, pass_no, line, i, source):
    global alphabet_words

    global daemon_specific_ids
    global last_daemon_specific_id_str_match  # ''
    global last_daemon_specific_scan_blocks_match  # ''

    global kernel_specific_ids
    global last_kernel_specific_id_str_match  # ''
    global last_kernel_specific_scan_blocks_match  # ''

    global kernel_misc_wc_scan_blocks  # kernel_misc_scan_table.split("\n")

    global daemon_misc_wc_scan_blocks  # daemon_misc_scan_table.split("\n")

    global messages_skipped  # 0 # count of messages which were skipped over for scan processing
    global messages_skipped_skip_prefix  # 0 # count of messages which were skipped over for scan processing

    global syslog_skip_misc_words  # syslog_skip_misc_list.split("~")
    global syslog_separate_first_token  # False # True/False: need to separate 1st token from rest of msg line: 'kernel:foo...'

    global prev_scan_msg
    global last_matched_skip_prefix_0  # ''
    global last_matched_skip_prefix_1  # ''
    global last_matched_skip_prefix_2  # ''
    global last_matched_skip_prefix_3  # ''
    global last_non_match_line_0  # ''
    global last_non_match_line_1  # ''
    global last_non_match_line_2  # ''
    global last_non_match_line_3  # ''
    global skip_same_last_non_match  # 0

    line = adjust_log_message(hl, line, source)

    if syslog_separate_first_token and "/dmesg" not in source:
        cl = line.find(':')
        sl = line.find(' ')
        max_colon_pos = max(sl, 20)
        if cl > 1 and cl < max_colon_pos and cl + 1 != sl:
            # debug_print(z,"pre -->{0}".format(line))
            line = line.replace(':', ': ')
            # debug_print(z,"post-->{0}".format(line))

    # all dmesg messages  have "kernel:" pre-pended to them so don't do the skip_prefix work for them
    # don't do the skip check for msgs we need to look at: (kernel: multipathd, etc)
    # if not "/dmesg" in source:
    if line.startswith("kernel:") or line.startswith("multipathd:") or line.startswith("lvm"):
            pass
    else:
        # # <||Developer Note||>
        # try to exit early for the case of log messages we know we are not interested in...
        if (last_matched_skip_prefix_0 != '' and line.startswith(last_matched_skip_prefix_0)) or \
           (last_matched_skip_prefix_1 != '' and line.startswith(last_matched_skip_prefix_1)) or \
           (last_matched_skip_prefix_2 != '' and line.startswith(last_matched_skip_prefix_2)) or \
           (last_matched_skip_prefix_3 != '' and line.startswith(last_matched_skip_prefix_3)):
            if pass_no == 1:
                messages_skipped += 1
                messages_skipped_skip_prefix += 1
            # debug_print(z,"match skip prefix: '{0}' -> line: '{1}'".format(skip_prefix,line)) # COMMENT
            return(False)  # not matched, skipped due to msg starting witn an instance of the skip_prefix array

        fc = line[0:1].lower()  # first char, lower case
        if fc.isalpha():
            sskw = 'syslog_skip_' + fc + '_words'
            el = 'global {0}; syslog_skip_words = {1}'.format(sskw, sskw)
            exec(el)
        else:
            syslog_skip_words = syslog_skip_misc_words

        for skip_prefix in syslog_skip_words:

            if skip_prefix == '' or skip_prefix.startswith("#"):
                continue
            if line.startswith(skip_prefix):
                last_matched_skip_prefix_3 = last_matched_skip_prefix_2
                last_matched_skip_prefix_2 = last_matched_skip_prefix_1
                last_matched_skip_prefix_1 = last_matched_skip_prefix_0
                last_matched_skip_prefix_0 = skip_prefix
                if pass_no == 1:
                    messages_skipped += 1
                    messages_skipped_skip_prefix += 1
                # debug_print(z,"match skip prefix: '{0}' -> line: '{1}'".format(skip_prefix,line)) # COMMENT
                return(False)  # not matched, skipped due to msg starting witn an instance of the skip_prefix array
        # end: for skip_prefix in syslog_skip_words:
    # end: else:

    # <||Developer Note||>
    #
    # originally there was one array of scan blocks, but as more entries were added, performance decreased
    # significantly thus multiple scan arrays were created to minimize the number of checks made.
    #

    # <||Developer Note||>
    # check 4 line cache of recent messages which we know failed to match in order to skip iterating thru
    # the current scan_block array
    if line == last_non_match_line_0 or \
       line == last_non_match_line_1 or \
       line == last_non_match_line_2 or \
       line == last_non_match_line_3:
        skip_same_last_non_match += 1
        # debug_print(z,"{0}: line".format(line))
        # debug_print(z,"{0}: last_non_match_line_0".format(last_non_match_line_0))
        return(False)
    match = False
    scan_blocks = ''
    kernel_msg = False
    kernel_misc = False
    daemon_misc = False
    id_string = ''

    lline = line.lower()  # scan_blocks can have upper and lower case text, the actual checks respect case but
    # this allows us to keeps the lists simpler when there are UPPER & lower entries. ie. SCSI & scsi

    if line.startswith("kernel: "):  # any "kernel: " line

        kernel_msg = True

        if last_kernel_specific_id_str_match != '' and lline.startswith(last_kernel_specific_id_str_match):
            scan_blocks = last_kernel_specific_scan_blocks_match
        else:
            # +----- line[8:9] if not alpha, fast path right to kernel_misc_wc
            # !
            # v
            # "kernel: _..."
            #
            if line[8:9].isalpha():

                for var_id in kernel_specific_ids:
                    if var_id == '' or var_id.startswith('# '):
                        continue
                    tmp = var_id.split('|')
                    # debug_print(z,"'{0}'".format(tmp[1]))
                    # <<---- case INsensitive match (allows things like 'kernel: SCSI' and 'scsi' to match one set of msgs in 1 table
                    # debug_print(z,'kernel: {0}'.format(tmp[1]))
                    if lline.startswith('kernel: ' + tmp[1]):  # <<---- case insensitive match
                        # (allows things like 'kernel: SCSI' and 'kernel: scsi' to match one set of msgs in 1 table
                        # debug_print(z,'match...') # keep commented unless doing serious debugging
                        var_name = 'kernel_' + tmp[0] + '_scan_blocks'
                        id_string = 'kernel: ' + tmp[1]
                        el = 'global {0}; scan_blocks = {1}'.format(var_name, var_name)
                        exec(el)
                        break
                # end: for var_id in kernel_specific_ids:
                if scan_blocks == '':
                    kernel_misc = True  # use kernel wildcard scan blocks if there is no prefix match
                    for l in alphabet_words:
                        if l != 'wc' and lline.startswith("kernel: " + l):
                            var_name = 'kernel_misc_' + l + '_scan_blocks'
                            el = 'global {0}; scan_blocks = {1}'.format(var_name, var_name)
                            exec(el)
                            break
                        # end: if l != 'wc' and lline.startswith(l):
                    # end: for l in alphabet_words:
                # end: if scan_blocks == '':

            else:

                scan_blocks = kernel_misc_wc_scan_blocks  # go straight to "kernel: <wildcard>" scan blocks ...

            # end: if not line[8:9].isalpha():

    else:
        if last_daemon_specific_id_str_match != '' and line.startswith(last_daemon_specific_id_str_match):
            scan_blocks = last_daemon_specific_scan_blocks_match
        else:
            for var_id in daemon_specific_ids:
                if var_id == '' or var_id.startswith('# '):
                    continue
                tmp = var_id.split('|')
                if line.startswith(tmp[1]):
                    var_name = 'daemon_' + tmp[0] + '_scan_blocks'
                    id_string = tmp[1]
                    el = 'global {0}; scan_blocks = {1}'.format(var_name, var_name)
                    exec(el)
                    break
            # end: for var_id in daemon_specific_ids:
            if scan_blocks == '':
                daemon_misc = True  # use daemon wildcard scan blocks if there is no prefix match
                for l in alphabet_words:
                    if l != 'wc' and lline.startswith(l):
                        var_name = 'daemon_misc_' + l + '_scan_blocks'
                        el = 'global {0}; scan_blocks = {1}'.format(var_name, var_name)
                        exec(el)
                        break
                    # end: if l != 'wc' and lline.startswith(l):
                # end: for l in alphabet_words:
    # else:

    if scan_blocks != '':
        match = match_log_msg_vs_scan_blocks(hl, pass_no, line, i, scan_blocks, source)
        # debug_print(4,"match={0}".format(match))

    if kernel_msg:
        if match:
            if not kernel_misc and id_string != '':
                last_kernel_specific_scan_blocks_match = scan_blocks
                last_kernel_specific_id_str_match = id_string
        else:
            if kernel_misc:
                scan_blocks = kernel_misc_wc_scan_blocks  # try with "kernel: <wildcard>" scan blocks ...
                match = match_log_msg_vs_scan_blocks(hl, pass_no, line, i, scan_blocks, source)
                # debug_print(4,"match={0}".format(match))
    else:
        if match:
            if not daemon_misc and id_string != '':
                last_daemon_specific_scan_blocks_match = scan_blocks
                last_daemon_specific_id_str_match = id_string
        else:
            if daemon_misc:
                scan_blocks = daemon_misc_wc_scan_blocks  # try with daemon wildcard scan blocks ...
                match = match_log_msg_vs_scan_blocks(hl, pass_no, line, i, scan_blocks, source)
                # debug_print(4,"match={0}".format(match))

    if not match:
        # debug_print(z,"{0}: line".format(line))
        # debug_print(z,"{0}: last_non_match_line".format(last_non_match_line))
        last_non_match_line_3 = last_non_match_line_2
        last_non_match_line_2 = last_non_match_line_1
        last_non_match_line_1 = last_non_match_line_0
        last_non_match_line_0 = line

    prev_scan_msg = line

    return(match)

# ---------------------------------------------#
# function: match_log_msg_vs_scan_blocks()
# called by check_log_msg
# ---------------------------------------------#


def match_log_msg_vs_scan_blocks(hl, pass_no, line, i, scan_blocks, source):
    global count_of_times_do_scan_block_called
    global match_log_msg_matches  # 0
    global match_log_msg_match_calls  # 0
    global sw_debug_level

    scan_match = False
    # scan line against patterns in this scan_table:
    for scan_block in scan_blocks:

        scan_elements = scan_block.split("~")
        scan_pattern = scan_elements[0]

        if scan_pattern == "" or scan_pattern.startswith("#"):
            continue

        # if PASS is not specified in the scan_block, it defaults to being evaluated on pass 1
        # so if we are beyond pass 1 and PASS in not in the scan block, continue now without doing the match check
        if pass_no > 1 and 'PASS' not in scan_block:
            continue

        match_log_msg_match_calls += 1
        # debug_print(0,scan_pattern) # uncomment to figure what patter is throwing regex exceptions
        if not re.match(scan_pattern, line):      # <<--- primary match statement
            # check debug level locally to reduce overhead
            if sw_debug_level >= 4:
                debug_print(4, "'{0}' *DOES NOT* match pattern {1} ({2},{3}) p={4}".
                            format(line, scan_pattern, i, source, pass_no))
            continue  # <<--- primary match statement -- not matched, look at next scan block

        match_log_msg_matches += 1

        pass_match_no = 1  # Default to call on pass 1
        if 'PASS' in scan_block:
            swc = len(scan_elements)
            for e in range(1, swc - 1):
                ele = scan_elements[e]
                if ele == "" or ele.startswith("#"):
                    continue
                tmp = ele.split(':')
                e_id = tmp[0]
                e_val = tmp[1]
                if e_id == 'PASS':
                    pass_match_no = int(e_val)
                    break

        if pass_no == pass_match_no:
            debug_print(4, "'{0}' *** MATCHES **** pattern {1} ({2},{3}) p={4}".
                        format(line, scan_pattern, i, source, pass_no))
            do_scan_block(scan_block, pass_no, line, "SCAN", i, source)  # <<--- process scan block
            count_of_times_do_scan_block_called += 1

        else:
            continue  # as if not a match

        scan_match = True

        match_break = True
        if 'MATCH' in scan_block:
            swc = len(scan_elements)
            for e in range(1, swc - 1):
                ele = scan_elements[e]
                if ele == "" or ele.startswith("#"):
                    continue
                tmp = ele.split(':')
                e_id = tmp[0]
                e_val = tmp[1]
                if e_id == 'MATCH':
                    if e_val == "STOP":
                        match_break = True
                    elif e_val == "CONTINUE":
                        match_break = False
                    else:
                        error_print('d', "MATCH:{0} invalid".format(e_val))
                    break

        if match_break:
            break  # stop looking at scan blocks now

    # end: for scan_block in scan_blocks:

    return(scan_match)


# ---------------------------------------------#
# function: do_unrecov_io_error()
# ---------------------------------------------#
def do_unrecov_io_error(line, words, source):
    #
    # kernel: raid1: sdb: unrecoverable I/O read error for block 6166912
    #
    # words = line.split() # # passed by do_scan_block
    dev_id = words[2].rstrip(":")
    scsi_adr = dev_2_lun[dev_id]
    io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)
    anomaly_line = "'{0}' ({1})".format(line, source)
    handle_anomaly("IOERR", anomaly_line)

    return


# ---------------------------------------------#
# function: check_write_read_cache()
# keep track of devices which have write or read cache disalbled
#
# ---------------------------------------------#
def check_write_read_cache(line, words, source):
    global all_write_cache_disabled_devs  # ''
    global all_read_cache_disabled_devs  # ''

    debug_print(3, "'{0}' ({1})".format(line, source))
    # 0       1  2        3     4     5      6         7    8      9
    # kernel: sd 0:2:0:0: [sda] Write cache: disabled, read cache: disabled, supports DPO and FUA
    if len(words) < 10:
        return
    dev = words[3].strip("[]")
    write_cache_status = words[6].rstrip(",")
    read_cache_status = words[9].rstrip(",")

    if write_cache_status == "disabled":
        all_write_cache_disabled_devs = unique_list(all_write_cache_disabled_devs, dev)
    if read_cache_status == "disabled":
        all_read_cache_disabled_devs = unique_list(all_read_cache_disabled_devs, dev)

    return


# ---------------------------------------------#
# function: do_attempt_access_beyond_end_of_device()
# actually called with "...: rw=n, want=n, limit=n" message
# ---------------------------------------------#
def do_attempt_to_access_beyond_end_of_device(line, words, source):
    global prev_msg_line
    global ioerr_abeod_dm
    global ioerr_abeod_sd
    global ioerr_abeod_misc
    #
    # kernel: attempt to access beyond end of device [# generic msg, no specifics, followed by:]
    #
    # kernel: dm-nn: rw=0, want=nnnnnnnn, limit=nnnnnnnn
    # -or-
    # kernel: sdc: rw=0, want=nnnnnnnn, limit=nnnnnnnn
    #
    debug_print(4, "'{0}' '{1}' ({2})".format(line, prev_msg_line, source))
    if "attempt to access beyond end of device" not in prev_msg_line:
        return

    scsi_adr = ''
    dev_id = words[1].rstrip(":")

    if re.match(dm_re, dev_id):
        track_dm_nnn_errors(dev_id)
        ioerr_abeod_dm += 1
    else:
        plen = get_len_partition_suffix(dev_id)
        _dev_id = dev_id
        if plen:
            _dev_id = dev_id[0:len(dev_id) - plen]
        scsi_adr = dev_2_lun[_dev_id]
        # scsi address may be null in the case where devid is not an sd device
        if scsi_adr != '':
            io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)
        if dev_id.startswith("sd"):
            ioerr_abeod_sd += 1
        else:
            ioerr_abeod_misc += 1
    return

# ---------------------------------------------#
# function: do_att_abeod()
# called to summarize ioerr-8 instances
# ---------------------------------------------#


def do_att_abeod(line, source):
    global ioerr_abeod_sd
    global ioerr_abeod_dm
    global ioerr_abeod_misc
    global sd_re_p
    global dm_re

    debug_print(3, "ioerr_sd={0} ioerr_dm={1}".format(ioerr_abeod_sd, ioerr_abeod_dm))

    if ioerr_abeod_sd:
        anomaly_line = "Found {0} 'kernel: attempt to access beyond end of device' [sd] messages. See KCS {1} ({2})".\
                       format(ioerr_abeod_sd, kcs_url("21135"), source)
        handle_anomaly("IOERR", anomaly_line)

    if ioerr_abeod_dm:
        anomaly_line = "Found {0} 'kernel: attempt to access beyond end of device' [dm] messages. [total_dm_io_errors++]  See KCS {1} ({2})".\
                       format(ioerr_abeod_dm, kcs_url("21135"), source)
        handle_anomaly("IOERR", anomaly_line)
    if ioerr_abeod_misc:
        anomaly_line = "Found {0} 'kernel: attempt to access beyond end of device' [misc] messages. See KCS {1} ({2})".\
                       format(ioerr_abeod_dm, kcs_url("21135"), source)
        handle_anomaly("IOERR", anomaly_line)
    return


# ---------------------------------------------#
# function: do_buffer_io_error()
# ---------------------------------------------#
def do_buffer_io_error(line, words, source):
    # global all_buffer_io_error_devices # ''
    global all_buffer_io_error_sd_devices  # ''
    global all_buffer_io_error_dm_devices  # ''
    global buffer_io_errors_on_passive_devices  # 0
    #
    # kernel: Buffer I/O error on device sda, logical block nnnn
    # kernel: Buffer I/O error on device sda1, logical block nnnn
    # kernel: Buffer I/O error on dev sdd1, logical block 549880250, lost async page write
    # kernel: Buffer I/O error on device dm-3, logical block nnnn
    # kernel: Buffer I/O error on dev sdac, logical block 6813584, async page read
    #
    debug_print(4, "{0} ({1})".format(line, source))
    scsi_adr = ''
    dev_id = words[6].rstrip(",")
    # all_buffer_io_error_devices = unique_list(all_buffer_io_error_devices,dev_id)

    if re.match(dm_re, dev_id):
        all_buffer_io_error_dm_devices = unique_list(all_buffer_io_error_dm_devices, dev_id)
        track_dm_nnn_errors(dev_id)
    else:
        all_buffer_io_error_sd_devices = unique_list(all_buffer_io_error_sd_devices, dev_id)
        plen = get_len_partition_suffix(dev_id)
        _dev_id = dev_id
        if plen:
            _dev_id = dev_id[0:len(dev_id) - plen]
        scsi_adr = dev_2_lun[_dev_id]
        io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)

        if scsi_adr != '':
            if scsi_lun_path_status[scsi_adr] == "passive":
                buffer_io_errors_on_passive_devices += 1
    return

# ---------------------------------------------#
# function: summ_buffer_sd_io_error()
# ---------------------------------------------#


def summ_buffer_sd_io_error():
    # global all_buffer_io_error_devices # ''
    global all_buffer_io_error_sd_devices  # ''
    global all_dev_mfgs  # ''
    global buffer_io_errors_on_passive_devices  # 0

    t_io_e = "[total_io_errors++]"
    tmp = sort_list(all_buffer_io_error_sd_devices)
    words = tmp.split()
    dev_count = len(words)

    ins_text = "{0} {1} unique device{2}".format(t_io_e, dev_count, plural(dev_count))
    if dev_count > 0 and dev_count < 10:
        ins_text = "{0} [{1}]".format(ins_text, tmp)

    if buffer_io_errors_on_passive_devices > 0:
        ins_text = "{0}, {1} error{2} on passive device{2}, {3}".\
                   format(ins_text, buffer_io_errors_on_passive_devices, plural(buffer_io_errors_on_passive_devices), cfa_kcs("18746"))

    if word_in_list('EMC', all_dev_mfgs) or word_in_list('DGC', all_dev_mfgs):
        if "KCS" in ins_text:  # Already have CFA KCS in insert text ?
            ins_text = "{0} & EMC devices present; {1}".format(ins_text, kcs_url("386883"))  # yes, just add KCS ...
        else:
            ins_text = "{0}, EMC devices present; {1}".format(ins_text, cfa_kcs("386883"))  # no, add CFA KCS ...
    return(ins_text)

# ---------------------------------------------#
# function: summ_buffer_dm_io_error()
# ---------------------------------------------#


def summ_buffer_dm_io_error():
    # global all_buffer_io_error_devices # ''
    global all_buffer_io_error_sm_devices  # ''
    global all_dev_mfgs  # ''
    global buffer_io_errors_on_passive_devices  # 0

    t_io_e = "[total_dm_io_errors++]"
    tmp = sort_list(all_buffer_io_error_dm_devices)
    words = tmp.split()
    dev_count = len(words)

    ins_text = "{0} {1} unique device{2}".format(t_io_e, dev_count, plural(dev_count))
    if dev_count > 0 and dev_count < 10:
        ins_text = "{0} [{1}]".format(ins_text, tmp)

    return(ins_text)


# ---------------------------------------------#
# function: do_blk_update_request_io_error()
# kernel: blk_update_request: I/O error, dev sdccc, sector nnnnnnnnnnn
# ---------------------------------------------#
def do_blk_update_request_io_error(line, words, source):
    global all_blk_update_req_io_error_sd_devices  # ''
    global all_blk_update_req_io_error_dm_devices  # ''

    debug_print(4, "{0} ({1})".format(line, source))
    scsi_adr = ''
    dev_id = words[5].rstrip(",")

    if re.match(dm_re, dev_id):
        all_blk_update_req_io_error_dm_devices = unique_list(all_buffer_io_error_dm_devices, dev_id)
        track_dm_nnn_errors(dev_id)
    else:
        all_blk_update_req_io_error_sd_devices = unique_list(all_buffer_io_error_sd_devices, dev_id)
        plen = get_len_partition_suffix(dev_id)
        _dev_id = dev_id
        if plen:
            _dev_id = dev_id[0:len(dev_id) - plen]
        scsi_adr = dev_2_lun[_dev_id]
        io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)

    return


# ---------------------------------------------#
# function: summ_blk_update_request_sd_error():
# ---------------------------------------------#
def summ_blk_update_request_sd_error():
    global all_blk_update_req_io_error_sd_devices  # ''

    t_io_e = "[total_io_errors++]"
    tmp = sort_list(all_blk_update_req_io_error_sd_devices)
    words = tmp.split()
    dev_count = len(words)

    ins_text = "{0} {1} unique device{2}".format(t_io_e, dev_count, plural(dev_count))
    if dev_count > 0 and dev_count < 10:
        ins_text = "{0} [{1}]".format(ins_text, tmp)

    return(ins_text)

# ---------------------------------------------#
# function: summ_blk_update_request_dm_error():
# ---------------------------------------------#


def summ_blk_update_request_dm_error():
    global all_blk_update_req_io_error_dm_devices  # ''

    t_io_e = "[total_dm_io_errors++]"
    tmp = sort_list(all_blk_update_req_io_error_dm_devices)
    words = tmp.split()
    dev_count = len(words)

    ins_text = "{0} {1} unique device{2}".format(t_io_e, dev_count, plural(dev_count))
    if dev_count > 0 and dev_count < 10:
        ins_text = "{0} [{1}]".format(ins_text, tmp)

    return(ins_text)

# ---------------------------------------------#
# function: do_end_request_error()
# ---------------------------------------------#


def do_end_request_error(line, words, source):
    global all_detached_devices
    global total_end_requests  # 0
    global dm_re, vxvm_re
    #
    # kernel: end_request: I/O error, dev sdo, sector 2096200
    # kernel: end_request: I/O error, dev dm-26, sector 128
    # kernel: end_request: I/O error, dev VxVM2500, sector 62866
    # kernel: end_request: critical target error, dev dm-26, sector 128
    # kernel: end_request: critical medium error, dev dm-26, sector 128
    # kernel: end_request: critical space allocation error, dev dm-1, sector 20476800
    # kernel: end_request: critical space allocation error, dev sdd, sector 204759864
    # kernel: end_request: critical nexus error, dev sdd, sector 204759864
    #

    total_end_requests += 1

    for j in range(0, len(words)):
        if words[j] == "error," and words[j + 1] == "dev":
            debug_print(4, "{0} ({1})".format(line, source))
            scsi_adr = ''
            dev_id = words[j + 2].rstrip(",")

            if re.match(dm_re, dev_id):
                track_dm_nnn_errors(dev_id)
            elif re.match(vxvm_re, dev_id):
                pass
            else:
                scsi_adr = dev_2_lun[dev_id]
                io_err_ha_bus_tgt_lun(scsi_adr, dev_id, line, source)
                return

    return

# ---------------------------------------------#
# function: track_dm_nnn_errors()
# ---------------------------------------------#


def track_dm_nnn_errors(dm_dev):
    global total_dm_io_errors  # 0
    global high_dm_io_error_count  # 0
    global high_dm_io_error_dev  # ''
    global dev_2_errs  # Counter()

    total_dm_io_errors += 1
    dev_2_errs[dm_dev] += 1
    error_count = dev_2_errs[dm_dev]
    if error_count > high_dm_io_error_count:
        high_dm_io_error_count = error_count
        high_dm_io_error_dev = dm_dev

    return

# ---------------------------------------------#
# function: track_dm_nnn_lvm_errors()
# ---------------------------------------------#


def track_dm_nnn_lvm_errors(id):
    global dm_2_lvm_errs  # Counter()           # key: dm id,               data: lvm error count  e.g. dm-215,  1
    dm_nnn = get_dm_nnn_from_id(id)
    if dm_nnn != '':
        dm_2_lvm_errs[dm_nnn] += 1
    # debug_print(0,dm_nnn)
    return


# ---------------------------------------------#
# function: get_dm_nnn_from_id()
# ---------------------------------------------#
def get_dm_nnn_from_id(id):
    global dm_re, mm_re
    global dev_2_dms  # Key_data()

    tmp_id = ''
    tmp_vg_lv = ''
    mm = ''
    # debug_print(0,id)
    dm_maj = get_device_mapper_major()

    if id.startswith("/dev/mapper/"):
        id = id[len("/dev/mapper/"):]

    if id.startswith("/dev/"):
        id = id[len("/dev/"):]

    if re.match(mm_re, id):
        id = conv_mm_2_bd(mm)
    if re.match(dm_re, id):
        return(id)

    mm = conv_id_2_mm(id, '')
    if mm == '':
        tmp = id.split("/")
        wc = len(tmp)
        if wc == 2:
            tmp_vg_lv = "{0}-{1}".format(tmp[0], tmp[1].replace("-", "--"))
            mm = conv_id_2_mm(tmp_vg_lv, "lvm")

    if mm == '':
        # debug_print(0,'no mm 1')
        return ''

    tmp = mm.split(":")
    ma = tmp[0]
    mi = tmp[1]

    if int(ma) == dm_maj:
        return("dm-{0}".format(mi))

    dms = dev_2_dms[id]
    if dms != '':
        tmp = dms.split()
        return(tmp[0])

    if mm == '':
        # debug_print(0,'no mm 2')
        # return
        pass

    minor = get_first_block_minor_no(dm_maj)
    i = 0

    while minor != -1:

        mm = "{0}:{1}".format(dm_maj, minor)
        dm_nnn = "dm-{0}".format(minor)
        aliases = conv_mm_2_bd_alias_list(mm)
        # debug_print(0,"{0} '{1}'".format(mm,aliases))
        tmp = aliases.split()
        for alias in tmp:
            # debug_print(0,"{0} '{1}'".format(id,alias))
            if alias == id:
                return(dm_nnn)
            pvs = get_lv_pvs(alias)
            tmp2 = pvs.split()
            for pv in tmp2:
                # debug_print(0,"{0} '{1}'".format(id,pv))
                if pv == id:
                    return(dm_nnn)
            # end: for pv in tmp2:
        # end: for alias in tmp:

        i += 1
        minor = get_next_block_minor_no(dm_maj, i)

    # end: while minor != -1:

    return('')


# ---------------------------------------------#
# function: process_blocked_tasks()
# two formats:
# longer: kernel: [418317.164658] INFO: task oracle:39860 blocked for more than 120 seconds.
# medium: kernel:: INFO: task oracle:39860 blocked for more than 120 seconds.
# shorter: kernel: INFO: task kjournald:5338 blocked for more than 120 seconds.
# ---------------------------------------------#
def process_blocked_tasks(line, words, source):
    global blocked_duration  # 0
    global blocked_task_count  # Counter()
    global blocked_task_names  # Key_data()
    global total_blocked_task_count  # 0
    global all_blocked_tasks  # ""
    global all_blocked_task_types  # ""
    global all_scsi_dev_types
    global Virtual_guest
    global cmdline  # Key_data()

    task_table = ""\
                 "Oracle "\
        "cssdagent "\
        "mdb_ckpt_ "\
        "ocssd.bin "\
        "octssd.bin "\
        "ohasd.bin "\
        "ologgerd "\
        "ora_.* "\
        "oraagent "\
        "oraagent.bin "\
        "oracle "\
        "oracle_8650_ "\
        "orarootagent "\
        "orarootagent.bi "\
        "osysmond "\
        "acfs.* "\
        "asm_.* "\
        "\n"\
                 "IO "\
        "cpio "\
        "dd "\
        "fc_wq_[0-9] "\
        "fdisk "\
        "flush "\
        "kpartx "\
        "kswapd[0-9] "\
        "md[0-9]_raid1 "\
        "modprobe "\
        "mt "\
        "multipath "\
        "multipathd "\
        "parted "\
        "pdflush "\
        "raid1 "\
        "readfiles "\
        "scsi_wq_[0-9] "\
        "scsi_id "\
        "scsi "\
        "splunkd "\
        "tar "\
        "udevd "\
        "\n"\
                 "Filesystem "\
        "gfs2.* "\
        "jbd2 "\
        "kjournald "\
        "mkfs.ext4 "\
        "mkfs "\
        "mmfsd "\
        "nfsd "\
        "xfsaild "\
        "\n"\
                 "Database "\
        "db2sync "\
        "db2sysc "\
        "mysqld "\
        "\n"\
                 "LVM "\
        "lvcreate "\
        "lvm "\
        "lvs "\
        "pvdisplay "\
        "pvs "\
        "pvsi "\
        "vgdisplay "\
        "vgs "\
        "\n"\
                 "Veritas "\
        "dmp_daemon "\
        "tldd "\
        "vx_naio_worker "\
        "vx_worklist_thr "\
        "vx_worklist "\
        "vxconfigd "\
        "vxdclid "\
        "vxesd "\
        "vxiod "\
        "vxvm "\
        "\n"\
                 "Symantec "\
        "bpcd "\
        "bptm "\
        "vnetd "\
        "\n"\
                 "HP "\
        "hpsum "\
        "devbra "\
        "cmascsid "\
        "\n"\
                 "EMC "\
        "emcp_mond "\
        "emcpd "\
        "emcpdefd "\
        "emcprequestd "\
        "emcpmiscd "\
        "MpxPeriodicCall "\
        "\n"\
                 "Cluster "\
        "clurgmgrd "\
        "clusvcadm "\
        "clvmd "\
        "cpglockd "\
        "rgmanager "\
        "\n"\
                 "SAN "\
        "qla2xxx_.* "\
        "lpfc.* "\
        "fc_rport.* "\
        "\n"\
                 "Miscellaneous "\
        ".* "\
        "\n"\
        ""

    # words = line.split() # # done by do_scan_block
    wc = len(words)
    w_offset = 0
    if words[1].startswith('[') or words[1] == ':':
        w_offset = 1  # longer version, word offest = 1 for '[nnnnn.nnnnn]'
    tmp_blocked_duration = words[(wc - 2)]  # 2nd to last word
    if not tmp_blocked_duration.isdigit():
        return

    blocked_duration = int(tmp_blocked_duration)

    tmp = words[3 + w_offset]
    tmp = tmp.replace(':', ' ')
    tmp = tmp.replace('/', ' ')
    tmp = tmp.replace('-', ' ')
    tmp = tmp.split()
    task_name = tmp[0]
    twc = len(tmp)
    task_pid = tmp[twc - 1]
    match_count = 0
    total_blocked_task_count += 1
    all_blocked_tasks = unique_list(all_blocked_tasks, task_name)

    task_table_lines = task_table.split("\n")
    for task_line in task_table_lines:
        task_table_names = task_line.split()
        tnwc = len(task_table_names)
        if tnwc < 2:
            continue

        task_table_type = task_table_names[0]
        for t in range(1, tnwc):

            if match_count == 0 and re.match(task_table_names[t], task_name):

                blocked_task_count[task_table_type] += 1
                blocked_task_names[task_table_type] = unique_list(blocked_task_names[task_table_type], task_name)
                match_count += 1
                all_blocked_task_types = unique_list(all_blocked_task_types, task_table_type)
                debug_print(3, "{0} {1} {2} '{3}' ({4})".format(task_table_type, task_table_names[t], task_name, line, source))

    if task_name == "modprobe" and ("st" in all_scsi_dev_types and "ch" in all_scsi_dev_types):
        anomaly_line = "Found '{0}', {1} ({2})".\
                       format(line, cfa_kcs("394123"), source)
        handle_anomaly("ST", anomaly_line)

    if task_name == "jbd2" and not Virtual_guest:
        if cmdline["elevator"] == "cfq" or cmdline["elevator"] == '':
            if cmdline["elevator"] == '':
                tmp = "unknown"
            else:
                tmp = cmdline["elevator"]
            blurb = "(elevator set to '{0}')".format(tmp)
            anomaly_line = "Found '{0}', {1}, {2} ({3})".\
                           format(line, blurb, cfa_kcs("408833"), source)
            handle_anomaly("HUNG", anomaly_line)

    if task_name == "elxhbamgrd":
        anomaly_line = "Found '{0}', {1} ({2})".\
                       format(line, cfa_kcs("489243"), source)
        handle_anomaly("HUNG", anomaly_line)

    return


# ---------------------------------------------#
# function: crunch_multipath_conf()
# ---------------------------------------------#
def crunch_multipath_conf():
    global MultipathConf  # Key_data()
    global all_MultipathConf_keys  # ""
    global rh_major

    mpc_file = "etc/multipath.conf"
    fh = openfile(mpc_file)
    if fh is None:
        return

    d0_object_list = "defaults blacklist blacklist_exceptions multipaths devices"
    d1_object_list = "multipath device"
    current_object_list = ''
    d0_object_string = ''
    d1_object_string = ''
    current_object_name = ""
    depth = 0
    need_leading_brace = False
    issued_lb_emsg = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        line = adjust_for_dbcs(line, i, mpc_file)

        if not is_printable(line):
            error_print('d', "@unprintable data: line({0})='{1}'".format(i, line))

        debug_print(4, "line({0})='{1}'".format(i, line))

        if need_leading_brace:
            if line.startswith("{"):
                need_leading_brace = False
                line = line[1:]
                line = line.strip()
                if line == "":
                    continue
            else:
                if not issued_lb_emsg:
                    l_brace = '{'
                    error_print('d', "Expecting '{0}', for current object {1}, found '{2}' on line {3} ({4})".format(l_brace, current_object_name, line, i, mpc_file))
                    issued_lb_emsg = True
        words = line.split()
        wc = len(words)
        word0 = words[0]
        word1 = ''
        word2 = ''
        word3 = ''
        if wc > 1:
            word1 = words[1]
        if wc > 2:
            word2 = words[2]
        if wc > 3:
            word3 = words[3]

        # normally sections start with 2 words, i.e.; 'devices {' but sometimes the space is missing
        # and you get 'mulitpath{' -- this bit of code fixes that up.
        if wc == 1 and word0.endswith("{"):
            word0 = word0[0:len(word0) - 1]
            word1 = "{"
            wc = 2

        # top-level section start?
        if depth == 0 and wc >= 1:
            if word_in_list(word0, d0_object_list):
                current_object_name = word0
                current_object_list = push_list(word0, current_object_list)
                d0_object_string = ''
                depth += 1
                if wc >= 2 and word1.startswith("{"):
                    pass
                elif wc == 1:
                    need_leading_brace = True
                    issued_lb_emsg = False
                if wc > 2 and not word2.startswith("#"):
                    error_print('d', "@extra data ?:line no.={0}, wc={1}, line='{2}'".format(i, wc, line))
                debug_print(3, "section beg depth={0} object list={1} '{2}' ({3} {4})".format(depth, current_object_list, line, i, mpc_file))
                continue

        # next-level section start?
        if depth > 0 and wc >= 1:
            if word_in_list(word0, d1_object_list):
                current_object_name = word0
                current_object_list = push_list(current_object_name, current_object_list)
                d1_object_string = ''
                depth += 1
                if wc >= 2 and word1.startswith("{"):
                    pass
                elif wc == 1:
                    need_leading_brace = True
                    issued_lb_emsg = False
                if wc > 2 and not word2.startswith("#"):
                    error_print('d', "@extra data ?:line no.={0}, wc={1}, line='{2}'".format(i, wc, line))
                debug_print(2, "section beg depth={0} object list={1} '{2}' ({3} {4})".format(depth, current_object_list, line, i, mpc_file))
                continue

        # end-of-section?
        if mpc_section_end(word0, wc, i, line, mpc_file):
            need_leading_brace = False  # we can reset this now (should only be set at this point if there is a syntax error)
            if depth > 1:
                debug_print(3, "pre-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                if current_object_name != top_list(current_object_list):
                    error_print('d', "EOS logic problem: object name error: {0}/{1} '{2}".format(depth, current_object_name, current_object_list))

                if not word_in_list(current_object_name, d1_object_list):
                    error_print('d', "EOS logic problem: depth/section error: {0}/'{1}'".format(depth, current_object_list))
                else:
                    process_mpc_section_string(d1_object_string, current_object_name, mpc_file)
                    current_object_list = pop_list(current_object_list)
                    current_object_name = top_list(current_object_list)
                depth -= 1
                debug_print(3, "post-EOS: depth/section: {0}/{1} '{2}'".format(depth, current_object_list, line))
                continue
            elif depth == 1:
                debug_print(3, "pre-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                if current_object_name != top_list(current_object_list):
                    error_print('d', "EOS logic problem: object name error: {0}/{1} '{2}'".format(depth, current_object_name, current_object_list))
                if not word_in_list(current_object_name, d0_object_list):
                    error_print('d', "EOS logic problem: depth/section error: {0}/'{1}'".format(depth, current_object_list))
                else:
                    process_mpc_section_string(d0_object_string, current_object_name, mpc_file)
                    current_object_list = pop_list(current_object_list)
                    current_object_name = top_list(current_object_list)
                depth -= 1
                debug_print(3, "post-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                continue

        # generally the format is key data but have seen several examples like this:
        # devnode"^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*" where there no space between the key and the start of the data
        key = word0
        x = key.find("'")
        y = key.find('"')
        z = max(x, y)
        if z > -1:
            key = key[0:z]
        debug_print(3, "data  in: {0}".format(line))
        data = get_mpc_data(line)  # gather up all pieces of the data and strip off any comments
        key_and_data = key + " " + data
        debug_print(3, "data out: {0}".format(key_and_data))
        all_MultipathConf_keys = unique_list(all_MultipathConf_keys, key)

        if depth > 1:
            d1_object_string = d1_object_string + "\n" + key_and_data
        elif depth == 1:
            d0_object_string = d0_object_string + "\n" + key_and_data

        # \/ \/ \/ \/ \/ \/ ------------------------------------------------------------------- \/ \/ \/ \/ \/ \/ -----------+
        # !!!! TEMPORARY !!! REMOVE when actual objects are created, then check the object                                   |
        # check for holdover rhel 5 syntax in rhel6 multipath.conf file                                                      |
        # |
        # |
        # |
        # |

        if rhel_is('GE', '7.0') and key == "getuid_callout":
            anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which is RHEL5/6 syntax, For RHEL7 and above it is invalid. Refer to SFDC {2}".\
                           format(key, data, sfdc_url("01658069"))
            handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 1)

        rhel_5_words = "/sbin/scsi_id -g -u -s /block/%n"
        rhel_5_syntax = False
        if rhel_is('GE', '6.0') and key == "getuid_callout":
            tmp = rhel_5_words.split()
            for r5_word in tmp:
                if word_in_list(r5_word, data):
                    rhel_5_syntax = True
            if rhel_5_syntax:
                anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which contains RHEL5 syntax, For RHEL6 and above it should be '{2}'. Refer to KCS {3} and SFDC {4} & {5}".\
                               format(key, data, "/lib/udev/scsi_id --whitelisted --device=/dev/%n", kcs_url("78013"), sfdc_url("01523889"), sfdc_url("01522620"))
                handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 1)
        # end: if rhel_is('GE','6.0') and key == "getuid_callout":

        rhel_5_words = "/sbin/mpath_prio_alua /dev/%n"
        rhel_5_syntax = False
        if rhel_is('GE', '6.0') and key == "prio_callout":
            tmp = rhel_5_words.split()
            for r5_word in tmp:
                if word_in_list(r5_word, data.strip('"')):
                    rhel_5_syntax = True
            if rhel_5_syntax:
                anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which is RHEL5 syntax, For RHEL6 and above it should be '{2}'. Refer to KCS {3} and SFDC {4}".\
                               format(key, data, "prio alua", kcs_url("139193"), sfdc_url("01599352"))
                handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 5)
        # end: if rhel_is('GE','6.0') and key == "prio_callout":

        if key == "polling_interval":
            if not data.isdigit():
                anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which is not numeric".\
                               format(key, data)
                handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 5)
            elif int(data) < 4:
                anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which is less than 4, {2}".\
                               format(key, data, cfa_kcs("699153"))
                handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 5)
        # end: if key == "polling_interval":

        if key == "alias" and data.startswith("mpath"):  # see case
            anomaly_line = "Check multipath.conf, '{0}' is set to '{1}' which begins with 'mpath' which multipath uses/reserves, {2} & {3}".\
                           format(key, data, cfa_kcs("1246643"), sfdc_url("01761170"))
            handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 5)
        # end: if key == "alias" and data.startswith("mpath"):

        # !!!! TEMPORARY !!! REMOVE when actual objects are created, then check the object                                   |
        # TODO: check for 'bindings_file' on a non-root filesystem. if it is, reference kcs 17643                            |
        # https://access.redhat.com/solutions/59967 'Where is multipath `bindings` file in RHEL6 ?'                    |
        # TODO: when print device maps, check against "blacklist" spec and note blacklisted devices                          |
        # TODO: the vast majority of multipath.conf files specfiy 'user_friendly_name yes', if we find 'no' analyze..        |
        # /\ /\ /\ /\ /\ /\ ------------------------------------------------------------------- /\ /\ /\ /\ /\ /\ -----------+

    # end: for line in mpc_lines:

    # TODO: turn this code on once we are building mpc objects
    # if rhel_is('GE','6.0'):
        # if count of blacklist items or blacklist expection items > 0:
            # if default.find_multipaths == ('no'|''):
            # anomaly_line = consider using 'find_multipaths = yes' in lieu of specifying blacklist and blacklist_exceptions,
            # see kcs 66281
            # handle_anom

    words = all_MultipathConf_keys.split()
    for key in words:
        debug_print(3, "{0}={1}".format(key, MultipathConf[key]))
    # end: for key in words:

    Suggested_mpc_default = Key_data()

    settings_to_check = "polling_interval fast_io_fail dev_loss_tmo checker_timeout no_path_retry"

    Suggested_mpc_default["polling_interval"] = "5"
    Suggested_mpc_default["fast_io_fail"] = "5"
    Suggested_mpc_default["dev_loss_tmo"] = "10"
    Suggested_mpc_default["checker_timeout"] = "15"
    Suggested_mpc_default["no_path_retry"] = "fail"

    pi = MultipathConf["polling_interval"]
    fif = MultipathConf["fast_io_fail"]
    dlt = MultipathConf["dev_loss_tmo"]
    ct = MultipathConf["checker_timeout"]
    npr = MultipathConf["no_path_retry"]

    words = settings_to_check.split()
    for key in words:
        cval = MultipathConf[key]
        sval = Suggested_mpc_default[key]
        if sval.isdigit():
            sval_n = int(sval)
            if cval == '':
                cval_n = 0
            else:
                cval_n = int(cval)
            if cval_n != sval_n:
                debug_print(1, "per kcs 137073, mpc setting {0} should be {1}, (currently set to '{2}')".format(key, sval, cval))
        else:
            if cval != sval:
                debug_print(1, "per kcs 137073, mpc setting {0} should be '{1}', (currently set to '{2}')".format(key, sval, cval))

        # correlate with at least this msg: kernel: rport-2:0-0: blocked FC remote port time out: removing target and saving binding

    # end: for key in words:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, mpc_file))
    return

# ---------------------------------------------#
# function: get_mpc_data()
# get the data portion of an mpc line
# ---------------------------------------------#


def get_mpc_data(line):

    words = line.split()
    wc = len(words)

    wbeg = 1  # assume we'll start with the 2nd word
    word0 = words[0]
    key = word0
    x = key.find("'")
    y = key.find('"')
    z = max(x, y)
    if z > -1:
        word0 = key[z:]
        words[0] = word0
        wbeg = 0

    # key with no data? SNO
    if wc == 1 and wbeg == 1:
        return('')

    data = " "
    if "# " not in line:
        return(data.join(words[wbeg:]))

    data = ''
    for wn in range(wbeg, wc):
        dw = words[wn]
        x = dw.find('# ')
        if x == 0:
            return(data.strip())  # current token starts w/'# ', return whatever has been built up prior to this token
        if x >= 1:                      # current token has '# ' somewhere in the middle
            data = data + ' ' + dw[0:x]      # . pull off leading bit
            return(data.strip())         # . and return whatever has been built up prior plus the lead characters of this token
        if x == -1:
            data = data + ' ' + dw   # no '# ' in this token, continue to build up data, look at next token
    return(data.strip())                 # return built up data

# ---------------------------------------------#
# function: push_list()
# push an element on to the top of the list
# ---------------------------------------------#


def push_list(word, list):
    return(word + " " + list)

# ---------------------------------------------#
# function: pop_list()
# pop off the first element on the list
# ---------------------------------------------#


def pop_list(list):
    tmp = list.split()
    new_list = " "
    new_list = new_list.join(tmp[1:])
    return(new_list.strip())

# ---------------------------------------------#
# function: top_list()
# return top of list
# ---------------------------------------------#


def top_list(list):
    if list == '':
        return('')
    tmp = list.split()
    return(tmp[0])

# ---------------------------------------------#
# function: process_mpc_section_string()
# ---------------------------------------------#


def process_mpc_section_string(section_string, id, source):
    global multipath_conf_key_words  # multipath_conf_keywords.split()
    global rh_major

    lines = section_string.split("\n")

    # set all keyword values to null initially:
    for kw in multipath_conf_key_words:
        statement = "{0} = ''".format(kw)
        exec(statement)

    debug_print(3, "----> {0}".format(id))
    for line in lines:
        line = line.strip()

        if line == '':
            continue

        debug_print(3, line)

        words = line.split()
        word0 = words[0]
        word1 = ' '
        word1 = word1.join(words[1:])

        found = False
        for kw in multipath_conf_key_words:
            if word0 == kw:
                # turn the multipath.conf statements into python variables and values:
                # e.g. 'selector "round-robin 0"' becomes 'selector = "round-robin 0"'
                statement = "{0} = word1".format(kw)
                exec(statement)
                found = True
                break

        if not found:
            error_print('d', "unrecognized:'{0}'".format(line))

    # end: for line in lines:

    # TODO: turn this into an anomaly..display expected format and actual
    if wwid != '':
        mpc_validate_wwid('wwid', wwid)

    if selector != '' and path_selector == '' and rh_major >= 6:
        anomaly_line = "Using deprecated keyword: 'selector {0}' (use path_selector instead) ({1})".format(selector, source)
        handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 1)
        # sfdc 01616812

    if prio_callout != '' and rh_major >= 6:
        anomaly_line = "Using deprecated keyword: 'prio_callout {0}' (omit) ({1})".format(prio_callout, source)
        handle_anomaly("MULTIPATHCONF", anomaly_line)
        # sfdc 01616812

    if rr_min_io != '' and rr_min_io_rq == '' and rh_major >= 6:
        anomaly_line = "Using deprecated keyword: 'rr_min_io {0}' (use rr_min_io_rq instead) ({1})".format(rr_min_io, source)
        handle_anomaly_with_points("MULTIPATHCONF", anomaly_line, 'configuration', 1)

    # check polling_interval > 5
    # TODO: may want to recommend polling_interval, checker_timeout, fast_io_fail_tmo, and dev_loss_tmo ...
    # as per jmag in sfdc 01619086

    debug_print(3, "----> {0} done".format(id))
    return

# ---------------------------------------------#
# function: mpc_validate_wwid():
# check for wwid specified as a uuid
# ---------------------------------------------#


def mpc_validate_wwid(kw, word1):

    data = word1.strip('"')
    if data == "*" or data.endswith("*"):
        return
    if is_wwid(data):
        return
    if is_uuid(data):
        error_print('d', "data error: {0} {1} is a uuid".format(kw, word1))
    return


# ---------------------------------------------#
# function: mpc_section_end()
# check for end of section.
# ---------------------------------------------#
def mpc_section_end(w1, wc, i, line, source):
    if w1[0:1] == "}":
        if wc == 1 and w1 == "}":
            return(True)
        tmp_line = line
        if '# ' in line:
            tmp = line.split('# ')
            tmp_line = tmp[0]
        tmp = tmp_line.split()
        wc = len(tmp)
        if wc != 1 or tmp[0] != "}":
            error_print('d', "?syntax error?:'{0}' ({1} {2})".format(line, i, source))
        return True

    return False


# ---------------------------------------------#
# function: crunch_iscsid_conf()
# ---------------------------------------------#
def crunch_iscsid_conf():
    global iscsidConf_data  # Key_data()    # key: iscsid.conf kw       data: assoc. value      e.g. node.startup = automatic
    global all_iscsidConf_kwds  # ''        # all iscsid.conf keywords
    iscsid_file = "etc/iscsi/iscsid.conf"
    fh = openfile(iscsid_file)
    if fh is None:
        return
    boolean_keywords = "force-start"
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)
        kw = words[0]

        if wc > 2 and words[1] == '=':
            # kw   = words[0] # kw
            word1 = words[1]  # '='
            data = " "
            data = data.join(words[2:])  # data
            iscsidConf_data[kw] = data
            all_iscsidConf_kwds = unique_list(all_iscsidConf_kwds, kw)
        elif wc == 1 and word_in_list(boolean_keywords, kw):
            # kw   = words[0] # kw
            iscsidConf_data[kw] = 'True'
            all_iscsidConf_kwds = unique_list(all_iscsidConf_kwds, kw)
        else:
            debug_print(0, line)

    # end: for line in iscsid_lines:

    words = all_iscsidConf_kwds.split()
    for kw in words:
        debug_print(1, "{0}: {1} = {2}".format(iscsid_file, kw, iscsidConf_data[kw]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, iscsid_file))
    return


# ---------------------------------------------#
# function: process_session_recovery_timeout()
#
# kernel: session66: session recovery timed out after 5 secs
# kernel: session62: session recovery timed out after 120 secs
# ---------------------------------------------#
def process_session_recovery_timeout(line, words, source):
    global all_iscsi_session_timeouts  # ''     # unique second timeout values
    global iscsi_session_timeout_count  # Counter()  # key timeout value in seconds data: count of times timeout at the second count
    wc = len(words)
    if wc != 9:
        return  # ?

    timeout_length = words[7]
    if not timeout_length.isdigit():
        return  # ?

    all_iscsi_session_timeouts = unique_list(all_iscsi_session_timeouts, timeout_length)
    iscsi_session_timeout_count[timeout_length] += 1

    return

# ---------------------------------------------#
# function: summarize_session_recovery_timeout()
# ---------------------------------------------#


def summarize_session_recovery_timeout():
    global all_iscsi_session_timeouts  # ''     # unique second timeout values
    global iscsi_session_timeout_count  # Counter()  # key timeout value in seconds data: count of times timeout at the second count
    global iscsidConf_data  # Key_data()    # key: iscsid.conf kw       data: assoc. value      e.g. node.startup = automatic

    if all_iscsi_session_timeouts == '':
        return

    for i in range(1, 600 + 1):
        timeout_length = "{0}".format(i)
        if not word_in_list(timeout_length, all_iscsi_session_timeouts):
            continue
        timeout_occurences = iscsi_session_timeout_count[timeout_length]
        if i < 30:
            blurb = "(Should not cause cascading issues.)"
        else:
            blurb = "Consider reducing 'node.session.timeo.replacement_timeout = {0}' in iscsid.conf to avoid cascading issues in multipath, see {1}".\
                    format(iscsidConf_data["node.session.timeo.replacement_timeout"], sfdc_url("01512222"))

        anomaly_line = "iscsi session recovery timeout at {0} seconds occured {1} time{2}. {3}".\
                       format(timeout_length, timeout_occurences, plural(timeout_occurences), blurb)
        handle_anomaly("ISCSI", anomaly_line)

    # end: for i in range(1:600+1):

    return


# ---------------------------------------------#
# function: check_iscsi_host_no()
# kernel: set_host_param could not find host no nnnnn
# ---------------------------------------------#
def check_iscsi_host_no(line, words, source):
    global iscsi_host_no_gt_ffff_count  # 0

    host_no = words[7]
    if not host_no.isdigit():
        return
    host_no = int(host_no)
    if host_no < 65536:
        return
    iscsi_host_no_gt_ffff_count += 1
    return
# ---------------------------------------------#
# function: summary_iscsi_host_no()
# kernel: set_host_param could not find host no nnnnn
# ---------------------------------------------#


def summary_iscsi_host_no(line, words, source):
    global iscsi_host_no_gt_ffff_count  # 0

    anomaly_line = "encountered iscsi host no > 65535  in set_host_param message {0} time{1}, see {2}".\
                   format(iscsi_host_no_gt_ffff_count, plural(iscsi_host_no_gt_ffff_count), bz_url("1365094"))
    handle_anomaly("ISCSI", anomaly_line)
    return

# ---------------------------------------------#
# function: crunch_lvm_conf()
# ---------------------------------------------#


def crunch_lvm_conf():
    global LVMConf  # Key_data()
    global all_LVMConf_keys  # ""
    global lvm_data_state  # ''
    global service_procs  # Counter()
    global all_vg_names

    lvm_file = "etc/lvm/lvm.conf"
    fh = openfile(lvm_file)
    if fh is None:
        return

    d0_object_list = "activation allocation backup config devices dmeventd global log metadata shell"
    d1_object_list = ""
    current_object_list = ''
    d0_object_string = ''
    d1_object_string = ''
    current_object_name = ""
    depth = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        line = adjust_for_dbcs(line, i, lvm_file)

        words = line.split()
        wc = len(words)
        word0 = words[0]
        word1 = ''
        word2 = ''
        word3 = ''
        if wc > 1:
            word1 = words[1]
        elif wc > 2:
            word2 = words[2]
        elif wc > 3:
            word3 = words[3]

        # normally sections start with 2 words, i.e.; 'devices {' but sometimes the space is missing
        # and you get 'devices{' -- this bit of code fixes that up.
        if wc == 1 and word0.endswith("{"):
            word0 = word0[0:len(word0) - 1]
            word1 = "{"
            wc = 2

        # top-level section start?
        if depth == 0 and wc > 1:
            if word_in_list(word0, d0_object_list) and word1.startswith("{"):
                current_object_name = word0
                current_object_list = push_list(word0, current_object_list)
                d0_object_string = ''
                depth += 1
                if wc != 2:
                    error_print('d', "@extra data ?:{0},{1}".format(i, line))
                debug_print(3, "BOS depth={0} object list={1} '{2}' ({3} {4})".format(depth, current_object_list, line, i, lvm_file))
                continue

        # next-level section start?
        if depth > 0 and wc > 1:
            if word_in_list(word0, d1_object_list) and word1.startswith("{"):
                current_object_name = word0
                current_object_list = push_list(current_object_name, current_object_list)
                d1_object_string = ''
                depth += 1
                if wc != 2:
                    error_print('d', "@extra data ?:{0},{1}".format(i, line))
                debug_print(3, "BOS depth={0} object list={1} '{2}' ({3} {4})".format(depth, current_object_list, line, i, lvm_file))
                continue

        # end-of-section?
        if lvm_section_end(word0, wc, i, line, lvm_file):
            if depth > 1:
                debug_print(3, "pre-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                if current_object_name != top_list(current_object_list):
                    error_print('d', "EOS logic problem: object name error: {0}/{1} '{2}".format(depth, current_object_name, current_object_list))

                if not word_in_list(current_object_name, d1_object_list):
                    error_print('d', "EOS logic problem: depth/section error: {0}/'{1}'".format(depth, current_object_list))
                else:
                    process_lvm_section_string(d1_object_string, current_object_name)
                    current_object_list = pop_list(current_object_list)
                    current_object_name = top_list(current_object_list)
                depth -= 1
                debug_print(3, "post-EOS: depth/section: {0}/{1} '{2}'".format(depth, current_object_list, line))
                continue
            elif depth == 1:
                debug_print(3, "pre-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                if current_object_name != top_list(current_object_list):
                    error_print('d', "EOS logic problem: object name error: {0}/{1} '{2}'".format(depth, current_object_name, current_object_list))
                if not word_in_list(current_object_name, d0_object_list):
                    error_print('d', "EOS logic problem: depth/section error: {0}/'{1}'".format(depth, current_object_list))
                else:
                    process_lvm_section_string(d0_object_string, current_object_name)
                    current_object_list = pop_list(current_object_list)
                    current_object_name = top_list(current_object_list)
                depth -= 1
                debug_print(3, "post-EOS: depth/section: {0}/'{1}' '{2}'".format(depth, current_object_list, line))
                continue

        # generally the format is 'key = data' but have seen several examples like this:
        # key = [ "data1", "data2" ]
        # TODO (above bracketed data)
        if lvm_data_state != "continue":
            data = ''
            key = get_lvm_key(line)
            if key == '':
                continue

        debug_print(3, "data  in: {0}".format(line))
        tmp_data = get_lvm_data(line)  # gather up all pieces of the data and strip off any comments
        if data == '':
            data = tmp_data
        else:
            data = data + ' ' + tmp_data
        if lvm_data_state == "continue":
            continue  # get next line from file

        key_and_data = key + " " + data

        debug_print(3, "data out: {0}".format(key_and_data))
        all_LVMConf_keys = unique_list(all_LVMConf_keys, key)

        # -------- \/ \/ \/  !!! TEMPORARY !!! REMOVE when actual objects are created, then check the object !!! \/ \/ \/ --------+
        # |
        # |
        # \/

        if key == "scan" and data != "/dev":
            anomaly_line = "Check lvm.conf, generally it should have 'scan = /dev', currently it has 'scan = {0}'. Refer to SFDC {1}".format(data, sfdc_url("01523889"))
            handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 100)

        if key == "use_lvmetad" and data == "1":
            lvmtd_count = service_procs['lvmetad']
            if lvmtd_count == 0:
                anomaly_line = "Check lvm.conf, 'use_lvmetad = 1' but no instances are running. Refer to SFDC {0}".format(sfdc_url("01671439"))
                handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 50)
            else:
                # TODO: if key == "use_lvmetad" and data == "1" and in a clustered env or other env which doesn't play well with a cache
                # (how do we know if we are in a clustered env?)
                # see cases: 01806048, 01808565, 01809430
                #
                # kcs 2053483 - what is lvmetad and how do i disable it
                #
                anomaly_line = "Check lvm.conf, 'use_lvmetad = 1' and {0} instance{1} of lvmetad running, sometimes discouraged, {2}".format(lvmtd_count, plural(lvmtd_count), info_kcs("2053483"))
                handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 20)

        # /\
        # |
        # |
        # -------- /\ /\ /\  !!! TEMPORARY !!! REMOVE when actual objects are created, then check the object !!! /\ /\ /\ --------+
        if depth > 1:
            d1_object_string = d1_object_string + "\n" + key_and_data
            continue
        elif depth == 1:
            d0_object_string = d0_object_string + "\n" + key_and_data

        LVMConf[key] = data
    # end: for line in lvm_lines:

    if lvm_filter_accepts_all():
        if LVMConf["filter"] == "":
            blurb = "defaults to accepting"
        else:
            blurb = "accepts"
        anomaly_line = "Check lvm.conf, filter {0} all devices: [{1}] which can cause delays (especially at boot) as well as lead to the wrong devices being designated PVs, {2}".format(blurb, LVMConf["filter"], info_kcs("65960"))
        handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 100)

    if LVMConf["auto_activation_volume_list"] != "":
        tmp = LVMConf["auto_activation_volume_list"].split()
        for vg in tmp:
            if not word_in_list(vg, all_vg_names):
                anomaly_line = "Check lvm.conf, vg '{0}' listed in auto_activation_volume_list but not found".format(vg)
                handle_anomaly_with_points("LVMCONF", anomaly_line, 'configuration', 100)
        # end: for vg in tmp

    words = all_LVMConf_keys.split()
    for key in words:
        debug_print(4, "{0}={1}".format(key, LVMConf[key]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lvm_file))
    return

# ---------------------------------------------#
# function lvm_filter_accepts_all():
# return True/False if the lvm filter is set to accept all devices
# ---------------------------------------------#


def lvm_filter_accepts_all():
    global LVMConf  # Key_data()

    if LVMConf["filter"] == "a/.*/":
        return(True)

    # TODO: is the default to accept all??
    if LVMConf["filter"] == "" and file_exists_with_data("etc/lvm/lvm.conf"):
        return(True)
    return(False)


# ---------------------------------------------#
# function: get_lvm_key()
# get the key portion of an lvm line
# ---------------------------------------------#
def get_lvm_key(line):

    line = line.strip()
    if line == '':
        return('')

    words = line.split()
    wc = len(words)

    key = words[0]
    x = key.find('=')
    if x == -1:
        return(key)

    key = key[0:x]
    return(key)

# ---------------------------------------------#
# function: get_lvm_data()
# get the data portion of an lvm line
# ---------------------------------------------#


def get_lvm_data(line):
    global lvm_data_state  # ''

    _line = line
    line = line.strip()
    if line == '':
        return('')

    if lvm_data_state == 'continue':
        pass
    else:
        x = line.find('=')
        if x == -1:
            return('')

        line = line[x + 1:]
        line = line.strip()

        x = line.find("# ")
        if x != -1:
            # TODO -- do we need to check for hash sign within the data as opposed to assuming it is a comment??
            line = line[0:x]
            # error_print('d',_line)
            # return('')

    if line.startswith('[') and line.endswith("]"):
        line = line.strip("[]")
        line = line.strip()
    elif line.startswith('['):
        line = line.strip("[")
        line = line.strip()
        lvm_data_state = 'continue'
    elif line.endswith(']'):
        line = line.strip("]")
        line = line.strip()
        lvm_data_state = 'end'

    if line.find(',') != -1:
        line = line.replace(',', '')

    if line.startswith('"'):
        line = line.replace('"', '')

    if line.startswith("'"):
        line = line.replace("'", '')
    return(line)

# ---------------------------------------------#
# function: process_lvm_section_string()
# ---------------------------------------------#


def process_lvm_section_string(section_string, id):
    global lvm_conf_key_words  # lvm_conf_kewords.split()

    lines = section_string.split("\n")

    # set all keyword values to null initially:
    for kw in lvm_conf_key_words:
        statement = "{0} = ''".format(kw)
        exec(statement)

    debug_print(3, "----> {0}".format(id))
    for line in lines:
        line = line.strip()

        if line == '':
            continue

        debug_print(3, line)

        words = line.split()
        word0 = words[0]
        word1 = ' '
        word1 = word1.join(words[1:])

        found = False
        for kw in lvm_conf_key_words:
            if word0 == kw:
                statement = "{0} = word1".format(kw)
                exec(statement)
                found = True
                break

        if not found:
            error_print('d', "unrecognized:'{0}'".format(line))

    debug_print(3, "----> {0} done".format(id))
    return

# ---------------------------------------------#
# function: lvm_section_end()
# check for end of section.
# ---------------------------------------------#


def lvm_section_end(w1, wc, i, line, source):
    if w1[0:1] == "}":
        if wc == 1 and w1 == "}":
            return(True)
        tmp_line = line
        if '# ' in line:
            tmp = line.split('# ')
            tmp_line = tmp[0]
        tmp = tmp_line.split()
        wc = len(tmp)
        if wc != 1 or tmp[0] != "}":
            error_print('d', "?:'{0}' ({1} {2})".format(line, i, source))
        return True

    return False


# ---------------------------------------------#
# function: check_lvm_rule()
# evaluate the device(s) against the user passed rule or lvm.conf filter value (or default)
# ---------------------------------------------#
def check_lvm_rule(device_passed, rule_passed):
    rules = rule_passed.strip("[]")
    rules = rules.split(',')
    for rule in rules:
        rule = rule.strip()
        rule = rule.strip('"')
        orig_rule = rule
        if rule.startswith('a') or rule.startswith('r'):
            pass
        else:
            error_print('d', 'lvm rule "{0}" invalid; does not start with a or r'.format(orig_rule))
            return
        rule = rule[1:]  # rule minus a or r
        lr = len(rule)
        if lr < 3:
            error_print('d', 'lvm rule "{0}" invalid; regex portion too short'.format(orig_rule))
            return
        beg_delimiter = rule[0:1]
        end_delimiter = rule[(lr - 1):]
        if beg_delimiter != end_delimiter:
            error_print('d', 'lvm rule "{0}" invalid; regex delimiters not equal'.format(orig_rule))
            return

    device_passed = device_passed.replace(',', ' ')
    devs = device_passed.split()
    for dev in devs:
        dev = dev.strip()
        test_lvm_dev_vs_rule(dev, rule_passed)

    return

# ---------------------------------------------#
# function: test_lvm_dev_vs_rule()
# ---------------------------------------------#


def test_lvm_dev_vs_rule(dev, rule):

    rules = rule.strip("[]")
    rules = rules.split(',')
    for rule in rules:
        accept_rule = False
        reject_rule = False
        rule = rule.strip()
        orig_rule = rule
        rule = rule.strip('"')
        orig_rule = rule
        if rule.startswith('a'):
            accept_rule = True
        else:
            reject_rule = True
        rule = rule[1:]  # rule minus a or r
        lr = len(rule)
        beg_delimiter = rule[0:1]
        rule = rule.strip(beg_delimiter)
        try:
            rule_result = re.match(rule, dev)
        except Exception:
            error_print('d', 'lvm rule "{0}" has invalid regex syntax'.format(orig_rule))
            return

        debug_print(3, "{0} = match({1},{2})".format(rule_result, rule, dev))
        if rule_result:
            blurb1 = "accept"
            blurb2 = "accepted"
            if reject_rule:
                blurb1 = "REJECT"
                blurb2 = "REJECTED"
            errorprint("Device {0} matches '{1}' lvm rule \"{2}\", and will be {3}".format(dev, blurb1, orig_rule, blurb2))
            return

    errorprint("Device {0} did not match *any* lvm rule, accepted".format(dev))
    return

# ---------------------------------------------#
# function: check_lvm_backup_data()
# scan etc/lvm/backup data files for:
# 1. if missing or unknown uuids were found, see if they can be found in backup data
# 2. if VGs were found with no PVs, check for devices in the lvm backup data
# ---------------------------------------------#


def check_lvm_backup_data():
    global all_vg_names
    global all_unassoc_uuids  # ""

    global uuids_to_check  # ''
    global uuids_found  # 0
    global unassoc_uuids_found  # 0

    global all_vgs_with_no_pvs  # ''
    global all_vgs_with_missing_pvs  # ''
    global missing_pvs_found  # 0
    uuid_count = wordcount(uuids_to_check)
    vg_nopv_count = wordcount(all_vgs_with_no_pvs)
    unassoc_uuid_count = wordcount(all_unassoc_uuids)

    dir = "etc/lvm/backup/"
    if stat_dir(dir, '', 0) is None:
        if uuid_count:
            errorprint("Encountered {0} missing or unknown uuid{1} in sos report, however there is no etc/lvm/backup directory to check".
                       format(uuid_count, plural(uuid_count)))
        if vg_nopv_count:
            errorprint("Encountered {0} VG{1} in sos report with no PVs, however there is no etc/lvm/backup directory to check".
                       format(vg_nopv_count, plural(vg_nopv_count)))
        return  # out now if dir does not exist

    # read directory for filenames (which are named for the volume groups which they describe)
    # generally all files in this directory are Volume group backups, but not always, for instance lvm.conf backups have been seen
    files = [f for f in listdir(dir) if isfile(join(dir, f))]

    for fn in files:

        debug_print(3, '{0}'.format(fn))
        # see VG/LV naming note above
        vg_fn = fn
        if vg_fn.count("-") > 0 and vg_fn.count("--") == 0:
            vg_fn = vg_fn.replace("-", "--")

        crunch_lvm_backup_file(dir, fn)

    # done: for fn in files:

    if uuid_count or vg_nopv_count or unassoc_uuid_count:
        errorprint("")

    if uuid_count:
        errorprint("Encountered {0} missing or unknown uuid{1} in sos report, found {2} of them in etc/lvm/backup data".
                   format(uuid_count, plural(uuid_count), uuids_found))

    if vg_nopv_count:
        errorprint("Encountered VG{0} with no PVs in sos report, found {1} of {2} VG{3} in etc/lvm/backup data".
                   format(plural(vg_nopv_count), vg_nopvs_found, vg_nopv_count, plural(vg_nopv_count)))

    if unassoc_uuid_count:
        errorprint("Encountered unassociated PV uuid{0} in sos report, found {1} of {2} uuid{3} in etc/lvm/backup data".
                   format(plural(unassoc_uuid_count), unassoc_uuids_found, unassoc_uuid_count, plural(unassoc_uuid_count)))

    if uuid_count or vg_nopv_count or unassoc_uuid_count:
        errorprint("")
        errorprint("If metadata corruption is found, {0} and {1}".format(cfa_kcs("3334"), "https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Logical_Volume_Manager_Administration/mdatarecover.html"))
        errorprint("")

    return

# ---------------------------------------------#
# function: crunch_lvm_backup_file()
# read through an lvm backup file
# ---------------------------------------------#


def crunch_lvm_backup_file(dir, fn):
    global uuids_to_check  # ''
    global all_vg_names  # ''
    global uuids_found  # 0
    global unassoc_uuids_found  # 0
    global vg_nopvs_found  # 0
    global all_vgs_with_no_pvs  # ''
    global all_vgs_with_missing_pvs  # ''
    global all_unrecognised_disk_label_devices  # list of /dev/sd.. or /dev/dm-nn devices without recognised labels
    global all_unassoc_uuids  # ""
    global sw_u

    check_devices = False
    file = dir + fn
    fh = openfile(file)
    if fh is None:
        return

    if word_in_list(fn, all_vgs_with_no_pvs):
        vg_nopvs_found += 1
        check_devices = True

    found_vg_start = False
    found_overall_pv_start = False
    found_pv_start = False

    pv_name = ''
    pv_uuid = ''
    pv_dev = ''
    pv_devs = ''  # all unique pvs listed in vg
    pv_uuid_found = False
    pvs_in_vg = 0
    pvs_unknown_in_vg = 0
    bu_vg_name = ''

    backup_age = 0
    age_line = ''
    lines_printed = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        if line == '' or line.startswith("#"):
            continue

        line = line.strip()
        words = line.split()

        if line.startswith("creation_"):
            # creation_host = "pdiadb01v"    # Linux pdiadb01v 2.6.18-194.el5 # 1 SMP Tue Mar 16 21:52:39 EDT 2010 x86_64
            # creation_time = 1409582102    # Mon Sep  1 16:35:02 2014
            if line.startswith("creation_host ="):
                creation_host = words[2]
            if line.startswith("creation_time ="):
                wc = len(words)
                if wc > 8 and words[3] == "# ":
                    tmp = line.split("# ")
                    backup_date_time = tmp[1].strip()
                    backup_age = object_age(backup_date_time)
                    if backup_age > .5:
                        age_line = "Warning: backup data greater than 6 months old: {0} year{1}, '{2}' ({3})".\
                            format(backup_age, plural(backup_age), backup_date_time, file)
            continue
        # end: if line.startswith("createion_")

        if line == fn + " {":
            found_vg_start = True
            bu_vg_name = fn
            continue

        if not found_vg_start:
            continue

        if line == "physical_volumes {":
            found_overall_pv_start = True
            continue

        if not found_overall_pv_start:
            continue

        if re.match(".* {", line):
            pv_name = words[0]
            found_pv_start = True
            continue

        if not found_pv_start:
            continue
        if line.startswith("id = "):
            # id = "P5PkLl-7GaR-Q9Z8-K33a-imkp-lrq9-dzsl4P"
            pv_uuid = words[2].strip('"')
            continue
        # end: if line.startswith("id = "):

        if line.startswith("device = "):
            # device = "/dev/emcpowere"       # Hint only
            pv_dev = words[2].strip('"')

            debug_print(4, "{0} {1} '{2}'".format(fn, pv_dev, all_unrecognised_disk_label_devices))
            if word_in_list(pv_dev, all_unrecognised_disk_label_devices):
                errorprint("VG {0} PV {1} listed in backup data but that PV now has an unrecognised label ({2})".
                           format(fn, pv_dev, file))
                lines_printed += 1

            if pv_dev == "unknown":
                pvs_unknown_in_vg += 1
            else:
                pvs_in_vg += 1
                pv_devs = unique_list(pv_devs, pv_dev)

            if sw_u and pv_dev.startswith("/dev/sd"):
                dev_id = pv_dev[len("/dev/"):]
                if re.match(sd_re, dev_id):
                    if dev_2_parts[dev_id] != "":
                        errorprint("Backup VG {0} lists PV device {1} but the sos report lists partitions for {2} [{3}] ({4})".
                                   format(bu_vg_name, pv_dev, dev_id, dev_2_parts[dev_id], dir + fn))
                        lines_printed += 1
            continue
        # end: if line.startswith("device = "):

        if line.startswith("status = ["):
            continue  # future use...
        # end: if line.startswith("status = ["):

        if line.startswith("flags = ["):
            # flag = ["MISSING"]
            wc = len(words)
            flag = words[wc - 1].strip('[]"')
            if flag == "MISSING":
                if word_in_list(bu_vg_name, all_vgs_with_missing_pvs):
                    blurb = "(expected)"
                else:
                    blurb = "(unexpected)"
                errorprint("VG {0} PV {1} listed as MISSING in backup data {2} ({3})".
                           format(fn, pv_dev, blurb, file))
                lines_printed += 1
            continue
        # end: if line.startswith("flags = ["):
        if found_pv_start and line == "}":  # end of 'pv<id> {' section?

            if word_in_list(pv_uuid, uuids_to_check):
                errorprint('Found missing uuid "{0}", device {1} in VG {2} PV {3} section of ({4})'.
                           format(pv_uuid, pv_dev, fn, pv_name, file))
                lines_printed += 1
                pv_uuid_found = True
                uuids_found += 1
                errorprint('Consider having cu run "dd if={0} of=/tmp/lvmmetadata.out bs=1M count=10" in order to check for corruption.'.format(pv_dev))

            if word_in_list(pv_uuid, all_unassoc_uuids):
                errorprint('Found unassociated uuid "{0}", device {1} in VG {2} PV {3} section of ({4})'.
                           format(pv_uuid, pv_dev, fn, pv_name, file))
                lines_printed += 1
                # pv_uuid_found = True
                unassoc_uuids_found += 1
            found_pv_start = False  # reset PV items
            pv_name = ''
            pv_uuid = ''
            pv_dev = ''

    # end: for line in ls_lines:

    if check_devices:
        if pvs_unknown_in_vg > 0:
            unknown_blurb = "[{0} unknown]".format(pvs_unknown_in_vg)
        else:
            unknown_blurb = ''
        errorprint("VG {0} has no PVs, {1} PV{2} listed in backup data [{3}] {4} ({5})".
                   format(fn, pvs_in_vg, plural(pvs_in_vg), pv_devs, unknown_blurb, file))
        lines_printed += 1
        pvs_in_vg += 1

    if sw_u and (bu_vg_name != '' and not word_in_list(bu_vg_name, all_vg_names)):
        errorprint("Backup data exists for VG {0} but not found in current volume groups ({1})".format(bu_vg_name, dir + fn))
        lines_printed += 1

    if lines_printed and age_line != '':
        errorprint(age_line)
        lines_printed += 1
    if lines_printed:
        errorprint('')  # write a blank line between VGs

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, file))
    return


# ---------------------------------------------#
# function: test_mpc_rule()
# evaluate the device(s) against the rule or multipath.conf
# ---------------------------------------------#
def test_mpc_rule(device_passed, rule_passed):
    return

# ---------------------------------------------#
# function: crunch_multipath_data()
# ---------------------------------------------#


def crunch_multipath_data():

    mp_files = "sos_commands/devicemapper/multipath_-v4_-ll "\
               "sos_commands/multipath/multipath_-v4_-ll "\
               "sos_commands/devicemapper/multipath_-l "\
               "sos_commands/multipath/multipath_-l "\
               ""

    fns = mp_files.split()
    for fn in fns:
        if stat_file('', fn, 0) is None:
            continue
        crunch_multipath_file(fn)

    return

# ---------------------------------------------#
# function: crunch_multipath_file()
# some multipath_-v4_-ll files are prefixed w/'Mon dd hh:mm:ss | ', if found we'll strip this off
# ---------------------------------------------#


def crunch_multipath_file(mp_file):
    global all_blacklisted_devices  # ''
    global all_ro_dm_devs  # ''
    global all_ro_mp_devs  # ''
    global hhmmss_re
    global Mon_re  # '(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)'
    global scsi_adr_re, var_spaces
    global sd_re  # 'sd[a-z]{1,3}'
    global dm_re  # 'dm-[0-9]{1,3}'
    global mm_re  # '[0-9]{1,3}:[0-9]{1,5}'
    global scsi_lun_path_status  # Key_data()   # key: scsi_adr             data: "active"/"passive"
    global LUNZ_count  # 0
    global n4_re

    #
    # \_ 5:0:0:8  sdd 8:48   [active][ghost]
    #
    # |- 5:0:0:8   sdbk 67:224  active ready running
    # `- 8:0:0:8   sder 129:48  active ready running
    mp_map_detail_ptrn = re.compile('[ ]{1,3}[\\\|`][_-][ ]' + scsi_adr_re + var_spaces + sd_re + ' ')
    mp_map_detail_ptrn2 = re.compile('[|][ ][|`][_-][ ]' + scsi_adr_re + var_spaces + sd_re + ' ')

    # TODO: process vg/pv/lv data
    # TODO: figure out how to associate /dev/dm-nn to the scsi/disk id that path will go to

    # DM multipath kernel driver not loaded
    # /etc/multipath.conf does not exist, blacklisting all devices.

    # Oct 09 19:10:23 | Discover device /sys/block/sdu
    # Oct 09 19:10:23 | sdu: not found in pathvec
    # Oct 09 19:10:23 | sdu: mask = 0x25
    # Oct 09 19:10:23 | sdu: dev_t = 65:64
    # Oct 09 19:10:23 | sdu: size = 3840
    # Oct 09 19:10:23 | sdu: subsystem = scsi
    # Oct 09 19:10:23 | sdu: vendor = EMC
    # Oct 09 19:10:23 | sdu: product = SYMMETRIX
    # Oct 09 19:10:23 | sdu: rev = 5874
    # Oct 09 19:10:23 | sdu: h:b:t:l = 5:0:0:0
    # Oct 09 19:10:23 | sdu: tgt_node_name = 0x500009740854ac00
    # Oct 09 19:10:23 | sdu: get_state
    #

    # Jan 03 16:32:33 | /etc/multipath.conf line 44, invalid keyword: devices
    # Jan 03 16:32:33 | /etc/multipath.conf line 45, invalid keyword: device
    # Jan 03 16:32:33 | /etc/multipath.conf line 46, invalid keyword: vendor
    # Jan 03 16:32:33 | /etc/multipath.conf line 47, invalid keyword: product
    # Jan 03 16:32:33 | /etc/multipath.conf line 48, invalid keyword: path_grouping_policy
    # Jan 03 16:32:33 | /etc/multipath.conf line 49, invalid keyword: path_checker
    # Jan 03 16:32:33 | /etc/multipath.conf line 50, invalid keyword: features
    # Jan 03 16:32:33 | /etc/multipath.conf line 51, invalid keyword: hardware_handler
    # Jan 03 16:32:33 | /etc/multipath.conf line 52, invalid keyword: prio
    # Jan 03 16:32:33 | /etc/multipath.conf line 53, invalid keyword: rr_weight
    # Jan 03 16:32:33 | /etc/multipath.conf line 54, invalid keyword: no_path_retry
    # Jan 03 16:32:33 | unmatched '}' at line 56 of /etc/multipath.conf
    # Jan 03 16:32:33 | /etc/multipath.conf line 56, invalid keyword: }

    fh = openfile(mp_file)
    if fh is None:
        return

    paths_list_found = False
    prev_dev = ""
    curr_dev = ""
    curr_mp_dev = ""
    curr_scsi_id = ""
    curr_dm_dev = ""
    mfg = ""
    model = ""
    scsi_adr = ""
    mm = ""
    tgt = ""
    active_path = False
    passive_path = False
    mpl_LUNZ_count = 0
    i = 0

    for mpl in fh:
        mpl = mpl[0:len(mpl) - 1]  # remove trailing \n
        i += 1
        if mpl == "":
            continue
        # Oct 09 19:10:23 | ...
        if re.match('^' + Mon_re + ' [0-9]{2} ' + hhmmss_re + ' \| ', mpl):
            mpl = mpl[len("Mon dd hh:mm:ss | "):]  # strip off 'Mon dd hh:mm:ss | '
        if mpl == "":
            continue

        words = mpl.split()
        wc = len(words)
        if words[0] == "libdevmapper:":
            # at some point more processing could be done
            # Examples:
            # Aug 09 08:47:53 | libdevmapper: ioctl/libdm-iface.c(1838): dm names   NF   [16384] (*1)
            # Aug 09 08:47:53 | libdevmapper: ioctl/libdm-iface.c(1838): dm table mpathcu  NF   [16384] (*1)
            # Aug 09 08:47:53 | libdevmapper: ioctl/libdm-iface.c(1838): dm table mpathcu  NF   [16384] (*1)
            # Aug 09 08:47:53 | libdevmapper: ioctl/libdm-iface.c(1838): dm status mpathcu  NF   [16384] (*1)
            continue

        # Jan 03 16:32:33 | unmatched '}' at line 56 of /etc/multipath.conf
        # Jan 03 16:32:33 | /etc/multipath.conf line 56, invalid keyword: }
        if word_in_list("/etc/multipath.conf", mpl):
            if word_in_list("invalid", mpl) or word_in_list("unmatched", mpl):
                anomaly_line = mpl
                handle_anomaly("MULTIPATHCONF", anomaly_line)
                continue

        # check for change in device
        if re.match('^' + sd_re + ': ', mpl) or re.match('^' + dm_re + ': ', mpl):
            curr_dev = words[0].rstrip(":")
            if curr_dev != prev_dev:
                debug_print(3, "{0} {1}".format(curr_dev, prev_dev))
                if scsi_adr != "":
                    add_scsi_info_from_mpo(prev_dev, scsi_adr, mfg, model, mm, tgt, mp_file)
                prev_dev = curr_dev
                mfg = ""
                model = ""
                scsi_adr = ""
                mm = ""
                tgt = ""

        # ram4: device node name blacklisted
        ptrn = ".*: device node name blacklisted"
        if re.match(ptrn, mpl):
            dev_id = words[0].rstrip(":")
            all_blacklisted_devices = unique_list(all_blacklisted_devices, dev_id)
        if "round-robin" in mpl:
            active_path = False
            passive_path = False
            if "active" in mpl:
                active_path = True
            if "enabled" in mpl:
                passive_path = True

        if "active" in mpl and "ready" in mpl:
            scsi_adr = normalize_scsi_adr(words[0])
            if scsi_adr == '':
                scsi_adr = normalize_scsi_adr(words[1])
            if scsi_adr == '' and wc >= 3:
                scsi_adr = normalize_scsi_adr(words[2])
            if scsi_adr != '':
                if active_path:
                    scsi_lun_path_status[scsi_adr] = "active"
                if passive_path:
                    scsi_lun_path_status[scsi_adr] = "passive"
                    debug_print(3, "passive {0} '{1}'".format(scsi_adr, mpl))

        # case  for an example of a short mp_file with these lines
        if mpl == "DM multipath kernel driver not loaded" or \
           mpl == "/etc/multipath.conf does not exist, blacklisting all devices.":
            anomaly_line = "'{0}' ({1})".format(mpl, mp_file)
            handle_anomaly("MULTIPATH", anomaly_line)
        # case  for a full blown mp_file

        if "failed" in mpl or "faulty" in mpl or "ghost" in mpl:
            match = track_failed_faulty_multipath(mpl, i, mp_file)
            if 'LUNZ' in mpl:
                mpl_LUNZ_count += 1

        # sdq: vendor = IBM
        if re.match(sd_re + ': vendor = ', mpl):
            if wc >= 4:
                mfg = words[3]
            continue

        # sdq: product = 2145
        if re.match(sd_re + ': product = ', mpl):
            if wc >= 4:
                model = " "
                model = model.join(words[3:])
            continue

        # sdq: h:b:t:l = 3:0:0:9
        if re.match(sd_re + ': h:b:t:l = ', mpl):
            if wc >= 4:
                scsi_adr = words[3]
            continue

        # sdq: dev_t = 68:64
        if re.match(sd_re + ': dev_t = ', mpl):
            if wc >= 4:
                mm = words[3]
            continue

        # sdq: tgt_node_name = 0x500507680100df9b
        if re.match(sd_re + ': tgt_node_name = ', mpl):
            if wc >= 4:
                tgt_node = words[3]
            continue

        # sdq: size = 125829120
        if re.match(sd_re + ': size = ', mpl):
            if wc >= 4:
                size_ = int(words[3]) * 512  # size in 512 byte blocks
                set_device_size(curr_dev, size_, mp_file)
            continue

        if mpl == "===== paths list =====":
            paths_list_found = True
            continue

        #
        # ===== paths list =====
        # uuid hcil     dev  dev_t  pri dm_st chk_st vend/prod/rev     dev_st
        # 5:0:0:15 sdaj 66:48  -1  undef ready  EMC,SYMMETRIX     running
        #
        # uuid hcil      dev   dev_t    pri dm_st  chk_st  vend/prod/rev
        # 1:0:3:2   sdyp  129:656  0   [undef][ready] EMC,SYMMETRIX
        if paths_list_found and re.match('^' + var_spaces + scsi_adr_re + var_spaces + sd_re + var_spaces + mm_re, mpl):
            if wc < 7:
                continue  # incomplete line, see case
            scsi_adr = words[0]
            dev_id = words[1]
            mm = words[2]
            pri = words[3]
            dm_st = words[4]
            if dm_st.startswith('['):
                dm_st = dm_st.replace('[', ' ')
                dm_st = dm_st.replace(']', ' ')
                tmp = dm_st.split()
                dm_st = tmp[0]
                chk_st = tmp[1]
                mfg_model = words[5]
            else:
                dm_st = words[4]
                chk_st = words[5]
                mfg_model = words[6]
            tmp = mfg_model.split(',')
            twc = len(tmp)
            mfg = tmp[0]
            model = ''
            if twc > 1:
                model = tmp[1]
            add_scsi_info_from_mpo(dev_id, scsi_adr, mfg, model, mm, '', mp_file)
            curr_dm_dev = ''
            prev_dev = ''
            debug_print(4, "{0} {1} {2} {3} {4}".format(dev_id, scsi_adr, mfg, model, mm))

        m = mp_map_detail_ptrn.match(mpl)
        if m:
            add_scsi_info_from_mp_map_detail(mpl, curr_dm_dev, mp_file)
            # continue # allow these lines to be printed out below

        m = mp_map_detail_ptrn2.match(mpl)
        if m:
            add_scsi_info_from_mp_map_detail2(mpl, curr_dm_dev, mp_file)
            # continue # allow these lines to be printed out below

        if re.match('(\*word|params|status)', words[0]):
            continue

        # examples:
        # mpathf (360000970000292605419533030333931) dm-6 EMC,SYMMETRIX
        # ocrvote1 (360050768018100be9000000000000340) dm-11 IBM,2145
        if re.match('^.* \(.*\) ' + dm_re, mpl):
            curr_mp_dev = words[0]
            curr_scsi_id = words[1].strip('()')
            curr_dm_dev = words[2]
            add_dm_info(curr_dm_dev, curr_mp_dev, mp_file)

        # size=23G features='1 queue_if_no_path' hwhandler='0' wp=ro
        # size=2.8M features='1 queue_if_no_path' hwhandler='0' wp=rw
        if re.match('^size=.* features=', mpl) or re.match('^\[size=.*\]\[features=', mpl):
            if " wp=ro" in mpl or "[ro]" in mpl:
                if re.match(dm_re, curr_dm_dev):
                    all_ro_dm_devs = unique_list(all_ro_dm_devs, curr_dm_dev)
                    all_ro_mp_devs = unique_list(all_ro_mp_devs, curr_mp_dev)

        # "asm-prbrm-data-t1-042 (360000970000295700711533030413337) dm-89 EMC,SYMMETRIX
        # "['360a98000417641307224434d59355932', 'dm-244', 'NETAPP,LUN']
        start_pos = mpl.find('dm-')

        if start_pos != -1:
            curr_dm_dev = mpl[start_pos + len("dm-"):]
            for j in range(0, len(curr_dm_dev) + 1):
                curr_char = curr_dm_dev[j:j + 1]
                if curr_char.isdigit():
                    continue
                else:
                    break
            curr_dm_dev = "dm-" + curr_dm_dev[0:j]
            # debug_print(z,"{0} '{1}' ['{2}' '{3}]".format(i,mpl,curr_dm_dev,curr_mp_dev))
            add_dm_info(curr_dm_dev, '', mp_file)
            # wmpl = mpl.split()
            # print wmpl
            # curr_dm_dev = wmpl[2]

    # end: for mpl in fh:

    # see case  (cases says 'ask hw vendor why LUNs are R/O')
    if all_ro_dm_devs != "":
        # error_print('i',"ro dm devs: {0}".format(all_ro_dm_devs))
        # error_print('i',"ro mp devs: {0}".format(all_ro_mp_devs))
        tmp = all_ro_dm_devs.split()
        cnt_ro_dm_devs = len(tmp)
        anomaly_line = "{0} dm-nn device{1} listed as readonly (wp=ro), {2} ({3})".\
                       format(cnt_ro_dm_devs, plural(cnt_ro_dm_devs), cfa_sfdc("01520786"), mp_file)
        handle_anomaly("MULTIPATHCONF", anomaly_line)
    if mpl_LUNZ_count:
        anomaly_line = "{0} LUNZ device{1} listed as 'faulty', consider blacklisting, {2} ({3})".\
                       format(LUNZ_count, plural(LUNZ_count), cfa_sfdc("01007563"), mp_file)
        handle_anomaly("MULTIPATHCONF", anomaly_line)
        LUNZ_count += mpl_LUNZ_count

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, mp_file))
    return

# ---------------------------------------------#
# function: track_failed_faulty_multpath()
#
# 1:0:0:1   sdb  8:16   -1  undef faulty Cisco,Virtual FDD/HDD   running
# 1:0:0:2   sdc  8:32   -1  undef faulty Cisco,Virtual Floppy    running
#
# |- 3:0:0:1 sdv 65:80 active faulty running
# `- 1:0:0:1 sdb 8:16 active faulty running
#
# |- 1:0:0:26 sdcm 69:160  active faulty running
# `- 2:0:1:26 sdem 128:224 active faulty running
#
# 1:0:1:3  sde  8:64    -1  undef faulty 3PARdata,VV   running
# 1:0:1:5  sdg  8:96    -1  undef faulty 3PARdata,VV   running
#
# 1:0:3:5  sdgk 132:0   -1  undef ghost  Nimble,Server running
# 1:0:3:6  sdgm 132:32  -1  undef ghost  Nimble,Server running
# 1:0:3:7  sdgp 132:80  -1  undef ghost  Nimble,Server running
#
#
# # :# :# :# VxDMP10   201:144     -1  undef faulty ,
# # :# :# :# VxDMP11   201:160     -1  undef faulty ,
#
# sometimes:  "|- h:b:t:l -  m:m    failed faulty running"
# ---------------------------------------------#


def track_failed_faulty_multipath(mpl, i, mp_file):
    global rr_tracks
    global rr_tracks_exterior
    global mm_2_path_errs  # Counter()

    # debug_print(z,mpl)
    mpl = squeeze(mpl)
    tmp = mpl.split()

    if mpl == "io_setup failed":
        return  # see case

    if word_in_list(tmp[0], rr_tracks_exterior):
        mpl = mpl[len(tmp[0]) + 1:]  # remove rr_tracks word
        mpl = squeeze(mpl)
        tmp = mpl.split()
        # debug_print(z,mpl)

    if word_in_list(tmp[0], rr_tracks):
        mpl = mpl[len(tmp[0]) + 1:]  # remove rr_tracks word
        mpl = squeeze(mpl)
        tmp = mpl.split()
        # debug_print(z,mpl)
    scsi_adr = normalize_scsi_adr(tmp[0])
    mm = tmp[2]

    match = check_log_msg(0, 1, squeeze(mpl), i, mp_file)

    if not match:  # create individual anom if no match in list daemon_misc_scan_tables
        anomaly_line = "'{0}' ({1})".format(mpl, mp_file)
        handle_anomaly_with_points("MULTIPATH", anomaly_line, 'multipath', 10)

    if word_in_list("HITACHI", all_dev_mfgs):
        anomaly_line = "Multipath failure found with HITACHI devices present, {0}".\
                       format(cfa_kcs("276353"))
        handle_anomaly("MULTIPATH", anomaly_line)

    if scsi_adr != '':
        io_path_ha_bus_tgt_lun(scsi_adr, mpl, mp_file)
    mm_2_path_errs[mm] += 1

    # debug_print(z,"{0}: {1}".format(match,mpl))
    return(match)

# ---------------------------------------------#
# function: crunch_lsblk_data()
# ---------------------------------------------#


def crunch_lsblk_data():

    ls_files = "sos_commands/block/lsblk "\
               "sos_commands/filesys/lsblk "\
               ""

    tmp = ls_files.split()
    for ls_file in tmp:
        if ls_file == '':
            continue
        crunch_lsblk_file(ls_file, False)

    return

# ---------------------------------------------#
# function: crunch_lsblk_file()
# vg_only is a True/False boolean indicating
# whether only vg name data should be gathered (True),
# or full data gathering should be done (False)
# ---------------------------------------------#


def crunch_lsblk_file(ls_file, vg_only):
    global sd_re, sd_re_p, dm_pa_re, mpath_re
    global rr_tracks, rr_tracks_exterior
    global dm_pa_re
    global data_xxx_out  # False

    if not file_exists_with_data(ls_file):
        return

    fh = openfile(ls_file)
    if fh is None:
        return

    rrts = rr_tracks.split()
    curr_dm_dev = ""
    continued_line = False
    dev_id = ""
    sub_dev_id = ""
    type_available = False
    level = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1

        # debug_print(z,line) #
        if line.startswith("lsblk: failed"):
            continue

        if line.startswith("lsblk: ") and "unknown device name" in line:
            continue
        if line.startswith("lsblk: ") and "failed to get dm name" in line:
            continue

        if line.endswith("failed to get device path"):
            anomaly_line = "Found '{0}' ({1})".format(line, ls_file)
            handle_anomaly("MULTIPATH", anomaly_line)
            continue

        # case
        # timeout: warning: timer_create: Resource temporarily unavailable
        if "timeout:" in line or "warning:" in line:
            continue

        # -------------------------------------------------------
        # Samples:
        #
        #
        # NAME             MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
        # sdq               65:0    0 185.3G  0 disk
        # |-sdq1            65:1    0   243M  0 part
        # |-sdq2            65:2    0   1.9G  0 part  /dev/.initramfs/live
        # |-sdq3            65:3    0   1.9G  0 part
        # `-sdq4            65:4    0 181.3G  0 part
        # |-HostVG-Swap (dm-15)
        # 253:15   0  15.6G  0 lvm   [SWAP]
        # |-HostVG-Config (dm-16)
        # 253:16   0     8M  0 lvm
        # | `-ovirt-crypt-config (dm-19)
        # 253:19   0     6M  0 crypt /config
        # |-HostVG-Logging (dm-17)
        # 253:17   0  15.6G  0 lvm   /var/log
        # `-HostVG-Data (dm-18)
        # 253:18   0   150G  0 lvm
        # `-ovirt-crypt-data (dm-20)
        # 253:20   0   150G  0 crypt /data
        # sde                8:64   0    10M  0 disk
        #
        #
        # NAME                              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
        # vda                               252:0    0   25G  0 disk
        # |-vda1                            252:1    0  500M  0 part /boot
        # |-vda2                            252:2    0 19.5G  0 part
        # | |-vg_rhssquorum-lv_root (dm-0)  253:0    0  4.9G  0 lvm  /      <-- 2nd level items
        # | |-vg_rhssquorum-lv_swap (dm-1)  253:1    0    4G  0 lvm  [SWAP]     .
        # | |-vg_rhssquorum-LogVol03 (dm-2) 253:2    0  9.9G  0 lvm  /var       .
        # | `-vg_rhssquorum-LogVol02 (dm-3) 253:3    0    2G  0 lvm  /tmp       . . .
        # `-vda3                            252:3    0    5G  0 part
        # `-vg_rhssquorum-LogVol03 (dm-2) 253:2    0  9.9G  0 lvm  /var
        # sr0                                11:0    1 1024M  0 rom
        #
        #
        # NAME                       MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
        # sda                          8:0    0 279.4G  0 disk
        # `-mpatha (dm-0)            253:0    0 279.4G  0 mpath
        # |-mpathap1 (dm-1)        253:1    0   250M  0 part  /boot
        # `-mpathap2 (dm-2)        253:2    0 279.1G  0 part
        # |-vg01-lv_root (dm-3)  253:3    0    15G  0 lvm   /
        # |-vg01-lv_swap (dm-4)  253:4    0    32G  0 lvm   [SWAP]
        # |-vg01-lv_var (dm-95)  253:95   0     5G  0 lvm   /var
        # |-vg01-lv_home (dm-96) 253:96   0     5G  0 lvm   /home
        # |-vg01-lv_opt (dm-97)  253:97   0    60G  0 lvm   /opt
        # `-vg01-lv_data (dm-98) 253:98   0   100G  0 lvm   /data
        # sr0                         11:0    1  1024M  0 rom
        # sdc                          8:32   0     5G  0 disk
        # `-vote02 (dm-5)            253:5    0     5G  0 mpath
        # `-vote02p1 (dm-11)       253:11   0     5G  0 part
        # sdd                          8:48   0     5G  0 disk
        # `-vote03 (dm-6)            253:6    0     5G  0 mpath
        # `-vote03p1 (dm-12)       253:12   0     5G  0 part
        # sde                          8:64   0     1T  0 disk
        # `-asm_db01 (dm-7)          253:7    0     1T  0 mpath
        # `-asm_db01p1 (dm-13)     253:13   0  1024G  0 part
        # sdf                          8:80   0     1T  0 disk
        # `-asm_db02 (dm-8)          253:8    0     1T  0 mpath
        # `-asm_db02p1 (dm-14)     253:14   0  1024G  0 part
        # sdg                          8:96   0     1T  0 disk
        # `-asm_log01 (dm-9)         253:9    0     1T  0 mpath
        # `-asm_log01p1 (dm-16)    253:16   0  1024G  0 part
        # sdh                          8:112  0     1T  0 disk
        # `-nj_asm_db01 (dm-10)      253:10   0     1T  0 mpath
        # `-nj_asm_db01p1 (dm-19)  253:19   0  1024G  0 part
        #
        #
        #
        # Older style lsblk files do not have 'TYPE':
        #
        # NAME                              MAJ:MIN RM   SIZE RO MOUNTPOINT
        # sda                                 8:0    0 558.7G  0
        # ├─sda1                              8:1    0   250M  0 /boot
        # └─sda2                              8:2    0 558.5G  0
        # ├─vg_biqa-LogVol01 (dm-4)       253:4    0    15G  0 /
        # ├─vg_biqa-LogVol00 (dm-5)       253:5    0   152G  0 [SWAP]
        # ├─vg_biqa-LogVol05 (dm-6)       253:6    0     8G  0 /tmp
        # ├─vg_biqa-LogVol04 (dm-7)       253:7    0    20G  0 /opt
        # ├─vg_biqa-LogVol06 (dm-8)       253:8    0    10G  0 /home
        # ├─vg_biqa-LogVol03 (dm-9)       253:9    0    15G  0 /usr
        # ├─vg_biqa-LogVol02 (dm-10)      253:10   0    15G  0 /var
        # └─vg_biqa-LogVol07 (dm-11)      253:11   0   800G  0 /var/lib/libvirt/images
        # sdb                                 8:16   0 558.7G  0
        # └─sdb1                              8:17   0 558.7G  0
        # └─vg_biqa-LogVol07 (dm-11)      253:11   0   800G  0 /var/lib/libvirt/images
        #
        #
        # NAME                         MAJ:MIN RM   SIZE RO MOUNTPOINT
        # sda                            8:0    0 278.9G  0
        # |-sda1                         8:1    0   200M  0 /boot
        # `-sda2                         8:2    0 278.7G  0
        # |-VolGroup-LogVol00 (dm-0) 253:0    0  16.7G  0 /
        # |-VolGroup-LogVol04 (dm-1) 253:1    0  47.3G  0 /var
        # |-VolGroup-LogVol01 (dm-2) 253:2    0  1000M  0 /home
        # |-VolGroup-LogVol03 (dm-3) 253:3    0  19.5G  0 /usr
        # |-VolGroup-LogVol02 (dm-4) 253:4    0   9.8G  0 /tmp
        # `-VolGroup-LogVol05 (dm-5) 253:5    0   184G  0 /var/lib/ldap
        # sdb                            8:16   0   5.6M  1
        # sdc                            8:32   0   5.6M  1
        # sde                            8:64   0     1T  0
        # sdd                            8:48   0     1T  0
        #
        # -------------------------------------------------------
        # sdq               65:0    0 185.3G  0 disk
        # |-sdq1            65:1    0   243M  0 part
        # |-sdq2            65:2    0   1.9G  0 part  /dev/.initramfs/live
        # |-sdq3            65:3    0   1.9G  0 part
        # `-sdq4            65:4    0 181.3G  0 part
        # |-HostVG-Swap (dm-15)
        # 253:15   0  15.6G  0 lvm   [SWAP]
        # |-HostVG-Config (dm-16)
        # 253:16   0     8M  0 lvm
        # | `-ovirt-crypt-config (dm-19)                    <==== 3 tokens and cont'd line
        # 253:19   0     6M  0 crypt /config
        # |-HostVG-Logging (dm-17)
        # 253:17   0  15.6G  0 lvm   /var/log
        # `-HostVG-Data (dm-18)
        # 253:18   0   150G  0 lvm
        # `-ovirt-crypt-data (dm-20)
        # 253:20   0   150G  0 crypt /data
        #
        #
        # ---
        #
        # sdj                                     8:144  0   1.2T  0 disk
        # |-vgdata-opt_mycom                    253:3    0 197.7G  0 lvm  /opt/mycom
        # |-vgdata-opt_mycom_data               253:5    0   3.6T  0 lvm  /opt/mycom/data
        # |-vgdata-opt_mycom_data_oracle        253:7    0   1.7T  0 lvm  /opt/mycom/data/oracle
        # `-vgdata-opt_mycom_data_oracle_nims   253:8    0 297.7G  0 lvm  /opt/mycom/data/oracle/nims/arch
        # sdk                                     8:160  0   1.2T  0 disk
        # `-vgdata-opt_mycom_data               253:5    0   3.6T  0 lvm  /opt/mycom/data
        # sr0                                    11:0    1  1024M  0 rom
        # rbd0                                  252:0    0  12.7P  0 disk /opt/mycom/cluster_rbd0  <<---- "P"etabyte
        # rbd1                                  252:16   0    60T  0 disk /opt/mycom/cluster1
        #
        # ---
        #
        # Gluster config with lvms subordinate to other lvms (needs clarification) - as an example, see case
        # Also see note below on 'parentage'
        # sda                                        8:0    0 27.3T  0 disk
        # `-sda1                                     8:1    0 27.3T  0 part
        # |-vg_node-pool_node04lv_tmeta (dm-2)   253:2    0 15.8G  0 lvm
        # | `-vg_node-pool_node04lv-tpool (dm-4) 253:4    0   27T  0 lvm
        # |   |-vg_node-pool_node04lv (dm-5)     253:5    0   27T  0 lvm
        # |   `-vg_node-node04lv (dm-6)          253:6    0   27T  0 lvm  /gluster/node0
        # `-vg_node-pool_node04lv_tdata (dm-3)   253:3    0   27T  0 lvm
        # `-vg_node-pool_node04lv-tpool (dm-4) 253:4    0   27T  0 lvm
        # |-vg_node-pool_node04lv (dm-5)     253:5    0   27T  0 lvm
        # `-vg_node-node04lv (dm-6)          253:6    0   27T  0 lvm  /gluster/node0
        #
        # (alternate form)
        # NAME                                     MAJ:MIN  RM   SIZE RO TYPE MOUNTPOINT
        # sdcyu                                    128:2720  0   272G  0 disk
        # |-sdcyu1                                 128:2721  0   512M  0 part /boot
        # `-sdcyu2                                 128:2722  0 271.5G  0 part
        # |-rootvg-lv_var (dm-0)                 253:0     0    20G  0 lvm  /var
        # |-rootvg-lv_root (dm-1)                253:1     0    15G  0 lvm  /
        # |-rootvg-lv_opt (dm-2)                 253:2     0    10G  0 lvm  /opt
        # |-rootvg-lv_home (dm-3)                253:3     0    10G  0 lvm  /home
        # |-rootvg-lv_tmp (dm-4)                 253:4     0    10G  0 lvm  /tmp
        # |-rootvg-lv_opt_openv (dm-5)           253:5     0    10G  0 lvm  /opt/openv
        # |-rootvg-lv_opt_logs (dm-6)            253:6     0    10G  0 lvm  /opt/logs
        # |-rootvg-lv_opt_controlm (dm-7)        253:7     0    10G  0 lvm  /opt/controlm
        # |-rootvg-lv_ctm_sysout (dm-8)          253:8     0     5G  0 lvm  /opt/controlm/ctm/sysout
        # `-rootvg-lv_var_log_monitor (dm-9)     253:9     0    20G  0 lvm  /var/log/monitor
        #
        # emcpowerl                                120:176   0    72G  0 disk
        # `-emcpowerl1                             120:177   0    72G  0 part
        # |-u01vg_fasdp14-lv_u01 (dm-15)         253:15    0    50G  0 lvm
        # `-u01vg_fasdp14-lv_dbs_manobra (dm-17) 253:17    0    44G  0 lvm
        #
        # format with no (dm-nn) data
        # NAME                         MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
        # sda                            8:0    0   1.5T  0 disk
        # sdj                            8:144  0 111.8G  0 disk
        # |-sdj1                         8:145  0   512M  0 part
        # | `-md0                        9:0    0   512M  0 raid1 /boot
        # `-sdj2                         8:146  0 111.3G  0 part
        # `-md1                        9:1    0 111.2G  0 raid1
        # |-vg_rootdisk-lv_swap    253:0    0     4G  0 lvm   [SWAP]
        # |-vg_rootdisk-lv_root    253:1    0     6G  0 lvm   /
        # |-vg_rootdisk-lv_export  253:2    0     1G  0 lvm   /export
        # |-vg_rootdisk-lv_patrol  253:3    0     2G  0 lvm   /var/opt/bmc_patrol
        # |-vg_rootdisk-lv_var_log 253:4    0     8G  0 lvm   /var/log
        # `-vg_rootdisk-lv_var     253:5    0     4G  0 lvm   /var
        #
        # format with little space for name before maj:min causing that info to written on next line:
        # NAME    MAJ:MIN   RM   SIZE RO TYPE MOUNTPOINT
        # loop0     7:0      0    16M  0 loop /usr/AccessData/agent/.psa
        # loop1     7:1      0   256M  0 loop /usr/AccessData/agent/.psad
        # sda       8:0      0 279.4G  0 disk
        # |-sda1    8:1      0   300M  0 part /boot
        # `-sda2    8:2      0 279.1G  0 part
        # |-vg01-rootlv (dm-0)
        # 253:0      0     8G  0 lvm  /
        # .
        # <snip>
        # .
        # sdok    129:256    0    50G  0 disk
        # |-sdok1 129:257    0    16M  0 part
        # `-sdok4 129:260    0    50G  0 part
        # asm!volume1-180
        # 252:92161  0   230G  0 disk
        #
        #
        # -------------------------------------------------------

        match = False
        word_offset = 0
        if line == "" or line[0:4] == "NAME":
            if "TYPE" in line:
                type_available = True
            continue

        if "XXX.XXX.XXX.XXX" in line:
            data_xxx_out = True
            continue  # case

        char1 = line[0:1]
        words = line.split()
        wc = len(words)

        last_word = words[wc - 1]
        if not continued_line and (wc <= 2 or re.match(dm_pa_re, last_word)):
            # long word one (or two) token, reMainder on next line
            continued_line = True
            part1 = line
            continue

        if continued_line is True:  # create combined line
            first_char = line[0:1]
            if first_char.isalpha() or first_char.isdigit():
                error_print("d", "line {0}: '{1}' part1:{2} ({3})".format(i, line, part1, ls_file))
                continue
            line = part1 + " " + line
            char1 = line[0:1]
            part1 = ""
            continued_line = False

        words = line.split()
        wc = len(words)
        word0 = words[0]
        word1 = words[1]

        # if re.match("loop[0-9]{1,2}",word0):
        # continue

        if char1.isalpha() or char1.isdigit():  # not a "sub" line starting with: "' ',|,`,etc."
            level = 0
            word_offset = 0
            crnt_level_pos = -1
            prev_level_pos = -1
            par_dev_id = ""
            par_majmin = ""
            sub_dev_id = ""
            sub_size = ""
            sub_line = ""
            sub_dm_id = ""
            prev_dev_id = ""
            prev_majmin = ""
            prev_type = ""

            dev_id = word0
            dm_id = ""

            if re.match(dm_pa_re, word1):
                word_offset = 1
                dm_id = words[1].strip("()")
                add_dm_info(dm_id, dev_id, ls_file)

            majmin = words[1 + word_offset]
            if not valid_major_minor(majmin, True, ls_file):
                continue

            if dev_id.startswith("cciss!"):
                dev_id = dev_id[len("cciss!"):]
                track_cciss_devs(dev_id, majmin, ls_file)

            tmp = majmin.split(":")
            major = int(tmp[0])
            minor = int(tmp[1])

            # RM = words[2+word_offset]
            # SIZE = words[3+word_offset].replace(",",".")
            # mg_conv() handles interpretting commas as decimal points now
            SIZE = words[3 + word_offset]
            # RO = words[4+word_offset]

            word5 = ''
            if type_available:
                word5 = words[5 + word_offset]
            stg_type = get_lsblk_stg_type(type_available, word5, dev_id, majmin, ls_file)

            isize = mg_conv(SIZE, 0, 0)
            # debug_print(z,"{0} -> {1} ({2})".format(SIZE,isize,dev_id)) # REMOVE
            if isize == -1:
                error_print("d", "line {0}: '{1}' size:{2} ({3})".format(i, line, SIZE, ls_file))
            else:
                if stg_type == "disk":
                    set_device_size(dev_id, isize, ls_file)
                elif dm_id != '':
                    set_device_size(dm_id, isize, ls_file)

            maj_type = get_major_type(major, "block")

            if (stg_type == "disk" or stg_type == "rom") and major != get_device_mapper_major():
                if stg_type == "disk":
                    dev_type = "sd"
                elif stg_type == "rom":
                    dev_type = "sr"
                else:
                    dev_type = ""
                scsi_adr = dev_2_lun[dev_id]
                if scsi_adr == "":
                    debug_print(2, "({0} {1}) scsi_adr[{2}] lookup failed".format(i, ls_file, dev_id))
                else:
                    add_normalized_scsi_data(scsi_adr, dev_type, dev_id, "", line, ls_file)
                add_mm_bd(dev_id, majmin, ls_file)

            if stg_type == "vx":
                errorprint(54646 / 0)

            mountpoint = words[wc - 1]  # last word in line if present
            if not mountpoint.startswith("/"):
                mountpoint = ""
                # TODO refactor mount data

            prev_level_pos = 0  # remember current as previous now
            prev_dev_id = dev_id
            prev_majmin = majmin
            prev_type = stg_type

            continue

        else:  # this is a 'sub-line', i.e. it is hanging off the main line or another sub-line (2nd level)

            match = False
            word_offset = 0
            for word in words:
                for rrt in rrts:
                    if word == rrt:
                        match = True
                        word_offset += 1
                        if word in rr_tracks_exterior:
                            level += 1
                            # TODO - better analysis of levels
                        break  # for rrt in rrts
                if not match:
                    break  # for word in words

            sub_dev_id = words[0 + word_offset]

            for rrt in rrts:
                if sub_dev_id.startswith(rrt):
                    sub_dev_id = sub_dev_id[len(rrt):]
                    if sub_dev_id == "":   # this is possible:  '`- (m:m)'
                        continue

            crnt_level_pos = line.find(sub_dev_id)

            if crnt_level_pos < 2:
                error_print('l', "{0}=line.find('{1}') line='{2}' ({3})".format(crnt_level_pos, sub_dev_id, line, ls_file))
            else:
                if crnt_level_pos == prev_level_pos:
                    pass
                elif crnt_level_pos > prev_level_pos and prev_type != "lvm":  # avoid assigning parentage from one lvm vol to another
                    par_dev_id = prev_dev_id
                    par_majmin = prev_majmin
                    par_type = prev_type

            if sub_dev_id.startswith("cciss!"):
                sub_dev_id = sub_dev_id[len("cciss!"):]
                track_cciss_devs(sub_dev_id, majmin, ls_file)

            sub_dm_id = words[1 + word_offset]
            if re.match(dm_pa_re, sub_dm_id):
                sub_dm_id = sub_dm_id.strip("()")
                word_offset += 1
            else:
                sub_dm_id = ''

            if re.match(mm_re, words[1 + word_offset]):
                sub_majmin = words[1 + word_offset]
            else:
                sub_majmin = ''
                error_print('d', "mm field not where expected in line '{0}' ({1})".format(line, ls_file))

            word5 = ''
            if type_available:
                word5 = words[5 + word_offset]
            sub_stg_type = get_lsblk_stg_type(type_available, word5, sub_dev_id, majmin, ls_file)
            # mg_conv() handles interpretting commas as decimal points now
            # sub_size = words[3+word_offset].replace(",",".")
            sub_size = words[3 + word_offset]

            sub_line = " "
            sub_line = sub_line.join(words[1 + word_offset:])  # start with maj:min
            # TODO: associate sub_dev_id with dev_id
            # TODO: if present, associate sub_dm_id with sub_dev_id

            # rrt_token=''
            # debug_print(z,"rrt_token '{0}' word0: '{1}' sub_dev_id '{2}' sub_dm_id '{3}' sub_size '{4}'".
            # format(rrt_token,word0,sub_dev_id,sub_dm_id,sub_size))
            crunch_lsblk_line(i, vg_only,
                              dev_id, majmin, stg_type,
                              par_dev_id, par_majmin, par_type,
                              sub_dev_id, sub_majmin, sub_stg_type,
                              sub_dm_id, sub_line, sub_size, ls_file)
            prev_level_pos = crnt_level_pos  # remember current as previous now
            prev_dev_id = sub_dev_id
            prev_majmin = sub_majmin
            prev_type = sub_stg_type

        # end else:  # this is a 'sub-line', i.e. it is hanging off the main line or another sub-line (2nd level)
    # end: for line in ls_lines:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ls_file))
    return

# ---------------------------------------------#
# function: crunch_lsblk_line()
# ---------------------------------------------#


def crunch_lsblk_line(i, vg_only, dev_id, majmin, stg_type, par_dev_id, par_majmin, par_stg_type, sub_dev_id, sub_majmin, sub_stg_type, sub_dm_id, sub_line, sub_size, source):
    global sd_re, sd_re_p
    global all_lsblk_lvm_names  # ''
    global all_lsblk_mpath_names  # ''
    global all_lsblk_dm_names  # ''
    words = sub_line.split()
    wc = len(words)
    # if True:
    # debug_print(z,"i={0} vg_only={1} ({2})".format(i,vg_only,source))
    # debug_print(z,"dev_id={0}, majmin={1}, stg_type={2}".format(dev_id,majmin,stg_type))
    # debug_print(z,"par_dev_id={0}, par_majmin={1}, par_stg_type={2}".format(par_dev_id,par_majmin,par_stg_type))
    # debug_print(z,"sub_dev_id={0}, sub_majmin={1}, sub_stg_type={2}".format(sub_dev_id,sub_majmin,sub_stg_type))
    # debug_print(z,"sub_dm_id={0}, sub_line={1}, sub_size={2}".format(sub_dm_id,sub_line,sub_size))

    # if sub_stg_type == "dm":
    # debug_print(z,"i={0} vg_only={1} ({2})".format(i,vg_only,source))
    # debug_print(z,"dev_id={0}, majmin={1}, stg_type={2}".format(dev_id,majmin,stg_type))
    # debug_print(z,"par_dev_id={0}, par_majmin={1}, par_stg_type={2}".format(par_dev_id,par_majmin,par_stg_type))
    # debug_print(z,"sub_dev_id={0}, sub_majmin={1}, sub_stg_type={2}".format(sub_dev_id,sub_majmin,sub_stg_type))
    # debug_print(z,"sub_dm_id={0}, sub_line={1}, sub_size={2}".format(sub_dm_id,sub_line,sub_size))

    if sub_majmin.startswith("201:"):
        sub_stg_type = "vx"

    if sub_stg_type == "lvm":
        # debug_print(z,"sub_dev_id={0}".format(sub_dev_id))
        # vg_name = check_vg_prefix(sub_dev_id,source)
        if vg_only:
            vg_name = split_vg_name(sub_dev_id, source)
        else:
            vg_name = split_valid_vg_name(sub_dev_id, source)
        # debug_print(z,'vgn={0}'.format(vg_name))
        lv_name = split_lv_name(sub_dev_id, source)
        # debug_print(z,'lvn={0}'.format(lv_name))
        debug_print(3, "{0},{1},{2},'{3}'".format(vg_name, lv_name, sub_dev_id, sub_line))
        vg_name = update_vg(vg_name, "", source)
        lv_path = ""
        lv_uuid = ""
        # print("@clsb ({0} {1}) {2} {3} {4} {5}".format(i,source,dev_id,sub_dev_id,sub_dm_id,sub_line))
        # print("@clsb {0} {1} {2}".format(vg_name,lv_name,vg_lv_name))
        update_lv(vg_name, lv_name, lv_path, lv_uuid, sub_majmin, source)
        all_lsblk_lvm_names = unique_list(all_lsblk_lvm_names, sub_dev_id)

        # new  |
        # \|/
        if par_dev_id != '':
            pv_dev_id = par_dev_id
            pv_majmin = par_majmin
            pv_stg_type = par_stg_type
        else:
            pv_dev_id = dev_id
            pv_majmin = majmin
            pv_stg_type = stg_type

        tmm = pv_majmin.split(':')
        pv_maj = int(tmm[0])
        pv_min = int(tmm[1])

        if pv_dev_id.startswith("mpath"):
            pv_path = "/dev/mapper/" + pv_dev_id
        elif pv_maj == get_device_mapper_major():
            pv_path = "/dev/mapper/" + pv_dev_id
        elif is_scsi_id(pv_dev_id):
            pv_path = "/dev/mapper/" + pv_dev_id
        elif word_in_list(pv_stg_type, "disk part rom"):
            pv_path = "/dev/" + pv_dev_id  # rom -> zSystem term for dasdxn partition
        elif pv_stg_type.startswith("raid"):
            pv_path = "/dev/" + pv_dev_id
        elif pv_stg_type.startswith("loop"):
            pv_path = "/dev/" + pv_dev_id
        else:
            pv_path = "/dev/mapper/" + pv_dev_id
        # if re.match(sd_re_p,pv_dev_id) or re.match(sd_re,pv_dev_id): pv_path = "/dev/"+pv_dev_id
        # else: pv_path = "/dev/mapper/"+pv_dev_id
        update_pv(vg_name, pv_dev_id, pv_path, '', pv_majmin, source)

    if sub_stg_type == "mpath":
        all_lsblk_mpath_names = unique_list(all_lsblk_mpath_names, sub_dev_id)

    if sub_stg_type == "dm":
        all_lsblk_dm_names = unique_list(all_lsblk_dm_names, sub_dev_id)
        # for docker names, this conversion takes place, e.g.:
        # docker-202:17-22282243-c7eeb849087d4cfc82d5e1c30eda9216400026caf2225e8bc089daa7696098cf
        # to:
        # docker-202_17-22282243-c7eeb849087d4cfc82d5e1c30eda9216400026caf2225e8bc089daa7696098cf
        # to account for ':' not being allowed in file names
        # specifically the sos_commands/filesys/dumpe2fs_-h_.dev.mapper.docker-202_17-22282243-c7eeb849087d4cfc82d5e1c30eda9216400026caf2225e8bc089daa7696098cf_.<mount_point>
        # In the above, the fn is broken down in to device name.
        if re.match('docker-' + n3_re + ':' + n3_re + '-.*', sub_dev_id):
            all_lsblk_dm_names = unique_list(all_lsblk_dm_names, sub_dev_id.replace(':', '_'))

    if vg_only:
        return

    isize = mg_conv(sub_size, 0, 0)
    if isize == -1:
        error_print("d", sub_line)
        isize = 0
    # else: isize = (isize + 1023) / 1024 # keep size in KB

    if sub_dm_id != "" and isize:
        set_device_size(sub_dm_id, isize, source)
        add_dm_info(sub_dm_id, sub_dev_id, source)

    if sub_stg_type == "mpath":
        set_device_size(sub_dev_id, isize, source)
        add_mm_bd(sub_dev_id, sub_majmin, source)
    elif sub_stg_type == "part":
        set_device_size(sub_dev_id, isize, source)
        # add_partition_2_dev(dev_id,sub_dev_id,source)
        check_dev_partition(sub_dev_id, source)
        add_mm_bd(sub_dev_id, sub_majmin, source)
    elif sub_stg_type == "crypt":
        # TODO handle crypt
        pass
    elif sub_stg_type == "disk":
        # TODO handle disk
        pass
    else:
        pass

    return


# ---------------------------------------------#
# function: get_lsblk_stg_type()
# either pull from "TYPE" column if available or determine based on device if not
# NAME             MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
# sdq               65:0    0 185.3G  0 disk
# |-sdq1            65:1    0   243M  0 part
#
# ---------------------------------------------#
def get_lsblk_stg_type(type_available, word, device_id, majmin, source):
    global sd_re, sd_re_p, dm_re, sr_re

    valid_types = "disk part lvm mpath rom dm crypt md raid0 raid1 raid4 raid5 raid6 raid10 switch loop dmraid linear"

    if type_available:
        if word_in_list(word, valid_types):
            return(word)
        error_print('d', "storage type={0} not in '{1}' ({2})".format(word, valid_types, source))
        return('')

    if re.match(sd_re_p, device_id):
        return("part")
    if re.match(sd_re, device_id):
        return("disk")
    if re.match(sr_re, device_id):
        return("rom")
    if re.match(fd_re, device_id):
        return("disk")  # fdn device
    if re.match(lo_re, device_id):
        return("disk")  # loopn device
    if re.match(mdn_re, device_id):
        return("md")  # md device
    if split_valid_vg_name(device_id, source) != '':
        return("lvm")
    if device_id.startswith("mpath"):
        return("mpath")

    if majmin != '':
        # this section due to case ; 120:power2 199:VxVM 201:VxDMP
        tmp = majmin.split(':')
        maj = tmp[0]
        maj_type = get_block_major_name(maj)
        return(maj_type)

    error_print('d', "unable to determine storage type based on device {0} ({1})".format(device_id, source))
    return('')


# ---------------------------------------------#
# function: crunch_mcelog()
# ---------------------------------------------#
def crunch_mcelog():
    global ATTN

    mce_log = "var/log/mcelog"
    fh = openfile(mce_log)
    if fh is None:
        return

    last_time_line = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        if line == '':
            continue
        i += 1
        if line.startswith("TIME "):
            # TIME 1467091367 Tue Jun 28 08:22:47 2016
            words = line.split()
            wc = len(words)
            if wc != 7:
                continue
            last_time_line = line
    # end: for line in lines:

    if i > 0:
        attn_blurb = ''
        if last_time_line == '':
            age = "?"
        else:
            tmp = last_time_line.split()
            last_time_line = " "
            last_time_line = last_time_line.join(tmp[2:])
            age_of_most_recent_error = object_age(last_time_line)
            age = "{0}".format(age_of_most_recent_error)
            if age_of_most_recent_error < .2:
                attn_blurb = ATTN

        anomaly_line = "{0} is {1} lines long, check for hardware errors, most recent error is {2} years old {3}".\
                       format(mce_log, i, age, attn_blurb)
        handle_anomaly_with_points("MCE", anomaly_line, 'hardware', 10)
    # end: if i > 0:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, mce_log))
    return

# ---------------------------------------------#
# function: crunch_ceph_data()
# ---------------------------------------------#


def crunch_ceph_data():
    global ceph_status  # False

    ceph_file = "sos_commands/ceph/ceph_status"
    fh = openfile(ceph_file)
    if fh is None:
        return ceph_status
    ceph_status = True
    i = 0
    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if "health" in line:
            errorprint("ceph status: {0}".format(line))

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ceph_file))

    return ceph_status


# ---------------------------------------------#
# function: crunch_gluster_data()
# ---------------------------------------------#
def crunch_gluster_data():
    global gluster_status  # False

    gluster_file = "sos_commands/gluster/gluster_peer_status"
    fh = openfile(gluster_file)
    if fh is None:
        return gluster_status

    gluster_status = True
    i = 0
    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if "Number of Peers" in line:
            errorprint("gluster status: {0}".format(line))

    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, gluster_file))
    return gluster_status


# ---------------------------------------------#
# function: crunch_sysctl_data()
# ---------------------------------------------#
def crunch_sysctl_data():
    global meminfo_2_vm  # Key_data
    global sysctl  # Key_data
    global total_mem
    global mb, kb
    global data_xxx_out  # False

    sysctl_file = "sos_commands/kernel/sysctl_-a"
    fh = openfile(sysctl_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        words = line.split()
        wc = len(words)
        if wc < 3:
            continue
        keyw = words[0]
        eqlit = words[1]
        word3 = words[2]
        if eqlit != "=":
            continue
        if "XXX.XXX.XXX.XXX" in word3:  # case
            data_xxx_out = True
            continue
        # hack to make it easy to check semxxx settings
        if keyw == "kernel.sem":
            sysctl["kernel.semmsl"] = int(words[2])
            sysctl["kernel.semmns"] = int(words[3])
            sysctl["kernel.semopm"] = int(words[4])
            sysctl["kernel.semmni"] = int(words[5])
            i += 4
            continue
        if keyw == 'net.ipv4.tcp_rmem' or keyw == 'net.ipv4.tcp_wmem':
            sysctl[keyw] = words[2] + ' ' + words[3] + ' ' + words[4]
            i += 1
            continue
        if word3.isdigit():
            sysctl[keyw] = int(word3)
            i += 1

    # end: for line in sysctl_lines:

    hugepages_nr = sysctl["vm.nr_hugepages"]
    hugepage_size = get_hugepage_size()
    hugepages_mem = hugepages_nr * hugepage_size
    if (total_mem * kb) < hugepages_mem:
        anomaly_line = "The number of Huge pages allocated {0} ({1}) exceeds total memory {2}".format(hugepages_nr, mg_disp(hugepages_mem, 1), mg_disp(total_mem, kb))
        handle_anomaly_with_points("MEM", anomaly_line, 'configuration', 1)

    debug_print(4, "saved {0} sysctl settings".format(i))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, sysctl_file))
    return


# ---------------------------------------------#
# function: get_hugepage_size()
# return the size of a hugepage in bytes
# ---------------------------------------------#
def get_hugepage_size():
    global sysctl  # Key_data
    global total_mem
    global mb, kb

    hugepage_size = sysctl['meminfo.Hugepagesize']

    if hugepage_size == -1:
        return(2 * mb)  # nothing set or available, return normal default size

    if hugepage_size < mb:
        return(hugepage_size * kb)  # if size < 1mb, assume it was specified in proc/meminfo but without the 'kB' modifier

    return(hugepage_size)


# ---------------------------------------------#
# function: crunch_sys_directory()
# crunch selected subdirectories and files under sys/
# ---------------------------------------------#
def crunch_sys_directory():
    global fc_dev_loss_tmo  # ''

    if not dir_exists("sys"):
        return
    subdirs = "block bus class devices firmware fs kernel module"
    tmp = subdirs.split()
    for dir in tmp:

        if not dir_exists("sys/" + dir):
            continue

        if dir == "block":
            crunch_sys_block()
        elif dir == "bus":
            pass
        elif dir == "class":
            pass
        elif dir == "devices":
            pass
        elif dir == "firmware":
            pass
        elif dir == "fs":
            pass
        elif dir == "kernel":
            pass
        elif dir == "module":
            crunch_sys_module()
    # end: for dir in tmp:

    fc_dev_loss_tmo = readline1("sys/module/scsi_transport_fc/parameters/dev_loss_tmo")

    return

# ---------------------------------------------#
# function: crunch_sys_block()
# ---------------------------------------------#


def crunch_sys_block():
    global all_schedulers  # ''                 # unique list of all block/<device>/queue/scheduler's encountered

    path = "sys/block"

    # dirs = [ f for f in listdir(path) if isfile(join(path,f)) ]
    dirs = [f for f in listdir(path)]

    for dir_ in dirs:  # dir = device name; e.g.  sys/block/>sda</queue/scheduler

        crunch_sys_block_dev_queue_scheduler(dir_, "sys/block/" + dir_ + "/queue/scheduler")

        # crunch_sys_block_dev_queue_discard_max_bytes("sys/block/"+dir_+"/queue/discard_max_bytes") # not recorded in sos reports yet # see case

        # other files under <dev>/queue could be captured ...

    # done: for fn in files:

    return

# ---------------------------------------------#
# function: crunch_sys_block_dev_queue_scheduler()
# ---------------------------------------------#


def crunch_sys_block_dev_queue_scheduler(dir_, file_):
    global dev_2_scheduler  # Key_data()        # key: device id,           data: scheduler name    e.g. sda, cfq
    global all_schedulers  # ''                 # unique list of all block/<device>/queue/scheduler's encountered
    global scheduler_2_devs  # Key_data()        # key: scheduler name       data: devices found     e.g. cfq, sda sdb

    if not file_exists(file_):
        return

    scheduler_list = readline1(file_).strip()
    if scheduler_list == "none":
        return
    if scheduler_list == "[none]":
        return  # Ubuntu

    tmp = scheduler_list.split()
    for scheduler in tmp:
        if not re.match("\[(cfq|deadline|noop)\]", scheduler):
            continue
        scheduler = scheduler.strip("[]")
        break
    # end: for scheduler in tmp:

    all_schedulers = unique_list(all_schedulers, scheduler)
    dev_2_scheduler[dir_] = scheduler
    scheduler_2_devs[scheduler] = unique_list(scheduler_2_devs[scheduler], dir_)
    # debug_print(z,"{0}: {1}".format(dir_,scheduler))
    return

# ---------------------------------------------#
# function: crunch_sys_module()
# ---------------------------------------------#


def crunch_sys_module():
    global scsi_mod_parameters  # Key_data()    # key: parm name        data: parm value   e.g. max_luns, 1024
    global all_scsi_mod_parameters  # ''        # unique list of all module/scsi_mod/parameters found
    global fc_parameters  # Key_data()          # key: parm name        data: parm value   e.g. dev_loss_tmo, 60
    global lpfc_parameters  # Key_data()        # key: parm name        data: parm value   e.g. lpfc_use_msi, 0
    global all_fc_parameters  # ''              # unique list of all module/scsi_transport_fc/parameters found
    global all_lpfc_parameters  # ''            # unique list of all module/lpfc/parameters found

    path = "sys/module/scsi_mod/parameters"

    if dir_exists(path):
        files = [f for f in listdir(path) if isfile(join(path, f))]

        for fn in files:  # file = scsi parm; e.g.  sys/module/scsi_mod/parameters/max_luns

            parm_value = readline1(path + "/" + fn)
            if parm_value == "":
                continue
            # debug_print(z,"{0}: '{1}'".format(fn,parm_value))
            scsi_mod_parameters[fn] = parm_value
            all_scsi_mod_parameters = unique_list(all_scsi_mod_parameters, fn)

        # end: for fn in files:

    # end: if dir_exists(path):

    tmp = all_scsi_mod_parameters.split()
    for kw in tmp:
        debug_print(2, "scsi_mod_parameters[{0}]:{1}".format(kw, scsi_mod_parameters[kw]))
    # end: for kw in tmp:

    path = "sys/module/scsi_transport_fc/parameters"

    if dir_exists(path):
        files = [f for f in listdir(path) if isfile(join(path, f))]

        for fn in files:  # file = fc parm; e.g.  sys/module/scsi_transport_fc/parameters/dev_loss_tmo

            parm_value = readline1(path + "/" + fn)
            if parm_value == "":
                continue
            # debug_print(z,"{0}: '{1}'".format(fn,parm_value))
            fc_parameters[fn] = parm_value
            all_fc_parameters = unique_list(all_fc_parameters, fn)

        # end: for fn in files:

    # end: if dir_exists(path):

    tmp = all_fc_parameters.split()
    for kw in tmp:
        debug_print(2, "fc_parameters[{0}]:{1}".format(kw, fc_parameters[kw]))
    # end: for kw in tmp:

    path = "sys/module/lpfc/parameters"

    if dir_exists(path):
        files = [f for f in listdir(path) if isfile(join(path, f))]

        for fn in files:  # file = fc parm; e.g.  sys/module/scsi_transport_fc/parameters/dev_loss_tmo

            parm_value = readline1(path + "/" + fn)
            if parm_value == "":
                continue
            # debug_print(z,"{0}: '{1}'".format(fn,parm_value))
            lpfc_parameters[fn] = parm_value
            all_lpfc_parameters = unique_list(all_lpfc_parameters, fn)

        # end: for fn in files:

    # end: if dir_exists(path):

    tmp = all_lpfc_parameters.split()
    for kw in tmp:
        debug_print(2, "lpfc_parameters[{0}]:{1}".format(kw, lpfc_parameters[kw]))
    # end: for kw in tmp:

    return


# ---------------------------------------------#
# function: crunch_meminfo()
# ---------------------------------------------#
def crunch_meminfo():
    global meminfo_2_vm  # Key_data
    global sysctl  # Key_data
    global all_size_modifiers  # "b kb mb gb tb pb"
    global modifier_2_size  # Key_data_m1()

    if file_exists_with_data("meminfo"):
        file = "meminfo"
    else:
        file = "proc/meminfo"
    fh = openfile(file)
    if fh is None:
        return

    j = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        words = line.split()
        wc = len(words)

        if wc < 2:
            continue

        keyw = "meminfo." + words[0].rstrip(":")

        tmp_key = meminfo_2_vm[keyw]  # need to convert keywords names?
        if tmp_key != "":
            key = tmp_key
        mv = 1
        if wc == 3:
            multiplier = words[2].lower()  # if present, normally 'kB'
            if word_in_list(multiplier, all_size_modifiers):
                mv = modifier_2_size[multiplier]
            else:
                error_print('d', "'{0}' - {1} ({2})".format(line, i, file))

        word2 = words[1]
        if word2.isdigit():
            sysctl[keyw] = int(word2) * mv
            # debug_print(z,"sysctl[{0}]={1}".format(keyw,word2))
            j += 1

        # debug_print(z,"sysctl[{0}]={1}".format(keyw,word2))

    # end: for mil in meminfo_lines:

    debug_print(3, "saved {0} sysctl settings meminfo".format(j))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, file))
    return


# ---------------------------------------------#
# function: crunch_dmi_data()
# ---------------------------------------------#
def crunch_dmi_data():
    global dmi_cpu_data
    global dmi_sys_data

    dmi_file = "sos_commands/hardware/dmidecode"
    fh = openfile(dmi_file)
    if fh is None:
        return

    sys_info = False
    cpu_info = False
    proc_info = False
    proc_count = 0
    cpu_family = ''
    cpu_mfg = ''
    cpu_speed = ''
    sys_mfg = ''
    sys_name = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        line = line.strip()
        if line == "":
            continue

        if re.match("Handle 0x.*, DMI type [0-9]{1,3}, [0-9]{1,5} bytes", line):
            # reset all markers:
            sys_info = False
            cpu_info = False
            proc_info = False
            continue

        if line == "System Information":
            sys_info = True
        if sys_info:
            words = line.split()
            wc = len(words)
            if line.startswith("Manufacturer:") and wc > 1:
                sys_mfg = " "
                sys_mfg = sys_mfg.join(words[1:])
                sys_mfg = sys_mfg.strip()
            if line.startswith("Product Name:") and wc > 2:
                sys_name = " "
                sys_name = sys_name.join(words[2:])
                sys_name = sys_name.strip()

        if line == "Type: Central Processor":
            cpu_info = True
        if cpu_info:
            words = line.split()
            wc = len(words)
            if line.startswith("Family: "):
                if cpu_family == '' and not line.endswith("<OUT OF SPEC>"):
                    cpu_family = words[1]
            if line.startswith("Manufacturer: "):
                if cpu_mfg == '' and not line.endswith("Not Specified"):
                    cpu_mfg = words[1]
            if line.startswith("Max Speed: "):
                if cpu_speed == '' and not line.endswith("Unknown"):
                    cpu_speed = words[2] + words[3]
            if line.startswith("Current Speed: ") and "VMware" in sys_mfg:
                if not line.endswith("Unknown"):
                    cpu_speed = words[2] + words[3]
            if line.startswith("Handle "):
                cpu_info = False

        if line == "Processor Information":
            cpu_info = True
        if cpu_info:
            if line == "Type: Central Processor":
                proc_count += 1

    # normally cpu_count is set to higest cpu number (0 based) so sub 1 here as it is added back in display
    if proc_count:
        set_cpu_count((proc_count - 1), dmi_file)

    if cpu_family != '' and cpu_mfg != '':
        dmi_cpu_data = "{0}/{1} {2}".format(cpu_mfg, cpu_family, cpu_speed)
        debug_print(2, "cpu: {0}".format(dmi_cpu_data))

    if sys_name != '' or sys_mfg != '':
        dmi_sys_data = squeeze(sys_mfg + " " + sys_name)
        # dmi_sys_data = "{0} {1}".format(sys_mfg,sys_name)
        # dmi_sys_data = dmi_sys_data.strip()
        debug_print(3, "sys: {0}".format(dmi_sys_data))
        check_virtual_status(dmi_sys_data, dmi_file)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, dmi_file))
    return

# ---------------------------------------------#
# function: crunch_cmdline()
# usually 1 line:
# ro root=/dev/mapper/vg_system-lv_root pci=nomsi rd_NO_LUKS  KEYBOARDTYPE=pc KEYTABLE=us LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=145M@0M rd_LVM_LV=vg_system/lv_swap rd_LVM_LV=vg_system/lv_root pci=bfsort rd_NO_DM
#
# ---------------------------------------------#


def crunch_cmdline():
    global cmdline  # Key_data()
    global all_cmdline_keys  # ""

    cmdline_file = "proc/cmdline"
    fh = openfile(cmdline_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        crunch_cmdline_data(line, cmdline_file)

    # end: for line in cmdline_lines:

    words = all_cmdline_keys.split()
    for key in words:
        debug_print(4, "{0}={1}".format(key, cmdline[key]))
    # end: for key in words:

    # debug4:[crunch_cmdline.8832] rd_LVM_LV=vg_biqa/LogVol01 vg_biqa/LogVol00
    if cmdline["rd_LVM_LV"] != '':
        words = cmdline["rd_LVM_LV"].split()
        for vg_lv in words:
            tmp = vg_lv.split("/")
            vg_name = tmp[0]
            lv_name = tmp[1]
            vg_name = update_vg(vg_name, '', cmdline_file)
            update_lv(vg_name, lv_name, '', '', '', cmdline_file)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, cmdline_file))
    return

# ---------------------------------------------#
# function: crunch_cmdline_data()
# ---------------------------------------------#


def crunch_cmdline_data(line, source):

    if line == "" or line.startswith("#"):
        return
    # if "=" not in line: return
    tcmdline = Key_data()
    tmpkeys = ''

    words = line.split()
    for word in words:

        if '=' in word:
            tmp = word.split("=")
            twc = len(tmp)
            key = tmp[0]
            data = tmp[1].strip('"')
            if tcmdline[key] == '':
                tcmdline[key] = data
            else:
                tcmdline[key] = tcmdline[key] + ' ' + data
        # end: if '=' in word:
        else:
            key = word
            data = '<keyword>'
            tcmdline[key] = data

        tmpkeys = unique_list(tmpkeys, key)

    # end: for word in words:

    words = tmpkeys.split()
    for key in words:
        debug_print(3, "tcmdline[{0}] = {1} ({2})".format(key, tcmdline[key], source))
        check_cmdline_element(key, tcmdline[key], source)
    return


# ---------------------------------------------#
# function: check_cmdline_element()
# check (and set if appropriate) a cmdline value
# ---------------------------------------------#
def check_cmdline_element(key, new_value, source):
    global cmdline  # Key_data()
    global all_cmdline_keys  # ""

    if new_value == '':
        return
    if new_value == cmdline[key]:
        return
    if cmdline[key] == '':
        cmdline[key] = new_value
        cmdline_origin[key] = source
        all_cmdline_keys = unique_list(all_cmdline_keys, key)
        return

    if key == "crashkernel" and new_value == "auto":
        return  # allow this difference
    # seen frequently, e.g.: [1] cmdline value [crashkernel] already seen as 130M@0M (proc/cmdline), attempting to set to auto (var/log/dmesg)

    anomaly_line = "cmdline value [{0}] already seen as {1} ({2}), attempting to set to {3} ({4})".\
                   format(key, cmdline[key], cmdline_origin[key], new_value, source)
    handle_anomaly("CMDLINE", anomaly_line)
    return

# ---------------------------------------------#
# function: crunch_oracleasm()
# ---------------------------------------------#


def crunch_oracleasm():
    global OracleASM  # Key_data()
    global all_OracleASM_keys  # ""

    ora_file = "etc/sysconfig/oracleasm"
    fh = openfile(ora_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n
        i += 1
        if line == "" or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        words = line.split("=")
        wc = len(words)
        key = words[0]
        data = words[1].strip('"')
        OracleASM[key] = data
        all_OracleASM_keys = unique_list(all_OracleASM_keys, key)

    words = all_OracleASM_keys.split()
    for key in words:
        debug_print(4, "{0}={1}".format(key, OracleASM[key]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, ora_file))
    return

# ---------------------------------------------#
# function: crunch_grub()
# ---------------------------------------------#


def crunch_grub():
    global grub  # Key_data()
    global all_grub_keys  # ""

    grub_file = "etc/default/grub"
    fh = openfile(grub_file)
    if fh is None:
        return

    i = 0
    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        words = line.split("=")
        wc = len(words)
        key = words[0]
        data = ''
        if wc > 1:
            data = words[1]
        if data.startswith('"'):
            beg = line.find('"')
            end = line.rfind('"')
            data = line[beg:end + 1]
        if data.startswith("'"):
            beg = line.find("'")
            end = line.rfind("'")
            data = line[beg:end + 1]
        grub[key] = data
        all_grub_keys = unique_list(all_grub_keys, key)

    words = all_grub_keys.split()
    for key in words:
        debug_print(3, "{0}={1}".format(key, grub[key]))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, grub_file))
    return

# ---------------------------------------------#
# function: crunch_lsof()
# check open file listing for anything noteworthy
# ---------------------------------------------#


def crunch_lsof():

    lsof_file = "sos_commands/filesys/lsof_-b_M_-n_-l"
    if not file_exists_with_data(lsof_file):
        lsof_file = "lsof"
    fh = openfile(lsof_file)
    if fh is None:
        return

    deleted_files_cnt = 0
    deleted_files_size = 0
    found_start = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        # COMMAND      PID     USER   FD      TYPE             DEVICE   SIZE/OFF                 NODE NAME
        # COMMAND     PID   TID     USER   FD      TYPE             DEVICE SIZE/OFF       NODE NAME
        if line.startswith("COMMAND"):
            found_start = True
            continue

        debug_print(4, "{0} '{1}'".format(i, line))
        # cssdmonit  12421        0    4w      REG                0,3          0           4026531864 /proc/sysrq-trigger
        # cssdagent  12438        0    4w      REG                0,3          0           4026531864 /proc/sysrq-trigger
        # -- (with tid \|/
        # systemd       1              0    6r      DIR               0,23        0          1 /sys/fs/cgroup/systemd

        if not found_start:
            continue

        words = line.split()
        wc = len(words)
        if wc < 6:
            # debug_print(z,"{0}: '{1}'".format(i,line))
            continue

        proc_name = words[0]
        proc_id = words[1]
        of = words[wc - 1]  # last word unless status is '(deleted)'
        word_size = ''

        if words[wc - 1] == "(deleted)":
            of = words[wc - 2]
            word_size = words[wc - 3]
            if word_size.isdigit():
                deleted_files_cnt += 1
                deleted_files_size += int(word_size)

        if of == "/proc/sysrq-trigger":
            if proc_name.startswith("cssd"):
                anomaly_line = "Process {0}[{1}] has {2} open, {3}".\
                               format(proc_name, proc_id, of, cfa_sfdc("01653112"))
                handle_anomaly("ORACLE", anomaly_line)
            else:
                anomaly_line = "Process {0}[{1}] has {2} open".format(proc_name, proc_id, of)
                handle_anomaly("NOTE", anomaly_line)
    # end: for line in lsof_lines:

    if deleted_files_cnt > 99 or deleted_files_size > gb:
        anomaly_line = "Found {0} deleted files occupying {1} ({2})".\
                       format(deleted_files_cnt, mg_disp(deleted_files_size, 1), lsof_file)
        handle_anomaly("FS", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lsof_file))
    return


# ---------------------------------------------#
# function crunch_system_startup()
# ---------------------------------------------#
def crunch_system_startup():
    global rh_major
    global kernelNum

    if rh_major >= 7 or kernelNum['major'] >= 3:
        crunch_systemctl("run_level")
        crunch_systemctl("services")
    else:
        crunch_inittab()
        crunch_chkconfig()

    return

# ---------------------------------------------#
# function: crunch_systemctl()
# ---------------------------------------------#


def crunch_systemctl(reason):

    systemctl_files = ""\
        "sos_commands/systemd/systemctl_list-units_--all "\
        "sos_commands/systemd/systemctl_list-units "\
        ""

    files_processed = 0
    tmp = systemctl_files.split()
    for systemctl_file in tmp:
        if systemctl_file == '':
            continue

        if file_exists_with_data(systemctl_file) and files_processed == 0:
            files_processed += 1
            if reason == "run_level":
                crunch_systemctl_run_level(systemctl_file)
            elif reason == "services":
                crunch_systemctl_services(systemctl_file)

    # end: for systemctl_file in tmp:

    if files_processed == 0 and reason == "run_level":
        run_level = 3  # assume 3
        error_print("f", "No files found to process in sos_command/systemd/systemctl/, assuming run level 3")

    return


# ---------------------------------------------#
# function: crunch_systemctl_run_level()
# currently just looking for 'multi-user.target' and 'graphical.targe'
#
# rhel 7 only.
# ---------------------------------------------#
def crunch_systemctl_run_level(systemctl_file):
    global run_level
    fh = openfile(systemctl_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)
        if wc < 4:
            continue

        load = words[1]
        active = words[2]
        sub = words[3]

        if words[0] == "emergency.target":
            if load == "loaded" and active == "active":
                run_level = max(run_level, 1)

        if words[0] == "rescue.target":
            if load == "loaded" and active == "active":
                run_level = max(run_level, 1)

        # if words[0] == "basic.target": # from centos: "Basic System" ?? useful?
            # if load == "loaded" and active == "active": run_level = max(run_level,1)

        # if words[0] == "sysinit.target": # from centos: "System Initialization" useful?
            # if load == "loaded" and active == "active": run_level = max(run_level,1)

        # TODO: investigate mor                              e
        # saw this in centos file: (case )
        # egrep 'emergency.target|rescue.target|multi-user.target|graphical.target' sos_commands/systemd/systemctl_list-units_--all
        # emergency.target                                             loaded    inactive dead      Emergency Mode
        # graphical.target                                             loaded    inactive dead      Graphical Interface
        # multi-user.target                                            loaded    inactive dead      Multi-User System
        # rescue.target                                                loaded    inactive dead      Rescue Mode
        #
        # yields: @error[d]:[crunch_systemctl_run_level.22852] unable to find run level target in sos_commands/systemd/systemctl_list-units_--all, assuming 3

        if words[0] == "multi-user.target":
            if load == "loaded" and active == "active":
                run_level = max(run_level, 3)

        if words[0] == "graphical.target":
            if load == "loaded" and active == "active":
                run_level = max(run_level, 5)

    # end: for line in systemtcl_lines:

    if run_level == -1:
        run_level = 3  # assume 3
        error_print("d", "unable to find run level target in {0}, assuming 3".format(systemctl_file))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, systemctl_file))
    return

# ---------------------------------------------#
# function: crunch_systemctl_services()
# rhel 7 only.
#
# * multipathd.service                                                                                                     loaded    failed   failed    Device-Mapper Multipath Device Controller
# * netconsole.service                                                                                                     loaded    failed   failed    SYSV: Initializes network console logging
# network.service                                                                                                        loaded    active   exited    LSB: Bring up/down networking
#
# ---------------------------------------------#


def crunch_systemctl_services(systemctl_file):
    global config_service  # Key_data() # "on/off/''"
    global service_procs  # Counter()
    global services_count  # 0
    global all_services
    global run_level
    fh = openfile(systemctl_file)
    if fh is None:
        return

    services = all_services.split()
    srvc_rl_on = "{0}:on".format(run_level)
    srvc_rl_off = "{0}:off".format(run_level)
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)
        if wc < 4:
            continue

        if words[0] == "*":
            offset = 1
        else:
            offset = 0
        service = words[0 + offset]
        load = words[1 + offset]
        active = words[2 + offset]
        sub = words[3 + offset]

        if service.endswith(".service"):
            service = service.rstrip(".service")
            services_count += 1
            if word_in_list(service, all_services):  # use run_level+1 as service names takes slot 0
                if load == "loaded":
                    if active == "active":
                        config_service[service] = "on"
                    elif active == "inactive":
                        config_service[service] = "inactive"
                    elif active == "failed":
                        config_service[service] = "on-failed"
                    else:
                        config_service[service] = "on?-" + active
                else:
                    config_service[service] = "off"

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, systemctl_file))
    return

# ---------------------------------------------#
# function: crunch_inittab()
# currently just looking for id:<run_level>:initdefault
#
# under rhel 7, inittab is obsolete.
# replaced by systemd; multi-user.target and graphical.target
# ---------------------------------------------#


def crunch_inittab():
    global run_level
    inittab_file = "etc/inittab"
    if not file_exists_with_data(inittab_file):
        run_level = 3  # assume 3
        error_print("f", "{0}: No such file, assuming run level 3".format(inittab_file))
        return
    fh = openfile(inittab_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if line == "" or line.startswith("#"):
            continue

        if re.match("id:[0-6]:initdefault:", line):
            tmp = line.split(":")
            run_level = int(tmp[1])

    if run_level == -1:
        run_level = 3  # assume 3
        error_print("d", "unable to find run level in {0}, assuming 3".format(inittab_file))

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, inittab_file))
    return

# ---------------------------------------------#
# function: crunch_chkconfig()
# service_name     0:on/off 1:on/off 2:on/off 3:on/off 4:on/off 5:on/off 6:on/off
#
# run levels:     mode                            action
# 0 -         halt                            halts the system
# 1 -         single user mode                single user mode for special admin work
# 2 -         local multiuser                 local mulituser, network interfaces not configed and no network services
# 3 -         multiuser w/networking          starts the system normally
# 4 -         undefined                       not used
# 5 -         X11                             run level 3 + display manager
# 6 -         reboot                          reboots the system
# ---------------------------------------------#


def crunch_chkconfig():
    global config_service  # Key_data() # "on/off/''"
    global service_procs  # Counter()
    global services_count  # 0
    global all_services
    global run_level

    config_file = "sos_commands/startup/chkconfig_--list"
    if not file_exists_with_data(config_file):
        config_file = "chkconfig"
    fh = openfile(config_file)
    if fh is None:
        return

    services = all_services.split()
    srvc_rl_on = "{0}:on {1}:activo {2}:marche {3}:sim {4}:ÆôÓÃ {5}:Ein {6}:활성{7}:启用".\
        format(run_level, run_level, run_level, run_level, run_level, run_level, run_level, run_level)
    srvc_rl_off = "{0}:off {1}:desactivado {2}:arrêt {3}:não {4}:¹Ø±Õ {5}:Aus {6}:해제 {7}:关闭".\
                  format(run_level, run_level, run_level, run_level, run_level, run_level, run_level, run_level)

    flush = False
    xinetd_count = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#") or line.startswith("/sbin/chkconfig") or flush:
            continue

        if "xinetd" in line:
            xinetd_count += 1

        if line == "xinetd based services:" or \
           line == "servizi basati su xinetd:" or \
           line == "servicios basados en xinetd:" or \
           line == "»ùÓÚ xinetd µÄ·þÎñ£º" or \
           line == "services basés sur xinetd :" or \
           line == "servidos baseados no xinetd:" or \
           line == "»ùÓÚ xinetd µÄ·þÎñ£º" or \
           line == "xinetd-basierende Dienste:" or \
           xinetd_count == 2:
            flush = True  # until such time as we need any xinetd service info
            continue

        words = line.split()
        wc = len(words)
        service = words[0]
        services_count += 1

        if (run_level + 1) > wc:
            error_print("d", line)
            continue

        if word_in_list(service, all_services):  # use run_level+1 as service names takes slot 0
            if words[run_level + 1] in srvc_rl_on:
                config_service[service] = "on"
            elif words[run_level + 1] in srvc_rl_off:
                config_service[service] = "off"
            else:
                error_print("d", line)
                config_service[service] = "?"

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, config_file))
    return


# ---------------------------------------------#
# function: check_services()
# ---------------------------------------------#
def check_services():
    global service_procs  # Counter()
    global all_services
    global run_level
    global sysctl
    global mp_services  # "RedHat,multipathd "
    global filescanner_services  # "Trend_Micro,ds_agent "
    # global fs_netdev_opt_cnt      # 0           # number of times '_netdev' fs option seen
    global total_iscsi_luns

    services_that_should_be_on = "multipathd kdump"  # normally..'should' might be too strong
    #
    # This is moot since netfs itself is just a script (not a daemon) that runs init & shutdown time
    # if fs_netdev_opt_cnt > 0:
    # services_that_should_be_on = services_that_should_be_on+" netfs"
    services = services_that_should_be_on.split()
    for service in services:
        service_anom(service, "Red Hat", False)
    # end: for service in services:

    services_that_should_be_off = ""
    services = services_that_should_be_off.split()
    for service in services:
        service_anom(service, "Red Hat", False)
    # end: for service in services:

    tmp_mp_1 = mp_services.split()
    for mp_service_pair in tmp_mp_1:
        tmp_mp_2 = mp_service_pair.split(",")
        vendor = tmp_mp_2[0]
        service = tmp_mp_2[1]
        if service == "multipathd":
            continue  # handled above in 'services_that_should_be_on'

        # print a line for any other mp service that is configured on and/or running
        service_anom(service, vendor, True)

    # end: for mp_service_pair in tmp_mp_1:

    fscan_proc_count = 0
    fscan_anom_count = 0
    fscan_anom_list = ''

    tmp_fscan_1 = filescanner_services.split()
    for fs_service_pair in tmp_fscan_1:
        tmp_fscan_2 = fs_service_pair.split(",")
        service = tmp_fscan_2[1]
        fscan_proc_count += service_procs[service]
    # end: for fs_service_pair in tmp_fscan_1:

    for i in range(1, 10):
        fscan_id = "ID:susceptible_to_filescanners_{0}".format(i)
        scan_block = get_scan_block(fscan_id)
        if scan_block != '':
            fscan_anom_count += scan_count[scan_block]
            tmp3 = scan_block.split("~")
            for se in tmp3:
                if se.startswith("ANOM:"):
                    tmp4 = se.split(":")
                    anom_id = tmp4[1]
                    fscan_anom_list = unique_list(fscan_anom_list, anom_id)
            # end: for se in tmp3:
    # end: for i in range(1,10):

    if fscan_proc_count and fscan_anom_count:
        for fs_service_pair in tmp_fscan_1:
            tmp_fscan_2 = fs_service_pair.split(",")
            vendor = tmp_fscan_2[0]
            service = tmp_fscan_2[1]
            proc_count = service_procs[service]
            if proc_count:
                blurb = "potentially the cause of {0} anomalies [{1}], {2}".\
                        format(fscan_anom_count, fscan_anom_list, cfa_sfdc("01824451"))
                anomaly_line = "found {0} instances of file scanning service {1} from {2} running, {3}".\
                               format(proc_count, service, vendor, blurb)
                handle_anomaly("SERVICE", anomaly_line)
        # end: for fs_service_pair in tmp_fscan_1:
    # end: if fs_proc_count and fs_anom_count:

    # describe what the kdump config is
    panic_list = ""\
                 "kernel.panic:panic~"\
                 "kernel.panic_on_oops:oops~"\
                 "kernel.softlockup_panic:softlockup~"\
                 "kernel.unknown_nmi_panic:unknown nmi~"\
                 "kernel.panic_on_unrecovered_nmi:unrecoverd nmi~"\
                 "kernel.panic_on_io_nmi:io nmi~"\
                 "kernel.hung_task_panic:hung task~"\
                 "kernel.panic_on_warn:warn~"\
                 "vm.panic_on_oom:out of memory~"\
                 ""

    tmp1 = panic_list.split("~")
    panic_reasons = ''
    for panic_pair in tmp1:
        if panic_pair == '':
            continue
        tmp2 = panic_pair.split(":")
        kw = tmp2[0]
        desc = tmp2[1]
        if sysctl[kw] == 1:
            panic_reasons = csp(panic_reasons, desc)
    # end: for panic_pair in tmp1:

    words = panic_reasons.split(',')
    wc = len(words)
    kdump_status = service_status('kdump')
    anomaly_line = "kdump configured {0}, enabled dump trigger{1}: {2}, {3} & {4}".format(kdump_status, plural(wc), panic_reasons, info_kcs("23069"), kcs_url("382913"))
    handle_anomaly("KDUMP", anomaly_line)

    # check for hald
    if service_procs["hald"] > 0:

        udev_anom_count = 0
        for i in range(1, 10):
            fscan_id = "ID:udev-{0}".format(i)
            scan_block = get_scan_block(fscan_id)
            if scan_block != '':
                udev_anom_count += scan_count[scan_block]
        # end: for i in range(1,10):

        if udev_anom_count > 0:
            anomaly_line = "hald is running and {0} udev anomalies have been seen, can be interfering, see {1}".\
                           format(udev_anom_count, kcs_url("206493"))
            handle_anomaly("SERVICE", anomaly_line)

        blurb = ''
        if run_level <= 3:
            blurb = ", especially at run level {0}".format(run_level)
        anomaly_line = "hald is running, but generally, on a server, it is not needed{0}, see {1}".\
                       format(blurb, kcs_url("16609"))
        handle_anomaly("SERVICE", anomaly_line)
    # end: if service_procs["hald"] > 0:

    if total_iscsi_luns > 0:
        if service_procs["iscsid"] == 0:
            anomaly_line = "found {0} iscsi lun{1} but no instances of iscsid are running".\
                           format(total_iscsi_luns, plural(total_iscsi_luns))
            handle_anomaly("SERVICE", anomaly_line)

        if service_status("iscsid") != "on":
            anomaly_line = "found {0} iscsi lun{1} but iscsid has service status of {2}".\
                           format(total_iscsi_luns, plural(total_iscsi_luns), service_status("iscsid"))
            handle_anomaly("SERVICE", anomaly_line)

    # end: if total_iscsi_luns > 0:

    return


# ---------------------------------------------#
# function: service_status()
# return the status of a service with some additional code wrapped around it for display purposes.
# ---------------------------------------------#
def service_status(service_name):
    global config_service  # Key_data() # "on/off/''"
    global services_count  # 0

    if services_count == 0:
        service_status = "(unavailable)"
    else:
        service_status = config_service[service_name]
        if service_status == "":
            service_status = "<unknown>"

    debug_print(3, "service_status[{0}] = {1}".format(service_name, service_status))
    return(service_status)


# ---------------------------------------------#
# function: service_anom()
# conditionaly display status of service
# ---------------------------------------------#
def service_anom(service_name, vendor, optional):
    global service_procs  # Counter()
    global run_level

    sp_count = service_procs[service_name]
    sp_status = service_status(service_name)
    blurb = ''

    if optional:
        if sp_count == 0 and sp_status != "on":
            return

    and_or_but = "and"
    if sp_count > 0 and sp_status == "off":
        and_or_but = "but"
    if sp_count == 0 and sp_status == "on":
        and_or_but = "but"

    if service_name != "kdump":     # kdump has a service but no running processes..
        if sp_count:
            blurb = and_or_but + " {0} running instance{1} found".format(sp_count, plural(sp_count))
        else:
            blurb = and_or_but + " is not running"

    anomaly_line = "service {0} from {1}, at run level {2}, is configured '{3}' {4}".\
        format(service_name, vendor, run_level, sp_status, blurb)
    handle_anomaly("SERVICE", anomaly_line)


# ---------------------------------------------#
# function: crunch_modprobe_conf()
# ---------------------------------------------#
def crunch_modprobe_conf():

    modprobe_conf_files = "etc/modprobe.conf "\
                          "sos_commands/kernel/modprobe.conf"

    tmp = modprobe_conf_files.split()
    for modprobe_conf_file in tmp:
        crunch_modprobe_conf_file(modprobe_conf_file)

    return

# ---------------------------------------------#
# function: crunch_modprobe_conf_file()
# ---------------------------------------------#


def crunch_modprobe_conf_file(modprobe_conf_file):
    global all_modprobe_alias_entries  # ''
    global modprobe_alias_data  # Key_data()     # key: alias name          data: alias data e.g.: scsi_adapter cciss
    # e.g.: eth0 bnx2x
    fh = openfile(modprobe_conf_file)
    if fh is None:
        return

    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)
        if words[0] == "alias":
            alias_entry = words[1]
            all_modprobe_alias_entries = unique_list(all_modprobe_alias_entries, alias_entry)
            alias_data = words[2]
            modprobe_alias_data[alias_entry] = unique_list(modprobe_alias_data[alias_entry], alias_data)

    # end: for line in probe_lines:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, modprobe_conf_file))
    return

# ---------------------------------------------#
# function: crunch_lsmod()
# ---------------------------------------------#


def crunch_lsmod():
    global all_lsmods  # ''
    global lsmod_data  # Key_data()     # key: module name          data: size & used by data e.g. lockd  73662 nfs
    lsmod_file = "sos_commands/kernel/lsmod"
    if not file_exists_with_data(lsmod_file):
        lsmod_file = "lsmod"
    fh = openfile(lsmod_file)
    if fh is None:
        return

    hdr_found = False
    scsi_dh_mods = ''
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        words = line.split()
        wc = len(words)
        if wc == 4 and (words[0] == "Module" and words[1] == "Size"):
            hdr_found = True
            continue

        if not hdr_found:
            continue
        mod_name = words[0]
        if re.match("scsi_dh_.*", mod_name):
            scsi_dh_mods = unique_list(scsi_dh_mods, mod_name)
        mod_data = ' '
        mod_data = mod_data.join(words[1:])  # data is size and optional "Used by" data.
        all_lsmods = unique_list(all_lsmods, mod_name)
        lsmod_data[mod_name] = mod_data

    # end: for line in lsmod_lines:

    words = scsi_dh_mods.split()
    wc = len(words)
    if wc > 1:
        anomaly_line = "Found {0} scsi_dh_.* handler modules: [{1}]. see SFDC {2} ({3})".format(wc, scsi_dh_mods, "12345678", lsmod_file)
        handle_anomaly_with_points("SFDC", anomaly_line, 'configuration', 1)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lsmod_file))
    return


# ---------------------------------------------#
# function: check_lsmod_info()
# "kernel: device-mapper: multipath: Could not failover the device: Handler <handler_name> Error nn"
# ---------------------------------------------#
def check_lsmod_info(line, words, source):
    global all_lsmods  # ''
    global lsmod_data  # Key_data()     # key: module name          data: size & used by data e.g. lockd  73662 nfs
    mod_name = words[9]
    if not word_in_list(mod_name, all_lsmods):
        anomaly_line = "module {0} not loaded, see MULTIPATH, {1} ({2})".\
                       format(mod_name, cfa_sfdc("01074319"), source)
        handle_anomaly_with_points("MULTIPATH", anomaly_line, 'configuration', 10)

    return


# ---------------------------------------------#
# function: crunch_modinfo_info()
# ---------------------------------------------#
def crunch_modinfo_info():

    crunch_modinfo_directory("./sos_commands/kernel/")
    return

# ---------------------------------------------#
# function: crunch_modinfo_directory()
# ---------------------------------------------#


def crunch_modinfo_directory(path):

    if stat_dir(path, '', 0) is None:
        return

    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:
        if not fn.startswith("modinfo_"):
            continue
        crunch_modinfo_file(path + fn)

    return

# ---------------------------------------------#
# function: crunch_modinfo_file()
#
# filename:       /lib/modules/3.10.0-514.16.1.el7.x86_64/weak-updates/hpdsa/hpdsa.ko
# ---------------------------------------------#


def crunch_modinfo_file(fn):
    global all_lsmods  # ''
    global lsmod_data  # Key_data()      # key: module name          data: size & used by data e.g. lockd  73662 nfs
    global lsmod_version  # Key_data()   # key: module name          data: mod version   e.g. 3.10.0-514.6.1.el7
    global event_count  # Counter()      # key: event type           data: event count         e.g. lpfc 12

    fh = openfile(fn)
    if fh is None:
        return

    event_kmod_list = ""\
                      "fnic.ko "\
                      "hpdsa.ko "\
                      "hpsa.ko "\
                      "lpfc.ko "\
                      "cciss.ko "\
                      ""
    e_k_words = event_kmod_list.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        # filename:       /lib/modules/3.10.0-514.16.1.el7.x86_64modinfo: ERROR: Module workqueue not found.
        if "ERROR:" in line:
            continue
        words = line.split()
        wc = len(words)

        if not line.startswith("filename: "):
            continue

        path = words[1]
        tpwds = path.split("/")
        tpwc = len(tpwds)
        kmod_fn = tpwds[tpwc - 1]  # last portion of path xxx.ko
        kmod_fn = kmod_fn.replace(".ko", "")  # minus .ko
        all_lsmods = unique_list(all_lsmods, kmod_fn)

        if path.startswith("/lib/modules/"):
            #
            # 0/  1/      2/                        3/           4/    5/       6
            # /lib/modules/3.10.0-514.6.1.el7.x86_64/weak-updates/hpdsa/hpdsa.ko
            version = tpwds[3]
            # version = normalize_rpm_version(version)
            lsmod_version[kmod_fn] = version  # keep the version that may need to be displayed
            debug_print(3, "lsmod_version[{0}] = {1}".format(kmod_fn, version))
        # end: if path.startswith("/lib/modules/":

        # The ”weak-updates” reference to ”weak” relates to the fact that driver updates are ”weakly”
        # coupled to the kernel they load against, as opposed to the drivers and other modules that
        # came shipped with the kernel, which by default take precedence as a matter of system policy.
        #
        # Driver Updates are always installed into a (specified at build time) subdirectory of the system
        # ”extra” directory provided by the exact kernel they were built against.
        #
        # see: http://people.redhat.com/jcm/el6/dup/docs/dup_book.pdf
        #
        if "/weak-updates/" in line:
            # weak_path = words[1]
            # tpwds = weak_path.split('/')
            # tpwc  = len(tpwds)
            # weak_fn = tpwds[tpwc-1] # last portion of path xxx.ko
            # weak_fn = weak_fn.replace(".ko","") # minus .ko
            blurb = ''
            # weak_fn = weak_fn.replace("-","_") # otherwise anything w/a '-' comes up "NOT running"
            if lsmod_data[kmod_fn] == '':
                blurb = "NOT "
            anomaly_line = "Probable 3rd party module {0}running '{1}' found ({2})".format(blurb, words[1], fn)
            handle_anomaly("THIRDPARTY", anomaly_line)
            if blurb == '':
                for e_k in e_k_words:
                    ec = event_count[kmod_fn]
                    if path.endswith(e_k) and ec:
                        anomaly_line = "3rd party module {0}.ko runnning and {1} related event{2} occurred".\
                                       format(kmod_fn, ec, plural(ec))
                        handle_anomaly("THIRDPARTY", anomaly_line)
                        # could add kcs 42843: "Does RH support modified kernels or 3rd party pkgs?"
            continue

        # TODO: Hilight if there are lpfc events found and non-inbox lpfc driver in use KCS 24756 (switch to RHEL supplied driver)
        # TODO: Hilight if there are fnic events found and non-inbox fnic driver in use KCS 24756 (switch to RHEL supplied driver)
        # TODO: Hilight if there are cciss io errors found and non-inbox cciss driver in use

    check_kern_min_versions(fn)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, fn))
    return

# ---------------------------------------------#
# function: check_kern_min_versions()
# ---------------------------------------------#


def check_kern_min_versions(source):
    global rh_major
    global all_lsmods  # ''
    global lsmod_version  # Key_data()   # key: module name          data: mod version   e.g. 3.10.0-514.6.1.el7
    global kmod_pkg_min  # Key_data()           # key: rhel_maj_+"_"+kmod fn    data: min recomended version
    global kmod_pkg_min_kcs  # Key_data()       # key: rhel_maj_+"_"+kmod fn    data: kcs/sfdc reference

    words = all_lsmods.split()
    for kmod in words:
        key = "{0}_{1}".format(rh_major, kmod)
        if kmod_pkg_min[key] != '':
            if normalize_rpm_version(lsmod_version[kmod]) < normalize_rpm_version(kmod_pkg_min[key]):
                blurb = ''
                tmp = kmod_pkg_min_kcs[key].split()
                for kcs in tmp:
                    if len(kcs) == 8 and kcs[0] == '0':
                        url = sfdc_url(kcs)
                    else:
                        url = kcs_url(kcs)
                    blurb = blurb + " " + url
                # end: for kcs in tmp:
                if blurb != '':
                    blurb = squeeze(cfa_text + " " + blurb)
                anomaly_line = "kmod {0} is at version {1} which is below the recommended level of {2}, {3} ({4})".\
                               format(kmod, lsmod_version[kmod], kmod_pkg_min[key], blurb, source)
                handle_anomaly("RPM", anomaly_line)
    # end: for kmod in words:

    return

# ---------------------------------------------#
# function: crunch_rpm_info()
# ---------------------------------------------#


def crunch_rpm_info():

    # installed-rpms should generally work as it is symlinked to one of the flavors in sos_commands/rpm/rpm_...
    rpm_files = ""\
                "installed-rpms "\
                "rpm-qa "\
                "rpm-Va "\
                "sos_commands/rpm/rpm_-Va "\
                "sos_commands/rpm/rpm_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_.b "\
                "sos_commands/rpm/rpm_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_-- "\
                "sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_INSTALLTIME_VENDOR_BUILDHOST_SIGPGP_SIGPGP_pgpsig_awk_-F_printf_-59s_s_n_1_2_sort "\
                "sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_awk_-F_printf_-59s_s_n_1_2_sort_-f "\
                ""

    fns = rpm_files.split()
    for fn in fns:
        if file_exists_with_data(fn):
            crunch_rpm_file(fn)
            break

    return

# ---------------------------------------------#
# function: crunch_rpm_file()
# ---------------------------------------------#


def crunch_rpm_file(rpm_file):
    global rpm_pkg  # Key_data()
    global rpm_pkg_source  # Key_data()
    global OracleLinux_lines

    global rpm_dm_mp  # "device-mapper-multipath"
    global rpm_mp_pkgs  # rpm_dm_mp+" EMCpower.LINUX VRTSaslapm"
    global rpm_pkgs  # rpm_mp_pkgs+" iscsi-initiator-utils EMCpower.LINUX"

    global rpm_pkg_min  # Key_data()            # key: pkg name             data: minimum recommendd pkg version
    global rpm_pkg_min_kcs  # Key_data()        # key: pkg name             data: kcs article referencing min pkg version

    global rpm_words  # "ksym kmod multipath udev" # words we care about
    global rh_major  # 0

    fh = openfile(rpm_file)
    if fh is None:
        return

    rpws = rpm_words.split()
    rpkgs = rpm_pkgs.split()
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        # line = line.lstrip(' ')
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue
        words = line.split()
        wc = len(words)

        if line.startswith("oraclelinux-"):
            # (short): oraclelinux-release-5-8.0.2.i386                            Tue 27 Mar 2012 08:52:11 AM CDT (short)
            # (long):  oraclelinux-release-6Server-7.0.6.x86_64                    Tue Apr 19 03:31:27 2016  1461036687  Oracle America  x86-ol6-builder-06.us.oracle.com    8901....
            oline = ' '
            if wc > 8:
                oline = oline.join(words[0:6])
            else:
                oline = oline.join(words[0:10])
            oline = "{0} ({1})".format(oline, rpm_file)
            OracleLinux_lines = OracleLinux_lines + "\n" + oline

        if "Unsatisfied dependencies" in line:
            for rpm_word in rpws:
                if rpm_word in line:
                    anomaly_line = "'{0}' found in ({1})".format(line, rpm_file)
                    handle_anomaly("RPM", anomaly_line)
                    break
            continue

        fpkg = ''
        fversion = ''
        pkg_and_version = crunch_rpm_pkg_name_version(words[0])
        if pkg_and_version != '':
            tmp = pkg_and_version.split()
            twc = len(tmp)
            fpkg = tmp[0]
            if twc == 2:
                fversion = tmp[1]

        for pkg in rpkgs:
            if pkg == fpkg:  # is this a pkg that is being tracked? if so save its version
                rpm_pkg[pkg] = fversion
                rpm_pkg_source[pkg] = rpm_file
                continue
        # end: for pkg in rpkgs:

        rhel_fpkg = "{0}_{1}".format(rh_major, fpkg)
        if rpm_pkg_min[rhel_fpkg] != '':
            debug_print(3, "{0} {1}".format(pkg, rpm_pkg_min[rhel_fpkg]))
            if normalize_rpm_version(rpm_pkg[fpkg]) < normalize_rpm_version(rpm_pkg_min[rhel_fpkg]):
                if rpm_pkg_min_kcs[rhel_fpkg] == '':
                    kcs_blurb = ''
                else:
                    kcs_blurb = info_kcs(rpm_pkg_min_kcs[rhel_fpkg])
                anomaly_line = "RPM package '{0}' is at version {1} which is below the recommended level of {2}, {3} ({4})".\
                               format(fpkg, rpm_pkg[fpkg], rpm_pkg_min[rhel_fpkg], kcs_blurb, rpm_file)
                handle_anomaly("RPM", anomaly_line)
        # end: if rpm_pkg_min[rhel_fpkg] != '':

    # end: for line in rpm_lines:

    if rpm_pkg[rpm_dm_mp] != '' and rpm_pkg_source[rpm_dm_mp] == rpm_file:
        words = rpm_mp_pkgs.split()
        for pkg in words:
            if pkg == rpm_dm_mp:
                continue
            if rpm_pkg[pkg] != '':
                anomaly_line = "Both {0} and {1} appear to be installed, but only one should be run, see KCS {2} ({3})".\
                    format(rpm_dm_mp, pkg, kcs_url("358783"), rpm_file)
                handle_anomaly("RPM", anomaly_line)
        # end: for pkg in words:

    if rpm_pkg['lvm2'] != '' and rpm_pkg['lvm2-cluster'] != '':
        if rpm_pkg['lvm2'] == rpm_pkg['lvm2-cluster']:
            blurb = ''  # all is well
        elif rpm_pkg['lvm2'] > rpm_pkg['lvm2-cluster']:
            blurb = 'consider upgrading'
        elif rpm_pkg['lvm2'] < rpm_pkg['lvm2-cluster']:
            blurb = 'upgrade ASAP'

        if blurb != '':
            anomaly_line = "RPM package 'lvm2' is at version {0} while 'lvm2-cluster' is at version {1}, {2}, see KCS {3} ({4})".\
                           format(rpm_pkg['lvm2'], rpm_pkg['lvm2-cluster'], blurb, kcs_url('18999'), rpm_file)
            handle_anomaly("RPM", anomaly_line)

    if rpm_pkg['lvm2'] != '' and rpm_pkg['lvm2-libs'] != '':
        if rpm_pkg['lvm2'] == rpm_pkg['lvm2-libs']:
            blurb = ''  # all is well
        elif rpm_pkg['lvm2'] > rpm_pkg['lvm2-libs']:
            blurb = 'upgrade ASAP'
        elif rpm_pkg['lvm2'] < rpm_pkg['lvm2-libs']:
            blurb = 'consider upgrading'

        if blurb != '':
            anomaly_line = "RPM package 'lvm2' is at version {0} while 'lvm2-libs' is at version {1}, {2}, see KCS {3} ({4})".\
                           format(rpm_pkg['lvm2'], rpm_pkg['lvm2-libs'], blurb, kcs_url('18999'), rpm_file)
            handle_anomaly("RPM", anomaly_line)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, rpm_file))
    return

# ---------------------------------------------#
# function: crunch_rpm_pkg_name_version(pkg_and_vers)
# ---------------------------------------------#


def crunch_rpm_pkg_name_version(pkg_and_vers):
    pkg = ''
    pkg_build = True
    vers = ''
    vers_build = False

    tmp = pkg_and_vers.split('-')
    wc = len(tmp)
    if wc < 2:
        return('')

    for w in tmp:
        char1 = w[0:1]

        if w.isdigit or (char1.isdigit() and '.' in w):
            tmpw = w.replace('-', '.')
            tmp2 = tmpw.split('.')
            if tmp2[0].isdigit():
                pkg_build = False
                vers_build = True

        if pkg_build:
            if pkg == '':
                pkg = w
            else:
                pkg = pkg + "-" + w
            continue

        if vers_build:
            if vers == '':
                vers = w
            else:
                vers = vers + "-" + w
            continue
    # end: for w in tmp:

    if pkg == '' and vers == '':
        return('')

    debug_print(3, "{0}: '{1}' ~ '{2}'".format(pkg_and_vers, pkg, vers))

    return(pkg + " " + vers)


# ---------------------------------------------#
# function: normalize_rpm_version()
# ---------------------------------------------#
def normalize_rpm_version(vers):
    skip_words = "el6 el7 x86_64 x86_32 noarch"
    vers = vers.replace('-', '.')
    words = vers.split('.')
    wc = len(words)
    if wc < 2:
        return('')  # should not occur
    norm_vers = ''
    for v in words:
        if word_in_list(v, skip_words):
            continue
        v = "{0}".format(v.rjust(4, '0'))
        if norm_vers == '':
            norm_vers = v
        else:
            norm_vers = norm_vers + '.' + v

    debug_print(3, "in:{0} out:{1}".format(vers, norm_vers))
    return(norm_vers)


# ---------------------------------------------#
# function: crunch_lvs_data()
# LV               VG   Attr   LSize  Origin  Snap%  Move Log Copy%  Convert Devices
# appsvol          vg00 -wi-a- 16.00G                                        /dev/md126(512)
# corevol          vg00 -wi-a- 16.00G                                        /dev/md126(2048)
# crashvol         vg00 -wi-a- 16.00G                                        /dev/md126(1536)
# homevol          vg00 -wi-a- 16.00G                                        /dev/md126(2560)
# rootvol          vg00 owi-ao 16.00G                                        /dev/md126(0)
# rootvol_snapshot vg00 swi-a-  6.00G rootvol  19.57                         /dev/md127(0)
# simpana          vg00 -wi-a- 24.00G                                        /dev/md126(3584)
# swapvol          vg00 -wi-a- 16.00G                                        /dev/md126(3072)
# varvol           vg00 owi-ao 16.00G                                        /dev/md126(1024)
# varvol_snapshot  vg00 swi-a-  2.00G varvol   12.96                         /dev/md127(192)
#
# LV                      VG               Attr       LSize   Pool Origin Data%  Meta%  Move Log                 Cpy%Sync Convert LV Tags Devices
# lv_allstate             vg_apps          -wi-ao----   1.00g                                                                             /dev/vx/dmp/disk_1s1(0)
# lv_crash                vg_crash_lxm0043 mwi-aom--- 512.00g                                [lv_crash_mlog]     100.00                   lv_crash_mimage_0(0),lv_crash_mimage_1(0)
# [lv_crash_mimage_0]     vg_crash_lxm0043 iwi-aom--- 512.00g                                                                             /dev/vx/dmp/hitachi_vsp0_056e(0)
#
#
# ---------------------------------------------#
def crunch_lvs_data():

    lvs_files = "" \
        "sos_commands/devicemapper/lvs_-a_-o__devices " \
        "sos_commands/devicemapper/lvs_-a_-o_devices " \
        "sos_commands/lvm2/lvs_-a_-o_devices " \
        "sos_commands/lvm2/lvs_-a_-o_lv_tags_devices_--config_global_locking_type_0 "\
        "sos_commands/lvm2/lvs_-a_-o_lv_tags_devices_--config_global_locking_type_0_2 "\
        ""

    tmp = lvs_files.split()
    for lvs_file in tmp:
        if lvs_file == '' or lvs_file.startswith("#"):
            continue
        if file_exists_with_data(lvs_file):
            crunch_lvs_data_file(lvs_file)
    # end: for lvs_file in tmp:

    return

# ---------------------------------------------#
# function: crunch_lvs_data_file()
# ---------------------------------------------#


def crunch_lvs_data_file(lvs_file):
    global vg_2_dup_uuids  # Key_data()         # key: vg name              data: list of duplicate uuids vg was known as
    global all_vgs_with_missing_pvs  # ''  # list of all VGs with missing PVs

    fh = openfile(lvs_file)
    if fh is None:
        return

    lvm_read_failed_re = "/dev/.*: read failed after " + n5_re + " of " + n12_re + " at .*"

    found_hdr = False
    dup_pv_count = 0
    read_0_failed_msg = 0
    corruption_count = 0
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
    # line = line.lstrip(' ')
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        if line.startswith("File descriptor"):  # sos command python artifact
            continue

        if line.startswith("vsnprintf failed for config line"):  # (case )
            continue

        if line.startswith("_log_array_value_used: failed to write node value"):  # (case )
            anomaly_line = "'{0}', {1} ({2})".format(line, cfa_bz("1396654"), lvs_file)
            handle_anomaly("LVM", anomaly_line)
            continue

        if line.startswith("Logging initialised"):  # (case )
            continue

        if line.startswith("Couldn't find device "):
            # Couldn't find device with uuid P5PkLl-7GaR-Q9Z8-K33a-imkp-lrq9-dzsl4P.
            could_not_find_lvm_uuid(line, lvs_file)
            continue

        if line.startswith("Found duplicate PV"):
            dup_pv_count += 1
            continue

        if line.startswith("Incorrect metadata area"):
            anomaly_line = "'{0}' ({1})".format(line, lvs_file)
            handle_anomaly("LVM", anomaly_line)
            continue

        if line.startswith("Configuration setting") and "invalid." in line:
            anomaly_line = "'{0}' ({1})".format(line, lvs_file)
            handle_anomaly("LVMCONF", anomaly_line)
            continue

        if line.startswith("Configuration setting") and "unknown." in line:
            anomaly_line = "'{0}' ({1})".format(line, lvs_file)
            handle_anomaly("LVMCONF", anomaly_line)
            continue

        if line.endswith(": Checksum error"):
            do_checksum_anom(line, lvs_file)
            continue

        if line.endswith(" Was device resized?"):
            do_resized_anom(line, lvs_file)
            continue

        if line.startswith("WARNING: Duplicate VG name") and "takes precedence over" in line:
            words = line.split()
            wc = len(words)
            vg_name = words[4].rstrip(":")  # take off trailing ':'
            vg_uuid = words[5]
            vg_dup_uuid = words[wc - 1]
            if vg_uuid == "Existing":
                vg_uuid = words[6]
            vg_2_dup_uuids[vg_name] = unique_list(vg_2_dup_uuids[vg_name], clean_uuid(vg_dup_uuid))
            vg_name = update_vg_override(vg_name, vg_uuid, lvs_file)

        if line.startswith("WARNING:"):
            if "This could corrupt your metadata" in line:  # ignore as it seems to be printed most of the time...
                pass
            else:
                blurb = ''
                if line.startswith("WARNING: Duplicate VG name"):
                    blurb = "{0}".format(cfa_kcs("39278"))
                if line.startswith("WARNING: Cannot find matching striped segment"):
                    blurb = "{0}".format(cfa_kcs("3231111"))
                anomaly_line = squeeze("'{0}' {1} ({2})".format(line, blurb, lvs_file))
                handle_anomaly_with_points("LVMW", anomaly_line, "lvm", 4)
            continue

        # /run/lvm/lvmetad.socket: connect failed: Connection refused
        if line.startswith("/run/lvm/lvmetad.socket"):
            continue

        words = line.split()
        wc = len(words)
        if wc < 3:
            continue

        if re.match("/dev/.*: read failed .*", line):
            # anomaly_line = "'{0}' ({1})".format(line,lvs_file)
            # handle_anomaly("LVM",anomaly_line)
            # if re.match("/dev/.*: read failed after 0 of 4096 at .*",line):
            if re.match(lvm_read_failed_re, line):
                read_0_failed_msg += 1
            track_dm_nnn_lvm_errors(words[0].rstrip(":"))
            continue

        if line.startswith("No Volume groups found"):
            continue

        words = line.split()
        wc = len(words)
        if wc < 3:
            continue

        if words[0] == "LV" and words[1] == "VG" and words[2] == "Attr":
            found_hdr = True
            cc_snap_pct = line.find("Snap%")
            cc_data_pct = line.find("Data%")
            cc_meta_pct = line.find("Meta%")
            cc_copy_pct = line.find("Copy%")
            cc_cpy_sync_pct = line.find("Cpy%Sync")
            continue

        if not found_hdr:
            continue

        corrupt_line = vg_line_corrupt(line)
        if corrupt_line:
            corruption_count += 1
            continue

        lv_name = words[0]
        lv_name = lv_name.strip("[]")  # see case  nycassandra12-2014110312491415036966/sos_commands/devicemapper
        vg_name = words[1]
        vg_name = update_vg(vg_name, '', lvs_file)
        update_lv(vg_name, lv_name, '', '', '', lvs_file)

        lv_attr = words[2]
        lv_size = words[3]
        vg_devs = words[wc - 1]  # last words (comma separated if multiple devices)

        # debug_print(z,"vg:{0}: vg_devs:'{1}'".format(vg_name,vg_devs))

        # The lv_attr bits (flag display bytes) are:
        #
        # lv_attr[0] Volume type: (C)ache, (m)irrored, (M)irrored without initial sync, (o)rigin, (O)rigin with merging
        # snapshot,   (r)aid,  (R)aid  without  initial  sync,  (s)napshot,  merging  (S)napshot,  (p)vmove,
        # (v)irtual, mirror or raid (i)mage, mirror or raid (I)mage out-of-sync, mirror (l)og device,  under
        # (c)onversion,  thin (V)olume, (t)hin pool, (T)hin pool data, raid or pool m(e)tadata or pool meta-
        # data spare.
        #
        # lv_attr[1] Permissions: (w)riteable, (r)ead-only, (R)ead-only activation of non-read-only volume
        #
        # lv_attr[2] Allocation policy:  (a)nywhere, (c)ontiguous, (i)nherited, c(l)ing, (n)ormal This  is  capitalised
        # if the volume is currently locked against allocation changes, for example during pvmove(8).
        #
        # lv_attr[3] fixed (m)inor
        #
        # lv_attr[4] State:  (a)ctive,  (s)uspended, (I)nvalid snapshot, invalid (S)uspended snapshot, snapshot (m)erge
        # failed, suspended snapshot (M)erge failed, mapped (d)evice present without tables,  mapped  device
        # present  with  (i)nactive table, thin-pool (c)heck needed, suspended thin-pool (C)heck needed, (X)
        # unknown
        #
        # lv_attr[5] device (o)pen, (X) unknown
        #
        # lv_attr[6] Target type: (C)ache, (m)irror, (r)aid, (s)napshot, (t)hin,  (u)nknown,  (v)irtual.   This  groups
        # logical  volumes related to the same kernel target together.  So, for example, mirror images, mir-
        # ror logs as well as mirrors themselves appear as (m) if they use the original device-mapper mirror
        # kernel  driver;  whereas  the  raid equivalents using the md raid kernel driver all appear as (r).
        # Snapshots using the original device-mapper driver appear as (s); whereas snapshots of thin volumes
        # using the new thin provisioning driver appear as (t).
        #
        # lv_attr[7] Newly-allocated data blocks are overwritten with blocks of (z)eroes before use.
        #
        # lv_attr[8] Volume Health, where there are currently three groups of attributes identified:
        #
        # Common ones for all Logical Volumes: (p)artial, (X) unknown.
        # (p)artial  signifies  that one or more of the Physical Volumes this Logical Volume uses is missing
        # from the system. (X) unknown signifies the status is unknown.
        #
        # Related to RAID Logical Volumes: (r)efresh needed, (m)ismatches exist, (w)ritemostly.
        # (r)efresh signifies that one or more of the Physical Volumes this RAID  Logical  Volume  uses  had
        # suffered  a write error. The write error could be due to a temporary failure of that Physical Vol-
        # ume or an indication that it is failing.  The device should be refreshed or replaced. (m)ismatches
        # signifies that the RAID logical volume has portions of the array that are not coherent.  Inconsis-
        # tencies are detected by initiating a "check" on a RAID logical volume.  (The scrubbing operations,
        # "check"  and  "repair",  can  be  performed  on a RAID logical volume via the ’lvchange’ command.)
        # (w)ritemostly signifies the devices in a RAID 1 logical volume that have been marked write-mostly.
        #
        # Related to Thin pool Logical Volumes: (F)ailed, out of (D)ata space, (M)etadata read only.
        # (F)ailed  is set if thin pool encounters serious failures and hence no further I/O is permitted at
        # all. The out of (D)ata space is set if thin pool has run out of data space. (M)etadata  read  only
        # signifies  that thin pool encounters certain types of failures but it’s still possible to do reads
        # at least, but no metadata changes are allowed.
        #
        # (F)ailed is set when related thin pool enters Failed state and no further I/O is permitted at all.
        #
        # lv_attr[9] s(k)ip activation: this volume is flagged to be skipped during activation.

        snap_pct_full = float(get_value_from_line(cc_snap_pct, line))
        data_pct_full = float(get_value_from_line(cc_data_pct, line))
        if (lv_attr[0] == 's' or lv_attr[0] == 'S') and snap_pct_full > 97.0:
            anomaly_line = "warning: {0}-{1} snap space is {2}% full, {3} & {4} ({5})".\
                           format(vg_name, lv_name, snap_pct_full, cfa_kcs("56141"), kcs_url("232283"), lvs_file)
            handle_anomaly_with_points("LVM", anomaly_line, 'lvm', 10)

        # meta_pct_full = float(get_value_from_line(cc_meta_pct,line))
        # cpy_sync_pct_full = float(get_value_from_line(cc_cpy_sync_pct,line))

        # "-wi-ao"     - 6 chars ex. case: 01100214
        # "swi-I-s--"  - 9 chars
        # "-wi-s-----" - 10 chars
        if len(lv_attr) == 6 or len(lv_attr) == 8 or len(lv_attr) == 9 or len(lv_attr) == 10:
            pass
        else:
            error_print("d", "attr length not 6/8/9/10 -> {0} [{1},'{2}'] ({3})".format(len(lv_attr), i, line, lvs_file))
            continue

        if lv_attr[4] == "I":  # "sw-I-s--" ex. case: 01128050
            inv_pct_full = snap_pct_full
            if inv_pct_full == -1:
                inv_pct_full = data_pct_full
            anomaly_line = "Snapshot {0}-{1} invalidated {2}% full, {3} & {4} ({5})".\
                           format(vg_name, lv_name, inv_pct_full, cfa_kcs("56141"), kcs_url("232283"), lvs_file)
            handle_anomaly_with_points("LVM", anomaly_line, 'lvm', 10)
        reason = ''
        # "-wi-s-----" ex. case: 01100276
        if lv_attr[4] == "s":
            reason = 'suspended'
        if lv_attr[4] == "m":
            reason = 'merge failed'
        if lv_attr[4] == "c":
            reason = "thin-pool check needed"
        if lv_attr[4] == "C":
            reason = "suspended thin-pool check needed"

        # TODO flag LV which is active but not open? Need to test and see how frequently this may occur. see case
        # if lv_attr[4] == "a" and lv_attr[5] != "o":

        if reason != '':
            anomaly_line = "VG/LV {0}-{1} {2} ({3})".format(vg_name, lv_name, reason, lvs_file)
            handle_anomaly_with_points("LVM", anomaly_line, 'lvm', 10)

        reason = ''
        if len(lv_attr) == 10:
            if lv_attr[8] == "p":
                reason = 'one or more PVs this LV uses is missing'
                all_vgs_with_missing_pvs = unique_list(all_vgs_with_missing_pvs, vg_name)
            if lv_attr[8] == "r":
                reason = 'refresh needed'
            if lv_attr[8] == "m":
                reason = 'mismatches exist'
            if lv_attr[8] == "F":
                reason = 'thin pool serious failures'
            if lv_attr[8] == "D":
                reason = 'thin pool has run out of data space'
            if lv_attr[8] == "M":
                reason = 'thin pool Meta data read only'
            if reason != '':
                blurb = ''
                if 'thin pool' in reason:
                    blurb = ", see {0}".format(kca_url("766133"))
                anomaly_line = "VG/LV {0}-{1} {2}{3} ({4})".format(vg_name, lv_name, reason, blurb, lvs_file)
                handle_anomaly_with_points("LVM", anomaly_line, 'lvm', 20)

        if "unknown device" in line:
            # anom
            continue

        if not vg_devs.startswith("/"):
            continue

        if not vg_devs.startswith("/dev"):
            # (SHOULD NOT OCCUR)
            error_print('d', "({0} {1}) vg_devs does not start with '/dev' -> {2}".format(i, lvs_file, vg_devs))
            continue

        tmp = vg_devs.split(',')
        dc = len(tmp)
        vg_devs = ''
        for pv_dev in tmp:
            j = pv_dev.find('(')
            if j == -1:
                # (SHOULD NOT OCCUR)
                error_print('d', "({0} {1}) find('(','{2}') = -1".format(i, lvs_file, pv_dev))
            else:
                pv_dev = pv_dev[0:j]
                pv_uuid = ''
                pv_mm = ''
                pv_name = os.path.basename(pv_dev)
                update_pv(vg_name, pv_name, pv_dev, pv_uuid, pv_mm, lvs_file)

    # end: for line in lvs_lines:

    if dup_pv_count > 0:
        anomaly_line = "Found {0} duplicate PV line{1}, {2} ({3})".\
                       format(dup_pv_count, plural(dup_pv_count), cfa_kcs("2989"), lvs_file)
        handle_anomaly_with_points("LVM", anomaly_line, 'lvm', dup_pv_count)

    if read_0_failed_msg > 0:
        anomaly_line = "Found {0} '{1}' line{2}, {3} ({4})".\
                       format(read_0_failed_msg, lvm_read_failed_re, plural(read_0_failed_msg), info_kcs("415783"), lvs_file)
        handle_anomaly_with_points("LVM", anomaly_line, "LVM", read_0_failed_msg)

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, lvs_file))
    return


# ---------------------------------------------#
# function: could_not_find_lvm_uuid()
# track lvm uuids that could not be found (source is lvm cmd output or var/log/messages)
# ---------------------------------------------#
def could_not_find_lvm_uuid(line, source):
    global uuids_to_check  # ''

    anomaly_line = "'{0}' ({1})".format(line, source)
    handle_anomaly("LVMW", anomaly_line)
    words = line.split()
    wc = len(words)
    uuid = words[wc - 1].rstrip('.')
    uuids_to_check = unique_list(uuids_to_check, uuid)

    return
# ---------------------------------------------#
# function: get_value_from_line()
# return the nnn.nn percentage value from line
# ---------------------------------------------#


def get_value_from_line(cc_beg, line):
    if cc_beg == -1:
        return(-1)
    s = line[cc_beg:cc_beg + len("nnn.nn")]
    s = s.strip()
    if s == '':
        return(-1)
    if not is_float(s):
        return(-1)
    return(s)

# ---------------------------------------------#
# function: crunch_sar_data()
# ---------------------------------------------#


def crunch_sar_data():
    global await_devices  # ''                  # unique await devices
    global await_buckets  # Counter()           # key: bucket # data: bucket count      e.g. 0        37
    global svctm_devices  # ''                  # unique svctm devices
    global svctm_buckets  # Counter()           # key: bucket # data: bucket count      e.g. 5        12
    global anomaly_points  # Counter()  # Key: Anomaly point type (one of all_anomaly_point_types)  Data: point value

    crunch_sar_directory("./sos_commands/sar/")

    await_total = 0
    svctm_total = 0
    for i in range(0, 5):  # 0-4
        perf_points = (await_buckets[i] + svctm_buckets[i]) * (i + 1)  # the higher the ms bucket range, apply a bonus factor
        anomaly_points['performance'] += perf_points
        await_total += await_buckets[i]
        svctm_total += svctm_buckets[i]

    if await_total > 0:
        tmp = await_devices.split()
        do_sar_dev_perf_anom("await", await_buckets, len(tmp))

    if svctm_total > 0:
        tmp = svctm_devices.split()
        do_sar_dev_perf_anom("svctm", svctm_buckets, len(tmp))

    return

# ---------------------------------------------#
# function: do_sar_dev_perf_anom()
# issue anomaly for await or svctim
# ---------------------------------------------#


def do_sar_dev_perf_anom(type, buckets, dev_count):

    total_events = buckets[0] + buckets[1] + buckets[2] + buckets[3] + buckets[4]
    anomaly_line = "Excessive {0} times: [10-50ms]:{1}, [50-100ms]:{2}, [100-500ms]:{3}, [500-1000ms]:{4}, [>1000ms]:{5}, total events: {6}, unique devices: {7}".\
                   format(type, buckets[0], buckets[1], buckets[2], buckets[3], buckets[4], total_events, dev_count)
    # debug_print(z,anomaly_line)
    handle_anomaly("PERF", anomaly_line)
    return

# ---------------------------------------------#
# function: crunch_sar_directory()
# ---------------------------------------------#


def crunch_sar_directory(path):

    if stat_dir(path, '', 0) is None:
        return

    fn_prefix_list_1 = "sar "\
                       ""
    fn_prefixes_1 = fn_prefix_list_1.split()
    files = [f for f in listdir(path) if isfile(join(path, f))]

    for fn in files:

        for fn_prefix in fn_prefixes_1:  # parted or fdisk output files
            if fn.startswith(fn_prefix) and re.match("sar[0-9]{1,2}", fn):
                crunch_sar_file(path + fn)

    # done: for fn in files:
    return


# ---------------------------------------------#
# function: crunch_sar_file()
#
# +---< col 1
# |
# 00:00:16          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
# 12:30:14       dev8-0     27.82      0.00    437.09     15.71     16.74    601.65    178.08    495.39
# 12:30:14      dev8-32     13.52      3.88    166.30     12.59      5.26    390.97    288.92    390.48
# 12:30:14      dev8-64     84.48  47700.61   3440.48    605.33     31.36    371.14     41.45    350.15
#
# other headers:
# 00:00:01        CPU      %usr     %nice      %sys   %iowait    %steal      %irq     %soft    %guest     %idle
# 00:00:01          tps      rtps      wtps   bread/s   bwrtn/s
# 00:00:01     pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff
# 00:00:01     pswpin/s pswpout/s
# 00:00:01       proc/s   cswch/s
# 00:00:01          tps      rtps      wtps   bread/s   bwrtn/s
# 00:00:01      frmpg/s   bufpg/s   campg/s
# 00:00:01    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit
# 00:00:01    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
# 00:00:01    dentunusd   file-nr  inode-nr    pty-nr
# 00:00:01      runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15
# 00:00:01          TTY   rcvin/s   xmtin/s framerr/s prtyerr/s     brk/s   ovrun/s
# 00:00:01        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
# 00:00:01        IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s
# 11:20:01       call/s retrans/s    read/s   write/s  access/s  getatt/s
# 11:20:01      scall/s badcall/s  packet/s     udp/s     tcp/s     hit/s    miss/s   sread/s  swrite/s saccess/s sgetatt/s
# 11:20:01       totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw
#
# ---------------------------------------------#
def crunch_sar_file(sar_file):

    fh = openfile(sar_file)
    if fh is None:
        return

    header_words = ""\
                   "DEV "\
                   "CPU "\
                   "tps "\
                   "pgpgin/s "\
                   "pswpin/s "\
                   "proc/s "\
                   "tps "\
                   "frmpg/s "\
                   "kbmemfree "\
                   "kbswpfree "\
                   "dentunusd "\
                   "runq-sz "\
                   "TTY "\
                   "IFACE "\
                   "IFACE "\
                   "call/s "\
                   "scall/s "\
                   "totsck "\
                   ""
    hdr_words = header_words.split()
    dev_hdr_found = False
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove ending \n
        i += 1
        line = line.strip()
        if line == "" or line.startswith("#"):
            continue

        line = line.replace(",", ".")  # fix up euro centric decimal points
        words = line.split()
        wc = len(words)

        if wc < 2:
            continue

        word1 = words[1]
        if not is_float(word1):
            for hw in hdr_words:
                if word1 == hw:
                    # reset all hdr state flags
                    dev_hdr_found = False
                    # cpu_hdr_found = False
                    # ...
                    break

        if wc == 10 and words[1] == "DEV":
            dev_hdr_found = True
            # debug_print(z,words[1])
            continue

        if wc == 10 and dev_hdr_found:
            # debug_print(z,words[1])
            crunch_sar_file_dev(i, line, words)
    # end: for line in fh:

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, sar_file))
    return

# ---------------------------------------------#
# function: crunch_sar_file_dev()
# process device sar data
#
# 00:00:01          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
# 00:10:01       dev8-0    161.42   6454.00    201.72     41.23      0.39      2.42      0.58      9.35
# 00:10:01      dev8-16      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
# 00:10:01      dev8-32      0.00      0.01      0.00      8.00      1.00 402000.00 600223.00    100.41
# .
# .
# .
# 16:30:01    dev253-16     27.96      3.73  10569.76    378.22      0.77     27.44     10.50     29.34
# 16:30:01    dev253-17     26.62      0.71  10600.65    398.31      0.55     20.72      9.87     26.28
# 16:30:01    dev252-256513      0.95      0.00      0.00      0.00      0.00      0.00      0.00      0.00  <<<--- occasional high outliers
# Average:       dev8-0     24.29    465.74    233.60     28.79      0.01      0.43      0.19      0.47
#
# ---------------------------------------------#


def crunch_sar_file_dev(i, line, words):
    global sar_device_perf_data  # False
    global await_devices  # ''                  # unique await devices
    global await_buckets  # Counter()           # key: bucket # data: bucket count      e.g. 0        37
    global svctm_devices  # ''                  # unique svctm devices
    global svctm_buckets  # Counter()           # key: bucket # data: bucket count      e.g. 5        12
    global await_dev_samples  # counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
    global await_dev_total_time  # counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
    global svctm_dev_samples  # counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
    global svctm_dev_total_time  # counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
    global high_await_mm  # ''
    global high_await_time  # 0
    global high_svctm_mm  # ''
    global high_svctm_time  # 0

    # debug_print(z,words[1])
    dev_time = words[0]
    if dev_time == "Average:":
        return

    dev_name = words[1]
    if not re.match("dev[0-9]{1,10}-[0-9]{1,4}", dev_name):  # raised from dev[0-9]{1,3}-[0-9]{1,4} to dev[0-9]{1,10}-[0-9]{1,4} based on 01831364
        if dev_name.startswith('dev0--'):
            return  # see case  sos_commands/sar19
        error_print('d', "{0} '{1}'".format(i, line))
        return

    dev_tps = float(words[2])
    dev_rdps = float(words[3])
    dev_wrps = float(words[4])
    dev_avgrqsz = float(words[5])
    dev_avgqusz = float(words[6])
    dev_await = float(words[7])
    dev_svctm = float(words[8])
    dev_util = float(words[9])
    # major = 0
    # minor = 0
    # mm = ''

    # if re.match("dev[0-9]{1,3}-[0-9]{1,4}",dev_name):

    tmp1 = dev_name[len("dev"):]  # remove "dev"
    tmp2 = tmp1.split("-")
    major = int(tmp2[0])
    minor = int(tmp2[1])
    mm = "{0}:{1}".format(major, minor)

    # end: if re.match("dev[0-9]{1,3}-[0-9]{1,4}",dev_name):

    if dev_await >= 10.0:
        sar_device_perf_data = True
        if dev_await >= 10.0 and dev_await < 50.0:
            slot = 0
        elif dev_await >= 50.0 and dev_await < 100.0:
            slot = 1
        elif dev_await >= 100.0 and dev_await < 500.0:
            slot = 2
        elif dev_await >= 500.0 and dev_await < 1000.0:
            slot = 3
        elif dev_await >= 1000.0:
            slot = 4
        await_buckets[slot] += 1
        await_devices = unique_list(await_devices, dev_name)
        # debug_print(z,"{0}: {1}".format(i,line))
        await_dev_samples[mm] += 1
        await_dev_total_time[mm] += dev_await
        if high_await_time < await_dev_total_time[mm]:
            high_await_time = await_dev_total_time[mm]
            high_await_mm = mm
        track_sar_major_minor(major, minor)

    if dev_svctm >= 10.0:
        sar_device_perf_data = True
        if dev_svctm >= 10.0 and dev_svctm < 50.0:
            slot = 0
        elif dev_svctm >= 50.0 and dev_svctm < 100.0:
            slot = 1
        elif dev_svctm >= 100.0 and dev_svctm < 500.0:
            slot = 2
        elif dev_svctm >= 500.0 and dev_svctm < 1000.0:
            slot = 3
        elif dev_svctm >= 1000.0:
            slot = 4
        svctm_buckets[slot] += 1
        svctm_devices = unique_list(svctm_devices, dev_name)
        # debug_print(z,"{0}: {1}".format(i,line))
        svctm_dev_samples[mm] += 1
        svctm_dev_total_time[mm] += dev_svctm
        if high_svctm_time < svctm_dev_total_time[mm]:
            high_svctm_time = svctm_dev_total_time[mm]
            high_svctm_mm = mm
        track_sar_major_minor(major, minor)

    return

# ---------------------------------------------#
# function: track_sar_major_minor(major,minor):
# track the high and low major number of device(s) w/performance issues
# and the high and low minor numbers of devices within that major number
# ---------------------------------------------#


def track_sar_major_minor(major, minor):
    global lo_major_perf  # big_num
    global hi_major_perf  # 0
    global hi_minor_perf  # Key_data_max()
    global lo_minor_perf  # Key_data_min()

    lo_major_perf = min(lo_major_perf, major)
    hi_major_perf = max(hi_major_perf, major)

    lo_minor_perf[major] = min(lo_minor_perf[major], minor)
    hi_minor_perf[major] = max(hi_minor_perf[major], minor)
    return


# ---------------------------------------------#
# function: check_blocked_task_anomalies():
# build any blocked task anomalies
# ---------------------------------------------#
def check_blocked_task_anomalies():
    global blocked_duration  # 0
    global all_blocked_tasks  # ""
    global all_blocked_task_types  # ""
    global total_blocked_task_count  # 0
    global blocked_task_count  # Counter()
    global blocked_task_names  # Key_data()
    global service_time  # Counter() #

    if total_blocked_task_count == 0:
        return

    all_blocked_task_types = sort_list(all_blocked_task_types)
    tmp = all_blocked_task_types.split()
    for task_table_type in tmp:
        tmp_list = sort_list(blocked_task_names[task_table_type])
        tmp = tmp_list.split()
        tc = len(tmp)
        anomaly_line = "Found {0} '[{1}] task blocked for more than {2} seconds.' message{3}. Task name{4}: {5}, {6}".\
            format(blocked_task_count[task_table_type],
                   task_table_type,
                   blocked_duration,
                   plural(blocked_task_count[task_table_type]),
                   plural(tc),
                   blocked_task_names[task_table_type],
                   info_kcs('31453'))
        handle_anomaly("HUNG", anomaly_line)
    # end: for task_table_type in tmp:

    if service_time['corosync'] > 10 * 60 and ('xfs' in blocked_task_names['Filesystem']):
        anomaly_line = "Found {0} corosync task{1} using {2} cpu seconds AND at least 1 blocked xfs task, {3}".\
            format(service_procs['corosync'],
                       plural(service_procs['corosync']),
                       service_time['corosync'],
                       cfa_kcs('2444531'))
        handle_anomaly("HUNG", anomaly_line)

    return

# ---------------------------------------------#
# function: do_scan_block()
# if function == 'SCAN'
# do any EXEC processing
# track match count
# if PROC_SCAN == 'DETAIL' create individual anomaly
#
# if function == 'SUMMARY'
# do any EXEC processing
# if PROC_SUMM != 'SKIP' create summary anomaly
# ---------------------------------------------#


def do_scan_block(scan_block, pass_no, line, function, line_no, source):
    global scan_count  # Counter()
    global scan_origin  # Key_data()

    # used by "EXEC_SCAN" or "EXEC_SUMM" code snippets:
    global Virtual_guest
    global Virtual_type
    global Oracle
    global all_dev_mfgs
    global all_fs_types
    global cpus_active
    global info_text  # "information in"
    global cfa_text  # "check for applicability of"
    global event_count  # Counter()      # key: event type           data: event count         e.g. lpfc 12
    global anomaly_points  # Counter()  # Key: Anomaly point type (one of all_anomaly_point_types)  Data: point value
    global cmdline  # Key_data()
    global kernelStr  # Key_data()
    global kernelNum  # Counter()
    global very_big_device_list  # ''

    eid_url_list = 'CFA_KCS INFO_KCS KCS INFO_KCA KCA BZ SFDC URL INFO_URL'
    scan_elements = scan_block.split("~")
    scan_pattern = scan_elements[0]

    debug_print(3, "({0}) '{1}'".format(scan_count[scan_block], scan_block))
    debug_print(3, "{0},{1},{2},{3},{4}".format(pass_no, line, function, line_no, source))

    url_data = ''
    anom = ''
    ins_text = ''
    test_scan_str = ''
    exec_scan_str = ''
    test_summ_str = ''
    exec_summ_str = ''
    proc_scan = ''
    proc_summ = ''
    id = ''
    scb_pass = 1

    swc = len(scan_elements)
    for e in range(1, swc - 1):

        ele = scan_elements[e]
        if ele == "":
            continue

        tmp = ele.split(':')
        e_id = tmp[0]  # element id

        # e_val = tmp[1] # may contain further colons that are part of the data
        e_val = ele[len(e_id) + 1:]  # element value
        if word_in_list(e_id, eid_url_list):
            bool = True
            # check for 2nd colon, e.g.: "KCS:12345:(Virtual_guest)~" -- this is a conditional url reference
            if ":" in e_val and not e_val.startswith("http"):
                tmpa = e_val.split(':')
                e_val = tmpa[0]
                url_test_str = tmpa[1]
                url_test_str = "bool=" + url_test_str
                debug_print(3, "{0} {1}".format(bool, url_test_str))
                exec(url_test_str)
                debug_print(3, "{0} {1}".format(bool, url_test_str))
            if bool:
                if e_id == "CFA_KCS" or e_id == "INFO_KCS" or e_id == "INFO_KCA" or e_id == "INFO_URL":
                    url_data = url_data + ' ' + do_scan_url(e_id, e_val)
                else:
                    url_data = url_data + ' ' + e_id + ' ' + do_scan_url(e_id, e_val)
                debug_print(4, "url_data[{0}]".format(url_data))
        elif e_id == 'ANOM':
            anom = e_val
        elif e_id == 'PROC_SCAN':
            proc_scan = e_val     # SKIP|DETAIL|...
        elif e_id == 'PROC_SUMM':
            proc_summ = e_val     # SKIP|...
        elif e_id == 'EXEC_SCAN':
            exec_scan_str = do_exec_str(exec_scan_str, e_val)     # 'rtn(line,source)'|'(foo = bar +1)'|...
        elif e_id == 'TEST_SCAN':
            test_scan_str = e_val     # 'bool expression'
        elif e_id == 'EXEC_SUMM':
            exec_summ_str = do_exec_str(exec_summ_str, e_val)     # 'rtn(line,source)'|'(foo = bar +1)'|...
        elif e_id == 'TEST_SUMM':
            test_summ_str = e_val     # 'bool expression'
        elif e_id == 'INSTXT':
            ins_text = e_val
        elif e_id == 'ID':
            id = e_val
        elif e_id == 'PASS':
            scb_pass = e_val
        elif e_id == 'MATCH':
            continue
        elif e_id.startswith("#"):
            continue                # allow an element to be commented out
        else:
            error_print('l', "?:{0} scan_block:{1}".format(e_id, scan_block))

    # end: for e in range(1,swc-1):

    if function == "SCAN" and test_scan_str != '':
        words = line.split()
        debug_print(3, "{0} {1}".format(test_scan_str, line))
        test_scan_str = "bool=({0})".format(test_scan_str)
        exec(test_scan_str)
        debug_print(3, "{0} {1}".format(bool, test_scan_str))
        if not bool:
            return
    # end: if function == "SCAN" and test_scan_str != '':

    if function == "SCAN" and exec_scan_str != '':
        words = line.split()
        debug_print(3, "{0} {1}".format(exec_scan_str, line))
        exec(exec_scan_str)
    # end: if function == "SCAN" and exec_scan_str != '':

    if function == "SUMMARY" and test_summ_str != '':
        words = line.split()
        debug_print(3, "{0} {1}".format(test_summ_str, line))
        test_summ_str = "bool=({0})".format(test_summ_str)
        exec(test_summ_str)
        debug_print(3, "{0} {1}".format(bool, test_summ_str))
        if not bool:
            return
    # end: if function == "SUMMARY" and test_summ_str != '':

    if function == "SUMMARY" and exec_summ_str != '':
        words = line.split()
        debug_print(3, "{0} {1}".format(exec_summ_str, line))
        exec(exec_summ_str)
    # end: if function == "SUMMARY" and exec_summ_str != '':

    if function == "SCAN":
        scan_count[scan_block] += 1
        debug_print(4, "scan_count[{0}]".format(scan_count[scan_block]))
        if scan_origin[scan_block] == "":
            scan_origin[scan_block] = source
        elif scan_origin[scan_block] == source:
            pass
        elif scan_origin[scan_block].endswith(source):
            pass
        else:
            scan_origin[scan_block] = unique_list(scan_origin[scan_block], source)
    # end: if function == "SCAN":

    if proc_scan == "DETAIL" and proc_summ == "":
        proc_summ = "SKIP"

    if (function == "SUMMARY" and proc_summ != "SKIP") or (function == "SCAN" and proc_scan == "DETAIL"):
        anom_ref = ''
        url_data = url_data.strip()
        # cfa = ", check for applicability of "
        if url_data != '':
            if url_data.startswith(cfa_text):
                anom_ref = ", " + url_data
            elif url_data.startswith(info_text):
                anom_ref = ", " + url_data
            else:
                anom_ref = ", " + cfa_text + " " + url_data

        if ins_text != "":
            if ins_text.startswith("eval "):
                ins_statement = 'ins_text=' + ins_text[5:]
                debug_print(4, "'{0}'".format(ins_statement))
                exec(ins_statement)
                debug_print(4, "'{0}'".format(ins_text))
            anom_ref = ", " + ins_text + anom_ref
        anom_ref = "{0} ({1})".format(anom_ref, source)

        if function == "SCAN":
            # create anom for each detail line
            anomaly_line = "Found '{0}'{1}".format(line, anom_ref)
        else:
            # create anom for sum of all occurrences
            anomaly_line = "Found {0} '{1}' message{2}{3}".\
                format(scan_count[scan_block], scan_pattern, plural(scan_count[scan_block]), anom_ref)

        debug_print(3, "Function={0} {1} {2} '{3}]'".format(function, anom, anomaly_line, scan_block))

        if anom == '':
            if 'KCS' in url_data or 'KCA' in url_data:
                anom = 'KCS'
        if anom == '':
            if 'BZ' in url_data:
                anom = 'BZ'
        if anom == '':
            if 'SFDC' in url_data:
                anom = 'SFDC'
        if anom == '':
            anom = 'NOTE'

        handle_anomaly(anom, anomaly_line)

    # end: if (function == "SUMMARY" and proc_summ != "SKIP") or (function == "SCAN" and proc_scan == "DETAIL"):

    if (function == "SCAN" and proc_scan != "DETAIL") and anom != '':
        track_anomaly_timeline(anom)
    return

# ---------------------------------------------#
# function: do_exec_str()
# helper function to build up an exec string
# ---------------------------------------------#


def do_exec_str(exec_str, e_val):
    if exec_str == '':
        return(e_val)
    return(exec_str + ';' + e_val)

# ---------------------------------------------#
# function: do_scan_url()
# helper function to build a url
# ---------------------------------------------#


def do_scan_url(id, data):
    global info_text  # "information in"

    if id == 'CFA_KCS':
        return(cfa_kcs(data))
    elif id == 'INFO_KCS':
        return(info_kcs(data))
    elif id == 'KCS':
        return(kcs_url(data))
    elif id == 'INFO_KCA':
        return(info_kca(data))
    elif id == 'KCA':
        return(kca_url(data))
    elif id == 'BZ':
        return(bz_url(data))
    elif id == 'SFDC':
        return(sfdc_url(data))
    elif id == 'URL':
        return((data))
    elif id == 'INFO_URL':
        return((info_text + ' ' + data))
    else:
        error_print("{0} '{1}'".format(id, data))
        return('')


# ---------------------------------------------#
# function: kern_2_type():
# ---------------------------------------------#
def kern_2_type(kernel_level):
    global ke_level  # Key_data()
    kernel_type = ''

    int_err = '<InternalError>'
    rhel_version = ke_level[kernel_level]

    if rhel_version == '':
        if kernelStr['builder'] == "RedHat":
            kernel_type = int_err  # sno
        elif "Oracle" in kernelStr['builder']:
            kernel_type = 'Oracle'
        elif "fedora" in kernelStr['builder']:
            kernel_type = 'fedora'
        elif "CentOS" in kernelStr['builder']:
            kernel_type = 'CentOS'
        elif "uek" in kernel_level:
            kernel_type = 'Oracle'
        else:
            kernel_type = '<unknown>'
    else:
        tmp = rhel_version.split()
        wc = len(tmp)
        if wc == 1:
            kernel_type = "RHEL GA"  # simple case, not an errata kernel version
        else:
            kernel_type = "errata"  # errata version, second word is the date it was issued

    if kernel_type == int_err:
        error_print('l', "kernel type set to {0} based on kernel level {1} - new table entry may be needed".format(kernel_type, kernel_level))

    return(kernel_type)

# ---------------------------------------------#
# function: kern_2_rhel():
# ---------------------------------------------#


def kern_2_rhel(kernel_level):
    global ke_level  # Key_data()

    rhel_version = ke_level[kernel_level]

    if rhel_version == '':
        return(rhel_version)

    tmp = rhel_version.split()
    wc = len(tmp)

    if wc == 1:
        return(rhel_version)  # simple case, not an errata kernel version

    rhel_version = tmp[0]  # errata version, second word is the date it was issued
    return(rhel_version)

# ---------------------------------------------#
# function: kern_2_date():
# ---------------------------------------------#


def kern_2_date(kernel_level):
    global ke_level  # Key_data()
    global rh_date  # Key_data()

    rhel_version = ke_level[kernel_level]

    if rhel_version == '':
        return('')  # ?, no match

    tmp = rhel_version.split()
    wc = len(tmp)

    if wc > 1:  # errata kernel version
        rhel_version = tmp[0]  # errata version, second word is the date it was issued
        kernel_date = tmp[1]
    else:
        kernel_date = rh_date[rhel_version]

    debug_print(3, "kern_level:{0} kernel_date:{1}".format(kernel_level, kernel_date))
    return(kernel_date)


# ---------------------------------------------#
# function: kernel_age()
# token is either RHEL version; 5.4,5.11,6.7,7.1, etc.
# or kernel version nn.nnn.nnnn.nnnn [kernel_normalize() format]
# ---------------------------------------------#
def kernel_age(token):
    global rh_date  # Key_data()

    rel_date = ''

    if token == '':
        debug_print(3, "null token passed")
        return 0

    if token == '0.0':
        debug_print(3, "0.0 token passed")
        return 0

    if token == kernel_normalize(0, 0, 0, 0):
        debug_print(3, "zero normalized token passed")
        return 0

    if len(token) > 6:  # token is kernel level
        rel_date = kern_2_date(token)
        if rel_date == '':
            rel_date = find_est_kernel_rel_date(token)
    else:
        # token is 'm.m'
        rel_date = rh_date[token]

    if rel_date == '':  # if n.m format then probably an Ubuntu release
        debug_print(1, "unable to determine rel date of for '{0}'".format(token))
        return 0

    if rel_date == 'TBA':
        error_print('l', "need to update rh_date table for {0}".format(token))
        return 0

    # rel_date format: yyyy-mm-dd unless find_est_kern_rel_date() called
    # in which case it *may* be in 'Day Mon nn hh:mm:ss tz yyyy' format
    debug_print(3, 'token:{0} rel_date:{1}'.format(token, rel_date))

    age = object_age(rel_date)
    return(age)


# ---------------------------------------------#
# function: object_age()
# calculate the age of an object relative to the data of the sos report
# return the result as n.m where n is year count and m is remainder portion
# e.g. if 1.5 is returned then the object is a one and one half years old.
# ---------------------------------------------#
def object_age(arg_date):

    # debug_print(z,arg_date)

    days = "Sun Mon Tue Wed Thu Fri Sat"

    month = Key_data()
    month["Jan"] = "01"
    month["Feb"] = "02"
    month["Mar"] = "03"
    month["Apr"] = "04"
    month["May"] = "05"
    month["Jun"] = "06"
    month["Jul"] = "07"
    month["Aug"] = "08"
    month["Sep"] = "09"
    month["Oct"] = "10"
    month["Nov"] = "11"
    month["Dec"] = "12"

    days_at_month = Counter()
    # (ingoring leap years - fuzzy math)
    # Ja Fe Ma Ap Ma Ju Ju Au Se Oc No
    days_at_month["01"] = 0
    days_at_month["02"] = 0 + 31
    days_at_month["03"] = 0 + 31 + 28
    days_at_month["04"] = 0 + 31 + 28 + 31
    days_at_month["05"] = 0 + 31 + 28 + 31 + 30
    days_at_month["06"] = 0 + 31 + 28 + 31 + 30 + 31
    days_at_month["07"] = 0 + 31 + 28 + 31 + 30 + 31 + 30
    days_at_month["08"] = 0 + 31 + 28 + 31 + 30 + 31 + 30 + 31
    days_at_month["09"] = 0 + 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31
    days_at_month["10"] = 0 + 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30
    days_at_month["11"] = 0 + 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30 + 31
    days_at_month["12"] = 0 + 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30 + 31 + 30
    # Ja Fe Ma Ap Ma Ju Ju Au Se Oc No

    if len(arg_date) == len("yyyy-mm-dd"):
        tmp = arg_date.split("-")  # yyyy-mm-dd
        arg_yyyy = tmp[0]
        arg_mm = tmp[1]
        arg_dd = tmp[2]
    else:
        tmp = arg_date.split()  # format1: Wed Aug 26 15:10:15 EDT 2015
        # format2: Mon Sep  1 16:35:02 2014
        # 0,  1, 2,       3,  4,   5
        arg_dow = tmp[0]
        if not word_in_list(arg_dow, days):
            debug_print(0, "arg '{0}' dow:{1}?".format(arg_date, arg_dow))
        arg_mm = tmp[1]
        arg_mm = month[arg_mm]  # conv "Nov" to "11", etc
        arg_dd = tmp[2]
        arg_time = tmp[3]
        if len(tmp[4]) == 4 and tmp[4].isdigit():
            arg_tz = ''
            arg_yyyy = tmp[4]
        else:
            arg_tz = tmp[4]
            arg_yyyy = tmp[5]

    arg_year = int(arg_yyyy)
    arg_days = days_at_month[arg_mm] + int(arg_dd)

    sos_date = get_general_data("date")
    # sos_date format: Wed Aug 26 15:10:15 EDT 2015  # (from the time command)
    # or rarely: 2015xx 05xx 06xx xxxxx hh:mm:ss TZ
    if sos_date == '':
        return 0
    if "XXX.XXX.XXX.XXX" in sos_date:
        return 0

    sos_date = sos_date.replace(',', ' ')  # remove any punctuation
    words = sos_date.split()
    if word_in_list(words[0], days) and month[words[1]] != '':
        sos_mm = words[1]
        sos_mm = month[sos_mm]  # conv "Nov" to "11", etc
        sos_dd = words[2]
        sos_yyyy = words[5]
    elif words[0].startswith("20"):
        sos_yyyy = words[0][0:4]
        sos_mm = words[1][0:2]
        sos_dd = words[2][0:2]
        # Japanese date caused problems: '2016年  6月  6日 月曜日 04:26:03 JST'
        # strip off anything non-numeric
        if not sos_mm[1:2].isdigit():
            sos_mm = sos_mm[0:1]
        if not sos_dd[1:2].isdigit():
            sos_dd = sos_dd[0:1]
    else:
        sos_mm = foreign_date(sos_date, "MM")
        if sos_mm == '':
            return 0
        sos_mm = month[sos_mm]  # conv "Nov" to "11", etc
        sos_dd = foreign_date(sos_date, "DD")
        sos_yyyy = foreign_date(sos_date, "YYYY")

    sos_year = int(sos_yyyy)
    sos_days = days_at_month[sos_mm] + int(sos_dd)

    if sos_days < arg_days:
        sos_days = sos_days + 365
        sos_year = sos_year - 1

    age_year = sos_year - arg_year
    age_days = sos_days - arg_days

    age = float(age_year) + round((float(age_days) / 365), 1)
    debug_print(3, "sos:{0}-{1}-{2} {3} {4} kern:{5}-{6}-{7} {8} {9} age:{10} {11} {12}".
                format(sos_yyyy, sos_mm, sos_dd, sos_year, sos_days,
                       arg_yyyy, arg_mm, arg_dd, arg_year, arg_days,
                       age, age_year, age_days))

    return age


# ---------------------------------------------#
# function: foreign_date()
# take apart foreign fomratted date string
# ---------------------------------------------#
def foreign_date(date_str, ele):

    # English.Italian.Spanish.French.German"
    months = ""\
             "Jan.gen.ene.jan.Jan. "\
             "Feb.feb.feb.fév.Feb. "\
             "Mar.mar.mar.mar.März. "\
             "Apr.apr.abr.avr.Apr. "\
             "May.mag.may.mai.Mai. "\
             "Jun.giu.jun.juin.Juni.  "\
             "Jul.lug.jul.juillet.Juli. "\
             "Aug.ago.ago.août.Aug. "\
             "Sep.set.set.sep.Sep. "\
             "Oct.ott.oct.oct.Okt. "\
             "Nov.nov.nov.nov.Nov. "\
             "Dec.dic.dic.déc.Dez. "\
             ""

    w0 = ''
    w1 = ''
    w2 = ''
    w3 = ''
    w4 = ''
    w5 = ''
    tmp = date_str.split()
    tc = len(tmp)
    w0 = tmp[0]
    if tc > 1:
        w1 = tmp[1]
    if tc > 2:
        w2 = tmp[2]
    if tc > 3:
        w3 = tmp[3]
    if tc > 4:
        w4 = tmp[4]
    if tc > 5:
        w5 = tmp[5]

    if ele == "DD":
        for i in range(0, tc):
            dd = tmp[i]
            if dd.isdigit():
                if int(dd) >= 1 and int(dd) <= 31:
                    return(dd)
        return '0'

    if ele == "YYYY":
        for i in range(0, tc):
            yyyy = tmp[i]
            if yyyy.isdigit():
                if int(yyyy) >= 2000 and int(yyyy) <= 2099:
                    return(yyyy)
        return '0'

    if ele != "MM":
        return 'error'  # ??

    ml1 = months.split()
    mc1 = len(ml1)
    for mon_list in ml1:
        mons = mon_list.split('.')
        mc2 = len(mons)
        for mon in mons:
            if w2 == mon:
                return(mons[0])  # return the english month on match

    return ''

# ---------------------------------------------#
# function: find_est_kernel_rel_date()
# check in var/log/messages for Linux line:
# Oct  2 11:44:56 appdb1 kernel: Linux version 2.6.18-308.el5 (mockbuild@boris.build.redhat.com) (gcc version 4.1.2 20080704 (Red Hat 4.1.2-50)) # 1 SMP Fri Jan 27 17:24:02 EST 2012
#
# if no match found, return date of most recently released kernel prior to this one
# ---------------------------------------------#


def find_est_kernel_rel_date(kernel_token):
    global kernelStr  # Key_data()
    # global ke_level # Key_data()
    global rh_date  # Key_data()

    if kernelStr['date'] != '':
        return(kernelStr['date'])

    tmp = kernel_token.split(".")
    maj = int(tmp[0])
    min = int(tmp[1])
    rel1 = int(tmp[2])
    rel2 = int(tmp[3])

    est_date = ''
    while rel2 > 0:
        rel2 -= 1
        # rh_ma_mi = ke_level[kernel_normalize(maj,min,rel1,rel2)]
        rh_ma_mi = kern_2_rhel(kernel_normalize(maj, min, rel1, rel2))
        if rh_ma_mi != '':
            est_date = rh_date[rh_ma_mi]
        if est_date != '':
            return(est_date)
    return('')

# ---------------------------------------------#
# function: find_kernel_level()
# return the kernel level associated with the version of rhel passed in.
# e.g. find_kernel_level("6.5") returns 2.6.32.431
# ---------------------------------------------#


def find_kernel_level(rh_version):
    global rh_kernel_range  # Key_data()
    # global ke_level # Key_data()
    global rh_date  # Key_data()

    if rh_version.find(".") == -1:
        return('')

    tmp = rh_version.split(".")
    if len(tmp) != 2:
        return('')

    tmp_rh_maj = tmp[0]
    tmp_rh_min = tmp[1]

    if not tmp_rh_maj.isdigit():
        return('')
    if not tmp_rh_min.isdigit():
        return('')

    # e.g.: rh_kernel_range[5] = "02.006.0018.0008 02.006.0018.0398"
    kernel_range = rh_kernel_range[int(tmp_rh_maj)]
    if kernel_range == '':
        return('')

    tkr = kernel_range.split()
    k_lo = tkr[0]
    k_hi = tkr[1]
    tkr = k_lo.split(".")
    k_lo_maj = int(tkr[0])
    k_lo_min = int(tkr[1])
    k_lo_r1 = int(tkr[2])
    k_lo_r2 = int(tkr[3])

    tkr = k_hi.split(".")
    k_hi_maj = int(tkr[0])
    k_hi_min = int(tkr[1])
    k_hi_r1 = int(tkr[2])
    k_hi_r2 = int(tkr[3])

    # example of ke_level: ke_level["02.006.0018.0274"] = "5.7"
    for kmaj in range(k_lo_maj, k_hi_maj + 1):
        for kmin in range(k_lo_min, k_hi_min + 1):
            for kr1 in range(k_lo_r1, k_hi_r1 + 1):
                for kr2 in range(k_lo_r2, k_hi_r2 + 1):
                    tkmaj = "{0}".format(kmaj)
                    tkmin = "{0}".format(kmin)
                    tkr1 = "{0}".format(kr1)
                    tkr2 = "{0}".format(kr2)
                    kl_tmp = "{0}.{1}.{2}.{3}".\
                             format(tkmaj.rjust(2, '0'),
                                    tkmin.rjust(3, '0'),
                                    tkr1.rjust(4, '0'),
                                    tkr2.rjust(4, '0'))
                    # debug_print(z,"{0} {1}".format(kl_tmp,ke_level[kl_tmp]))
                    # if ke_level[kl_tmp] == rh_version:
                    if kern_2_rhel(kl_tmp) == rh_version:
                        kl_tmp = "{0}.{1}.{2}.{3}".format(kmaj, kmin, kr1, kr2)
                        return(kl_tmp)
    return('')  # should not occur (for the most part)

# ---------------------------------------------#
# function: check_misc_items()
# ---------------------------------------------#


def check_misc_items():
    global grub  # Key_data()
    global cmdline  # Key_data()
    global all_filesystems
    global all_fs_types
    global fs_2_mountpoint
    global fs_2_pctused
    global fs_2_type
    global fs_2_opts
    global all_vg_names
    global Virtual_guest
    # global Oracle
    global database_server  # False
    global anomaly_points  # Counter()
    global service_procs  # Key_data()
    global cfa_text  # "check for applicability of"
    global all_schedulers  # ""
    global scheduler_2_devs  # Key_data()
    global mfg_lun_count  # Counter()
    global rh_major
    global all_gpfs_problem_servers  # ''
    global pct_mem_buff_cache  # ''
    global per_cpu_load_avg_15min  # 0.0
    global page_allocation_failure_count  # 0
    global all_write_cache_disabled_devs  # ''
    global all_read_cache_disabled_devs  # ''

    if grub['GRUB_CMDLINE_LINUX'] != '':
        grub_cmdline = grub['GRUB_CMDLINE_LINUX']
        grub_quote = grub_cmdline[0:1]
        grub_cmdline = grub_cmdline.strip(grub_quote)
        tmp = grub_cmdline.split()
        twc = len(tmp)
        for grub_word in tmp:
            if grub_word.startswith("rd.lvm.lv=") and "swap" in grub_word:
                gt = grub_word.split("=")
                if len(gt) == 2:
                    swap_spec = gt[1]  # word 2
                    sww = swap_spec.split("/")
                    if len(sww) == 2:
                        vg = sww[0]
                        vg = update_vg(vg, '', 'etc/default/grub')
                        lv = sww[1]
                        swap_id = build_vg_lv(vg, lv, 'etc/default/grub')
                        if word_in_list(vg, all_vg_names):
                            match_count = 0
                            mis_match_count = 0
                            filesystems = all_filesystems.split()
                            for fs in filesystems:
                                if fs_2_type[fs] == "swap":
                                    if fs.endswith("/" + swap_id) or \
                                        fs.endswith("/" + swap_id.replace("-", "/")) or fs == "/dev/" + swap_spec:
                                            match_count += 1
                                    else:
                                        mis_match_count += 1
                            if match_count == 0 and mis_match_count > 0:
                                for fs in filesystems:
                                    if fs_2_type[fs] == "swap":
                                        debug_print(0, "{0} {1}".format(fs, swap_id))
                                        if not fs.endswith("/" + swap_id):
                                            anomaly_line = "GRUB swap parameter [{0}] does not appear to match swap filesystem [{1}], {2}".format(swap_spec, fs, cfa_sfdc("01498755"))
                                            handle_anomaly("SWAP", anomaly_line)

    io_sched = cmdline['elevator']
    if io_sched == '':
        io_sched = '<unknown>'
    deadline_devs = 0
    noop_devs = 0
    cfq_devs = 0
    if all_schedulers != "":
        deadline_devs = wordcount(scheduler_2_devs["deadline"])
        noop_devs = wordcount(scheduler_2_devs["noop"])
        cfq_devs = wordcount(scheduler_2_devs["cfq"])

    if Virtual_guest:
        if io_sched != "noop":
            anomaly_line = "This {0} virtual machine will benefit by switching from the {1} to the noop io scheduler, see KCA {2} & KCS {3}".\
                           format(Virtual_type, io_sched, kca_url("46958"), kcs_url("109223"))
            handle_anomaly_with_points("VM", anomaly_line, 'performance', 1)
            if all_schedulers != "":
                anomaly_line = "Current specific device scheduler distribution: cfq[{0}], deadline[{1}], noop[{2}]".\
                               format(cfq_devs, deadline_devs, noop_devs)
                handle_anomaly_with_points("VM", anomaly_line, 'performance', 1)
    else:
        if database_server and io_sched != "deadline":
            anomaly_line = "This '{0}' database server will benefit by switching from the {1} to the deadline io scheduler, see KCS {2} & {3}".\
                           format(database_vendors_found, io_sched, kcs_url("54164"), kcs_url("32376"))
            handle_anomaly_with_points("KERN", anomaly_line, 'performance', 1)
            if all_schedulers != "":
                anomaly_line = "Current specific device scheduler distribution: cfq[{0}], deadline[{1}], noop[{2}]".\
                               format(cfq_devs, deadline_devs, noop_devs)
                handle_anomaly_with_points("KERN", anomaly_line, 'performance', 1)

    if anomaly_points['lvm'] > 1 and service_procs['midaemon'] > 0:  # 1 lvm point for now..
        anomaly_line = "lvm issues found and midaemon present, {0} {1} & {2}".\
                       format(cfa_text, "https://softwaresupport.hpe.com/kb/KM02370410", sfdc_url("01675090"))
        handle_anomaly("LVM", anomaly_line)

    if mfg_lun_count["XTREMIO"] > 0 and service_procs["multipathd"] > 0 and rh_major == 7:
        anomaly_line = "XtremIO luns found and multipathd active, check multipath conf blacklisting, {0}".\
                       format(cfa_kcs("1159113"))
        handle_anomaly("MULTIPATHCONF", anomaly_line)

    if all_gpfs_problem_servers != '':
        anomaly_line = "The following gpfs nodes experienced problems: [{0}]".format(all_gpfs_problem_servers)
        handle_anomaly("GPFS", anomaly_line)

    if per_cpu_load_avg_15min > 1.0 and \
       (is_float(pct_mem_buff_cache) and pct_mem_buff_cache > 85) and \
       page_allocation_failure_count > 0:
        anomaly_line = "Found high load average and buff/cache usage, coupled with page allocation errors, consider dropping cache, see {0}".format(kcs_url("5409"))
        handle_anomaly("KERN", anomaly_line)

    wcd_dev_cnt = wordcount(all_write_cache_disabled_devs)
    if wcd_dev_cnt > 0:
        anomaly_line = "Found {0} device{1} with write cache disabled. This can adversely impact write performance.".format(wcd_dev_cnt, plural(wcd_dev_cnt))
        handle_anomaly("PERF", anomaly_line)
    rcd_dev_cnt = wordcount(all_read_cache_disabled_devs)
    if rcd_dev_cnt > 0:
        anomaly_line = "Found {0} device{1} with read cache disabled. This can adversely impact read performance.".format(rcd_dev_cnt, plural(rcd_dev_cnt))
        handle_anomaly("PERF", anomaly_line)
    return

# ---------------------------------------------#
# function: check_vmware_time_out()
# if virtual and timeout amount is less than 180 seconds reference kcs
# ---------------------------------------------#


def check_vmware_time_out(line, words, source):
    global Virtual_guest

    if not Virtual_guest:
        return(False)

    wc = len(words)
    len_of_timeout = words[wc - 1]
    if not len_of_timeout.endswith("s"):
        return(False)  # ?

    len_of_timeout = len_of_timeout.strip("s")
    if not len_of_timeout.isdigit():
        return(False)  # ??

    scsi_adr = normalize_scsi_adr(words[2])
    if scsi_adr != '':
        mfg = scsi_lun_mfg[scsi_adr]
        model = scsi_lun_mfg_model[scsi_adr]
        if word_in_list(mfg, "VMWARE QEMU VBOX MSFT") or "Virt" in model or "VBOX" in model:
            anomaly_line = "{0}, check virtual disk [{1}] status with {2} team".format(line, lun_2_dev[scsi_adr], mfg)
            handle_anomaly("SCSI", anomaly_line)

    timeout_value = int(len_of_timeout)
    if timeout_value >= 180:
        return(False)

    return True

# ---------------------------------------------#
# function: check_for_port_flap()
# ---------------------------------------------#


def check_for_port_flap(scan_block, source):
    device_reset_min = 4

    reset_issued_count = scan_count[scan_block]  # ID_DEVICE_RESET_ISSUED
    reset_failed_count = scan_count[get_scan_block("ID:DEVICE_RESET_FAILED")]
    reset_succeeded_count = scan_count[get_scan_block("ID:DEVICE_RESET_SUCCEEDED")]
    if reset_issued_count > device_reset_min and (reset_failed_count + reset_succeeded_count) > device_reset_min:
        anomaly_line = "Check for port flap: {0} device resets issued, {1} device resets failed, {2} device resets succeeded".\
                       format(reset_issued_count, reset_failed_count, reset_succeeded_count)
        handle_anomaly_with_points("QLA", anomaly_line, 'hardware', (reset_failed_count * 2))

    return
# ---------------------------------------------#
# function: check_for_port_flap_alt()
# ---------------------------------------------#


def check_for_port_flap_alt(scan_block, source):
    device_reset_min = 4

    reset_issued_count = scan_count[scan_block]  # ID_DEVICE_RESET_ISSUED_ALT
    reset_failed_count = scan_count[get_scan_block("ID:DEVICE_RESET_FAILED_ALT")]
    reset_succeeded_count = scan_count[get_scan_block("ID:DEVICE_RESET_SUCCEEDED_ALT")]
    if reset_issued_count > device_reset_min and (reset_failed_count + reset_succeeded_count) > device_reset_min:
        anomaly_line = "Check for port flap: {0} device resets issued, {1} device resets failed, {2} device resets succeeded".\
                       format(reset_issued_count, reset_failed_count, reset_succeeded_count)
        handle_anomaly_with_points("QLA", anomaly_line, 'hardware', (reset_failed_count * 2))

    return

# ---------------------------------------------#
# function: check_for_qla_loop_up_down()
# ---------------------------------------------#


def check_for_qla_loop_up_down(scan_block, source):
    qla_loop_up_down_min = 4

    qla_loop_up_count = scan_count[get_scan_block("ID:QLA2XXX_LOOP_UP_DETECTED")]
    qla_loop_down_count = scan_count[get_scan_block("ID:QLA2XXX_LOOP_DOWN_DETECTED")]
    if qla_loop_up_count and qla_loop_down_count and ((qla_loop_up_count + qla_loop_down_count) >= qla_loop_up_down_min):
        anomaly_line = "Multiple qla2xxx LOOP UP({0}) and LOOP DOWN({1}) events encountered, {2} ({3})".\
                       format(qla_loop_up_count, qla_loop_down_count, cfa_kcs("499833"), source)
        handle_anomaly_with_points("QLA", anomaly_line, 'hardware', (qla_loop_down_count + qla_loop_up_count))

    return

# ---------------------------------------------#
# function: do_lpfc_link()
# ---------------------------------------------#


def do_lpfc_link(scan_block, source):
    global max_host
    lpfc_link_up_events = scan_count[scan_block]
    lpfc_link_down_events = scan_count[get_scan_block("ID:lpfc_link_down")]

    # if lpfc_link_down_events > (max_host + 1) and lpfc_link_up_events > (max_host + 1):
    if lpfc_link_down_events > 1 and lpfc_link_up_events > 1:
        anomaly_line = "Multiple lpfc link UP({0}) and link DOWN({1}) events encountered, {2}".\
                       format(lpfc_link_up_events, lpfc_link_down_events, cfa_kcs("33221"))
        handle_anomaly_with_points("LPFC", anomaly_line, 'hardware', (lpfc_link_down_events + lpfc_link_up_events))

    return

# ---------------------------------------------#
# function: do_sata_link()
# ---------------------------------------------#


def do_sata_link(scan_block, source):
    global max_host

    sata_link_id = get_scan_block_id(scan_block)

    sata_link_up_events = scan_count[get_scan_block("ID:sata_link_up")]
    sata_link_down_events = scan_count[get_scan_block("ID:sata_link_down")]
    # debug_print(0,"{0} link up events {1}, link down events {2}".format(sata_link_id,sata_link_up_events,sata_link_down_events))

    # If do_sata_link() is being called w/sata_link_down id and sata_link_up_events > 0 then
    # the routine has already been called with id sata_link_up and the anomaly issued.
    # Processing will continue if only sata_link_down events were encountered
    if sata_link_id == "ID:sata_link_down" and sata_link_up_events > 0:
        return

    sata_link_hard_reset_events_1 = scan_count[get_scan_block("ID:sata_link_hard_reset_1")]
    sata_link_hard_reset_events_2 = scan_count[get_scan_block("ID:sata_link_hard_reset_2")]
    sata_link_hard_resets = sata_link_hard_reset_events_1 + sata_link_hard_reset_events_2

    # if sata_link_down_events > (max_host + 1) and sata_link_up_events > (max_host + 1):
    # if sata_link_down_events > sata_link_up_events:

    issue_anomaly = False

    if (sata_link_hard_resets == 0) and \
            (sata_link_down_events > 0 and sata_link_up_events == 0):
            issue_anomaly = True

    if (sata_link_hard_resets > 0) and \
            (sata_link_down_events + sata_link_up_events) > 0:
            issue_anomaly = True
    if issue_anomaly:
        anomaly_line = "Multiple sata link UP({0}) and link DOWN({1}) events encountered (with {2} hard resets), {3}".\
                       format(sata_link_up_events, sata_link_down_events, sata_link_hard_resets, cfa_kcs("293693"))
        handle_anomaly_with_points("SATA", anomaly_line, 'hardware', (sata_link_down_events + sata_link_up_events))

    return


# ---------------------------------------------#
# function: do_mpathd_error()
# "multipathd: checker failed path <major:minor> in map <map_name>"
# |                                      |                  |
# +--> # end: MULTIPATHD KCS nnnnnn       |                  |
# +--> MULTIPATHD (m:m lookup failed)
# |
# +--> MULTIPATHD (map lookup failed)
#
# multipathd: checker failed path 8:128 in map 360050768018207232800000000000231
# ---------------------------------------------#
def do_mpathd_error(line, words, source):
    global scsi_id_2_devs
    global mm_2_bd_aliases  # Key_data()
    global mm_checker_failed_path  # ''
    global mm_lookup_failed  # ''
    global mm_not_assoc_w_mapname  # ''

    line = line.strip()
    debug_print(3, "'{0}' ({1})".format(line, source))

    # multipathd: checker failed path maj:min in map <str>
    # words = line.split() # created and passed by do_scan_block()
    mm = words[4]
    map_name = words[7]
    mm_checker_failed_path = unique_list(mm_checker_failed_path, mm)

    dev_id = conv_mm_2_bd(mm)

    if dev_id == "":
        # "major/minor lookup failed for ma:mi associated with map_name'
        # anomaly_line = "major/minor lookup failed for {0} associated with {1} '{2} ({3})".\
                        # format(mm,map_name,line,source)
        # handle_anomaly("MULTIPATHD",anomaly_line)
        mm_lookup_failed = unique_list(mm_lookup_failed, mm)
        return

    if word_in_list(dev_id, mp_2_devs[map_name]):
        return

    dm_ids = dev_2_dms[dev_id]

    if dm_ids != "":
        dms = dm_ids.split()
        for dm_id in dms:
            dm_mm = conv_id_2_mm(dm_id, "dm")
            if dm_mm != "":
                # if map_name == major_minor_2_mp[dm_mm]: return
                if map_name == mm_2_bd_aliases[dm_mm]:
                    return

    # if map name is a scsi id (36...) then check dev id in its associated device list
    devs = scsi_id_2_devs[map_name]
    if word_in_list(dev_id, devs):
        return

    # "ma:mi[dev_id] not associated with map_name'
    # anomaly_line = "{0}[{1}] not associated with {2} '{3}' ({4})".format(mm,dev_id,map_name,line,source)
    # handle_anomaly("MULTIPATHD",anomaly_line)
    mm_not_assoc_w_mapname = unique_list(mm_not_assoc_w_mapname, mm)

    return

# ---------------------------------------------#
# function: check_multipath_anomalies()
# ---------------------------------------------#


def check_multipath_anomalies():
    global mm_lookup_failed  # ''
    global mm_not_assoc_w_mapname  # ''
    global devs_in_checker_reports_path  # ''
    global devs_scsi_lookup_failed  # ''
    global mm_multipath_err_getting_dev  # ''
    global mm_multipath_err_getting_dev_mm_lookup_failed  # ''

    wc0 = word_count(mm_checker_failed_path)
    wc1 = word_count(mm_lookup_failed)
    wc2 = word_count(mm_not_assoc_w_mapname)

    wca = word_count(devs_in_checker_reports_path)
    wcb = word_count(devs_scsi_lookup_failed)

    wcx = word_count(mm_multipath_err_getting_dev)
    wcy = word_count(mm_multipath_err_getting_dev_mm_lookup_failed)
    blurb = "Check for existence of note on messages evaluated prior to reboot, below."

    if wc1 > 0:
        anomaly_line = "out of {0} unique major:minor number{1} in 'multipathd: checker failed path maj:min in map map_name' {2} {3} not found. {4}".\
                       format(wc0, plural(wc0), wc1, was_were(wc1), blurb)
        handle_anomaly("MULTIPATHD", anomaly_line)

    if wc2 > 0:
        anomaly_line = "out of {0} unique major:minor number{1} in 'multipathd: checker failed path maj:min in map map_name' {2} {3} not associated with 'map_name'. {4}".\
                       format(wc0, plural(wc0), wc2, was_were(wc2), blurb)
        handle_anomaly("MULTIPATHD", anomaly_line)

    # if wc2 > 0:
    # anomaly_line = "{0}[{1}] not associated with {2} '{3}' ({4})".format(mm,dev_id,map_name,line,source)
    # handle_anomaly("MULTIPATHD",anomaly_line)

    if wcb > 0:
        anomaly_line = "out of {0} unique device name{1} in '... checker reports path is up/down/timed out', {2} {3} not associated with a scsi address. {4}".\
                       format(wca, plural(wca), wcb, was_were(wcb), blurb)
        handle_anomaly("MULTIPATHD", anomaly_line)

    if wcy > 0:
        anomaly_line = "out of {0} unique major:minor number{1} in 'kernel: device-mapper: table: maj:min: error getting device', {2} {3} not associated with a device. {4}".\
                       format(wcx, plural(wcx), wcy, was_were(wcy), blurb)
        handle_anomaly("MULTIPATH", anomaly_line)
    return


# ---------------------------------------------#
# function: do_mpathd_mark_as_failed()
# "multipathd: ma:mi mark as failed"
# ---------------------------------------------#
def do_mpathd_mark_as_failed(line, words, source):
    # debug_print(z,"'{0}' ({1})".format(line,source))
    mm = words[1].rstrip(':')
    sd_dev = conv_mm_2_bd(mm)
    # debug_print(z,"conv_mm_2_bd({0}):'{1}'".format(mm,sd_dev))
    if sd_dev == "":
        return
    scsi_adr = dev_2_lun[sd_dev]
    if scsi_adr == "":
        return
    io_path_ha_bus_tgt_lun(scsi_adr, line, source)  # count path errors
    return


# ---------------------------------------------#
# function: do_mpathd_checker_reports_path_state_a()
#
# "multipathd: sd_re: .* checker reports path (is up/down | in standby state)
#
# multipathd: sdcc: tur checker reports path in standby state  # case
# multipathd: sdah: tur checker reports path is up/down
# multipathd: sdu: readsector0 checker reports path is up/down
# multipathd: sdcr: checker msg is "directio checker reports path is up/down"
# multipathd: ORA_ASM_300G_T2_DISK35: sdk - tur checker reports path is up
# multipathd: sdalh: checker msg is "emc_clariion_checker: query command indicates error": readsector0 checker reports path is down (case )
# ---------------------------------------------#
def do_mpathd_checker_reports_path_state_a(line, words, source):

    # debug_print(z,line)
    if "checker msg is" in line:
        line = line.replace("checker msg is ", '')
        line = line.replace('"', '')
        words = line.split()

    if "emc_clariion_checker: query command indicates error" in line:
        line = line.replace("emc_clariion_checker: query command indicates error", '')
        line = line.replace(': ', '')
        words = line.split()
        # debug_print(z,line)

    if line.endswith("in standby state"):
        line = line.replace("in standby state", "in standby")
        words = line.split()
        # debug_print(z,line)

    wc = len(words)
    sd_dev = words[1]
    checker = words[2]
    state = words[wc - 1]
    # state = words[7]
    if not word_in_list(state, "up down standby") and wc > 7:
        state = words[7]
    do_mpathd_checker_reports_path_state_common(line, words, source, '', sd_dev, checker, state)
    return

# ---------------------------------------------#
# function: do_mpathd_checker_reports_path_state_b()
# "multipathd: .*: sd_re - .* checker reports path is up/down
#
# multipathd: mpathav: sdad - directio checker reports path is up/down
# multipathd: 3600507630affc6c70000000000004624: sdd - tur checker reports path is up/down
# multipathd: SIBM     2107900        7578631061A: sdgu - directio checker reports path is down  (case )
#
# sdad - directio checker reports path is up/down
# w0  w1 w2       w3      w4      w5   w6 w7
# ---------------------------------------------#


def do_mpathd_checker_reports_path_state_b(line, words, source):

    # debug_print(z,line)
    line = line[len("mulitpathd: "):]  # reminder of line without "multipathd: "
    x = line.find(':')
    mpath_dev = squeeze(line[0:x + 1])
    line = line[x + 2:]

    # line should now look something like: 'sdgu - directio checker reports path is down'
    words = line.split()
    wc = len(words)

    # mpath_dev = words[1]
    # sd_dev = words[2]

    sd_dev = words[0]
    checker = words[2]
    state = words[wc - 1]
    if not word_in_list(state, "up down") and wc > 7:
        state = words[7]
    do_mpathd_checker_reports_path_state_common(line, words, source, mpath_dev, sd_dev, checker, state)
    return

# ---------------------------------------------#
# function: do_mpathd_checker_reports_path_state_common()
# ---------------------------------------------#


def do_mpathd_checker_reports_path_state_common(line, words, source, mpath_dev, sd_dev, checker, state):
    global dev_2_lun
    global multipath_checkers_reporting_errors  # ''
    global checker_down_count  # Counter()
    global checker_up_count  # Counter()
    global checker_standby_count  # Counter()
    global checker_timed_out_count  # Counter()
    global devs_in_checker_reports_path  # ''
    global devs_scsi_lookup_failed  # ''

    mpath_dev = mpath_dev.rstrip(':')
    sd_dev = sd_dev.rstrip(':')
    checker = checker.rstrip(':')
    state = state.rstrip(':')
    scsi_adr = dev_2_lun[sd_dev]

    devs_in_checker_reports_path = unique_list(devs_in_checker_reports_path, sd_dev)

    # debug_print(z,"{0} [{1}] '{2}' ({3})".format(sd_dev,state,line,source))
    if scsi_adr == '':
        # anomaly_line = "no scsi adr for {0} '{1}' ({2})".format(sd_dev,line.rstrip(),source)
        # handle_anomaly("MULTIPATHD",anomaly_line)
        devs_scsi_lookup_failed = unique_list(devs_scsi_lookup_failed, sd_dev)
    else:
        if word_in_list(state, "down standby"):
            io_path_ha_bus_tgt_lun(scsi_adr, line, source)  # count path errors

    if state == "down":
        multipath_checkers_reporting_errors = unique_list(multipath_checkers_reporting_errors, checker)
        checker_down_count[checker] += 1
    elif state == "out":
        multipath_checkers_reporting_errors = unique_list(multipath_checkers_reporting_errors, checker)
        checker_timed_out_count[checker] += 1
    elif state == "up":
        checker_up_count[checker] += 1
    elif state == "standby":
        multipath_checkers_reporting_errors = unique_list(multipath_checkers_reporting_errors, checker)
        checker_standby_count[checker] += 1
    else:
        error_print('d', "'{0}' '{1}' ({2})".format(state, line, source))
        errorprint(8 / 0)
    return

# ---------------------------------------------#
# function: do_mpathd_checker_summary():
# ---------------------------------------------#


def do_mpathd_checker_summary(scan_block, source):
    global Oracle, all_dev_mfgs
    global multipath_checkers_reporting_errors  # ''
    global checker_down_count  # Counter()
    global checker_up_count  # Counter()
    global checker_standby_count  # Counter()
    global checker_timed_out_count  # Counter()

    scan_elements = scan_block.split("~")
    for element in scan_elements:
        if element.startswith("ID:mpathd-"):
            this_id = element
    # end: for element in scan_elements:

    # debug_print(z,"{0} -> {1}".format(this_id,scan_count[scan_block]))
    if scan_count[scan_block] == 0:
        return

    if this_id == "ID:mpathd-b":
        scan_block_4a = get_scan_block("ID:mpathd-a")
        scan_elements_4a = scan_block_4a.split("~")
        if scan_count[scan_block_4a] > 0:
            return  # did summary when called for MULTIPATHD

    if this_id == "ID:mpathd-d":
        scan_block_4c = get_scan_block("ID:mpathd-c")
        scan_elements_4c = scan_block_4c.split("~")
        if scan_count[scan_block_4c] > 0:
            return  # did summary when called for MULTIPATHD

    if this_id == "ID:mpathd-a":
        state = "down"
    elif this_id == "ID:mpathd-b":
        state = "down"
    elif this_id == "ID:mpathd-c":
        state = "up"
    elif this_id == "ID:mpathd-d":
        state = "up"
    elif this_id == "ID:mpathd-e":
        state = "timed out"
    elif this_id == "ID:mpathd-f":
        state = "standby"

    checkers = multipath_checkers_reporting_errors.split()
    # debug_print(z,multipath_checkers_reporting_errors)

    for checker in checkers:

        blurb = ''

        if state == "down":
            cnt = checker_down_count[checker]
            blurb = "[total_path_errors++]"
            if checker == "tur":
                blurb = ", {0} {1}".format(blurb, cfa_kcs("32833"))
            elif checker == "directio" and (Oracle or word_in_list('NETAPP', all_dev_mfgs)):
                blurb = ", {0} {1} & {2}".format(blurb, cfa_kcs("32833"), kcs_url("133643"))
            elif checker == "readsector0":
                blurb = ", {0} {1} & {2}".format(blurb, cfa_kcs("122813"), kcs_url("103923"))
        elif state == "timed out":
            cnt = checker_timed_out_count[checker]
            blurb = "[total_path_errors++]"
        elif state == "standby":
            cnt = checker_standby_count[checker]
            blurb = "[total_path_errors++]"
        elif state == "up":
            cnt = checker_up_count[checker]
        else:
            cnt = -1  # should not happen

        anomaly_line = squeeze("Found {0} 'multipathd: .* sdcc {1} checker reports path {2}' message{3} {4} ({5})".
                               format(cnt, checker, state, plural(cnt), blurb, source))
        handle_anomaly("MULTIPATHD", anomaly_line)

    return

# ---------------------------------------------#
# function do_mpathd_query_command_indicates_error_a()
# multipathd: sdb: emc_clariion_checker: query command indicates error
# multipathd: sdi: emc prio: query command indicates error
# multipathd: sdb: checker msg is "emc_clariion_checker: query command indicates error"
# ---------------------------------------------#


def do_mpathd_query_command_indicates_error_a(line, words, source):

    if "checker msg is" in line:
        line = line.replace("checker msg is ", '')
        line = line.replace('"', '')
        words = line.split()

    if "emc prio:" in line:
        line = line.replace("emc prio:", "emc_prio:")
        words = line.split()

    sd_dev = words[1]
    query_cmd = words[2]
    do_mpathd_query_command_common(line, words, source, '', sd_dev, query_cmd)
    return

# ---------------------------------------------#
# function do_mpathd_query_command_indicates_error_b()
# multipathd: mpatha: sdb: - emc_clariion_checker: query command indicates error
# multipathd: 36006016057e03000c6d14713b1d2e111: sdb: - emc_clariion_checker: query command indicates error
# ---------------------------------------------#


def do_mpathd_query_command_indicates_error_b(line, words, source):

    if "emc prio:" in line:
        line = line.replace("emc prio:", "emc_prio:")
        words = line.split()

    mpath_dev = words[1]
    sd_dev = words[2]
    query_cmd = words[4]
    do_mpathd_query_command_common(line, words, source, mpath_dev, sd_dev, query_cmd)
    return

# ---------------------------------------------#
# function: do_mpathd_query_command_common()
# ---------------------------------------------#


def do_mpathd_query_command_common(line, words, source, mpath_dev, sd_dev, query_cmd):
    global dev_2_lun
    global multipath_query_cmds_reporting_errors  # ''
    global query_cmd_count  # Counter()

    mpath_dev = mpath_dev.rstrip(':')
    sd_dev = sd_dev.rstrip(':')
    query_cmd = query_cmd.rstrip(':')
    scsi_adr = dev_2_lun[sd_dev]

    if scsi_adr == '':
        anomaly_line = "no scsi adr for {0} '{1}' ({2})".format(sd_dev, line.rstrip(), source)
        handle_anomaly("MULTIPATHD", anomaly_line)
    else:
        io_path_ha_bus_tgt_lun(scsi_adr, line, source)

    multipath_query_cmds_reporting_errors = unique_list(multipath_query_cmds_reporting_errors, query_cmd)
    query_cmd_count[query_cmd] += 1
    return

# ---------------------------------------------#
# function: do_mpathd_query_cmd_summary():
# ---------------------------------------------#


def do_mpathd_query_cmd_summary(scan_block, source):
    global multipath_query_cmds_reporting_errors  # ''
    global query_cmd_count  # Counter()

    qcmds = multipath_query_cmds_reporting_errors.split()
    for query_cmd in qcmds:
        cnt = query_cmd_count[query_cmd]

        anomaly_line = "Found {0} 'multipathd: sdcc {1} query command indicates error' message{2} ({3})".format(cnt, query_cmd, plural(cnt), source)
        handle_anomaly("MULTIPATHD", anomaly_line)

    return

# ---------------------------------------------#
# function: lun_assignment_check()
# ---------------------------------------------#


def lun_assignment_check(scan_block, source):
    global total_blocked_task_count
    global blocked_duration
    global Oracle

    lun_assignments_changed_count = scan_count[scan_block]

    scan_elements = scan_block.split("~")
    scan_pattern = scan_elements[0]
    tmp = scan_pattern.split()
    lun_type = tmp[1]

    if total_blocked_task_count > 0 and rhel_is("EQ", "5") and Oracle:
        anomaly_line = "Found {0} '{1} LUN assignment changed' message{2} and {3} 'task blocked for more than {4} seconds.' message{5}, "\
            "{5} ({6})".\
            format(lun_assignments_changed_count, lun_type, plural(lun_assignments_changed_count),
                   total_blocked_task_count, blocked_duration, plural(total_blocked_task_count),
                   cfa_kcs("1598403"), source)
        handle_anomaly("SD", anomaly_line)
    else:
        anomaly_line = "Found {0} '{1} LUN assignment changed' message{2} "\
            "{3} ({4})".\
            format(lun_assignments_changed_count, lun_type, plural(lun_assignments_changed_count),
                   cfa_kcs("53023"), source)
        handle_anomaly("SD", anomaly_line)

    return

# ---------------------------------------------#
# function: device_mapper_error_getting_device()
#
# kernel: device-mapper: table: 253:19: multipath: error getting device
# |                              |
# |                              |
# |                              +---- MULTIPATH (major/minor lookup fails)
# |
# +---- MULTIPATH (the message itself)
# ---------------------------------------------#


def device_mapper_error_getting_device(line, source):
    # global dm_2_path_errs # Counter()
    global mm_2_path_errs  # Counter()
    global multipath_err_getting_dev_mm_lookup_failed  # 0
    global mm_multipath_err_getting_dev  # ''  # unique list of mm numbers from above msg
    global mm_multipath_err_getting_dev_mm_lookup_failed  # '' # unique list mm numbers from above msg where mm lookup failed

    # debug_print(z,"'{0}' ({1})".format(line,source))

    # kernel: device-mapper: table: 253:19: multipath: error getting device
    # kernel: [  344.212692] device-mapper: table: 253:17: multipath: error getting device

    words = line.split()
    wc = len(words)
    if wc > 10:
        return  # should only occur rarely when there is lots of '<n>' junk in syslog data..

    if words[2] == 'table:':
        major_minor = words[3].rstrip(':')
    else:
        return

    if not valid_major_minor(major_minor, False, source):
        return  # most likely corrupt syslog data

    dev_id = conv_mm_2_bd(major_minor)
    mm_multipath_err_getting_dev = unique_list(mm_multipath_err_getting_dev, major_minor)

    if dev_id == "":
        # anomaly_line = "major/minor lookup failed for {0} '{1}' ({2})".format(major_minor,line,source)
        # handle_anomaly("MULTIPATH",anomaly_line)
        mm_multipath_err_getting_dev_mm_lookup_failed = unique_list(mm_multipath_err_getting_dev_mm_lookup_failed, major_minor)
    else:
        # dm_2_path_errs[dev_id]+=1
        mm_2_path_errs[major_minor] += 1

    debug_print(3, "{0} '{1}' -> {2}".format(major_minor, dev_id, line))

    return

# ---------------------------------------------#
# function: do_lin_tape()
# track IBMtapennn on scsi address
# called with either:
# kernel: lin_tape: detected device at host 5, channel 0, id 28, lun 0
# kernel: lin_tape: attached IBMtape26
# would have been nice if they had written all the info on one line but they didn't
# so we have combine the data from the two lines.
# ---------------------------------------------#


def do_lin_tape(line, words, line_no, source):
    global lintape_2_scsi  # Key_data()
    global lintape_2_scsi_origin  # Key_data()
    global scsi_2_lintape  # Key_data()
    global scsi_2_lintape_origin  # Key_data()
    global all_lintapes  # ""
    global last_lintape_scsi_adr  # ""
    global max_lintape  # 0

    if words[2] == "detected":
        host = words[6].strip(",")
        bus = words[8].strip(",")
        target = words[10].strip(",")
        lun = words[12]
        scsi_adr = "{0}:{1}:{2}:{3}".format(host, bus, target, lun)
        scsi_adr = normalize_scsi_adr(scsi_adr)
        if scsi_adr.endswith(":49409"):
            return  # see comment in crunch_scsi_scsi
        bld_ha_bus_tgt_lun(scsi_adr, source)
        last_lintape_scsi_adr = scsi_adr
        return

    if words[2] == "attached" and last_lintape_scsi_adr == "":  # should not occur
        error_print("d", "'{0}'".format(line))
        return

    if words[2] == "attached" and last_lintape_scsi_adr != "":
        lintape = words[3]
        max_lintape = max(max_lintape, len(lintape))
        all_lintapes = unique_list(all_lintapes, lintape)
        if lintape_2_scsi[lintape] == "":
            lintape_2_scsi[lintape] = last_lintape_scsi_adr
            lintape_2_scsi_origin[lintape] = source
        else:
            if lintape_2_scsi[lintape] != last_lintape_scsi_adr:
                action = file_check(lintape_2_scsi_origin[lintape], source)
                if do_anomaly(action):
                    anomaly_line = "lintape {0} already has scsi adr set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                        format(lintape, lintape_2_scsi[lintape], lintape_2_scsi_origin[lintape], last_lintape_scsi_adr, action, source)
                    handle_anomaly("DUP-1", anomaly_line)
                if action == "overridden":
                    lintape_2_scsi[lintape] = last_lintape_scsi_adr
                    lintape_2_scsi_origin[lintape] = source
        if scsi_2_lintape[last_lintape_scsi_adr] == "":
            scsi_2_lintape[last_lintape_scsi_adr] = lintape
            scsi_2_lintape_origin[last_lintape_scsi_adr] = source
        else:
            if scsi_2_lintape[last_lintape_scsi_adr] != lintape:
                action = file_check(scsi_2_lintape_origin[last_lintape_scsi_adr], source)
                if do_anomaly(action):
                    anomaly_line = "scsi adr {0} already has lintape set to {1} ({2}), attempting to set to {3} [{4}] ({5})".\
                        format(last_lintape_scsi_adr, scsi_2_lintape[last_lintape_scsi_adr], scsi_2_lintape_origin[last_lintape_scsi_adr], lintape, action, source)
                    handle_anomaly("DUP-2", anomaly_line)
                if action == "overridden":
                    scsi_2_lintape[last_lintape_scsi_adr] == lintape
                    scsi_2_lintape_origin[last_lintape_scsi_adr] == source
        debug_print(3, "{0} {1}".format(last_lintape_scsi_adr, lintape))
        last_lintape_scsi_adr = ""
        return


# ---------------------------------------------#
# function: do_nfs_not_responding()
# kernel: nfs: server <name> not responding, timed out
# kernel: nfs: server <name> not responding, still trying
# kernel: nfsacl: server <name> not responding, timed out
# kernel: nfsacl: server <name> not responding, still trying
# ---------------------------------------------#
def do_nfs_not_responding(line, words, source):
    global all_nfs_servers  # ''
    global nfs_servers_tmo  # Counter()   # key: nfs server name  data: count of times nfs server not responding
    nfs_server = words[3]
    all_nfs_servers = unique_list(all_nfs_servers, nfs_server)
    nfs_servers_tmo[nfs_server] += 1
    return


# ---------------------------------------------#
# function: check_nfs_not_responding()
# ---------------------------------------------#
def check_nfs_not_responding():
    global all_nfs_servers  # ''
    global nfs_servers_tmo  # Counter()   # key: nfs server name  data: count of times nfs server timed out
    if all_nfs_servers == '':
        return

    high_nfs_server = ''
    high_nfs_server_tmo_count = 0

    total_no_response_cnt = 0
    total_no_response_server_cnt = 0

    words = all_nfs_servers.split()
    wc = len(words)
    for nfs_server in words:
        if nfs_servers_tmo[nfs_server] > 0:
            total_no_response_cnt += nfs_servers_tmo[nfs_server]
            total_no_response_server_cnt += 1
            if nfs_servers_tmo[nfs_server] > high_nfs_server_tmo_count:
                high_nfs_server = nfs_server
                high_nfs_server_tmo_count = nfs_servers_tmo[nfs_server]
    # end: for nfs_server in words:

    if total_no_response_server_cnt == 0:
        return

    anomaly_line = "Found {0} nfs server{1} not responding, high nfs server {2} [{3} out of {4}]".\
                   format(total_no_response_server_cnt, plural(total_no_response_server_cnt),
                          high_nfs_server, high_nfs_server_tmo_count, total_no_response_cnt)
    handle_anomaly_with_points("NFS", anomaly_line, 'nfs', wc)
    return

# ---------------------------------------------#
# function: check_dm_mp_loaded()
# These messages are generally from var/log/dmesg and therefore the 'kernel:' portion is manufactured by sumsos
# (kernel:) device-mapper: multipath: version 1.9.0 loaded
# (kernel:) device-mapper: multipath round-robin: version 1.0.0 loaded
# (kernel:) device-mapper: multipath service-time: version 0.2.0 loaded
# (kernel:) device-mapper: multipath queue-length: version 0.1.0 loaded
# ---------------------------------------------#


def check_dm_mp_loaded(line, words, source):
    global multipath_modules  # ''
    if words[2] == "multipath:":
        module = words[2]
        version = words[4]
    else:
        module = words[3]
        version = words[5]

    data = module + version
    multipath_modules = unique_list(multipath_modules, data)
    return

# ---------------------------------------------#
# function: check_segfault_lines()
# track segfault data
# kernel: nailslogd[32430]: segfault at 11c ip 0000000000c06914 sp 00000000ffdf544c error 4 in libsqlite.so.0.8.6[bd3000+5b000]
# ---------------------------------------------#


def check_segfault_lines(line, words, source):
    global segfault_lines  # 0
    global serfault_module  # Counter()
    global all_segfault_modules  # ""

    segfault_lines += 1
    module = words[1]
    br_beg = module.find("[")
    module = module[0:br_beg]
    if "/" in module:
        tmp = module.split("/")
        wc = len(tmp)
        module = tmp[wc - 1]

    segfault_module[module] += 1
    all_segfault_modules = unique_list(all_segfault_modules, module)
    return

# ---------------------------------------------#
# function: check_segfault_anomalies()
# ---------------------------------------------#


def check_segfault_anomalies():
    global segfault_lines  # 0
    global segfault_module  # Counter()
    global all_segfault_modules  # ""
    debug_print(3, "{0} '{1}'".format(segfault_lines, all_segfault_modules))
    if segfault_lines == 0:
        return
    blurb = ""
    if all_segfault_modules != "":
        tmp_list = sort_list(all_segfault_modules)
        tmp = tmp_list.split()
        for module in tmp:
            blurb = "{0} {1}[{2}]".format(blurb, module, segfault_module[module])
        # end: for module in tmp:

    blurb = squeeze(blurb)
    if blurb == '':
        blurb = '[no module data]'
    blurb = "module data: " + blurb
    anomaly_line = "Found {0} 'kernel: module[nnnnn]: segfault at ...' message{1}, {2}".\
                   format(segfault_lines, plural(segfault_lines), blurb)
    handle_anomaly("SEGFAULT", anomaly_line)
    if word_in_list("multipath", all_segfault_modules):
        anomaly_line = "For multipath segfaults, {0}".format(cfa_bz("1349376"))
        handle_anomaly("SEGFAULT", anomaly_line)
    return

# ---------------------------------------------#
# function: check_abort_lines()
# track abort data
# abrt[pid]: Saved core dump of pid nnnnn (/path/module) to /var/spool/... (nnnnnnn bytes)
# ---------------------------------------------#


def check_abort_lines(line, words, source):
    global abort_lines  # 0
    global abort_module  # Counter()
    global all_aborted_modules  # ""

    abort_lines += 1
    module = words[7].strip("()")
    if module == "to":
        return  # no module info

    if "/" in module:
        tmp = module.split("/")
        wc = len(tmp)
        module = tmp[wc - 1]
    abort_module[module] += 1
    all_aborted_modules = unique_list(all_aborted_modules, module)
    return

# ---------------------------------------------#
# function: check_abort_anomalies()
# ---------------------------------------------#


def check_abort_anomalies():
    global abort_lines  # 0
    global abort_module  # Counter()
    global all_aborted_modules  # ""
    debug_print(3, "{0} '{1}'".format(abort_lines, all_aborted_modules))
    if abort_lines == 0:
        return
    blurb = ""
    if all_aborted_modules != "":
        tmp_list = sort_list(all_aborted_modules)
        tmp = tmp_list.split()
        for module in tmp:
            blurb = "{0} {1}[{2}]".format(blurb, module, abort_module[module])
        # end: for module in tmp:

    blurb = squeeze(blurb)
    if blurb == '':
        blurb = '[no module data]'
    blurb = "module data: " + blurb
    anomaly_line = "Found {0} 'abrt[nnnnn]: Saved core dump of pid nnnnn (/path/module)' message{1}, {2}".\
                   format(abort_lines, plural(abort_lines), blurb)
    handle_anomaly("ABRT", anomaly_line)
    return

# ---------------------------------------------#
# function: display_release_and_kernel()
# ---------------------------------------------#


def display_release_and_kernel():
    global release, release_extra, release_origin
    global rh_major, rh_minor
    # global ke_level # Key_data()
    global kernelStr  # Key_data()
    global kernel_version_line  # ''
    global ATTN
    global s390

    shipped_with_blurb = ''
    release_ma_mi = "{0}.{1}".format(rh_major, rh_minor)

    corr_rh_kern_level = ''
    corr_rh_kern_date = ''
    if release_ma_mi != "0.0" and "Red Hat" in release:
        corr_rh_kern_level = find_kernel_level(release_ma_mi)
        if corr_rh_kern_level != '':
            corr_rh_kern_date = kern_2_date(kernel_string_normalize(corr_rh_kern_level))

    release_blurb = ''
    if "Beta" in release:
        release_blurb = "{0} Non-GA".format(ATTN)

    kernel_extra = ''
    if s390:
        kernel_extra = "{0} IBM System/Z".format(ATTN)
    if "ppc" in kernelStr["arch"]:
        kernel_extra = "{0} powerPC".format(ATTN)

    kernel_type = kern_2_type(kernelStr['expanded'])
    kernel_rh_ma_mi = kern_2_rhel(kernelStr['expanded'])
    kernel_date = kern_2_date(kernelStr['expanded'])
    kernel_release_data = ''
    kernel_attn = ''

    if kernel_type == "RHEL GA" or kernel_type == "errata":
        kernel_release_data = "({0} {1}, released {2})".format(kernel_rh_ma_mi,
                                                               kernel_type,
                                                               kernel_date)
    elif kernel_type != '<unknown>':
        kernel_attn = "{0} Non-RHEL Kernel! ({1})".format(ATTN, kernel_type)
    else:
        kernel_attn = ''  # "{0} Non-RHEL Kernel! ({1})".format(ATTN,kernel_type)

    if kernel_type == "errata" or (kernel_rh_ma_mi != release_ma_mi and kernel_rh_ma_mi != ''):
        shipped_with_blurb = "({0} shipped with {1}, released {2})".format(release_ma_mi,
                                                                           corr_rh_kern_level,
                                                                           corr_rh_kern_date)

    if release == '':
        release = '<unknown>'
    errorprint(squeeze("release: {0} {1} {2} {3} ({4})".format(release,
                                                               release_extra,
                                                               release_blurb,
                                                               shipped_with_blurb,
                                                               release_origin)))

    # debug_print(z,kernel_type)
    # debug_print(z,kernelStr['level'])
    kernel = kernelStr['level']
    if kernel == '':
        kernel = '<unknown>'
    errorprint(squeeze("kernel: {0} {1} {2} {3}".format(kernel,
                                                        kernel_extra,
                                                        kernel_release_data,
                                                        kernel_attn)))

    if kernelStr['builder'] != '' and kernelStr['builder'] != "RedHat":
        errorprint("Non-RedHat kernel builder: {0}{1}".format(kernelStr['builder'], ATTN))
        if "Oracle" in kernelStr['builder'] and OracleLinux_lines != '':
            errorprint("OracleLinux: {0}".format(OracleLinux_lines))
        errorprint("")

    if "Red Hat" in release:
        rh_age = kernel_age("{0}.{1}".format(rh_major, rh_minor))
        k_age = kernel_age(kernelStr['expanded'])
        if rh_age > 2.5:
            errorprint("Warning: Running an older RHEL ({0} years old){1}".format(rh_age, ATTN))
        if k_age > 2.5:
            errorprint("Warning: Running an older kernel ({0} years old){1}".format(k_age, ATTN))

    # end: if "Red Hat" in release:

    debug_print(1, "complete")
    return

# ---------------------------------------------#
# function: display_boot_disk()
# ---------------------------------------------#


def display_boot_disk():
    global kernelStr  # Key_data()
    grub_dev_map = "boot/grub/device.map"
    if kernelNum['major'] >= 3:  # RHEL 7+ (allow for fedora too)
        grub_dev_map = "boot/grub2/device.map"

    fh = openfile(grub_dev_map)
    if fh is None:
        return

    boot_disk = "unknown"
    i = 0

    for line in fh:
        line = line[0:len(line) - 1]  # remove trailing \n

        i += 1
        if i == 2 and len(line) > 1:
            boot_disk = line

    errorprint("boot disk: {0} ({1})".format(boot_disk, grub_dev_map))
    errorprint("")

    closefile(fh, i)
    debug_print(1, "read {0} lines from {1}".format(i, grub_dev_map))
    return

# ---------------------------------------------#
# function: set_scan_blocks()
# ---------------------------------------------#


def set_scan_blocks():
    global alphabet_words

    global kernel_specific_ids
    global daemon_specific_ids

    global newline  # "\n"

    for var_id in kernel_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_name_scan_table = 'kernel_' + tmp[0] + '_scan_table'
        var_name_blocks = 'kernel_' + tmp[0] + '_scan_blocks'
        el = 'global {0},{1}; {2} = {3}.split(newline)'.format(var_name_blocks, var_name_scan_table, var_name_blocks, var_name_scan_table)
        exec(el)
        el = 'global {0}; lkesbs = len({1})'.format(var_name_blocks, var_name_blocks)
        exec(el)
        debug_print(1, "{0} {1}".format(lkesbs, var_name_blocks))
    # end: for var_id in daemon_specific_ids:

    for l in alphabet_words:
        kmst = 'kernel_misc_' + l + '_scan_table'
        kmsbs = 'kernel_misc_' + l + '_scan_blocks'
        el = 'global {0},{1}; {2} = {3}.split(newline)'.format(kmsbs, kmst, kmsbs, kmst)
        exec(el)
        el = 'global {0}; lkmsbs = len({1})'.format(kmsbs, kmsbs)
        exec(el)
        debug_print(1, "{0} {1}".format(lkmsbs, kmsbs))

    #
    #

    for var_id in daemon_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_name_scan_table = 'daemon_' + tmp[0] + '_scan_table'
        var_name_blocks = 'daemon_' + tmp[0] + '_scan_blocks'
        el = 'global {0},{1}; {2} = {3}.split(newline)'.format(var_name_blocks, var_name_scan_table, var_name_blocks, var_name_scan_table)
        exec(el)
        el = 'global {0}; ldmsbs = len({1})'.format(var_name_blocks, var_name_blocks)
        exec(el)
        debug_print(1, "{0} {1}".format(ldmsbs, var_name_blocks))
    # end: for var_id in daemon_specific_ids:

    for l in alphabet_words:
        dmst = 'daemon_misc_' + l + '_scan_table'
        dmsbs = 'daemon_misc_' + l + '_scan_blocks'
        el = 'global {0},{1}; {2} = {3}.split(newline)'.format(dmsbs, dmst, dmsbs, dmst)
        exec(el)
        el = 'global {0}; ldmsbs = len({1})'.format(dmsbs, dmsbs)
        exec(el)
        debug_print(1, "{0} {1}".format(ldmsbs, dmsbs))

    return

# ---------------------------------------------#
# function: sum_scan_blocks()
# ---------------------------------------------#


def sum_scan_blocks():
    global alphabet_words
    global kernel_specific_ids
    global daemon_specific_ids

    for var_id in kernel_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_name_blocks = 'kernel_' + tmp[0] + '_scan_blocks'
        el = 'global {0}; scan_blocks = {1}'.format(var_name_blocks, var_name_blocks)
        exec(el)
        for scan_block in scan_blocks:
            if scan_count[scan_block] == 0:
                continue
            do_scan_block(scan_block, 0, '', "SUMMARY", 0, scan_origin[scan_block])
        # end: for scan_block in scan_blocks:
    # end: for var_id in daemon_specific_ids:

    for l in alphabet_words:
        # exec 'scan_blocks = kernel_misc_'+l+'_scan_blocks'
        kmsbs = 'kernel_misc_' + l + '_scan_blocks'
        el = 'global {0}; scan_blocks = {1}'.format(kmsbs, kmsbs)
        exec(el)
        for scan_block in scan_blocks:
            if scan_count[scan_block] == 0:
                continue
            do_scan_block(scan_block, 0, '', "SUMMARY", 0, scan_origin[scan_block])
        # end: for scan_block in scan_blocks:
    # end: for l in alphabet_words:

    #
    for var_id in daemon_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_name_blocks = 'daemon_' + tmp[0] + '_scan_blocks'
        el = 'global {0}; scan_blocks = {1}'.format(var_name_blocks, var_name_blocks)
        exec(el)
        for scan_block in scan_blocks:
            if scan_count[scan_block] == 0:
                continue
            do_scan_block(scan_block, 0, '', "SUMMARY", 0, scan_origin[scan_block])
        # end: for scan_block in scan_blocks:
    # end: for var_id in daemon_specific_ids:

    for l in alphabet_words:
        # exec 'scan_blocks = daemon_misc_'+l+'_scan_blocks'
        dmsbs = 'daemon_misc_' + l + '_scan_blocks'
        el = 'global {0}; scan_blocks = {1}'.format(dmsbs, dmsbs)
        exec(el)
        for scan_block in scan_blocks:
            if scan_count[scan_block] == 0:
                continue
            do_scan_block(scan_block, 0, '', "SUMMARY", 0, scan_origin[scan_block])
        # end: for scan_block in scan_blocks:
    # end: for l in alphabet_words:

    return

# ---------------------------------------------#
# function: get_scan_block()
# ---------------------------------------------#


def get_scan_block(id):
    global alphabet_words
    global kernel_specific_ids
    global daemol_specific_ids
    for var_id in kernel_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_blocks_name = 'kernel_' + tmp[0] + '_scan_blocks'
        el = 'global {0}; scan_block = get_scan_block_2({1},id)'.format(var_blocks_name, var_blocks_name)
        exec(el)
        if scan_block != '':
            return(scan_block)
    # end: for var_id in kernel_specific_ids:

    for l in alphabet_words:
        var_blocks_name = 'kernel_misc_' + l + '_scan_blocks'
        el = 'global {0}; scan_block = get_scan_block_2({1},id)'.format(var_blocks_name, var_blocks_name)
        exec(el)
        if scan_block != '':
            return(scan_block)
    # end: for l in alphabet_words:

    #

    for var_id in daemon_specific_ids:
        if var_id == '' or var_id.startswith('# '):
            continue
        tmp = var_id.split('|')
        var_blocks_name = 'daemon_' + tmp[0] + '_scan_blocks'
        el = 'global {0}; scan_block = get_scan_block_2({1},id)'.format(var_blocks_name, var_blocks_name)
        exec(el)
        if scan_block != '':
            return(scan_block)
    # end: for var_id in daemon_specific_ids:

    for l in alphabet_words:
        var_blocks_name = 'daemon_misc_' + l + '_scan_blocks'
        el = 'global {0}; scan_block = get_scan_block_2({1},id)'.format(var_blocks_name, var_blocks_name)
        exec(el)
        if scan_block != '':
            return(scan_block)
    # end: for l in alphabet_words:

    return('')

# ---------------------------------------------#
# function: get_scan_block_2()
# run an array of scan_blocks looking for id
# ---------------------------------------------#


def get_scan_block_2(scan_blocks, id):

    for scan_block in scan_blocks:
        if id == get_scan_block_id(scan_block):
            return(scan_block)
    # end: for scan_block in scan_blocks:
    return('')

# ---------------------------------------------#
# function: get_scan_block_id()
# return the 'ID:...' value of a scan block
# ---------------------------------------------#


def get_scan_block_id(scan_block):
    scan_elements = scan_block.split("~")
    for element in scan_elements:
        if element.startswith("ID:"):
            return(element)
    # end: for element in scan_elements:
    return('')

# ---------------------------------------------#
# function: chk_configuration()
# ---------------------------------------------#


def chk_configuration():
    global sysctl
    global total_mem
    global Oracle

    errorprint("** start of configuration related section **")
    errorprint("")

    errorprint("")
    errorprint("** end of configuration related section **")

# ---------------------------------------------#
# function: check_table_data()
# ---------------------------------------------#


def check_table_data(table_string, table_id):
    c1 = table_string.count("|")
    c2 = table_string.count("~")
    if c1 == c2:
        return
    error_line = "Count of '|' characters [{0}] not equal count of '~' characters [{1}] in {2}".format(c1, c2, table_id)
    exit_print(error_line, RC_SKIPPED)


# =============================================#
# end of functions
# =============================================#

# ---------------------------------------------#
# ---------------------------------------------#
# ---------------------------------------------#
#
# # end: int main()
#
# MAIN()/Main/main
#
# check arguements:
# options (see usage() section)
# arg(1) = sos report file name or top-level directory
# name of extracted sosreprort
# (default is the cwd)
#
# ---------------------------------------------#
# ---------------------------------------------#
# ---------------------------------------------#
#
#
# qtttbbbmmmttthhh
kb = 1024
mb = kb * kb  # 1048576
gb = mb * kb  # 1073741824
tb = gb * kb  # 1099511627776
pb = tb * kb  # 1125899906842624
# qtttbbbmmmttthhh

all_size_modifiers = "b kb mb gb tb pb"
modifier_2_size = Key_data_m1()
modifier_2_size['b'] = 1
modifier_2_size['kb'] = kb
modifier_2_size['mb'] = mb
modifier_2_size['gb'] = gb
modifier_2_size['tb'] = tb
modifier_2_size['pb'] = pb

big_num = 9999999999999999

newline = "\n"

alphabet_list = "a b c d e f g h i j k l m n o p q r s t u v w x y z wc"
alphabet_words = alphabet_list.split()

printset = set(string.printable)

# callback_level is used to control FUNC(<name>) LINE(<line no.>) data printed out by lower level routines
callback_level = 0

first_time = time.time()  # used  at end
last_time = first_time  # used by debug prints
hostname = ""
hostname_short = ""  # without domain qualifiers, if present in hostname
uname_nodename = ""
uname_nodename_short = ""  # without domain qualifiers, if present in uname_nodename

this_script_name = os.path.basename(sys.argv[0])
sw_leave = False
tmp_dir = ""

ATTN = " <<<------ "
total_anomaly_count = 0
# anomaly_list = Key_data()
# anomaly_list = [anomaly_types][1 to ~]
#
# Note: any lower case anomaly ids are an indication that they are available to be used in the code.
# N.B.: the last id in each row must have a space after it.
anomaly_types = ""\
    "ABRT "\
    "BE2NET "\
    "BZ "\
    "CH "\
    "CLUSTER "\
    "CMDLINE "\
    "DASD "\
    "DATA-1 DATA-2 DATA-3 DATA-4 DATA-5 "\
    "DETACH "\
    "DUP-1 DUP-2 DUP-3 "\
    "DMSETUP "\
    "DT "\
    "EMC "\
    "EXT3 "\
    "EXT4 "\
    "FCOE "\
    "FD "\
    "FS "\
    "FW "\
    "GPFS "\
    "HPE "\
    "HUNG "\
    "HW "\
    "IOERR "\
    "ISCSI "\
    "KCS "\
    "KDUMP "\
    "KERN "\
    "LOCKUP "\
    "LPFC "\
    "LVM "\
    "LVMCONF "\
    "LVMW "\
    "MCE "\
    "MEM "\
    "MFG "\
    "MODPROBE "\
    "MULTIPATH "\
    "MULTIPATHCONF "\
    "MULTIPATHD "\
    "NETWORK "\
    "NFS "\
    "NOTE "\
    "ORACLE "\
    "PERF "\
    "PCI "\
    "PROC "\
    "QLA "\
    "RHEV "\
    "RPM "\
    "RPORT "\
    "RSRV "\
    "SATA "\
    "SCSI "\
    "SD "\
    "SEGFAULT "\
    "SERVICE "\
    "SES "\
    "SFDC "\
    "SR "\
    "ST "\
    "SWAP "\
    "SYSTEMD "\
    "TAINT "\
    "THIRDPARTY "\
    "UDEV "\
    "VERITAS "\
    "VM "\
    "VMCORE "\
    "VMWARE "\
    "XFS "\
    ""
words = anomaly_types.split()
max_anomaly_count = 2000
max_disp_anomaly_count = 20
anomaly_counts = Counter()  # Key: Anomaly type Data: count

# ----------------------------- #
sw_debug = False
sw_debug = True  # allow for easy testing using debug_print(0,'...')  (switch 0 to the appropriate level after testing)
sw_debug_level = 0

data_xxx_out = False            # see case
# ----------------------------- #
total_sos_files_opened = 0      # total number of sos report files opened for reading
# N.B. some files are opened more than once
total_sos_files_closed = 0      # total number of sos report files closed (should equal files opened - logic check)
total_sos_lines_read = 0        # total number of sos report file lines read
# ----------------------------- #
messages_file_count = 0
messages_line_count = 0
messages_skipped = 0  # count of messages which were skipped over for scan processing
messages_skipped_mark_or_repeat = 0  # count of messages which were skipped over for scan processing
messages_skipped_inv_hdr = 0  # count of messages which were skipped over for scan processing
messages_skipped_not_this_nodename = 0  # count of messages which were skipped over for scan processing
messages_skipped_skip_prefix = 0  # count of messages which were skipped over for scan processing
total_esc_messages_count = 0

first_message_timestamp = ''
last_message_timestamp = ''

no_data_message_lines = "No journal files were found.\n"\
                        "-- No entries --\n"

last_timestamp = ''
last_reboot_timestamp = ''

dmesg_files = "var/log/dmesg "\
              "sos_commands/kernel/dmesg "\
              "sos_commands/general/dmesg_now"

messages_fn = "messages"    # usual case, although can vary, for instance,  under Ubuntu it is kern.log
first_message_file_read = ''  # actual file name of first messages file read

if not file_exists("var/log/messages"):
    if file_exists("var/log/syslog"):
        messages_fn = "syslog"
    elif file_exists("var/log/kern.log"):
        messages_fn = "kern.log"


debug_print(1, messages_fn)

messages_file_list = "var/log/" + messages_fn + " "\
                     "var/log/" + messages_fn + ".gz "\
                     "sos_commands/general/tail_" + messages_fn + " "\
                     "sos_commands/general/tail_" + messages_fn + ".gz "\
                     "sos_commands/logs/journalctl_--no-pager_--boot "\
                     "sos_commands/logs/journalctl_--all_--this-boot_--no-pager "\
                     ""
syslog_nodenames_found = ''  # unique list of all syslog nodenames encountered
syslog_nodename_count = Counter()  # key: nodename data: count of that nodename in syslog lines
syslog_nodenames_match = ''  # unique list of all syslog nodenames which match this host (usually just 1, but can be 'foo foo.com')
syslog_nodenames_match_words = ''  # set to syslog_nodenames_match.split()
syslog_nodename_word_count = 0  # len(syslog_nodenames_match_words)
syslog_nodename_status = ''  # status line indicating outcome of nodename analysis in messages file
last_nodename = ''
last_nodename_matches_this_host = False
prev_msg_line = ''
prev_scan_msg = ''
last_non_match_line_0 = ''
last_non_match_line_1 = ''
last_non_match_line_2 = ''
last_non_match_line_3 = ''
skip_same_last_non_match = 0

# ----------------------------- #

# assign a point value to some anomaly types in order to direct more analysis into general areas when possible
all_anomaly_point_types = "hardware "\
                          "performance "\
                          "configuration "\
                          "rport "\
                          "lpfc "\
                          "qla2xxx "\
                          "be2net "\
                          "fcoe "\
                          "iscsi "\
                          "lvm "\
                          "multipath "\
                          "cluster "\
                          "filesystem "\
                          "nfs "\
                          ""
anomaly_points = Counter()  # Key: Anomaly point type (one of all_anomaly_point_types)  Data: point value

last_anomaly_type = ""
last_anomaly_line = ""
duplicate_anomalies_skipped = 0
duplicate_anomaly_counts = Counter()  # Key: Anomaly type Data: count


ioerr_abeod_sd = 0  # count of IOERR abeod sd io errors
ioerr_abeod_dm = 0  # count of IOERR abeod dm io errors
ioerr_abeod_misc = 0  # count of IOERR abeod non-sd & dm io errors

darted_file_spec = ''     # general file spec for parted/fdisk files with 'ul' errors
parted_sd_ul_errors = 0   # count of parted sd 'unrecognised label' errors
parted_dm_ul_errors = 0   # count of parted dm 'unrecognised label' errors
parted_misc_ul_errors = 0  # count of parted misc 'unrecognised label' errors
all_unrecognised_disk_label_devices = ''  # list of /dev/sd.. or /dev/dm-nn devices without recognised labels
all_vgs_with_no_pvs = ''  # list of all VGs with no PVs
all_vgs_with_missing_pvs = ''  # list of all VGs with missing PVs
vg_nopvs_found = 0        # number of VGs (with no PVs) found in etc/lvm/backup


# used to parse the various version of dmsetup files
rr_tracks = "|- \_ `- `- └─  ─  ├─ | │"   # requires the utf declaration at top-of-file
rr_tracks_exterior = "| │"   # used to determine if there are multiple levels accessed via an outside track:

#
# Regex data:
#
var_spaces = "\s+"  # represents a variable number of spaces
zero_or_more_spaces = "\s?"  # represents a variable number of spaces

hex_re = "[0-9a-fA-f]"               # valid hex digits
hex2_re = hex_re + '{1,2}'              # 1-2 hex digit number
hex4_re = hex_re + '{1,4}'              # 1-4 hex digit number
hex5_re = hex_re + '{5}'                # 5 hex digit number
hex16_re = hex_re + '{16}'               # 16 hex digit number (i.e. fc id)
mac_re = hex2_re + ":" + hex2_re + ":" + hex2_re + ":" + hex2_re + ":" + hex2_re + ":" + hex2_re  # MAC address: eg: 0e:fc:00:00:00:00

n12_re = "[0-9]{1,12}"                 # 1-12 digit number
n11_re = "[0-9]{1,11}"                 # 1-11 digit number
n10_re = "[0-9]{1,10}"                 # 1-10 digit number
n9_re = "[0-9]{1,9}"                   # 1-9 digit number
n8_re = "[0-9]{1,8}"                   # 1-8 digit number
n7_re = "[0-9]{1,7}"                   # 1-7 digit number
n6_re = "[0-9]{1,6}"                   # 1-6 digit number
n5_re = "[0-9]{1,5}"                   # 1-5 digit number
n4_re = "[0-9]{1,4}"                   # 1-4 digit number
n3_re = "[0-9]{1,3}"                   # 1-3 digit number
n2_re = "[0-9]{1,2}"                   # 1-2 digit number
n1_re = "[0-9]"                        # 1 digit number

nf4_re = "[0-9]{4}"                    # 4 digit number
nf3_re = "[0-9]{3}"                    # 3 digit number
nf2_re = "[0-9]{2}"                    # 2 digit number
nf1_re = "[0-9]{1}"                    # 1 digit number


br_time_1_ptrn = re.compile("\[[0-9]{1,8}\.[0-9]{1,8}\]")  # "[12345678.12345678]"
br_time_2_ptrn = re.compile("[0-9]{1,8}\.[0-9]{1,8}\]")    # " 12345678.12345678]"

facility_ptrn = "(auth|daemon|kern|local[0-9]|mail|syslog|user)"
daemon_nk_ptrn = "(|.*)"
priority_ptrn = "(alert|crit|emerg|err|info|notice|warning|debug)"

kernel_no_space_re = "kernel:[A-Z,a-z,\[].*"  # 'kernel:' followed by an upper or lower case letter or by '['
kernel_no_space_ptrn = re.compile(kernel_no_space_re)

tld_domain_ptrn = "(com|org|net|edu|gov|mil|int|local|localdomain)"
cc_domain_ptrn = "(ad|ae|ar|au|be|br|ca|cc|ch|cl|cn|de|es|eu|fr|gr|hk|ie|il|in|it|jp|mm|mx|nl|nz|pe|pk|ru|sa|sg|su|tv|tw|tz|uk|us|ve|za)"

Mon_re = "(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)"
Day_short_re = "(Mon|Tue|Wed|Thu|Fri|Sat|Sun)"
Day_full_re = "(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)"
hhmm_re = nf2_re + ":" + nf2_re
hhmmss_re = hhmm_re + ":" + nf2_re
hhmmssnnn_re = hhmmss_re + "\." + nf3_re
yyyy_re = nf4_re
yyyy_mm_dd_re = yyyy_re + "-" + nf2_re + "-" + nf2_re
yyyy_mon_dd_re = yyyy_re + " " + Mon_re + var_spaces + n2_re
yyyy_mon_dd_hhmmss_re = yyyy_mon_dd_re + " " + hhmmss_re

ip_addr_re = n3_re + "\." + n3_re + "\." + n3_re + "\." + n3_re
ip_addr_and_port_re = ip_addr_re + ":" + n5_re
ip_addr_and_mask_re = ip_addr_re + "/" + n3_re

scsi_adr_re = n3_re + ":" + n3_re + ":" + n3_re + ":" + n10_re

sg_re = "sg" + n4_re                  # scsi generic regex notation: sg0, sg386

lo_re = "loop" + n4_re                # loop device regex notation: loop0, loop10

sr_re = "sr" + nf1_re                 # scsi cd/dvd regex notation: sr0
sr_br_re = '\[' + sr_re + '\]'             # bracketed version: [sr0]

sd_re = 'sd[a-z]{1,3}'              # scsi disk regex notation: sda, sdfm
sd_br_re = '\[' + sd_re + '\]'             # bracketed version: [sdb]
sd_re_p = sd_re + '[0-9]{1,2}'          # scsi disk partition regex notation: sda1, sdfm3

nsd_re = 'nsd[0-9]{1,3}'             # NSD disk

vxvm_re = 'VxVM' + n5_re                 # veritas disk

vd_re = 'vd[a-z]{1,3}'              # virtio pci disk regex notation: vda, vdfm
vd_br_re = '\[' + vd_re + '\]'             # bracketed version: [vdb]
vd_re_p = vd_re + '[0-9]{1,2}'          # virtio pci disk partition regex notation: vda1, vdfm3

xvd_re = 'xvd[a-z]{1,3}'              # virtio pci disk regex notation: vda, vdfm
xvd_br_re = '\[' + xvd_re + '\]'             # bracketed version: [vdb]
xvd_re_p = xvd_re + '[0-9]{1,2}'          # virtio pci disk partition regex notation: vda1, vdfm3

drbd_re = 'drbd[0-9]{1,2}'             # drbdn devices
drbd_br_re = '\[' + drbd_re + '\]'           # bracketed version: [drbdn]

mdn_re = 'md[0-9]{1,2}'              # "multiple device" regex notation: md0, md1 (aka raid)

dfa_re = 'dfa[0-9]{1,2}'  # virtual devices dfa0, dfa1, ...

ccd_re = 'c[0-9]d[0-9]'              # HP internal disks
ccd_re_p = ccd_re + 'p[0-9]'             # . (partitions)

st_re = "st" + n3_re                  # scsi tape regex notation: st0, st12
st_br_re = '\[' + st_re + '\]'             # bracketed version: [st4]
nst_re = "nst" + n3_re                 # scsi tape regex notation "no rewind": nst0, nst12
rmt_re = "rmt" + n3_re                 # tape regex notation "no rewind": rmt0, rmt1

lt_re = "IBMtape" + n3_re             # IBM linux (lt) tape regex notation: IBMtape17
lt_ch_re = "IBMchanger" + n3_re          # IBM linux (lt) changer regex notation: IBMchanger0

tsm_re = "TSMtape" + n3_re             # TSMtape regex notation: TSMtape (Tivoli System Manger?)

dm_re = "dm-" + n4_re                 # device mapper regex notation: dm-0, dm-231
dm_pa_re = "\(" + dm_re + "\)"             # "(dm-nn)"

mpath_re = "mpath[a-z]{1,2}"

raid_re = "raid[0-9]"                 # raid notation: raid1, raid2, etc.

hda_re = "hd[a-z]"                   # hdx notation: hda, hdc, etc.
hda_re_p = hda_re + "[0-9]"              # hdx with partition notation: hda1

ide_re = "ide[0-9]"                  # ide notation: ide0, ide1, etc.

fd_re = "fd[0-9]"                   # fd notation: fd0, fd1, etc. (usually only fd0 present if at all)

pp_re = "emcpower[a-z]{1,2}"        # emc power path notation: emcpowera, ... emcpowertq

dasd_re = "dasd[a-z]"                 # IBM system/z dasd notation: dasda, dasdb
dasd_re_p = dasd_re + "[0-9]{1,2}"      # IBM system/z dase notation w/partition: dasda1, dasdb1

sddl_re = "sddlm[a-z]{1,2}"          # Oracle block disk name: sddlmkg, sddlmkh
sddl_re_p = sddl_re + "[0-9]{1,2}"       # Oracle block disk partition name: sddlmkg1, sddlmkh15

mm_re = n3_re + ":" + n7_re             # major minor regex notation: 8:2, 160:43, 253:409 201:1048575
mm_pa_re = "\(" + mm_re + "\)"             # "(maj:min)"
mm_pa_re2 = mm_pa_re.replace(":", "/")  # "(maj/min)" (notation used by Veritas)

n_dot_m_re = n2_re + "\." + n2_re          # n.m (up to 2 digits for n & m)

pa_n2_re = "\(" + n2_re + "\)"             # 1-2 digit number in parens

pid_re = n8_re                         # process id
pid_br_re = "\[" + pid_re + "\]"           # bracketed process id


ata_re = "ata" + n2_re                   # ata link; ata0, ata1 ... ata10
ata_port_re = ata_re + "\." + nf2_re       # ata link with port; ata0.00, ata1.02

pci_short_re = hex_re + '{2}:' + hex_re + '{2}\.' + hex_re + '{1}'  # pci address       xx:xx.x
pci_long_re = hex_re + '{4}:' + pci_short_re                 # pci address  xxxx:xx:xx.x
pci_br_long_re = "\[" + pci_long_re + "\]"                      # pci address [xxxx:xx:xx.x]

wwn_re = hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}:' + hex_re + '{2}'  # WWN id xx:xx:xx:xx:xx:xx:xx:xx

cuuu_re = n1_re + '\.' + n1_re + '\.' + hex_re + '{4}'  # s390 dasd address notation e.g.: 0.0.0220, 0.0.03f0
tag_re = "tag# " + n3_re                   # tag# 0, tag# 1, etc.

# re_search_list and re_replace_list must be kept in sync.
# the replace strings are substituted for the search strings in
# anomaly strings which are built from scan block reg ex search strings.
# this is all in an effort to make the resulting data a bit easier to read.
# note that order can be important for similar strings which means longer more specific strings
# appear before shorter, less specific (but similar) strings.
re_search_list = "" +\
                 ip_addr_and_port_re + " " +\
                 ip_addr_re + " " +\
                 scsi_adr_re + " " +\
                 sg_re + " " +\
                 lo_re + " " +\
                 sd_br_re + " " +\
                 sd_re_p + " " +\
                 sd_re + " " +\
                 vd_br_re + " " +\
                 vd_re_p + " " +\
                 vd_re + " " +\
                 xvd_br_re + " " +\
                 xvd_re_p + " " +\
                 xvd_re + " " +\
                 drbd_re + " " +\
                 drbd_br_re + " " +\
                 sr_br_re + " " +\
                 sr_re + " " +\
                 st_br_re + " " +\
                 st_re + " " +\
                 nst_re + " " +\
                 rmt_re + " " +\
                 lt_re + " " +\
                 lt_ch_re + " " +\
                 tsm_re + " " +\
                 dm_pa_re + " " +\
                 dm_re + " " +\
                 mm_pa_re + " " +\
                 mm_pa_re2 + " " +\
                 mm_re + " " +\
                 mpath_re + " " +\
                 mdn_re + " " +\
                 dfa_re + " " +\
                 ccd_re + " " +\
                 ccd_re_p + " " +\
                 hda_re_p + " " +\
                 hda_re + " " +\
                 pp_re + " " +\
                 dasd_re_p + " " +\
                 dasd_re + " " +\
                 cuuu_re + " " +\
                 sddl_re_p + " " +\
                 sddl_re + " " +\
                 nsd_re + " " +\
                 vxvm_re + " " +\
                 pid_br_re + " " +\
                 pid_re + " " +\
                 nf1_re + " " +\
                 nf2_re + " " +\
                 nf3_re + " " +\
                 nf4_re + " " +\
                 n12_re + " " +\
                 n11_re + " " +\
                 n10_re + " " +\
                 n9_re + " " +\
                 n8_re + " " +\
                 n7_re + " " +\
                 n6_re + " " +\
                 n5_re + " " +\
                 n4_re + " " +\
                 n3_re + " " +\
                 pa_n2_re + " " +\
                 n2_re + " " +\
                 n1_re + " " +\
                 pci_br_long_re + " " +\
                 pci_long_re + " " +\
                 pci_short_re + " " +\
                 wwn_re + " " +\
                 hex5_re + " " +\
                 hex4_re + " " +\
                 hex2_re + " " +\
                 mac_re + " " +\
                 ata_port_re + " " +\
                 ata_re + " " +\
                 fd_re + " " +\
                 ide_re + " " +\
                 raid_re + " " +\
                 "\# " +\
                 "\." +\
                 ""
#
# N.B. See regex_string_cleanup(string) for additional generic substitutions done in code rather than
# driven by the more specific correlations found in re_search_list -> re_replace_list.
#
re_replace_list = ""\
    "nnn.nnn.nnn:nnnnn "\
    "nnn.nnn.nnn "\
    "h:b:t:l "\
    "sgn "\
    "loopn "\
    "[sdccc] "\
    "sdcccn "\
    "sdccc "\
    "[vdccc] "\
    "vdcccn "\
    "vdccc "\
    "[xvdccc] "\
    "xvdcccn "\
    "xvdccc "\
    "drbdn "\
    "[drbdn] "\
    "[srn] "\
    "srn "\
    "[stn] "\
    "stn "\
    "nstn "\
    "rmtn "\
    "IBMtapen "\
    "IBMchangern "\
    "TSMtapen "\
    "(dm-nn) "\
    "dm-nn "\
    "(maj:min) "\
    "(maj/min) "\
    "maj:min "\
    "mpathcc "\
    "mdn "\
    "dfan "\
    "cndn "\
    "cndnpn "\
    "hdcn "\
    "hdc "\
    "emcpowercc "\
    "dasdcn "\
    "dasdc "\
    "n.n.xxxx "\
    "sddlmcn "\
    "sddlmc "\
    "nsdnnn "\
    "VxVMnnnnn "\
    "[nnnnnnnn] "\
    "nnnnn "\
    "n "\
    "nn "\
    "nnn "\
    "nnnn "\
    "nnnnnnnnnnnn "\
    "nnnnnnnnnnn "\
    "nnnnnnnnnn "\
    "nnnnnnnnn "\
    "nnnnnnnn "\
    "nnnnnnn "\
    "nnnnnn "\
    "nnnnn "\
    "nnnn "\
    "nnn "\
    "(nn) "\
    "nn "\
    "n "\
    "[xxxx:xx:xx.x] "\
    "xxxx:xx:xx.x "\
    "xx:xx.x "\
    "xx:xx:xx:xx:xx:xx:xx:xx "\
    "xxxxx "\
    "xxxx "\
    "xx "\
    "xx:xx:xx:xx:xx:xx "\
    "atann.nn "\
    "atan "\
    "fdn "\
    "iden "\
    "raidn "\
    "# "\
    ". "\
    ""
re_search_words = re_search_list.split()
re_replace_words = re_replace_list.split()
sw_t = False
sw_r = False
messages_start_line_ref = 0
if len(re_search_words) != len(re_replace_words):
    error_print("d:stderr", "counts of re_search_words:{0} != re_replace_words:{1}".
                format(len(re_search_words), len(re_replace_words)))
    cleanup(1)


total_hosts = 0
max_host = 0
total_buses = 0
max_bus = 0
total_targets = 0
max_target = 0
total_luns = 0
total_iscsi_luns = 0
# lo_lun added due to case  where the only luns were both 1082146837,
# which is most likely a manifistation of LUN identifier format as described by KCS 67157
lo_lun = big_num
max_lun = 0
LUNZ_count = 0
iscsi_LUNZ_count = 0
very_big_device_list = ''

total_mem = 0
pct_mem_buff_cache = ''
page_allocation_failure_count = 0

per_cpu_load_avg_1min = 0.0
per_cpu_load_avg_5min = 0.0
per_cpu_load_avg_15min = 0.0

ww_file_count = 0
total_io_errors = 0
total_path_errors = 0
total_timeouts = 0
total_dm_io_errors = 0
total_illegal_requests = 0
total_end_requests = 0

# sata_link_down_events = 0
# sata_link_up_events = 0
# lpfc_link_down_events = 0
# lpfc_link_up_events = 0
udevd_status_0100_cnt = 0

sw_performance = False
sw_configuration = False
sw_help = False
sw_leave = False
sw_cmd_fail = False
sw_sm = False
sw_sm_level = -1
sw_dm = False
sw_vg = False
sw_fs = False
sw_m = False
sw_msg_level = 0
sw_n = False
sw_r = False
sw_o = False
sw_i = False
sw_t = False
sw_u = False
sw_w = False
sw_pci = False
sw_pci_level = -1
sw_dup = False
sw_sim_oracle = False
sw_sim_vmware = False
sw_timeline = False  # -b[=d|h|m|s]
timeline_increment = ''  # Day, Hour, Minute, Second 'Nov 25 hh:mm:ss'
timeline_hdr_reduction = big_num  # big_number means 1st time, if timeline_increment != '' then its value will be something like 0, 3, ...
curr_anom_timestamp = ''
prev_anom_timestamp = ''  # prev timestamp added to variable all_timetamps
all_anom_timestamps = ''  # seperated with '~' characters (due to timestamps having spaces)
timestamp_anomalies = Key_data()  # key: timestamp data: list of anomalies occurring for this timestamp

lvm_device_to_test = ''
lvm_rule_to_eval = ''

mpc_device_to_test = ''
mpc_rule_to_eval = ''

Virtual_guest = False
Virtual_type = ""  # VMware, RHEV, etc.
Virtual_type_source = ""  # filename for source of Virtual_type
Hypervisor = False
Hypervisor_type = ""  # RHEV, XEN, etc.

database_vendors = "Oracle MySQL Db2 PostgreSQL sybase"
database_server = False
database_vendors_found = ''
database_procs = Counter()           # key: db vendor name       data: proc count          e.g. Oracle, 17

Oracle = False
OracleLinux_lines = ''

ceph_status = False
gluster_status = False
cluster_status = False
cluster_status_line = ''
corosync_ms_not_sched_total = 0.0
corosync_ms_threshold_total = 0.0
corosync_ms_msg_count = 0

dev_san_hana_count = 0
all_pci_addresses = ""               #
pci_address = Key_data()             # key: pci address         data: pci line
# # e.g. key:  0b:00.1
# # e.g. data: 'Fibre Channel: QLogic Corp. ...'
pci_address_2_hosts = Key_data()     # key: pci address         data: scsi host number(s) from unique_list(l,e)
# pci_address_2_host_origin = Key_data() # key: pci address       data: file origin name (aka source)
pci_errors = Counter()               # key: pci address         data: number of errors assoc w/this pci address
pci_devices = Key_data()             # key: pci address         data: device(s) accessable via this pci

all_dev_mfgs = ""  # EMC, NETAPP, etc. <<-- N.B. These values can be seen in upper/lower/mixed case. Because of this and
# the fact that these values are used as indices for mfg model info, we conv to UC.
all_dev_mfgs_orig = ""  # dev mfg info as originally seen w/o upper casing.
# May be needed for lvm.conf checking at some point.
max_mfg = 0
max_model = 0
mfg_lun_count = Counter()


all_hba_mfgs = ""  # Qlogic, LSI, etc.
mfg_hba_count = Counter()

all_oracle_sd_devices = ''
all_oracle_sd_device_subdirs = ''
all_oracle_sd_device_sources = ''

# oracle_procs = 0  # use database_procs["Oracle"] now...
oracle_sga = (8 * gb)

all_lsmods = ''
lsmod_data = Key_data()              # key: module name          data: size & used by data e.g. lockd  73662 nfs
lsmod_version = Key_data()           # key: module name          data: version level of kmod e.g. 3.10.0.514.6.1
event_count = Counter()              # key: event type           data: event count         e.g. lpfc 12

all_modprobe_alias_entries = ''     # eth[n], scsi_hostadapter, scsi_hostadapter[n], ipv6, etc
modprobe_alias_data = Key_data()     # key: alias name          data: alias data e.g.: scsi_adapter cciss


segfault_lines = 0                   # count of kernel module[pid]: segfault at xxx ip xxx sp xxx error n in ... messages
segfault_module = Counter()          # key: module name          data: count of times a core was saved
all_segfault_modules = ""            # list of all modules which were seen in the above message

abort_lines = 0                      # count of abrt[pid]: Save core dump of pid pid (/path/module) ... messages
abort_module = Counter()             # key: module name          data: count of times a core was saved
all_aborted_modules = ""             # list of all modules which were seen in the above message


# ---------------------------------------------#
# s390 fields (aka SystemZ, mainframe, IBM, zLinux, etc.)
# ---------------------------------------------#
s390 = False
s390_device_count = 0
max_hlq1 = 0
max_hlq2 = 0
high_cuuu = 0
low_cuuu = big_num
prev_dasd_eckd_line = 0
prev_dasd_cuu = ''
cuuu_2_class = Key_data()          # key: cuuu                 data: type              e.g. 0192     dasd
cuuu_2_class_origin = Key_data()   # key: cuuu                 data: file origin       e.g. 0192     var/log/dmesg
cuuu_2_type = Key_data()           # key: cuuu                 data: type              e.g. 0192     3390
cuuu_2_type_origin = Key_data()    # key: cuuu                 data: file origin       e.g. 0192     var/log/dmesg
cuuu_2_status = Key_data()         # key: cuuu                 data: status            e.g. 0192     active
cuuu_2_status_origin = Key_data()  # key: cuuu                 data: file origin       e.g. 0192     var/log/dmesg
class_2_cuuus = Key_data()          # key: class                data: cuuu[,cuuu]       e.g. dasd     0192 0193
type_2_cuuus = Key_data()           # key: type                 data: cuuu[,cuuu]       e.g. 3390     0192 0193
cuuu_2_dasd = Key_data()           # key: cuuu                 data: dasdid            e.g. 0192     dasda
cuuu_2_dasd_origin = Key_data()     # key: cuuu                 data: file origin       e.g. 0192     var/log/dmesg
dasd_2_cuuu = Key_data()           # key: dasdid               data: cuuu              e.g. dasda    0192
dasd_2_cuuu_origin = Key_data()     # key: dasdid               data: file origin       e.g. dasda    var/log/dmesg
dasd_2_parts = Key_data()           # key: dasdid               data: dasdid partition  e.g. dasda    dasda1,dasda2,..
cuuu_2_vol1 = Key_data()           # key: cuuu                 data: vol1 id           e.g. 0192     0X0129
cuuu_2_vol1_origin = Key_data()     # key: cuuu                 data: file origin       e.g. 0192    var/log/dmesg

# ---------------------------------------------#


# ---------------------------------------------#
#
rh_major = 0
rh_minor = 0
release = ""                       # typically, "Red Hat Enterprise Linux Server release 5|6|7.n (codename)"
release_origin = ""                # file where RHEL version found (usually etc/redhat-release)
release_extra = ""                  # if not null, then ATTN+<some anomaly>
rh_date = Key_data()                # key RHel version          data: release date      e.g. 5.9,6.4,7.1 data: yyyy-mm-dd
# -+
# |--> see https://access.redhat.com/articles/3078
# -+
rh_date["7.6"] = "TBA"
rh_date["7.5"] = "2018-04-10"
rh_date["7.4"] = "2017-08-01"
rh_date["7.3"] = "2016-11-03"
rh_date["7.2"] = "2015-11-19"
rh_date["7.1"] = "2015-03-05"
rh_date["7.0"] = "2014-06-09"

rh_date["6.10"] = "TBA"
rh_date["6.9"] = "2017-03-21"
rh_date["6.8"] = "2016-05-10"
rh_date["6.7"] = "2015-07-22"
rh_date["6.6"] = "2014-10-14"
rh_date["6.5"] = "2013-11-21"
rh_date["6.4"] = "2013-02-21"
rh_date["6.3"] = "2012-06-20"
rh_date["6.2"] = "2011-12-06"
rh_date["6.1"] = "2011-05-19"
rh_date["6.0"] = "2010-11-09"

rh_date["5.11"] = "2014-09-16"
rh_date["5.10"] = "2013-10-01"
rh_date["5.9"] = "2013-01-17"
rh_date["5.8"] = "2012-02-20"
rh_date["5.7"] = "2011-07-21"
rh_date["5.6"] = "2011-01-13"
rh_date["5.5"] = "2010-03-30"
rh_date["5.4"] = "2009-09-02"
rh_date["5.3"] = "2009-01-20"
rh_date["5.2"] = "2008-05-21"
rh_date["5.1"] = "2007-11-07"
rh_date["5.0"] = "2007-03-15"

rh_date["4.9"] = "2011-02-16"
rh_date["4.8"] = "2009-05-19"
rh_date["4.7"] = "2008-07-29"
rh_date["4.6"] = "2007-11-15"
rh_date["4.5"] = "2007-05-01"
rh_date["4.4"] = "2006-08-10"
rh_date["4.3"] = "2006-03-12"
rh_date["4.2"] = "2005-10-05"
rh_date["4.1"] = "2005-06-08"
rh_date["4.0"] = "2005-02-15"

ke_level = Key_data()                # key RHel kernel version   data: corr. rh rel ma.mi  e.g.02.006.0032.0504 data: "6.6"
# e.g.: 02.006.0032.0504 (RHEL 6.6)
# (use kernel_normalize() formatted value)
# -+
# |--> see https://access.redhat.com/articles/3078
# -+
#
#
# Errata kernel data:
# https://mojo.redhat.com/docs/DOC-1082179 REHL7
# https://mojo.redhat.com/docs/DOC-1082178 RHEL6
# https://mojo.redhat.com/docs/DOC-1082177 RHEL5
# https://mojo.redhat.com/docs/DOC-1082176 RHEL4
#
# RHEL 7 kernels: NB. adjust rh_kernel_range[7] when adding next RHEL 7 kernel
ke_level["03.010.0000.0863"] = "7.5"  # GA kernel level?? (above link does not confirm at present)
ke_level["03.010.0000.0862"] = "7.5 2018-03-22"  # 7.5 RC Respin # 3
ke_level["03.010.0000.0861"] = "7.5 2018-03-15"  # 7.5 RC Respin # 2
ke_level["03.010.0000.0860"] = "7.5 2018-03-07"  # 7.5 RC Respin # 1
ke_level["03.010.0000.0858"] = "7.5 2018-02-28"  # 7.5 Release Candidate
ke_level["03.010.0000.0830"] = "7.4 2018-01-15"
ke_level["03.010.0000.0693"] = "7.4"
ke_level["03.010.0000.0677"] = "7.4 2017-05-31"  # 6.4 snapshot2.2 ?? no record of 677 but showed up in case
ke_level["03.010.0000.0675"] = "7.4 2017-05-29"  # 6.4 snapshot2
ke_level["03.010.0000.0663"] = "7.4 2017-05-02"  # 6.4 beta kernel
ke_level["03.010.0000.0514"] = "7.3"
ke_level["03.010.0000.0324"] = "7.3 2016-06-15"
ke_level["03.010.0000.0327"] = "7.2"
ke_level["03.010.0000.0229"] = "7.1"
ke_level["03.010.0000.0123"] = "7.0"

# RHEL 6 kernels: NB. adjust rh_kernel_range[6] when adding next RHEL 6 kernel
ke_level["02.006.0032.0696"] = "6.9"
ke_level["02.006.0032.0642"] = "6.8"
ke_level["02.006.0032.0621"] = "6.8 2016-02-23"  # 6.8 beta kernel
ke_level["02.006.0032.0573"] = "6.7"
ke_level["02.006.0032.0554"] = "6.7 2015-04-14"  # 6.7 beta kernel
ke_level["02.006.0032.0504"] = "6.6"
ke_level["02.006.0032.0431"] = "6.5"
ke_level["02.006.0032.0358"] = "6.4"
ke_level["02.006.0032.0279"] = "6.3"
ke_level["02.006.0032.0220"] = "6.2"
ke_level["02.006.0032.0131"] = "6.1"
ke_level["02.006.0032.0071"] = "6.0"

# RHEL 5 kernels: NB. adjust rh_kernel_range[5] when adding next RHEL 5 kernel
ke_level["02.006.0018.0428"] = "5.11 2018-03-09"  # 5.11.z release build
ke_level["02.006.0018.0427"] = "5.11 2018-02-21"  # 5.11.z interim build
ke_level["02.006.0018.0426"] = "5.11 2018-02-07"  # 5.11.z emergency build/respin # 2
ke_level["02.006.0018.0425"] = "5.11 2018-01-24"  # 5.11.z emergency build/respin # 1
ke_level["02.006.0018.0424"] = "5.11 2018-01-17"  # 5.11.z emergency build
ke_level["02.006.0018.0423"] = "5.11 2017-09-22"
ke_level["02.006.0018.0422"] = "5.11 2017-07-19"
ke_level["02.006.0018.0420"] = "5.11 2017-06-09"
ke_level["02.006.0018.0419"] = "5.11 2017-01-23"
ke_level["02.006.0018.0418"] = "5.11 2017-01-14"
ke_level["02.006.0018.0417"] = "5.11 2016-11-19"
ke_level["02.006.0018.0416"] = "5.11 2016-10-26"
ke_level["02.006.0018.0412"] = "5.11 2016-08-01"
ke_level["02.006.0018.0411"] = "5.11 2016-06-02"
ke_level["02.006.0018.0410"] = "5.11 2016-04-08"
ke_level["02.006.0018.0409"] = "5.11 2016-02-12"
ke_level["02.006.0018.0408"] = "5.11 2015-12-11"
ke_level["02.006.0018.0407"] = "5.11 2015-10-16"
ke_level["02.006.0018.0406"] = "5.11 2015-05-01"
ke_level["02.006.0018.0404"] = "5.11 2015-03-06"
ke_level["02.006.0018.0402"] = "5.11 2015-01-08"
ke_level["02.006.0018.0400"] = "5.11 2014-12-14"
ke_level["02.006.0018.0398"] = "5.11"
ke_level["02.006.0018.0371"] = "5.10"
ke_level["02.006.0018.0348"] = "5.9"
ke_level["02.006.0018.0308"] = "5.8"
ke_level["02.006.0018.0274"] = "5.7"
ke_level["02.006.0018.0238"] = "5.6"
ke_level["02.006.0018.0194"] = "5.5"
ke_level["02.006.0018.0164"] = "5.4"
ke_level["02.006.0018.0155"] = "5.3 2009-06-19"
ke_level["02.006.0018.0128"] = "5.3"
ke_level["02.006.0018.0120"] = "5.2 2008-10-17"
ke_level["02.006.0018.0092"] = "5.2"
ke_level["02.006.0018.0053"] = "5.1"
ke_level["02.006.0018.0008"] = "5.0"

# RHEL 4 kernels: NB. adjust rh_kernel_range[4] when adding next RHEL 4 kernel
ke_level["02.006.0009.0106"] = "4.9 2014-12-16"
ke_level["02.006.0009.0105"] = "4.9 2013-03-12"
ke_level["02.006.0009.0104"] = "4.9 2012-05-09"
ke_level["02.006.0009.0103"] = "4.9 2011-11-11"
ke_level["02.006.0009.0100"] = "4.9"
ke_level["02.006.0009.0089"] = "4.8"
ke_level["02.006.0009.0078"] = "4.7"
ke_level["02.006.0009.0067"] = "4.6"
ke_level["02.006.0009.0055"] = "4.5"
ke_level["02.006.0009.0042"] = "4.4"
ke_level["02.006.0009.0034"] = "4.3"
ke_level["02.006.0009.0022"] = "4.2"
ke_level["02.006.0009.0011"] = "4.1"
ke_level["02.006.0009.0005"] = "4.0"

# use tbd - depends on the need to determine what rhel release an errata kernel falls between.
rh_kernel_range = Key_data()    # "Low High" kernel version for each RHEL major (update high end w/each kernel release)
rh_kernel_range[4] = "02.006.0009.0005 02.006.0009.0106"
rh_kernel_range[5] = "02.006.0018.0008 02.006.0018.0419"
rh_kernel_range[6] = "02.006.0032.0071 02.006.0032.0696"
rh_kernel_range[7] = "03.010.0000.0123 03.010.0000.0693"

# Kernel attributes from this sos report
kernelStr = Key_data()      # Key: various kernel attributes
kernelStr_origin = Key_data()      # Key: attribute source (var/log/dmesg, etc)
kernelNum = Counter()       # Key: various numeric kernel attributes
kernelNum_origin = Key_data()      # Key: attribute source (var/log/dmesg, etc)
# Kernel String attributes:
# Linux version 2.6.32-573.22.1.el6.x86_64 (mockbuild@x86-029.build.eng.bos.redhat.com) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) ) # 1 SMP Thu Mar 17 03:23:39 EDT 2016
# |           |              |                                          |                                                               |                          |
# +-----------+              +------------------------------------------+                                                               +--------------------------+
# |                                                         |                                                               |
# +-------------------------+                               |                                                               |
# |                               |                                                               |
kernelStr['level'] = ''          # Kernel level  <--+                               |                                                               |
kernelStr['builder'] = ''          # RedHat,CentOS,fedora,Oracle derived from  <------+                                                               |
kernelStr['date'] = ''             # Kernel date from Linux version line:  <--------------------------------------------------------------------------+
kernelStr['expanded'] = ''         # Kernel version expanded for ease of comparrison: nnnn.nnnn.nnnn.nnnn
# Kernel String attributes:
# # e.g.:     kernelStr['level'] = 2.6.32-573.22.1.el6.x86_64
# | | |  |            |
# | | |  |            |
kernelNum['major'] = 0             # Kernel major number; 2 or 3 <--+ | |  |            |
kernelNum['minor'] = 0             # Kernel minor number  <-----------+ |  |            |
kernelNum['rel1'] = 0              # Kernel minor release 1 number  <---+  |            |
kernelNum['rel2'] = 0              # Kernel minor release 2 number  <------+            |
kernelStr['arch'] = ''             # Kernel architecture  <-----------------------------+
# kernelStr['expanded'] = kernel_normalize(kernelNum['major'],kernelNum['minor'],kernelNum['rel1'],kernelNum['rel2'])
# kernel_version_line = ''
#
# ---------------------------------------------#


cpu_count = 0
cpus_active = 0

all_ipv4_addrs = ''
all_ipv6_addrs = ''
all_host_ip_names = ''  # host-192-1-1-12 ...

localhostname = ''

sos_report_fn = ""
corrupt_scsi_error_lines = 0

# When "-r" flag specified, only evaluate messages after this line number in var/log/messages.
# Set to the line number of most recent reboot (generally, "(r)syslogd started" message).
# Depending on how boot sessions' worth of messages there are in the syslog file, this option
# can help provide a clearer (less cluttered) view of what recently happened.
messages_start_line = 0
messages_start_line_ref = 0

# -----------------------------------------------------------
# format of syslog prefix data:
# original fmt is: 'Mon dd hh:mm:ss nodename ...'
# new fmt is:      'yyyy-mm-ddThh:mm:ss.nnnnnn+/-hh.mm nodename ...'
#
syslog_format = ''  # yyyy[n] / mdt / mdty / nmdt
# yyyy1 -> 2016-04-28Thh:mm:ss.nnnnnn+hh:mm nodename
# yyyy2 -> 2016 May 23 hh:mm:ss nodename
# yyyy3 -> 2016-04-28 hh:mm:ss +hh:mm nodename
# yyyy4 -> 2016-04-28 hh:mm:ss.nnn nodename
# yyyy5 -> 2016-04-28 hh:mm:ss (hh:mm:ss.nnn) nodename
# yyyy6 -> 2016-04-28 hh:mm:ss.nnnnnn+hh:mm nodename
# yyyy7 -> 2017-11-29 Wed hh:mm:ss nodename (see case )
# mdt   -> Apr 28 hh:mm:ss nodename
# nmdt  -> n Apr 28 hh:mm:ss nodename
#
syslog_hdr_fp_word_num = -1  # if facility/priority description is in the syslog messages then this is the word number where it is found
syslog_hdr_nn_word_num = -1  # word number of the nodename in the syslog messages
syslog_hdr_nn_word_num_expected = -1  # expected word number position of nodename based on syslog_format (in case no_host_data())
syslog_hdr_token_to_delete = -1  # clean up certain fac/pri standalone tokens such as "[n]", see case
syslog_hdr_fp_cleanup_style = -1  # if fac and/or pri are intermingled in a token requiring clean up,
# this number indicates how to do that clean up.
syslog_year = ''  # set if syslog_format = 'yyyy[n]'
syslog_next_year = ''  # set to syslog_year+1 if syslog_format = 'yyyy[n]'
syslog_last_year = ''  # set to syslog_year-1 if syslog_format = 'yyyy[n]'
syslog_hdr_rep_char = ''  # Normally the standard syslog prefix words are separated with spaces but occasionaly this is not the case.
# So far ',' has been seen. If set, this field is used with a replace call to turn the char back into spaces for parsing.
#
syslog_hdr_xnnxn_cruft = False
xnnxn_re = "<" + n4_re + ">" + n1_re
#
syslog_hdr_length = 0
syslog_hdr_and_nodename_length = 0
multiple_syslog_nodenames = False
multiple_syslog_nodenames_with_different_lengths = False
# syslog_nodename = '<unknown>'
syslog_separate_first_token = False  # True/False: need to separate 1st token from rest of msg line: 'kernel:foo...'
# syslog_separate_first_token = True # temp...
syslog_first_msg_token = -1  # position of first token in msg line (word no.)

syslog_check_list = ""\
    "kernel:~"\
    "systemd:~"\
    "su:~"\
    "snmpd:~"\
    "xinet:~"\
    "sudo:~"\
    ""
syslog_check_words = syslog_check_list.split("~")

last_msg_rptd = "last message repeated"
rsyslogd_mark = "rsyslogd: -- MARK --"
ratelimit_msg = "__ratelimit: "  # kernel: __ratelimit: nnnn callbacks supressed

# The following tokens and token fragments are matched against the first token in syslog messages
# and if there is a match then the syslog line is not run thru further matching logic.
# The list is order by frequency (roughly). See ~/bin/syslog_prefix_check
#
# On Jan 9, 2018, syslog_skip_list was broken into multiple lists starting w/first character of each token
# to minimize searching what had become  a long list.
# Within each list, the tokens should be arranged by highest frequency of occurnece if possible
syslog_skip_a_list = ""\
    "atomic-openshift-node[~"\
    "atomic-openshift-node:~"\
    "ansible-stat:~"\
    "ansible-copy:~"\
    "ansible-ping:~"\
    "ansible-command:~"\
    "audisp-remote:~"\
    "adclient[~"\
    "automount[~"\
    "account-server[~"\
    "account-replicator[~"\
    "account-auditor[~"\
    "auditd[~"\
    "abrtd:~"\
    "adinfo[~"\
    "ACML:~"\
    "aodh-evaluator[~"\
    "avahi-daemon[~"\
    "augenrules:~"\
    ""
syslog_skip_b_list = ""\
    ""
syslog_skip_c_list = ""\
    "ceph-osd[~"\
    "crond[~"\
    "CROND[~"\
    "container-server[~"\
    "container-replicator[~"\
    "container-updater[~"\
    "container-auidtor[~"\
    "cinder-api:~"\
    "cinder-api[~"\
    "cinder-scheduler[~"\
    "cinder-scheduler:~"\
    "cinder-backup[~"\
    "cinder-backup:~"\
    "cinder-volume[~"\
    "cinder-volume:~"\
    "cinder_scheduler:~"\
    "ceilometer-polling[~"\
    "cisco-vts-agent[~"\
    "chef-client[~"\
    "collectd[~"\
    "cf3[~"\
    "celery:~"\
    "cpuspeed:~"\
    "cimserver[~"\
    "Community:~"\
    "Connector~"\
    "cmclconfd[~"\
    "CCIRMTD[~"\
    ""
syslog_skip_d_list = ""\
    "dnsmasq-dhcp[~"\
    "dnsmasq[~"\
    "dhclient[~"\
    "dhclient:~"\
    "dockerd-current[~"\
    "dockerd-current:~"\
    "Delay(delay)[~"\
    "Delay(ceilometer-delay)[~"\
    "DB2[~"\
    "dzinfo[~"\
    "dbus~"\
    "dmeventd:~"\
    ""
syslog_skip_e_list = ""\
    "elasticsearch[~"\
    "EsxUtil:~"\
    "ECOM-Agent[~"\
    ""
syslog_skip_f_list = ""\
    ""
syslog_skip_g_list = ""\
    "goferd:~"\
    "gnocchi-metricd[~"\
    "ganesha_~"\
    "guard_tap[~"\
    "gatherd[~"\
    "gssproxy:~"\
    ""
syslog_skip_h_list = ""\
    "haproxy[~"\
    "heketi[:~"\
    "HEARTBEAT:~"\
    "heat-engine[~"\
    ""
syslog_skip_i_list = ""\
    "ironic-api[~"\
    "ironic-conductor[~"\
    "ironic-inspector[~"\
    "init:~"\
    "inetd[~"\
    "ISCAgent[~"\
    ""
syslog_skip_j_list = ""\
    "journal:~"\
    ""
syslog_skip_k_list = ""\
    "KEEPALIVE:~"\
    "Keepalived_vrrp[~"\
    "# kernel: pfo:~"\
    "# kernel: scsi_eh~"\
    "keystone-all[~"\
    ""
syslog_skip_l_list = ""\
    "logger:~"\
    "logrotate:~"\
    "lsass:~"\
    "lrmd[~"\
    ""
syslog_skip_m_list = ""\
    "manila-api[~"\
    "manila-share[~"\
    "manila-scheduler[~"\
    "Marklogic:~"\
    "mountd[~"\
    "mistral-server[~"\
    ""
syslog_skip_n_list = ""\
    "NetworkManager[~"\
    "neutron-server[~"\
    "neutron-openvswitch-agent[~"\
    "nfsdcltrack[~"\
    "nova-compute:~"\
    "nova-compute[~"\
    "nova-conductor:~"\
    "nova-conductor[~"\
    "nova-novncproxy:~"\
    "nova-novncproxy[~"\
    "nrpe[~"\
    "ntpd[~"\
    "ntpd-initres[~"\
    "ntpd:~"\
    "nslcd[~"\
    "named[~"\
    "ncsd:~"\
    "nscd:~"\
    "nailsd[~"\
    "NOFN~"\
    "nm-dispatcher[~"\
    "network:~"\
    ""
syslog_skip_o_list = ""\
    "Oracle~"\
    "Oracle Audit~"\
    "object-server[~"\
    "object-replicator[~"\
    "object-auditor[~"\
    "object-updater[~"\
    "ovs-vswitchd[~"\
    "openais[~"\
    "os-collect-config:~"\
    "os-collect-config[~"\
    "omiserver:~"\
    "oci-umount[~"\
    "oci-systemd-hook[~"\
    "ovs-vsctl[~"\
    "ovs-ctl[~"\
    "ovirt-ha-agent:~"\
    "ovirt-ha-broker:~"\
    ""
syslog_skip_p_list = ""\
    "puppet-agent~"\
    "puppet:~"\
    "proxy-server[~"\
    "pulseaudio[~"\
    "proftpd[~"\
    "pythonp:~"\
    "python[~"\
    "postfix~"\
    "privsep-helper[~"\
    "proftpd[~"\
    "pengine[~"\
    "pulp:~"\
    "pulp_streamer:~"\
    ""
syslog_skip_q_list = ""\
    "qdrouterd:~"\
    ""
syslog_skip_r_list = ""\
    "rngd:~"\
    "root:~"\
    "ROCANA:~"\
    "run-parts~"\
    "rsyncd[~"\
    "ricci[~"\
    "reposd[~"\
    "rpc.statd[~"\
    ""
syslog_skip_s_list = ""\
    "snmpd[~"\
    "snmpd:~"\
    "sshd[~"\
    "sudo:~"\
    "sudo[~"\
    "su:~"\
    "su[~"\
    "sudosh:~"\
    "setroubleshoot[~"\
    "setroubleshoot:~"\
    "ssh-server-g3~"\
    "ssh-~"\
    "SCB~"\
    "SQLAnywhere~"\
    "smartd[~"\
    "sysedge[~"\
    "sssd[~"\
    "selogrd[~"\
    "smhMonitori~"\
    "snmptrapd[~"\
    "SQLAnywhere\(~"\
    "subscription-manager:~"\
    "splunkagent-config:~"\
    "smbd[~"\
    ""
syslog_skip_t_list = ""\
    "tag_audit_log:~"\
    "tdodbc[~"\
    "TEAMSITE:~"\
    ""
syslog_skip_u_list = ""\
    "userhelper[~"\
    ""
syslog_skip_v_list = ""\
    "vdsm~"\
    "vasd[~"\
    ""
syslog_skip_w_list = ""\
    "winbindd[~"\
    ""
syslog_skip_x_list = ""\
    "xinetd[~"\
    ""
syslog_skip_y_list = ""\
    "yum[~"\
    ""
syslog_skip_z_list = ""\
    ""
syslog_skip_misc_list = ""\
    "/etc/gdm/Xsession:~"\
    "<NOFN~"\
    ".vgptool[~"\
    ""


for l in alphabet_words:
    if l != 'wc':
        sskl = 'syslog_skip_' + l + '_list'
        sskw = 'syslog_skip_' + l + '_words'
        el = "{0} = {1}.split('~')".format(sskw, sskl)
        exec(el)
        el = "wc = len({0})".format(sskw)
        exec(el)
        debug_print(1, "word count of {0} = {1}".format(sskw, wc - 1))


syslog_skip_misc_words = syslog_skip_misc_list.split("~")
wc = len(syslog_skip_misc_words)
debug_print(1, "word count of syslog_skip_misc_words = {0}".format(wc - 1))


# fast track prefix check (4 slot push-down stack), value of last 4 syslog skip words that matched
last_matched_skip_prefix_0 = 'snmpd['         # (initially seeded with higest frequency values)
last_matched_skip_prefix_1 = 'audisp-remote:'  # ...
last_matched_skip_prefix_2 = 'xinetd['        # ...
last_matched_skip_prefix_3 = 'journal:'       # ...

# -------------------------------------#
# Previous syslog message files are typically named either:
# messages-yyyymmdd
# -or-
# messages-nn
#
# in the case where the current messages file is null and/or the -mn option
# has been given, these fields are populated to allow reading and processing
# of previous messages files.
#
syslog_msg_fn_array = Key_data()  # indexed by 'n', where n will be between syslog_fn_min_n and max_n (inclusive)
syslog_fn_format_yyyymmdd = False
syslog_fn_format_n = False
syslog_fn_max_n = 0
syslog_fn_min_n = big_num
syslog_fn_cnt_n = 0
# -------------------------------------#


def errorprint(*args, **kwargs):
    """
    Prints to stderr a string
:type args: String to print
    """
    print(*args, file=sys.stderr, **kwargs)


def exitcitellus(code=False, msg=False):
    """
    Exits back to citellus with errorcode and message
:param msg: Message to report on stderr
:param code: return code
    """
    if msg:
        errorprint(msg)
    sys.exit(code)


# ---------------------------------------------#
# evalaute option switches and parameters
# ---------------------------------------------#
j = len(sys.argv)
i = 1

if j == 0 or os.getenv('CITELLUS_ROOT', '') != '':
    sos_report_fn = os.path.join(os.getenv('CITELLUS_ROOT', ''), "/")
else:
    while i < j:
        c_arg = sys.argv[i]
        if c_arg[0:1] == "-":
            chk_options(c_arg)
        else:
            if sos_report_fn == "":
                sos_report_fn = sys.argv[i]
            else:
                exit_print("sosreport filename already specified...", RC_FAILED)

        debug_print(3, "Arg[{0}]='{1}'".format(i, c_arg))
        i += 1

RC_OKAY = int(os.environ['RC_OKAY'])
RC_FAILED = int(os.environ['RC_FAILED'])
RC_SKIPPED = int(os.environ['RC_SKIPPED'])
citellus_live = int(os.getenv('CITELLUS_LIVE', '0'))
CITELLUS_ROOT = os.getenv('CITELLUS_ROOT', '')

if CITELLUS_ROOT != '':
    sos_report_fn = os.path.join(os.getenv('CITELLUS_ROOT', ''), "/")

# This script just runs in Snapshoot mode

if sos_report_fn == '':
    exitcitellus(code=RC_SKIPPED, msg="Not supported for Live mode and no sosreport specified")

# if sw_help is True:
# usage()
# exit(RC_OKAY)

if citellus_live != 0:
    exitcitellus(code=RC_SKIPPED, msg="Not supported for Live mode")

# define after option checks as max_anomaly_count can be changed...
anomaly_list = [["" for x in range(max_anomaly_count + 1)] for x in range(len(words) + 1)]


if lvm_device_to_test == '' and lvm_rule_to_eval != '':
    err_line = "Option -lvmrule='{0}' but no option value specified for -lvmdev=".format(lvm_rule_to_eval)


if lvm_device_to_test != '' and lvm_rule_to_eval != '':
    check_lvm_rule(lvm_device_to_test, lvm_rule_to_eval)
    exit(RC_OKAY)


locate_sos_report()  # may not return if problems are found


# Associative arrays:
#
# Array name                          Key                       Data                    Example
# (key)    (data)
# --------------------------------  --------------------------  ----------------------  ----------------------------------
scsi_host = Key_data()              # key: host,                data: host info line;   e.g. 0,       scsi0: qla2xxx
scsi_host_2_pci = Key_data()        # key: host,                data: pci address;      e.g. 0,       xx:xx.x
scsi_host_2_pci_origin = Key_data()  # key: host,                data: file origin       e.g. 0,       sos_commands/devicemapper/ls_-laR.dev
host_await_event_count = Counter()  # key: host,                data: count of excessive await events for this host from sar data
host_await_device_count = Counter()  # key: host,                data: count of excessive await devices for this host from sar data
host_svctm_event_count = Counter()  # key: host,                data: count of excessive svctm events for this host from sar data
host_svctm_device_count = Counter()  # key: host,                data: count of excessive svctm devices for this host from sar data

scsi_bus = Key_data()               # key: host:bus,            data: bus info line;    e.g. 0:0,     bus0
scsi_target = Key_data()           # key: host:bus:target,     data: target id;        e.g. 0:0:0,   target0
scsi_lun = Key_data()              # key: host:bus:target:lun, data: lun id;           e.g. 0:0:0:0, lun0 - sd[sda]
scsi_lun_origin = Key_data()       # key: host:bus:target:lun, data: file origin       e.g. 0:0:0:0, var/log/dmesg
scsi_lun_detail = Key_data()       # key: host:bus:target:lun, data: lun data line(s); e.g. 0:0:0:0, sd 0:2:0:0: Attached scsi generic sg1 type 0
scsi_lun_mfg = Key_data()          # key: host:bus:target:lun, data: mfg;              e.g. 0:0:0:0, HITACHI
scsi_lun_mfg_origin = Key_data()   # key: host:bus:target:lun, data: file origin       e.g. 0:0:0:0, var/log/dmesg
scsi_lun_mfg_model = Key_data()     # key: host:bus:target:lun, data: model;            e.g. 0:0:0:0, HITACHI
scsi_lun_mfg_model_origin = Key_data()     # key: host:bus:target:lun, data: file origin;    e.g. 0:0:0:0, var/log/messages
# scsi_2_path_errs = Counter()        # key: scsi id,             data: path error count  e.g. 0:0:1:2, 1
scsi_lun_path_status = Key_data()   # key: scsi_adr             data: "active"/"passive"
scsi_lun_rev_level = Key_data()   # key: scsi_adr        data: "02", "03", "04", etc
scsi_lun_rev_level_origin = Key_data()   # key: scsi_adr        data: proc/scsi/scsi
scsi_luns_w_rsrv_conflicts_rev_level_2 = ''

detached_device_count = 0
all_detached_devices = ""
all_failing_path_mm = ""
all_blacklisted_devices = ""
all_ro_dm_devs = ""
all_ro_mp_devs = ""
# all_buffer_io_error_devices = ''
all_buffer_io_error_sd_devices = ''
all_buffer_io_error_dm_devices = ''
buffer_io_errors_on_passive_devices = 0

all_blk_update_req_io_error_sd_devices = ''
all_blk_update_req_io_error_dm_devices = ''

all_cciss_devs = ''                 # all hpsa c0d0 named devices (including partitions)
# all_vdx_devs = ''                   # all vdx named devices (including partitions)
# all_dfa_devs = ''                   # all dfa named devices
# all_drbd_devs = ''                  # all drbd named devices

mfg_models = Key_data()            # key: mfg                  data: model(s)          e.g. EMC,     SYMMETRIX

max_dev_sgn = 0  # max len(dev_sgn)
sgn_2_lun = Key_data()              # key: sgn,                 data: scsi address;     e.g. sg1,     0:0:0:0
sgn_2_lun_origin = Key_data()       # key: sgn,                 data: file origin       e.g. sg1,     var/log/dmesg
lun_2_sgn = Key_data()              # key: scsi address,        data: sgn;              e.g. 0:0:0:0, sg1
lun_2_sgn_origin = Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg

max_dev_id = 0  # max len(dev_id)
dev_2_lun = Key_data()              # key: device id,           data: scsi address;     e.g. sda,     0:0:0:0
dev_2_lun_origin = Key_data()       # key: device id,           data: file origin       e.g. sda,     var/log/dmesg
dev_2_parts = Key_data()            # key: device id,           data: partion id(s)     e.g. sda,     sda1, sda2, ...
dev_2_aliases = Key_data()          # key: device id,           data: alias             e.g. hdc      cdrom, dvd
dev_2_size = Counter()              # key: any type device id   data: size              e.g. dm-0,sda,sda1  size(MB)
dev_2_size_origin = Key_data()      # key: any type device id   data: file origin       e.g. sda      var/log/dmesg
dev_2_errs = Counter()              # key: dm|sd  or partition id     data: error count e.g. dm-0,sda,sda1  nn

dev_2_scheduler = Key_data()        # key: device id,           data: scheduler name    e.g. sda, cfq
all_schedulers = ''                 # unique list of all block/<device>/queue/scheduler's encountered
scheduler_2_devs = Key_data()       # key: scheduler name       data: devices found     e.g. cfq, sda sdb

scsi_mod_parameters = Key_data()    # key: parm name            data: parm value        e.g. max_luns, 1024
all_scsi_mod_parameters = ''        # unique list of all module/scsi_mod/parameters found
fc_parameters = Key_data()          # key: parm name            data: parm value        e.g. dev_loss_tmo, 60
all_fc_parameters = ''              # unique list of all module/scsi_transport_fc/parameters found
lpfc_parameters = Key_data()        # key: parm name        data: parm value   e.g. lpfc_use_msi, 0
all_lpfc_parameters = ''            # unique list of all module/lpfc/parameters found

all_dev_aliases = ""
all_write_cache_disabled_devs = ''
all_read_cache_disabled_devs = ''

lun_2_dev = Key_data()              # key: scsi address,        data: device id;        e.g. 0:0:0:0, sda
lun_2_dev_origin = Key_data()       # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg
lun_2_type = Key_data()             # key: scsi address,        data: device type;      e.g. 0:0:0:0, sd
lun_2_type_origin = Key_data()      # key: scsi address,        data: file origin       e.g. 0:0:0:0, var/log/dmesg
host_devtypes = Key_data()          # key: host,                data: device types(s);  e.g. 0,       sd
lun_2_dev_aliases = Key_data()      # key: scsi address,        data: device id(s);     e.g. 0:0:0:0, nst120

dev_id_2_tgt_node = Key_data()      # key: device id,           data: 0x...             e.g. sda,     0x500507680100df9b
dev_id_2_tgt_node_origin = Key_data()  # key: device id,         data: file origin
tgt_node_2_dev_ids = Key_data()     # key: 0x...                data: device id(s)

dev_2_mp = Key_data()               # key: device id,           data: mp id;            e.g. sdab,    mpathe
dev_2_mp_origin = Key_data()        # key: device id,           data: file origin       e.g. sdab,    var/log/dmesg
mp_2_devs = Key_data()              # key: mp id,               data: device id(s);     e.g. mpathe,  sdab,...
mp_2_parts = Key_data()             # key: mp id,               data: mp part_id(s);    e.g. mpathe,  mpathep1,mpathep2,...
dev_2_dms = Key_data()              # key: device id,           data: dm id(s);         e.g. sdc,     dm-30,dm-31,...
dev_2_dm_origin = Key_data()        # key: device id,           data: file origin       e.g. sdcpc,   var/log/dmesg
#
dm_2_devs = Key_data()              # key: mm,                  data: device id(s);     e.g. 243:307,  sdcpc,...
# dm_2_path_errs = Counter()          # key: dm id,               data: path error count  e.g. dm-215,  1
mm_2_path_errs = Counter()          # key: major:minor # data: path error count  e.g. 202:215,  1
dm_2_lvm_errs = Counter()           # key: dm id,               data: path error count  e.g. dm-215,  1
max_dm = 0  # max len(dm-nnn) names
max_dm_nn = 0  # max nnn portion of "dm-nnn"
dm_array = Counter()                # key: dm id                data: number of times seen e.g. dm-12, 2

ls_dev_dm_major = -1                # dm-nn major number as seen in ls_-laR.dev file
proc_device_dm_major = -1           # device-mapper major number as seen in proc/devices (should be equal to ls_dev_dm_major)

dev_2_scsi_id = Key_data()          # key: device id,           data: scsi id;          e.g. sde,     ~33 char hex string
dev_2_scsi_id_origin = Key_data()   # key: device id,           data: file origin       e.g. sde,     sos_command/...
scsi_id_2_devs = Key_data()         # key: scsi id,             data: device ids;       e.g. hex str, sda,sdb,...
scsi_id_2_parts = Key_data()        # key: scsi id,             data: scsi_id_pn:device e.g. hex str,  hex str_pn:dev ...
len_std_scsi_id = 33
all_scsi_ids = ""
max_scsi_id = 0  # max len(scsi_id)

lintape_2_scsi = Key_data()          # key: lintape id           data: scsi adr          e.g. IBMtape2,  7:0:1:12
lintape_2_scsi_origin = Key_data()   # key: lintape id           data: file origin       e.g. IBMtape2, /var/log/messages
scsi_2_lintape = Key_data()          # key: scsi adr             data: lintape id        e.g. 7:0:1:12, IBMtape2
scsi_2_lintape_origin = Key_data()   # key: scsi adr             data: file origin       e.g. 7:0:1:12, /var/log/messages
all_lintapes = ""
last_lintape_scsi_adr = ""
max_lintape = 0  # max len(lintape)

dev_2_iscsi_id = Key_data()          # key: device id,           data: iscsi id;          e.g. sde,     ~13 char string
dev_2_iscsi_id_origin = Key_data()   # key: device id,           data: file origin       e.g. sde,     sos_command/...
iscsi_id_2_devs = Key_data()         # key: iscsi id,            data: device ids;       e.g. str, sda,sdb,...
iscsi_id_2_parts = Key_data()        # key: iscsi id,            data: iscsi_id_pn:device e.g. str,  str_pn:dev ...
len_std_iscsi_id = 13
all_iscsi_ids = ""
max_iscsi_id = 0  # max len(iscsi_id)
iscsi_host_no_gt_ffff_count = 0

dev_2_sata_id = Key_data()          # key: device id,           data: sata id;          e.g. sde,     ~13 char string
dev_2_sata_id_origin = Key_data()   # key: device id,           data: file origin       e.g. sde,     sos_command/...
sata_id_2_devs = Key_data()         # key: sata id,             data: device ids;       e.g. str, sda,sdb,...
sata_id_2_parts = Key_data()        # key: sata id,             data: sata_id_pn:device e.g. str,  str_pn:dev ...
len_std_sata_id = 13
all_sata_ids = ""
max_sata_id = 0  # max len(sata_id)

dev_2_ata_id = Key_data()           # key: device id,           data: ata id;          e.g. sde,     ~?? char string
dev_2_ata_id_origin = Key_data()    # key: device id,           data: file origin       e.g. sde,     sos_command/...
ata_id_2_devs = Key_data()          # key: ata id,              data: device ids;       e.g. str, sda,sdb,...
ata_id_2_parts = Key_data()         # key: ata id,              data: sata_id_pn:device e.g. str,  str_pn:dev ...
len_std_ata_id = -1
all_ata_ids = ""
max_ata_id = 0  # max len(sata_id)

dev_2_other_id = Key_data()          # key: device id,           data: other id;         e.g. sde,     ~13 char string
dev_2_other_id_origin = Key_data()   # key: device id,           data: file origin       e.g. sde,     sos_command/...
other_id_2_devs = Key_data()         # key: other id,            data: device ids;       e.g. str, sda,sdb,...
other_id_2_parts = Key_data()        # key: other id,            data: other_id_pn:device e.g. str,  str_pn:dev ...
len_std_other_id = 13
all_other_ids = ""
max_other_id = 0  # max len(other_id)

dev_2_wwn_id = Key_data()           # key: device id,           data: wwn id;           e.g. sde,     33 char hex wwn string
dev_2_wwn_id_origin = Key_data()    # key: device id,           data: file origin       e.g. sde,     sos_command/...
wwn_id_2_devs = Key_data()          # key: wwn id,              data: device ids;       e.g. hex str, sda,sdb,...
wwn_id_2_parts = Key_data()         # key: wwn id,              data: device ids;       e.g. hex str, hexstr-partn:sda,...
all_wwn_ids = ""
max_wwn_id = 0  # max len(wwn_id)

dev_2_usb_id = Key_data()           # key: device id,           data: usb id;           e.g. sde,     string
dev_2_usb_id_origin = Key_data()    # key: device id,           data: file origin       e.g. sde,     sos_command/...
usb_id_2_devs = Key_data()          # key: usb id,              data: device ids;       e.g. string, sda,sdb,...
usb_id_2_parts = Key_data()         # key: usb id,              data: device ids;       e.g. string, string-partn:sda,...
all_usb_ids = ""
max_usb_id = 0  # max len(usb_id)

dev_2_sas_id = Key_data()           # key: device id,           data: sas id;           e.g. sde,     string
dev_2_sas_id_origin = Key_data()    # key: device id,           data: file origin       e.g. sde,     sos_command/...
sas_id_2_devs = Key_data()          # key: sas id,              data: device ids;       e.g. string, sda,sdb,...
sas_id_2_parts = Key_data()         # key: sas id,              data: device ids;       e.g. string, string-partn:sda,...
all_sas_ids = ""
max_sas_id = 0  # max len(sas_id)

dev_2_virtio_id = Key_data()        # key: device id,           data: virtio id;        e.g. sde,     string
dev_2_virtio_id_origin = Key_data()  # key: device id,           data: file origin       e.g. sde,     sos_command/...
virtio_id_2_devs = Key_data()       # key: virtio id,           data: device ids;       e.g. string, sda,sdb,...
virtio_id_2_parts = Key_data()      # key: virtio id,           data: device ids;       e.g. string, string-partn:sda,...
all_virtio_ids = ""
max_virtio_id = 0  # max len(virtio_id)

dev_2_fc_id = Key_data()            # key: device id,           data: fc id;            e.g. sde,     hex fc id string
dev_2_fc_id_origin = Key_data()     # key: device id,           data: file origin       e.g. sde,     sos_command/...
fc_id_2_devs = Key_data()           # key: fc id,               data: device ids;       e.g. hex str, sda,sdb,...
fc_id_2_parts = Key_data()          # key: fc id,               data: device ids;       e.g. hex str-partn:sdxx,
all_fc_ids = ""
max_fc_id = 0  # max len(fc_id)

dev_2_md_id = Key_data()            # key: device id,           data: md id;            e.g. sde,     md0
dev_2_md_id_origin = Key_data()     # key: device id,           data: file origin       e.g. sde,     proc/mdstat,..
md_id_2_devs = Key_data()           # key: md id,               data: device ids;       e.g. md0,     sda,sdb,...
md_id_2_uuid = Key_data()           # key: md id,               data: uuid of md dev    e.g. md0,     uuid-string
md_id_2_dev_uuid = Key_data()       # key: md id,               data: dev uuid of md dev  e.g. md0,   dev-uuid-string
all_md_ids = ""
max_md_id = 0  # max len(md_id)

all_hd_ids = ""                     # add hd devices

dev_2_label = Key_data()            # key: device id,           data: label,            e.g. sda,     boot
dev_2_label_origin = Key_data()     # key: device id,           data: file origin       e.g. sda,     sos_command/...
label_2_devs = Key_data()           # key: label,               data: device id(s);     e.g. boot,    sda
all_label_ids = ""
max_label = 0  # maximum label length

all_uuids = ""
dev_2_uuid = Key_data()             # key: device id,           data: uuid,             e.g. sda,     d0f60ab1-4eda-4f68-9f3d-ffd364df8379
dev_2_uuid_origin = Key_data()      # key: device id,           data: file origin       e.g. sda,     sos_command/...
uuid_2_dev = Key_data()             # key: uuid,                data: device id;        e.g. d0f60ab1-4eda-4f68-9f3d-ffd364df8379, sda
uuid_2_dev_origin = Key_data()      # key: uuid,                data: file origin       e.g. d0f60ab1-4eda-4f68-9f3d-ffd364df8379, sos_command/...
pdev_2_uuid = Key_data()            # key: device id,           data: partition uuid,   e.g. sda,     d0f60ab1-4eda-4f68-9f3d-ffd364df8379
pdev_2_uuid_origin = Key_data()     # key: device id,           data: file origin       e.g. sdb1,    sos_command/...
uuid_2_pdev = Key_data()            # key: partition uuid,      data: device id;        e.g. d0f60ab1-4eda-4f68-9f3d-ffd364df8379, sda1
uuid_2_pdev_origin = Key_data()     # key: partition uuid,      data: file origin       e.g. d0f60ab1-4eda-4f68-9f3d-ffd364df8379, sos_command/...
max_uuid = 0  # maximum uuid length


max_major = 0                       # higest major number
max_minor = 0                       # higest minor number
major_size = -1                     # max display size needed for a major number
minor_size = -1                     # max display size needed for a minor number

lo_char_major = big_num             # lowest char major device number seen in this sos report
hi_char_major = -1                  # highest char major device number seen in this sos report

lo_block_major = big_num            # lowest block major device number seen in this sos report
hi_block_major = -1                 # highest block major device number seen in this sos report

lo_char_minor = Key_data_min()      # key: char major device number data: lowest char minor device number for this major number
hi_char_minor = Key_data_max()      # key: char major device number data: highest char minor device number for this major number
# to see if a char major has devices, compare hi_char_major[maj_num] to -1
char_minor_cnt = Counter()          # key: char major device number, data: count of minor device numbers
char_minor_devs = Key_data()        # key: char major device number, data: unique list of minor device numbers

lo_block_minor = Key_data_min()     # key: block major device number data: lowest block minor device number for this major number
hi_block_minor = Key_data_max()     # key: block major device number data: highest block minor device number for this major number
# to see if a block major has devices, compare hi_block_major[maj_num] to -1
block_minor_cnt = Counter()         # key: block major device number, data: count of minor device numbers
block_minor_devs = Key_data()       # key: block major device number, data: unique list of minor device numbers
last_major_used = -1                #
last_block_minor_cnt = -1
last_block_minor_array = ''.split()  # will be set to block_minor_devs[major].split()


bd_2_mm = Key_data()                # key: block device name    data: major:minor no.   e.g. sda,     8:0
bd_2_mm_origin = Key_data()         # key: block device name    data: file origin       e.g. sda,     sos_commands/devicemapper/ls_-laR.dev
mm_2_bd = Key_data()                # key: major:minor no.      data: block device name e.g. 8:0,     sda
mm_2_bd_origin = Key_data()         # key: major:minor no.      data: file origin       e.g. 8:0,     sos_commands/devicemapper/ls_-laR.dev

mm_2_bd_aliases = Key_data()        # key: major:minor no.      data: block device name alias(es) e.g. 253:0,    mpatha, vg-lv

# # The following 3 mm_ arrays are all 'unique_lists'
mm_checker_failed_path = ''         # mm number found in 'multipathd: checked failed path mm in map map_name
mm_lookup_failed = ''         # mm numbers that returned '' when looked from 'multipathd: checked failed path mm in map map_name
mm_not_assoc_w_mapname = ''         # mm numbers that were bound but not assoc w/map_name from 'multipathd: checked failed path mm in map map_name

# # The following 2 devs_ arrays are 'unique_lists'
devs_in_checker_reports_path = ''   # sd devs found in 'multipathd: map_name: sd_dev - xxxx checker reports path is <status>'
devs_scsi_lookup_failed = ''        # sd devs where scsi lookup failed in 'checker reports paths is <status>' messages

cd_2_mm = Key_data()                # key: char device name     data: major:minor no.   e.g. st0,     9:0
cd_2_mm_origin = Key_data()         # key: char device name   data: file origin       e.g. st0,     sos_commands/devicemapper/ls_-laR.dev
mm_2_cd = Key_data()                # key: major:minor no.      data: char device name  e.g. 9:0,     st0
mm_2_cd_origin = Key_data()         # key: major:minor no.    data: file origin       e.g. 9:0,     sos_commands/devicemapper/ls_-laR.dev


sysctl = Key_data_m1()              # key: sysctl.setting,      data: number            e.g. kernel.tainted 64

OracleASM = Key_data()              # key: ORACLEASM_keyword,   data: assoc. value      e.g. ORACLEASM_SCANORDER="mpath sd"
all_OracleASM_keys = ""

grub = Key_data()                   # key: grub keyword         data: assoc. value      e.g. GRUB_TIMEOUT=5
all_grub_keys = ""

iscsidConf_data = Key_data()        # key: iscsid.conf kw       data: assoc. value      e.g. node.startup = automatic
all_iscsidConf_kwds = ''            # all iscsid.conf keywords
all_iscsi_session_timeouts = ''     # unique second timeout values
iscsi_session_timeout_count = Counter()  # key timeout value in seconds data: count of times timeout at the second count

MultipathConf = Key_data()          # key: multipath.conf kw    data: assoc. value      e.g. max_fds, 8192
all_MultipathConf_keys = ""
LVMConf = Key_data()
all_LVMConf_keys = ""
lvm_data_state = ''  # or 'continue'  when this type of statement is found: kw = [ "value1", "value2",
# "value3", "value4",
# "value5", "value6" ]
multipath_modules = ''             # list of mulitpath modules noted as loaded (format: name:n.n.n)
# typically just one item

# count of 'kernel: device-mapper: table ma:mi: multipath error getting device' where ma:mi lookup failed
mm_multipath_err_getting_dev = ''  # unique list of mm numbers from above msg
mm_multipath_err_getting_dev_mm_lookup_failed = ''  # unique list mm numbers from above msg where mm lookup failed


cmdline = Key_data()                # key: cmdline key          data: assoc. value      e.g. KEYBOARDTYPE pc
cmdline_origin = Key_data()         # key: cmdline key          data: fn of source of data (1st occurence when seen in more than one source)
all_cmdline_keys = ""

scsi_host_io_errs = Counter()       # key: host,                data: error count       e.g. 0,       0-? all busses, tgts, luns
scsi_bus_io_errs = Counter()        # key: host:bus,            data: error count       e.g. 0:0,     0-? all tgts, luns
scsi_target_io_errs = Counter()    # key: host:bus:target,     data: error count       e.g. 0:0:0,   0-? all luns
scsi_lun_io_errs = Counter()       # key: host:bus:target:lun, data: error count       e.g. 0:0:0:0, 0-?

scsi_host_path_errs = Counter()     # key: host,                data: error count       e.g. 0,       0-? all busses, tgts, luns
scsi_bus_path_errs = Counter()      # key: host:bus,            data: error count       e.g. 0:0,     0-? all tgts, luns
scsi_target_path_errs = Counter()  # key: host:bus:target,     data: error count       e.g. 0:0:0,   0-? all luns
scsi_lun_path_errs = Counter()     # key: host:bus:target:lun, data: error count       e.g. 0:0:0:0, 0-?

scsi_host_timeouts = Counter()      # key: host,                data: timeout count     e.g. 0,       0-? all busses, tgts, luns
scsi_bus_timeouts = Counter()       # key: host:bus,            data: timeout count     e.g. 0:0,     0-? all tgts, luns
scsi_target_timeouts = Counter()   # key: host:bus:target,     data: timeout count     e.g. 0:0:0,   0-? all luns
scsi_lun_timeouts = Counter()      # key: host:bus:target:lun, data: timeout count     e.g. 0:0:0:0, 0-?

scsi_host_reservation_conflicts = Counter()   # as above w/scsi_..._path_errs and scsi_..._io_errs
scsi_bus_reservation_conflicts = Counter()    # .
scsi_target_reservation_conflicts = Counter()  # .
scsi_lun_reservation_conflicts = Counter()    # .
total_reservation_conflicts = 0
reservation_conflicts = Counter()             # key: dev_type   data: reservation conflict count e.g. sd,st

scsi_host_offlined_devices = Key_data()       # key: host number, list of unique devices offlined
scsi_host_offlined = Counter()                # as above w/scsi_..._path_errs and scsi_..._io_errs
scsi_bus_offlined = Counter()                 # .
scsi_target_offlined = Counter()              # .
scsi_lun_offlined = Counter()                 # .
total_offlined = 0
# offlined = Counter()                          # key: dev_type   data: reservation conflict count e.g. sd,st

scsi_host_not_added_luns = Key_data()         # key: host number, list of unique luns not added
scsi_host_not_added = Counter()               # as above w/scsi_..._path_errs and scsi_..._io_errs
scsi_bus_not_added = Counter()                # .
scsi_target_not_added = Counter()             # .
scsi_lun_not_added = Counter()                # .
total_not_added = 0
# not_added = Counter()                          # key: dev_type   data: not addded count e.g. sd,st

scsi_host_write_protected_luns = Key_data()   # key: host number, list of unique luns with write protect on
scsi_host_write_protected = Counter()         # as above w/scsi_..._path_errs and scsi_..._io_errs
scsi_bus_write_protected = Counter()          # .
scsi_target_write_protected = Counter()       # .
scsi_lun_write_protected = Counter()          # .
total_write_protected = 0

high_lun_sd_rc_count = 0
high_lun_sd_rc_lun = ''
high_lun_st_rc_count = 0
high_lun_st_rc_lun = ''
high_lun_mi_rc_count = 0
high_lun_mi_rc_lun = ''

scsi_host_detaches = Counter()      # as above w/scsi_..._path_errs and scsi_..._io_errs
scsi_bus_detaches = Counter()       # .
scsi_target_detaches = Counter()    # .
scsi_lun_detaches = Counter()       # .
total_detaches = 0

high_host_io_error_count = 0
high_host_io_error_host = ''
high_host_path_error_count = 0
high_host_path_error_host = ''
high_host_timeout_count = 0
high_host_timeout_host = ''
high_host_offlined_count = 0
high_host_offlined_host = ''

host_qla_abort_count = Counter()    # key: host number         data: qla abort countk
total_host_qla_abort_count = 0
high_host_qla_abort_count = 0
high_host_qla_abort_host = ''

high_lun_io_error_count = 0
high_lun_io_error_lun = ''
high_lun_detach_count = 0
high_lun_detach_lun = ''
high_lun_path_error_count = 0
high_lun_path_error_lun = ''
high_lun_timeout_count = 0
high_lun_timeout_lun = ''
high_lun_offlined_count = 0
high_lun_offlined_lun = ''
high_dm_io_error_count = 0
high_dm_io_error_dev = ''

sar_device_perf_data = False
await_devices = ''                  # unique await devices
svctm_devices = ''                  # unique svctm devices
await_buckets = Counter()           # key: bucket # data: bucket count      e.g. 0        37
svctm_buckets = Counter()           # key: bucket # data: bucket count      e.g. 5        12
await_dev_samples = Counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
await_dev_total_time = Counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
svctm_dev_samples = Counter()       # key: mm                   data: # of samples      e.g. dev8-4   7
svctm_dev_total_time = Counter()    # key: mm                   data: total time of samples  e.g. dev8-4   271.12
lo_major_perf = big_num
hi_major_perf = 0
lo_minor_perf = Key_data_min()      # key: major number         data: lowest minor # for that major
hi_minor_perf = Key_data_max()      # key: major number         data: highest minor # for that major
major_block_type = Key_data()       # key: major number         data: block type description
major_char_type = Key_data()       # key: major number         data: data character type description
major_block_type_default = Key_data()  # key: major number       data: default block type description
major_char_type_default = Key_data()  # key: major number       data: default character type description
high_await_mm = ''
high_await_time = 0
high_svctm_mm = ''
high_svctm_time = 0

multipath_checkers_reporting_errors = ''
checker_down_count = Counter()  # key: checker              data: count             e.g. 'tur'    23
checker_up_count = Counter()  # key: checker              data: count             e.g. 'tur'    23
checker_standby_count = Counter()  # key: checker              data: count             e.g. 'tur'    23
checker_timed_out_count = Counter()  # key: checker              data: count             e.g. 'tur'    23
multipath_query_cmds_reporting_errors = ''
query_cmd_count = Counter()         # key: query_cmd            data: count             e.g. emc_clariion_checker 12

all_scsi_dev_types = ""
scsi_dev_type_count = Counter()     # key: scsi device type     data: count of type     e.g. sd,      64

# used to help differentiate between names that are lvms vs mpath instances
all_lsblk_lvm_names = ''
all_lsblk_mpath_names = ''
all_lsblk_dm_names = ''

# process vg/lv data, build assoc arrays
no_volume_groups_found = 0          # number of 'No volume groups found.' lines found in vg file(s)
all_vg_names = ""
all_unassoc_uuids = ""              # UUID of PVs not associated with any VG
vg_2_attr = Key_data()             # key: vg name              data: attributes of vg search for VG_ATTR_NOTE
vg_2_uuid = Key_data()             # key: vg name              data: uuid
vg_2_uuid_origin = Key_data()      # key: vg name              data: file origin
vg_2_dup_uuids = Key_data()         # key: vg name              data: list of duplicate uuids vg was known as
uuid_2_vg = Key_data()             # key: uuid                 data: vg name
uuid_2_vg_origin = Key_data()      # key: uuid                 data: file origin
vg_2_all_lvs = Key_data()           # key: vg name              data: all lv names
vg_2_all_pvs = Key_data()           # key: vg name              data: all pv names

pv_2_uuid = Key_data()             # key: pv name              data: uuid
pv_2_uuid_origin = Key_data()      # key: pv name              data: file origin
pv_2_path = Key_data()             # key: pv name              data: pv path
pv_2_path_origin = Key_data()      # key: pv name              data: file origin
uuid_2_pv = Key_data()             # key: uuid                 data: pv name
uuid_2_pv_origin = Key_data()      # key: uuid                 data: file origin

lv_2_uuid = Key_data()             # key: lv name              data: uuid
lv_2_uuid_origin = Key_data()      # key: lv name              data: file origin
lv_2_path = Key_data()             # key: lv name              data: lv path  (example?)
uuid_2_lv = Key_data()             # key: uuid                 data: lv name
uuid_2_lv_origin = Key_data()      # key: uuid                 data: file origin
uuids_to_check = ''                 # LVM anomaly uuids to check on
uuids_found = 0                     # number of uuids_to_check we were able to find
unassoc_uuids_found = 0

# scsi error tracking variables
all_scsi_err_codes = ""             # all unique scsi "0x12345678" error codes
scsi_err_desc = Key_data()          # key: "0x12345678"         data: "desctiption of error"
scsi_err_count = Counter()          # key: "0x12345678"         data: count of this error accross all devices
scsi_err_dev_ids = Key_data()       # key: "0x12345678"         data: "sda, sdc, ..." all device ids encountering this error
scsi_err_scsi_adrs = Key_data()     # key: "0x12345678"         data: "0:1:0:3, 0:1:0:5, ..." all scsi id addresses encountering this error


run_level = -1                      # system runlevel from inittab

# list of tracked services
LIN_TAPED = 'lin_taped'
all_services = ""\
    "avrd "\
    "bpbkar "\
    "bpbkarv "\
    "clvmd "\
    "corosync "\
    "CVMClusterAgent "\
    "dsmrecalld "\
    "dsmrecall "\
    "fenced "\
    "glusterfs "\
    "glusterfsd "\
    "hald "\
    "haldeamon "\
    "iscsi "\
    "iscsid "\
    "kdump "\
    + LIN_TAPED + " "\
    "lldpad "\
    "ltfs "\
    "lvmetad "\
    "midaemon "\
    "mmfsd "\
    "nbcssc "\
    "netbackup "\
    "netfs "\
    "nfs "\
    "nfsd "\
    "omni "\
    "qdiskd "\
    "qemu-kvm "\
    "rgmanager "\
    "rtvscand "\
    "smbd "\
    "udevd "\
    "uma "\
    ""

# a '??' suffix means that the name is not known or not confirmed
# "vendor,daemon_name"
mp_services = "RedHat,multipathd "\
              "Veritas,dmp_daemon "\
              "Veritas,vxodm "\
              "EMC,emcpd "\
              "IBM,SDD?? "\
              "Fujitsu,Eternus?? "\
              "Hitachi,boot.hdlm "\
              ""
words = mp_services.split()
for tmp in words:
    tmp2 = tmp.split(',')
    vendor = tmp2[0]
    daemon = tmp2[1]
    all_services = unique_list(all_services, daemon)
# end: for tmp in words:


filescanner_services = ""\
    "Trend_Micro,ds_agent "\
    "Trend_Micro,ds_filter "\
    ""
words = filescanner_services.split()
for tmp in words:
    tmp2 = tmp.split(',')
    vendor = tmp2[0]
    daemon = tmp2[1]
    all_services = unique_list(all_services, daemon)
# end: for tmp in words:


total_rt_procs = 0                  # count of total real time processes
rt_procs = ''                       # list of unique real time process names
rt_proc_count = Counter()           # key: rt proc name         data: proc count

config_service = Key_data()         # key: service name         data: on/off (based on on/off for runlevel 3 & 5)
service_procs = Counter()          # key: service name         data: count of daemon procs from ps info
services_count = 0                  # count of *all* services tracked in the sos report
total_d_state_procs = 0             # count of processes in 'D' state
d_state_procs = ''                  # list of unique process names in 'D' state
d_state_proc_count = Counter()      # key: 'D' state proc name  data: proc count
total_z_state_procs = 0             # count of processes in 'Z' state
z_state_procs = ''                  # list of unique process names in 'Z' state
z_state_proc_count = Counter()      # key: 'Z' state proc name  data: proc count
service_time = Counter()           # key: service name         data: count of cpu seconds used by service (combined total if service implements more than one instance)

all_lockup_processes = ""           # list of all unique process names which have locked up
lock_process_pids = Key_data()      # key: process name         data: unique process id instances

total_procs = 0                     # total number of processes at time of sos report
proc_slots = 10                     # track this many instances of proc data in proc_xxxxx arrays
proc_cpu = Counter()           # 'proc_slots' count ordered array (highest->lowest) for %CPU
proc_cpu_line = Key_data()          # 'proc_slots' count ordered array  of data line from ps file
proc_mem = Counter()           # 'proc_slots' count ordered array (highest->lowest) for %MEM
proc_mem_line = Key_data()          # 'proc_slots' count ordered array  of data line from ps file
proc_tim = Counter()           # 'proc_slots' count ordered array (highest->lowest) for TIME
proc_tim_line = Key_data()          # 'proc_slots' count ordered array  of data line from ps file

for i in range(1, proc_slots + 1):
    proc_cpu[i] = 0.0
    proc_cpu_line[i] = "# # # "
    proc_mem[i] = 0.0
    proc_mem_line[i] = "# # # "
    proc_tim[i] = 0
    proc_tim_line[i] = "# # # "
# end: for i in range(1,proc_slots):


sar_slots = 10                      # track this many instances of sar await data in sar_xxxxx arrays
sar_await = Counter()           # 'sar_slots' count ordered array (highest->lowest) for await data
sar_await_dev = Key_data()          # 'sar_slots' count ordered array  of device id
sar_await_cnt = Counter()           # 'sar_slots' count ordered array  of await event count
sar_svctm = Counter()           # 'sar_slots' count ordered array (highest->lowest) for await data
sar_svctm_dev = Key_data()          # 'sar_slots' count ordered array  of device id
sar_svctm_cnt = Counter()           # 'sar_slots' count ordered array  of svctm event count

for i in range(1, sar_slots + 1):
    sar_await[i] = 0.0
    sar_await_dev[i] = "# # # "
    sar_await_cnt[i] = 0
    sar_svctm[i] = 0.0
    sar_svctm_dev[i] = "# # # "
    sar_svctm_cnt[i] = 0
# end: for i in range(1,sar_slots):


# Packages that impact storage and whose versions will be tracked
rpm_dm_mp = "device-mapper-multipath"
rpm_mp_pkgs = rpm_dm_mp + " EMCpower.LINUX VRTSaslapm"
rpm_pkgs = rpm_mp_pkgs + " udev lvm2 lvm2-libs lvm2-cluster iscsi-initiator-utils tuned-profiles-sap-hana"


rpm_words = "ksym kmod multipath udev"  # words we care about

rpm_pkg = Key_data()                # key: pkg name             data: pkg version
rpm_pkg_source = Key_data()         # key: pkg name             data: source file name

rpm_pkg_min = Key_data()            # key: pkg name             data: minimum recommendd pkg version
rpm_pkg_min_kcs = Key_data()        # key: pkg name             data: kcs article referencing min pkg version

rpm_pkg_min['6_udev'] = '147-2.63'
rpm_pkg_min_kcs['6_udev'] = '206493'

rpm_pkg_min['6_device-mapper-multipath'] = '0.4.9-62'
rpm_pkg_min_kcs['6_device-mapper-multipath'] = ''  # haven't found a kcs that calls out a version of d-m-m

rpm_pkg_min['7_device-mapper-multipath'] = '0.4.9-99'
rpm_pkg_min_kcs['7_device-mapper-multipath'] = '2857731'

# rpm_pkg_min['6_lvm2'] = '2.02.118-3'
# rpm_pkg_min_kcs['6_lvm2'] = ''


kmod_pkg_min = Key_data()                      # key: rhel_maj_+"_"+kmod fn    data: min recomended version
kmod_pkg_min_kcs = Key_data()                  # key: rhel_maj_+"_"+kmod fn    data: kcs/sfdc reference

kmod_pkg_min['7_hpdsa'] = '3.10.0-514.16.1'
kmod_pkg_min_kcs['7_hpdsa'] = '01848489'  # sfdc case


valid_device_types = "sd st sr ch ac esd ses"
num_2_dev_type = Key_data()         # key: ansi device type # data: character device type
num_2_dev_type["0"] = "sd"    # scsi disk
num_2_dev_type["1"] = "st"    # scsi tape
num_2_dev_type["5"] = "sr"    # cd/dvd
num_2_dev_type["8"] = "ch"    # changer
num_2_dev_type["12"] = "ac"   # array controller (raid)
num_2_dev_type["13"] = "esd"  # enclosure services device
num_2_dev_type["31"] = "un"   # unknown

all_gpfs_problem_servers = ''

nfs_servers_tmo = Counter()   # key: nfs server name  data: count of times nfs server timed out
all_nfs_servers = ''          # names of all nfs servers encountered
all_filesystems = ""          # all filesystems encountered
all_fs_types = ""             # all filesystem types encountered
fstab_redo_lines = ""         # line number(s) to redo from etc/fstab after crunch_mount and crunch_df_data have run
# typically LABEL= and UUID= mount directives that were not resolved to a device file name
# and will now be matched against mountpoint data from df or mount files
vg_lv_fs_but_no_vgs_list = ''  # vg_lv_name~source list of these items
fstype_count = Counter()      # key: fstype: count of filesystem of various types

fs_2_alias = Key_data()  # alias; UUID=..,LABEL=..,alt lvm name
fs_2_mountpoint = Key_data()  # key: fs_device
fs_2_mountpoint_origin = Key_data()  # key: fs_device
fs_2_pctused = Key_data()  # key: fs_device
fs_2_type = Key_data()  # key: fs_device
fs_2_type_origin = Key_data()  # key: fs_device
fs_2_opts = Key_data()  # key: fs_device
fs_2_blocks = Counter()  # key: fs_device
fs_2_block_size = Counter()  # key: fs_device
# fs_netdev_opt_cnt      = 0          # number of times '_netdev' fs option seen

fs_full_anom_lines = ''
#
# filesystem "devices" to ignore (psuedo file systems, usually in-core kernel trees)
# /dev, /proc, /sys are found in proc/mounts
fs_ign = ""\
    "adapter "\
    "AFS "\
    "archivemount "\
    "binfmt_misc "\
    "capifs "\
    "ceph-fuse "\
    "cgmfs "\
    "cgroup "\
    "configfs "\
    "cm_cgroups "\
    "cm_processes "\
    "cpuset "\
    "datafs "\
    "debugfs "\
    "/dev "\
    "devpts "\
    "devtmpfs "\
    "efivarfs "\
    "ftfs "\
    "gvfs-fuse-daemon "\
    "gvfsd-fuse "\
    "fusectl "\
    "lxcfs "\
    "mqueue "\
    "HPSASmartBootFS "\
    "hugetlbfs "\
    "nfsd "\
    "nodev "\
    "none "\
    "nsfs "\
    "ocfs2_dlmfs "\
    "oracleasmfs "\
    "overlay "\
    "proc "\
    "/proc "\
    "pstore "\
    "ramfs "\
    "rpc_pipefs "\
    "securityfs "\
    "selinuxfs "\
    "sharedfs "\
    "shm "\
    "shmfs "\
    "sunrpc "\
    "swap "\
    "/sys "\
    "sysfs "\
    "systemd "\
    "systemd-1 "\
    "tempfs "\
    "tmpfs "\
    "tracefs "\
    "udev "\
    "usbfs "\
    "-hosts "\
    ""

# valid filesystem types, but ignored
fs_types_ign = ""\
               "autofs "\
               "cgroup "\
               "devpts "\
               "proc "\
               "sysfs "\
               "tmpfs "\
               ""
# add 'iso9660,udf' and 'udf,iso9660' ??
# add '-' ??
fs_types = ""\
           "acfs "\
           "afs "\
           "auto "\
           "bind "\
           "capifs "\
           "cifs "\
           "cvfs "\
           "debugfs "\
           "devtmpfs "\
           "efi "\
           "egenfs "\
           "ext "\
           "ext[2|3|4] "\
           "fuse "\
           "gfs "\
           "gfs2 "\
           "glusterfs "\
           "gpfs "\
           "hugetlbfs "\
           "initramfs "\
           "iso9660 "\
           "lustre "\
           "mqueue "\
           "jfs "\
           "msdos "\
           "mvfs "\
           "nfs "\
           "nfs4 "\
           "none "\
           "ntfs "\
           "ocfs2 "\
           "ramfs "\
           "reiserfs "\
           "rootfs "\
           "safenetfs "\
           "secfs2 "\
           "selinuxfs "\
           "shmfs "\
           "smb "\
           "smbfs "\
           "squashfs "\
           "swap "\
           "tracefs "\
           "udf "\
           "usbfs "\
           "vfat "\
           "vxfs "\
           "xfs "\
           "zfs "\
           "" + fs_types_ign + ""\
           ""

fs_type_ptrns = fs_types.split()


# non local and/or non-sized
non_local_fs_types = ""\
                     "autofs "\
                     "cifs "\
                     "fuse "\
                     "fuse.glusterfs "\
                     "fuse.sshfs "\
                     "glusterfs "\
                     "lustre "\
                     "mqueue "\
                     "mvfs "\
                     "nfs "\
                     "nfs4 "\
                     "smbfs "\
                     ""

# ---

dm_mp_types = ""\
    "alua "\
    "cache "\
    "clustered-disk "\
    "crypt "\
    "linear "\
    "mirror "\
    "multipath "\
    "queue-length "\
    "queue_if_no_path "\
    "raid "\
    "raid1 "\
    "raid45 "\
    "round-robin "\
    "service-time "\
    "snapshot "\
    "snapshot-origin "\
    "striped "\
    "switch "\
    "thin "\
    "thin-pool "\
    ""

lvm_conf_keywords = '\
         abort_on_errors \
         abort_on_internal_errors \
         activation \
         activation_mode \
         allow_changes_with_duplicate_pvs \
         archive \
         archive_dir \
         auto_activation_volume_list \
         backup \
         backup_dir \
         cache \
         cache_dir \
         cache_file_prefix \
         cache_pool_max_chunks \
         cache_pool_metadata_require_separate_pvs \
         checks \
         cling_tag_list \
         command_names \
         data_alignment \
         data_alignment_detection \
         data_alignment_offset_detection \
         debug_classes \
         default_data_alignment \
         detect_internal_vg_cache_corruption \
         dir \
         dirs \
         disable_after_error_count \
         etc \
         external_device_info_source \
         fallback_to_clustered_locking \
         fallback_to_local_locking \
         file \
         filter \
         format_libraries \
         fw_raid_component_detection \
         global_filter \
         history_size \
         ignore_lvm_mirrors \
         ignore_suspended_devices \
         indent \
         issue_discards \
         level \
         library_dir \
         locking_dir \
         locking_library \
         locking_type \
         maximise_cling \
         md_chunk_alignment \
         md_component_check \
         md_component_detection \
         metadata_read_only \
         mirror_device_fault_policy \
         mirror_image_device_fault_policy \
         mirror_image_fault_policy \
         mirror_image_log_fault_policy \
         mirror_library \
         mirror_log_fault_policy \
         mirror_logs_require_separate_pvs \
         mirror_region_size \
         mirror_segtype_default \
         missing_stripe_filler \
         missing_stripe_filter \
         monitoring \
         multipath_component_detection \
         notify_dbus \
         obtain_device_list_from_udev \
         overwrite \
         polling_interval \
         preferred_names \
         prefix \
         prioritise_write_locks \
         process_priority \
         proc \
         profile_dir \
         pvmetadatacopies \
         pvmetadatasize \
         pv_min_size \
         raid10_segtype_default \
         raid_fault_policy \
         raid_region_size \
         readahead \
         replace_wwid_whitespace \
         require_restorefile_with_uuid \
         reserved_memory \
         reserved_stack \
         retain_days \
         retain_min \
         retry_deactivation \
         scan \
         silent \
         si_unit_consistency \
         snapshot_autoextend_percent \
         snapshot_autoextend_threshold \
         snapshot_library \
         sparse_segtype_default \
         suffix \
         sysfs_scan \
         syslog \
         system_id_source \
         test \
         thin_check_executable \
         thin_check_options \
         thin_library \
         thin_pool_autoextend_percent \
         thin_pool_autoextend_threshold \
         thin_pool_metadata_require_separate_pvs \
         types \
         udev_rules \
         udev_sync \
         umask \
         units \
         use_blkid_wiping \
         use_linear_target \
         use_lvmetad \
         use_lvmlockd \
         use_lvmpolld \
         use_mlockall \
         verbose \
         verify_udev_operations \
         volume_list \
         wait_for_locks \
         wipe_signatures_when_zeroing_new_lvs \
         write_cache_state \
         '
lvm_conf_key_words = lvm_conf_keywords.split()


multipath_conf_keywords = '\
        alias \
        alias_prefix \
        all_devs \
        bindings_file \
        checker_timeout \
        config_dir \
        default_getuid_callout \
        default_path_grouping_policy \
        default_selector \
        deferred_remove \
        delay_wait_checks \
        delay_watch_checks \
        devnode \
        detect_path_checker \
        detect_prio \
        dev_loss_tmo \
        disable_changed_wwids \
        failback \
        features \
        fast_io_fail_tmo \
        file_timeout \
        find_multipaths \
        flush_on_last_del \
        force_sync \
        getuid_callout \
        gid \
        hardware_handler \
        hwtable_regex_match \
        hw_str_match \
        ignore_new_boot_devs \
        log_checker_err \
        max_fds \
        max_polling_interval \
        max_sectors_kb \
        missing_uev_wait_timeout \
        mode \
        multipath_dir \
        new_bindings_in_boot \
        no_path_retry \
        path_checker \
        path_grouping_policy \
        path_selector \
        pg_prio_calc \
        pg_timeout \
        polling_interval \
        prio \
        prio_args \
        prio_callout \
        prkeys_file \
        product \
        product_blacklist \
        queue_without_daemon \
        reassign_maps \
        reload_readwrite \
        remove_retries \
        reservation_key \
        retain_attached_hw_handler \
        retrigger_delay \
        retrigger_tries \
        rr_min_io \
        rr_min_io_rq \
        rr_weight \
        selector \
        skip_kpartx \
        udev_dir \
        uid \
        uid_attribute \
        user_friendly_names \
        vendor \
        verbosity \
        wwid \
        wwids_file \
        '
multipath_conf_key_words = multipath_conf_keywords.split()
# dmi_line = "DMI: (not found in dmesg)"  # default value
dmi_sys_data = "(system data not available from dmidecode or dmesg)"  # default value
dmi_cpu_data = "(cpu data not available from dmidecode)"

meminfo_2_vm = Key_data()    # alias the data in proc/meminfo to the corresponding sysctl key where necessary
meminfo_2_vm["HugePages_Total"] = "vm.nr_hugepages"

blocked_duration = 0
blocked_task_count = Counter()   # Key: task_type  Data: blocked task count e.g.: "IO", 4
blocked_task_names = Key_data()  # Key: task_type  Data: blocked task count e.g.: "IO", scsi_wq_1, scsi_id, ..
total_blocked_task_count = 0
all_blocked_tasks = ""
all_blocked_task_types = ""

info_text = "information in"
cfa_text = "check for applicability of"

match_log_msg_match_calls = 0
match_log_msg_matches = 0
count_of_times_do_scan_block_called = 0  # (per calling routine)
count_of_times_add_scsi_info_called = 0  # (per calling routine)
scan_count = Counter()      # key: scan_block   data: count of scan_pattern matches
scan_origin = Key_data()    # key: scan_block   data: file origin for scan_pattern match
# ------------------------
#
# scan_table is made up of scan_blocks which are separated by new-lines (\n) -
# If desired, this would allow the scan_table to be moved to an external file and read in.
# The first line is the scan_pattern which is used to match against log file lines.
# The remai-ning elements are KEY:VALUE pairs.
#
# INFO_KCS:kcs number  - used to reference an existing knowledge solution that may help in this case,
# in the format, "information in KCS https://access.redhat.com/solutions/<kcs# >"
# INFO_KCA:kca number  - used to reference an existing knowledge article that may help in this case,
# in the format, "information in KCA https://access.redhat.com/articles/<kca# >"
# CFA_KCS:kcs number   - used to reference an existing knowledge solution that may help in this case,
# in the format, "check for applicability of KCS https://access.redhat.com/solutions/<kcs# >"
# KCS:kcs number       - used to reference an existing knowledge solution that may help in this case.
# KCA:kcs article      - used to reference an existing knowledge article that may help in this case.
# BZ:bz number         - used to reference an existing bugzilla entry that may help in this case.
# SFDC:sfcd number     - used to reference an existing salesforce case that may help in this case.
# URL:url              - used to reference a general url  that may help in this case, (eg emc, symantec, etc).
#
# conditional urls:    - any of the above keywords [INFO_KCS: thru URL:], can be conditionalized by adding the
# a second colon followed by a text string to be evaluated as True or False
# e.g.: "KCS:12345:(Virtual_guest)~"
#
# ANOM:anomaly id      - anomaly id to be associated with the detail or summary event,
# default is KCS when a a KCS reference is present, otherwise NOTE is used.
#
# INSTXT:text          - 'text' is inserted between "Found <n> 'log file line' messages" and the
# remaining portion of the anomaly message, often; "check for applicability of KCS nnn"
# 'text' can be written as 'eval ...' to do dynamic substitution,
# e.g.: "INSTXT:eval 'number of attempts {0}'.format(attempt_count)~"
#
# TEST_SCAN:string     - executed after scan_pattern is matched, allows further match refinement.
# the resulting value must evaluate to 'True' in order for the match to continue.
# EXEC_SCAN:string     - executed after scan_pattern is matched, allows additional processing to occur.
# The <string> should generally be simple; e.g.; event_counter+=1
# If more complex logic is needed a routine should be called; e.g.: (do_routine(line,words,source)).
# TEST_SUMM:string     - executed when non-zero scan_counts (associated with each scan_block) are processed.
# The resulting value must evaluate to 'True' in order for the scan_block summarization to continue.
# EXEC_SUMM:string     - executed when non-zero scan_counts (associated with each scan_block) are processed.
# See EXEC_SCAN for usage details.
# PROC_SCAN:DETAIL     - for every matched scan_pattern line, an anomaly line will be written. By default, only
# only a summary anomaly line will be created.
# PROC_SUMM:SKIP       - skip the creation of a summary anomaly line. Can be used with 'EXEC_SUMM:rtn(..)' to create
# more involved summary anomaly.
# ID:identity          - optional entry.
# provide a shorthand way to locate a scanblock. E.g.: scnblk = get_scan_block(identity)
# currently used to access the msg count for the scan block in question.
# MATCH:STOP|CONTINUE  - the default action is to STOP looking for further matches. Use MATCH:CONTINUE to continue
# scanning.
# ------------------------
#
# <||Developer Note||>
# N.B.
# scan entries marked as being present to short circuit further searching are based on experiences with large messages
# files (50k - 5m) lines, where matching a message and stopping the search eliminates thousands of additional checks
# both in the same scan table and, in some cases, into the associated wild card table. This is amplified when there are
# thousands of instances of the message in a messages file.
#
# ------------------------
# <||Developer Note||>
#
# A note on how to debug message matching:
#
# Invariably a developer may add a message to one of the daemon or kernel tables, and subsequent run of sumsos will not
# produce the expected/desired match.
#
# If a quick eyeball check does not yield an obvious reason, then the following method may be helpful:
#
# 1. Create a directory structure like this: 'mkdir -p sos_debug/var/log/'
# 2. Copy the message from the messages or dmesg file that is not mathcing.
# 3. Paste the message into sos_debug/var/log/dmesg or sos_debug/var/log/messages (depending on origin)
# 4. cd to sos_debug and run 'sumsos -debug=4 > foo'
# 5. With debug set to 4 a line for every match check that was made will be output to 'foo'
# 6. Check foo for the pattern you added that did not match. There are several reasons for not matching:
# a. If you don't see your newly added pattern, then it might be in the wrong group.
# For instance you might have added the pattern in the kernel_misc_u_scan_table when you meant to add it to the kernel_misc_t_scan_table
# b. If it is in the right group, it may be matching an ealier and possibly more generic, pattern. If this is the case, either put the new
# pattern ahead of the pattern that is matching, or add "MATCH:CONTINUE~"\ to the earlier pattern.
# c. If you see your new pattern and it is not matching such as the following:
#
# debug4:(0.0003)[match_log_msg_vs_scan_blocks.25101] 'kernel: sd 2:0:0:0: [sdb] FAILED Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK' *DOES NOT* match pattern kernel: sd [0-9]{1,3}:[0-9]{1,3}:[0-9]{1,3}:[0-9]{1,10}: \[sd[a-z]{1,3}\]\s+Failed Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK (1,var/log/messages) p=1
#
# split the line in half and compare the the messages against the pattern:
# debug4:(0.0003)[match_log_msg_vs_scan_blocks.25101] 'kernel: sd 2:0:0:0: [sdb] FAILED Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK' *DOES NOT* match pattern
# kernel: sd [0-9]{1,3}:[0-9]{1,3}:[0-9]{1,3}:[0-9]{1,10}: \[sd[a-z]{1,3}\]\s+Failed Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK (1,var/log/messages) p=1
#
# in the case above, you see that the pattern has 'Failed' while the message contains 'FAILED' thus causing the check to fail.
# Typos are the ususal cause of matches failing. Others include using a numeric field which is shorter than the data in the message.
# i.e. pattern is: '...delayed '+n2_re+' seconds...' and the message is: '...delayed 348 seconds...' n2_re will fail to match a 3 digit number (although n3_re will match a 2 digit number).
# d. Common typos:
# 1)  forgetting the field seperator: "kernel: some text"\ instead of "kernel: some text~"\
# 2)  forgetting the new-line on a new pattern: "\n"\
#
# ------------------------
# <||Developer Note||>
#
# Directions for adding a new daemon_<name>_scan_table or,
# a new kernel_<name>_scan_table:
#
# 1. Create the the list of daemon or kernel messages and associated attributes.
# 2. Add an entry to daemon_specific_scan_tables or kernel_specific_scan_tables
# (add to the end unless the id is known to occur extensively).
#
# Example; the fictious smoot daemon has a number of messages which need to be tracked.
# Create the scan table:
#
# daemon_smootd_scan_blocks = ''
# daemon_smootd_scan_table = ''\
# "smootd: message 1...~"\
# "KCS:123456~"\
# "ANOM:SMOOT~"\
# "\n"\
# "smootd: message 2...~"\
# "KCS:67891011~"\
# "ANOM:SMOOT~"\
# "\n"\
# ""
#
# Add a line to daemon_specific_scan_tables:
#
# "smootd|smootd:~"\
#
# daemon_<name>_scan_blocks|"<str>~" match check
# ------------------------
#
# # <||Developer Note||>
#
# See the "cautionary tale" below in the kernel section, regarding the avoidance of any strings in the
# daemon_specific_scan_tables which are subsets of one another.
#
# ------------------------
daemon_specific_scan_tables = ""\
                              "systemd|systemd~"\
    "multipathd|multipathd:~"\
    "lvm|lvm~"\
    "udev|udev~"\
                              "fcoemon|fcoemon:~"\
    "iscsid|iscsid:~"\
    "corosync|corosync~"\
    "cmaeventd|cmaeventd~"\
    "fenced|fenced~"\
    "qdiskd|qdiskd~"\
    "had|Had~"\
    "rgmanager|rgmanager~"\
    "mmfs|mmfs:~"\
    ""
# The above list should be kept in frequency order to minimize the number of time thru the for loop which does the matching.
# Although this can vary from case to case, the utility, syslog_prefix_check, can be used to periodically gather counts
# on large groups of cases in order to confirm message distributions.
#
check_table_data(daemon_specific_scan_tables, "daemon_specific_scan_tables")

daemon_specific_ids = daemon_specific_scan_tables.split('~')
last_daemon_specific_id_str_match = ''
last_daemon_specific_scan_blocks_match = ''
daemon_cmaeventd_scan_blocks = ''
daemon_cmaeventd_scan_table = \
    "cmaeventd" + pid_br_re + ": Logical drive " + n3_re + " of Array Controller: I/O request fatal error~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Logical drive " + n3_re + " of Embedded Array Controller: I/O request fatal error~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Logical drive " + n3_re + " of Embedded Array Controller: surface analysis uncorrected read error condition has ended.  Media defects have been overwritten by the host.~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Logical drive " + n3_re + " of Array Controller in slot " + n3_re + ": surface analysis uncorrected read error condition has ended.  Media defects have been overwritten by the host.~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Physical drive failed: .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Cache battery missing: Embedded Array Controller~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:HPE~"\
    "\n"\
    "cmaeventd" + pid_br_re + ": Cache disabled: Embedded Array Controller~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:HPE~"\
    "\n"\
    ""
#
daemon_corosync_scan_blocks = ''
daemon_corosync_scan_table = \
    "corosync" + pid_br_re + ": .* JOIN or LEAVE message was thrown away during flush operation~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "corosync" + pid_br_re + ": .* Corosync main process was not scheduled for " + n6_re + "." + n4_re + " ms \(threshold is " + n5_re + "." + n4_re + " ms\). Consider token timeout increase.*~"\
    "EXEC_SCAN:do_corosync_not_scheduled(line,words,source)~"\
    "INSTXT:eval summ_corosync_ms_values()~"\
    "KCS:1217663~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "corosync" + pid_br_re + ": .* Marking ringid " + n2_re + " interface " + ip_addr_re + " FAULTY~"\
    "KCS:400723~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "corosync" + pid_br_re + ": cman killed by node " + n1_re + " because we were killed by cman_tool or other application~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:308583~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "corosync" + pid_br_re + ": \[TOTEM \] A processor failed, forming new configuration.~"\
    "ANOM:CLUSTER~"\
    "\n"\
    ""
#
daemon_fcoemon_scan_blocks = ''
daemon_fcoemon_scan_table = \
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 1=lip datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=10~"\
    "ANOM:FCOE~"\
    "\n"\
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 2=link_up datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=10~"\
    "ANOM:FCOE~"\
    "\n"\
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 3=link_down datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=10~"\
    "ANOM:FCOE~"\
    "\n"\
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 4=lip_reset datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=10~"\
    "KCS:1144423~"\
    "ANOM:FCOE~"\
    "\n"\
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 5=rscn datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=30~"\
    "KCS:2297481~"\
    "ANOM:FCOE~"\
    "\n"\
    "fcoemon: FC_HOST_EVENT .* at .* secs on host.*code 65535=vendor_unique datalen .* data=.*~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=10~"\
    "KCS:1410043~"\
    "ANOM:FCOE~"\
    "\n"\
    ""
daemon_fenced_scan_blocks = ''
daemon_fenced_scan_table = \
    "fenced" + pid_br_re + ": cluster is down, exiting~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "fenced" + pid_br_re + ": fence .* failed~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "KCS:160563~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "fenced" + pid_br_re + ": fencing node .*~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "fenced" + pid_br_re + ": fence \".*\" .*~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    ""
#
daemon_had_scan_blocks = ''
daemon_had_scan_table = \
    "Had" + pid_br_re + ": VCS CRITICAL V-" + n2_re + "-" + n1_re + "-" + n5_re + " Mem usage on .* is 9" + n1_re + "%~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS CRITICAL V-" + n2_re + "-" + n5_re + "-" + n2_re + " \(.*\) .*:.*:.* failed to stop~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS CRITICAL V-" + n2_re + "-" + n5_re + "-" + n2_re + " \(.*\) .*:.*:.* process LISTENER not running~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS CRITICAL V-" + n2_re + "-" + n1_re + "-" + n5_re + " VxFEN driver not found. Error opening /dev/vxfen. Retrying.*~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS CRITICAL V-" + n2_re + "-" + n1_re + "-" + n5_re + " CPU usage on .* is " + n3_re + "~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n1_re + "-" + n5_re + " \(.*\) Resource\(.*\) - monitor procedure did not complete within the expected time.~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n1_re + "-" + n5_re + " .*~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "Had" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n5_re + "-" + n4_re + " .*~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    ""
# No need to add duplicate filters with "iscsid[pid]:" --  adjust_log_message() will remove "[pid]" portion
daemon_iscsid_scan_blocks = ''
daemon_iscsid_scan_table = \
    "iscsid: cannot make a connection to " + ip_addr_and_port_re + " \(.*,.*\)~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: connect to " + ip_addr_and_port_re + " failed \(No route to host\)~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=10~"\
    "INSTXT:if jumbo frames are active, check for consistent use~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: connect to " + ip_addr_and_port_re + " failed \(Connection refused\)~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=10~"\
    "INSTXT:if jumbo frames are active, check for consistent use~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: conn " + n2_re + " login rejected: target error \(" + n3_re + "/" + n3_re + "\)~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: session " + n2_re + " login rejected: Initiator failed authentication with target~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=10~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Kernel reported iSCSI connection " + n4_re + ":" + n4_re + " error \(1011\) state \(" + n3_re + "\).*~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:42956~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Kernel reported iSCSI connection " + n4_re + ":" + n4_re + " error \(1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed\) state \(" + n3_re + "\).*~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:42956~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Kernel reported iSCSI connection " + n4_re + ":" + n4_re + " error \(1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed\) state \(" + n3_re + "\).*~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:423473~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Connection" + n4_re + ":" + n4_re + " to \[target: .*, portal: .*\] through \[iface: .*\] is shutdown.~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:2040773~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: connection" + n4_re + ":" + n4_re + " is operational after recovery \(" + n3_re + " attempts\).*~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Kernel reported iSCSI connection " + n4_re + ":" + n4_re + " error .*~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:36141~"\
    "KCS:383473~"\
    "KCS:1423383~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Target requests logout within " + n2_re + " seconds for connection~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:971183~"\
    "ANOM:ISCSI~"\
    "\n"\
    "iscsid: Target dropping all connections, reconnect min " + n2_re + " max " + n2_re + "~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:1750333~"\
    "ANOM:ISCSI~"\
    "\n"\
    ""
#
daemon_lvm_scan_blocks = ''
daemon_lvm_scan_table = \
    "lvm.*~"\
    "# for all matching lvm messages, add one to the lvm anom point counter~"\
    "EXEC_SCAN:anomaly_points['lvm']+=1~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "lvm: Found duplicate PV .*: using /dev/" + sd_re_p + " not /dev/" + sd_re_p + "~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "\n"\
    "lvm: Found duplicate PV .*: using /dev/" + sd_re + " not /dev/" + sd_re + "~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "\n"\
    "lvm: Found duplicate PV .*: using /dev/.* not /dev/.*~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "\n"\
    "lvm: Using duplicate PV /dev/.* which is last seen, replacing /dev/.*~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "\n"\
    "lvm: Duplicate of PV .* dev /dev/.* exists on unknown device " + mm_re + ".*~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "\n"\
    "lvm: Duplicate of PV .* dev /dev/.* exists on unknown device " + mm_re + ".*~"\
    "TEST_SUMM:(service_procs['lvmetad'] > 0 and rh_major >= 7)~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm: device-mapper: create ioctl on .* failed: Device or resource busy~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm: .*: refresh before autoactivation failed.~"\
    "ANOM:LVMW~"\
    "\n"\
    "lvm: .*: autoactivation failed.~"\
    "ANOM:LVMW~"\
    "\n"\
    "lvm: /.*: stat failed: No such file or directory~"\
    "ANOM:LVMW~"\
    "\n"\
    "lvm: Refusing activation of partial LV .*." + var_spaces + "Use '--activationmode partial' to override.~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm: Refusing refresh of partial LV .*." + var_spaces + "Use '--activationmode partial' to override.~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm: WARNING: Not using lvmetad because config setting use_lvmetad=0.~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm: WARNING: PV .* on .* was already found on .*~"\
    "ANOM:LVMW~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "lvm: WARNING: PV .* prefers device .* because of previous preference.*~"\
    "ANOM:LVMW~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "lvm: Couldn't find device with uuid .*.~"\
    "EXEC_SCAN:could_not_find_lvm_uuid(line,source)~"\
    "PROC_SUMM:SKIP~"\
    "# ANOM:LVMW~"\
    "\n"\
    "lvmetad" + pid_br_re + ": Failed to accept connection errno " + n3_re + ".~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm" + pid_br_re + ": dm_task_run failed, errno = ~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm" + pid_br_re + ": device-mapper: waitevent ioctl on  failed: ~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm" + pid_br_re + ": Failed to suspend ~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm" + pid_br_re + ": Failed to extend ~"\
    "ANOM:LVM~"\
    "\n"\
    "lvm" + pid_br_re + ": Failed to extend thin .*-.*~."\
    "ANOM:LVM~"\
    "KCS:1521023~"\
    "\n"\
    "lvm" + pid_br_re + ": Insufficient free space: " + n5_re + " extents needed, but only " + n5_re + " available~"\
    "ANOM:LVM~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "KCS:1521023~"\
    "\n"\
    "lvm" + pid_br_re + ": Snapshot .*-.* changed state to: Invalid~"\
    "ANOM:LVM~"\
    "KCS:56141~"\
    "KCS:232283~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm" + pid_br_re + ": Snapshot .*-.* is now (95%|100%) full~"\
    "ANOM:LVM~"\
    "KCS:36607~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm" + pid_br_re + ": Thin .*-.* is now 100% full~"\
    "ANOM:LVM~"\
    "CFA_KCS:1521023~"\
    "EXEC_SCAN:anomaly_points['lvm']+=20~"\
    "\n"\
    "lvm" + pid_br_re + ": No longer monitoring snapshot .*~"\
    "ANOM:LVM~"\
    "KCS:1237823~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm" + pid_br_re + ": /.*: open failed: Too many open files~"\
    "ANOM:LVM~"\
    "KCS:2372961~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm" + pid_br_re + ": Can't get lock for .*~"\
    "ANOM:LVM~"\
    "EXEC_SCAN:anomaly_points['lvm']+=4~"\
    "\n"\
    "lvm" + pid_br_re + ": No longer monitoring RAID device .* for events~"\
    "ANOM:LVM~"\
    "# PROC_SCAN:DETAIL~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm" + pid_br_re + ": Unmounting invalid snapshot .* from .*~"\
    "ANOM:LVM~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:56141~"\
    "KCS:232283~"\
    "EXEC_SCAN:anomaly_points['lvm']+=10~"\
    "\n"\
    "lvm.*~"\
    "# if lvm message didn't match, remove one to the lvm anom point counter added at the top~"\
    "EXEC_SCAN:anomaly_points['lvm']-=1~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
#
daemon_mmfs_scan_blocks = ''
daemon_mmfs_scan_table = \
    "mmfs: mmfsd: Error=.*, ID=0x.*, Tag=.*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=3~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[N\] mmfsd is shutting down~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[N\] Reason for shutdown: Normal shutdown~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[N\] Reason for shutdown: Could not generate hostid for the node~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[N\] Node " + ip_addr_re + " \(.*\) lease renewal is overdue. Pinging to check if it is alive~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=4~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[N\] Expel " + ip_addr_re + " \(.*\) request from " + ip_addr_re + " \(.*\). Expelling: " + ip_addr_re + " \(.*\)~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[X\] Unable to retrieve the hostid of the node - GPFS daemon terminated. HostID=.* HostName=.*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[E\] Killing connection from " + ip_addr_re + " because the group is not ready for it to rejoin, err .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[E\] Node " + ip_addr_re + " \(.*\) is being expelled because of an expired lease. Pings sent: .*. Replies received: .*.~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "EXEC_SCAN:global all_gpfs_problem_servers;all_gpfs_problem_servers=unique_list(all_gpfs_problem_servers,words[4].strip('()'))~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[E\] File system .* unmounted by node .* \(.*\)~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:GPFS~"\
    "\n"\
    "mmfs: \[E\] Global NSD disk, " + nsd_re + ", not found.~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=4~"\
    "ANOM:GPFS~"\
    "\n"\
    ""
#
daemon_multipathd_scan_blocks = ''
daemon_multipathd_scan_table = \
    "multipathd: " + dm_re + ": adding map~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: event checker started~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: event checker exit~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: load table .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - emc_clariion_checker: Passive path is healthy~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - emc_clariion_checker: Active path to inactive snapshot WWN .*~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "multipathd: .*: Entering recovery mode: max_retries=" + n4_re + "~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: checker failed path " + mm_re + " in map .*~"\
    "# PASS:2~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:do_mpathd_error(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "# INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: overflow in attribute .*~"\
    "ANOM:MULTIPATHD~"\
    "KCS:426693~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": .* checker reports path is down~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_a(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-a~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - .* checker reports path is down~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_b(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-b~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: " + sd_re + ": .* checker reports path is up~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_a(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-c~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - .* checker reports path is up~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_b(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-d~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - .* checker timed out~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_b(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-e~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: " + sd_re + ": .* checker reports path in standby state~"\
    "EXEC_SCAN:do_mpathd_checker_reports_path_state_a(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "ID:mpathd-f~"\
    "EXEC_SUMM:do_mpathd_checker_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: " + sd_re + ": checker msg is \".*: query command indicates error\"~"\
    "EXEC_SCAN:do_mpathd_query_command_indicates_error_a(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SUMM:do_mpathd_query_cmd_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": .*: query command indicates error~"\
    "EXEC_SCAN:do_mpathd_query_command_indicates_error_a(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SUMM:do_mpathd_query_cmd_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: " + sd_re + " - .*: query command inidicates error~"\
    "EXEC_SCAN:do_mpathd_query_command_indicates_error_b(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SUMM:do_mpathd_query_cmd_summary(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: Too many open files~"\
    "ANOM:MULTIPATHD~"\
    "KCS:57576~"\
    "EXEC_SCAN:anomaly_points['multipath']+=10~"\
    "\n"\
    "multipathd: " + sd_re + ": failed to get path uid~"\
    "ANOM:MULTIPATHD~"\
    "TEST_SCAN:Virtual_guest~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": failed to get path uid~"\
    "ANOM:MULTIPATHD~"\
    "TEST_SCAN:not Virtual_guest~"\
    "INSTXT:check if device can return uid, if not blacklist~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": unusable path~"\
    "ANOM:MULTIPATHD~"\
    "INSTXT:consider rescanning devices then running multipath -v2~"\
    "INFO_KCS:969653~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: asm!.asm_ctl_.*: failed to get path uid~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: asm/.asm_ctl_.*: failed to get path uid~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: asm!.asm_ctl_.*: failed to store path info~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: asm/.asm_ctl_.*: failed to store path info~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: ofsctl: failed to get path uid~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: HDIO_GETGEO failed with 25~"\
    "ANOM:MULTIPATHD~"\
    "KCS:29537~"\
    "KCS:3348941~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": couldn't get asymmetric access state~"\
    "ANOM:MULTIPATHD~"\
    "KCS:1242553~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: stop event checker thread~"\
    "ANOM:MULTIPATHD~"\
    "TEST_SCAN:(rhel_is('LE','5.10'))~"\
    "KCS:648123~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + dm_re + ": add map (uevent)~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: " + dm_re + ": remove map (uevent)~"\
    "ANOM:MULTIPATHD~"\
    "INFO_KCS:62041~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + dm_re + ": devmap already registered~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "multipathd: " + dm_re + ": devmap not registered, can't remove~"\
    "ANOM:MULTIPATHD~"\
    "INFO_KCS:62041~"\
    "INSTXT:check blacklist~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: stop event checker thread~"\
    "ANOM:MULTIPATHD~"\
    "INFO_KCS:62041~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: error getting map status string~"\
    "ANOM:MULTIPATHD~"\
    "BZ:880121~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: " + sd_re + ": alua not supported~"\
    "MATCH:CONTINUE~"\
    "ANOM:MULTIPATHD~"\
    "TEST_SCAN:word_in_list('FALCON',all_dev_mfgs)~"\
    "EXEC_SCAN:anomaly_points['multipath']+=10~"\
    "\n"\
    "multipathd: " + sd_re + ": alua not supported~"\
    "ANOM:MULTIPATHD~"\
    "INFO_KCS:962403~"\
    "EXEC_SCAN:anomaly_points['multipath']+=10~"\
    "\n"\
    "multipathd: .*: remaining active paths: 8~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 7~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 6~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 5~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 4~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 3~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 2~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "\n"\
    "multipathd: .*: remaining active paths: 1~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "multipathd: .*: remaining active paths: 0~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=20~"\
    "\n"\
    "multipathd: .*: switch to path group # 2~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: .*: switch to path group # 1~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: force queue_without_daemon \(operator\)~"\
    "ANOM:MULTIPATHD~"\
    "INSTXT:ensure that this command was issued intentionally~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: " + mm_re + ": mark as failed~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "EXEC_SCAN:do_mpathd_mark_as_failed(line,words,source)~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "multipathd: " + sd_re + ": hds prio: SCSI error~"\
    "ANOM:MULTIPATHD~"\
    "KCS:1335913~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: " + mm_re + ": reinstated~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "multipathd: .*: failed to resize map: Invalid argument~"\
    "ANOM:MULTIPATHD~"\
    "BZ:1333492~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: .*: Failed to reload map read/write: Read-only file system~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: " + sd_re + ": spurious uevent, path already in pathvec~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: .*: failed in domap for addition of new path " + sd_re + "~"\
    "ANOM:MULTIPATHD~"\
    "KCS:2360781~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: asm.*: spurious uevent, path already in pathvec~"\
    "ANOM:MULTIPATHD~"\
    "KCS:2360781~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: A dynamic linking error occurred: \(/lib64/multipath/libprio.so: cannot open shared object file: No such file or directory\)~"\
    "ANOM:MULTIPATHD~"\
    "KCS:2462551~"\
    "\n"\
    "multipathd: A dynamic linking error occurred with initprio: \(/lib64/multipath/libpriooraclefspm.so: undefined symbol: initprio\)~"\
    "ANOM:MULTIPATHD~"\
    "KCS:1335913~"\
    "\n"\
    "multipathd: A dynamic linking error occurred: .*~"\
    "ANOM:MULTIPATHD~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "multipathd: .*: Disable queueing~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "multipathd: " + sd_re + ": No fc_remote_port device for 'rport-" + n1_re + ":" + n1_re + "-" + n1_re + "'~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "multipathd: --------shut down-------~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    ""
#
daemon_rgmanager_scan_blocks = ''
daemon_rgmanager_scan_table = \
    "rgmanager" + pid_br_re + ": Marking service:.* as 'disabled', but some resources may still be allocated~"\
    "ANOM:SERVICE~"\
    "\n"\
    "rgmanager" + pid_br_re + ": \[lvm\] HA LVM:  Improper setup detected~"\
    "KCS:21622~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": \[lvm\] * initrd image needs to be newer than lvm.conf~"\
    "KCS:21622~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": \[lvm\] WARNING: .*~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": \[lvm\] HA LVM: Unable to get volume group attributes for .*~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": State change: .* UP"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": State change: .* DOWN"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "rgmanager" + pid_br_re + ": Shutting down~"\
    "ANOM:SERVICE~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    ""
#
#
daemon_systemd_scan_blocks = ''
daemon_systemd_scan_table = \
    "systemd.*: Starting Session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Started Session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Created slice user-.*slice.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Starting user-.*slice.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Stoppng user-.*slice.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Removed slice user-.*slice.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: New session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Removed session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Created slice .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Removed slice .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: Timed out stoppping .*md.*~"\
    "# -->stoppping is correct~"\
    "ANOM:SYSTEMD~"\
    "KCS:3212261~"\
    "\n"\
    "systemd-logind: Failed to stat\(\) POSIX shared memory segment .*: Permission denied~"\
    "ANOM:SYSTEMD~"\
    "KCS:20622753~"\
    "\n"\
    "systemd-logind: New session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd-logind: Removed session.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd-logind: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "systemd.*: slow: '/usr/bin/sginfo -s /dev/" + sg_re + "' " + pid_br_re + "~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd-udevd.*: slow: 'scsi_id --export --whitelisted -d /dev/" + sd_re + "' " + pid_br_re + "~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd.*: timeout: killing '/usr/bin/sginfo -s /dev/" + sg_re + "' " + pid_br_re + "~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd-udevd.*: timeout: killing 'scsi_id --export --whitelisted -d /dev/" + sd_re + "' " + pid_br_re + "~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd.*: timeout: killing '/sbin/kpartx -a /dev/" + dm_re + "' " + pid_br_re + "~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd: Timed out waiting for device .*~"\
    "ANOM:SYSTEMD~"\
    "KCS:2273451~"\
    "KCS:1751483~"\
    "\n"\
    "systemd.*: iscsid.service: Failed with result '.*'~"\
    "ANOM:SYSTEMD~"\
    "ANOM:ISCSI~"\
    "\n"\
    "systemd-udevd: timeout: killing .*~"\
    "ID:udev-1~"\
    "KCS:1604953~"\
    "ANOM:UDEV~"\
    "\n"\
    "systemd-udevd: worker " + pid_br_re + " /devices/.* is taking a long time~"\
    "ID:udev-2~"\
    "ANOM:UDEV~"\
    "\n"\
    "systemd.*: Device .* appeared twice with different sysfs paths .* and .*~"\
    "ANOM:SYSTEMD~"\
    "INFO_KCS:2180111~"\
    "\n"\
    "systemd.*: multipathd\.service never wrote its PID file\. Failing~"\
    "ANOM:MULTIPATHD~"\
    "KCS:2857731~"\
    "\n"\
    "systemd.*: Job dev-mapper-.*\.device/start failed with result 'timeout'.*~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "systemd.*: Failed to start Device-Mapper Multipath Device Controller.~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "systemd.*: Unit multipathd.service entered failed state.~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "systemd.*: multipathd.service failed.~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "systemd.*: Failed to send unit remove signal for .*\.device: Transport endpoint is not connected~"\
    "ANOM:SYSTEMD~"\
    "\n"\
    "systemd.*: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
#
daemon_qdiskd_scan_blocks = ''
daemon_qdiskd_scan_table = \
    "qdiskd" + pid_br_re + ": Error reading node ID block " + n7_re + "~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "KCS:108213~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": Error writing node ID block " + n7_re + "~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "KCS:108213~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": Error writing to quorum disk~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "KCS:108213~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": qdiskd on node " + n2_re + " reports hung read\(\)~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "KCS:27764~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": Node " + n2_re + " evicted~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:27764~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": <.*> Node " + n2_re + " evicted~"\
    "EXEC_SCAN:anomaly_points['cluster']+=10~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:27764~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": Node " + n2_re + " is undead~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "qdiskd" + pid_br_re + ": <.*> Node " + n2_re + " is undead~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:CLUSTER~"\
    "\n"\
    ""
#
daemon_udev_scan_blocks = ''
daemon_udev_scan_table = \
    "udevd" + pid_br_re + ": worker " + pid_br_re + " unexpectedly returned with status 0x0100~"\
    "ID:udev-3~"\
    "KCS:206493~"\
    "ANOM:UDEV~"\
    "\n"\
    "udevd" + pid_br_re + ": worker " + pid_br_re + " failed while handling '/devices/pci.*/host.*/rport.*/target.*'.*~"\
    "ID:udev-4~"\
    "KCS:206493~"\
    "KCS:60087~"\
    "ANOM:UDEV~"\
    "\n"\
    "udevd" + pid_br_re + ": worker " + pid_br_re + " failed while handling .*~"\
    "ID:udev-4~"\
    "KCS:206493~"\
    "KCS:60087~"\
    "ANOM:UDEV~"\
    "\n"\
    "udevd-work" + pid_br_re + ": 'udisks-dm-export " + n3_re + " " + n2_re + "' unexpected exit with status 0x.*~"\
    "ID:udev-5~"\
    "ANOM:UDEV~"\
    "\n"\
    "udevadm settle - timeout of " + n3_re + " seconds reached, the event queue contains:~"\
    "ID:udev-6~"\
    "KCS:60087~"\
    "ANOM:UDEV~"\
    "\n"\
    ""
#
# --- start of miscellaneous daemon scan blocks
#
daemon_misc_a_scan_blocks = ''
daemon_misc_a_scan_table = \
    "abrt" + pid_br_re + ": Saved core dump of pid " + pid_re + " .*~"\
    "EXEC_SCAN:check_abort_lines(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:ABRT~"\
    "\n"\
    "AgentFramework" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n1_re + "-" + n5_re + " Thread\(.*\) Resource\(.*\) - monitor procedure did not complete within the expected time.~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "AgentFramework" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n1_re + "-" + n5_re + " Thread\(.*\) Agent is calling clean for resource\(.*\) because the resource became OFFLINE unexpectedly, on its own.~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "AgentFramework" + pid_br_re + ": VCS ERROR V-" + n2_re + "-" + n1_re + "-" + n5_re + " .*~"\
    "INSTXT:contact Veritas and open a parallel case~"\
    "ANOM:VERITAS~"\
    "\n"\
    "audispd: queue is full - dropping event~"\
    "KCS:25190~"\
    "\n"\
    "audispd: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "avrd" + pid_br_re + ": ioctl error on .* \(device .*, /dev/.*\) thru sg driver, Success~"\
    "ANOM:ST~"\
    "\n"\
    "avrd" + pid_br_re + ": Fatal open error on .* \(device .*, /dev/.*\), errno = " + n2_re + " \(.*\)~"\
    "ANOM:ST~"\
    "\n"\
    ""
daemon_misc_b_scan_blocks = ''
daemon_misc_b_scan_table = \
    "bptm" + pid_br_re + ": TapeAlert Code: 0x.*, Type: Critical, Flag: .*, from drive .*, Media Id .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:692423~"\
    "ANOM:ST~"\
    "\n"\
    "bptm" + pid_br_re + ": TapeAlert Code: 0x.*, Type: Warning, Flag: .*, from drive .*, Media Id .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:1570533~"\
    "ANOM:ST~"\
    "\n"\
    ""
daemon_misc_c_scan_blocks = ''
daemon_misc_c_scan_table = \
    "clurgmgrd: " + pid_br_re + ": <err> HA LVM:  Improper setup detected~"\
    "KCS:21622~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "clurgmgrd: " + pid_br_re + ": <err> - initrd image needs to be newer than lvm.conf~"\
    "KCS:21622~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "cmaidad" + pid_br_re + ": Physical Drive Status Change: .*Status is now Predictive Failure~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "KCS:1496983~"\
    "ANOM:HPE~"\
    "\n"\
    "cmcld" + pid_br_re + ": Service .* in package .* has gone down.~"\
    "ANOM:HPE~"\
    "\n"\
    "cmcld" + pid_br_re + ": Disabled node .* from running package .*.~"\
    "ANOM:HPE~"\
    "\n"\
    "cmcld" + pid_br_re + ": Failing package .* on node .* due to service failure.~"\
    "ANOM:HPE~"\
    "\n"\
    "cmserviced" + pid_br_re + ": Request to halt service .*oracle.*~"\
    "ANOM:ORACLE~"\
    "\n"\
    "cmserviced" + pid_br_re + ": Request to halt service .*~"\
    "ANOM:HPE~"\
    "\n"\
    "cmserviced" + pid_br_re + ": Service .*oracle.* terminated due to a signal\(" + n2_re + "\).~"\
    "ANOM:ORACLE~"\
    "\n"\
    "cmserviced" + pid_br_re + ": Service .* terminated due to a signal\(" + n2_re + "\).~"\
    "ANOM:HPE~"\
    "\n"\
    "crmd" + pid_br_re + ":" + var_spaces + "error: Operation .*: Timed Out \(node=.*, call=" + n4_re + ", timeout=" + n5_re + "ms\)~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "crmd" + pid_br_re + ":" + var_spaces + "error: Result of monitor operation for .* on .*: Timed Out~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "CmdServer" + pid_br_re + ": WARNING V-365-1-1 This host is not entitled to run Veritas Storage Foundation/Veritas Cluster Server.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    ""
daemon_misc_d_scan_blocks = ''
daemon_misc_d_scan_table = \
    ""
daemon_misc_e_scan_blocks = ''
daemon_misc_e_scan_table = \
    "emcp_mond: PP daemon: Warning: Unable to open configuration file /etc/opt/emcpower/emcp_mond.conf.  Using default values~"\
    "EXEC_SCAN:anomaly_points['config']+=50~"\
    "ANOM:EMC~"\
    "\n"\
    "emcp.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
daemon_misc_f_scan_blocks = ''
daemon_misc_f_scan_table = \
    "firmware_helper" + pid_br_re + ": loading of .* for .* failed " + pid_br_re + " unexpectedly returned with status 0x0100~"\
    "KCS:206493~"\
    "\n"\
    ""
daemon_misc_g_scan_blocks = ''
daemon_misc_g_scan_table = \
    ""
daemon_misc_h_scan_blocks = ''
daemon_misc_h_scan_table = \
    "hp-ams" + pid_br_re + ": WARNING: .*~"\
    "INSTXT:contact HPE and open a parallel case~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:HPE~"\
    "\n"\
    ""
daemon_misc_i_scan_blocks = ''
daemon_misc_i_scan_table = \
    "io_setup failed~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    ""
daemon_misc_j_scan_blocks = ''
daemon_misc_j_scan_table = \
    ""
daemon_misc_k_scan_blocks = ''
daemon_misc_k_scan_table = \
    "kdumpctl: Starting kdump: \[FAILED\]~"\
    "BZ:1247478~"\
    "ANOM:KDUMP~"\
    "\n"\
    ""
daemon_misc_l_scan_blocks = ''
daemon_misc_l_scan_table = \
    "lrmd" + pid_br_re + ": warning: .*:" + pid_re + " - timed out after " + n5_re + "ms~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "lrmd" + pid_br_re + ": .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
daemon_misc_m_scan_blocks = ''
daemon_misc_m_scan_table = \
    "mcelog: Unsupported new Family .*: only decoding architectural errors~"\
    "ANOM:HW~"\
    "KCS:658243~"\
    "\n"\
    "modprobe: FATAL: Module .* not found~"\
    "ANOM:MODPROBE~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "mptscsih: ioc0: attempting task abort! \(sc=.*\)~"\
    "ANOM:SCSI~"\
    "KCS:108273~"\
    "\n"\
    "MR_MONITOR\[" + n5_re + "\]: <MRMON" + n5_re + "> Controller ID:  " + n1_re + "   Unexpected sense:   PD~"\
    "KCS:65490~"\
    "ANOM:SCSI~"\
    "\n"\
    ""
daemon_misc_n_scan_blocks = ''
daemon_misc_n_scan_table = \
    ""
daemon_misc_o_scan_blocks = ''
daemon_misc_o_scan_table = \
    ""
daemon_misc_p_scan_blocks = ''
daemon_misc_p_scan_table = \
    "PowerPath: MPAPI: Error: Insufficient user privilege.~"\
    "ANOM:EMC~"\
    "\n"\
    ""
daemon_misc_q_scan_blocks = ''
daemon_misc_q_scan_table = \
    ""
daemon_misc_r_scan_blocks = ''
daemon_misc_r_scan_table = \
    ""
daemon_misc_s_scan_blocks = ''
daemon_misc_s_scan_table = \
    "sanlock" + pid_br_re + ": .* renewal error .*~"\
    "KCS:718043~"\
    "KCS:1306263~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "sanlock" + pid_br_re + ": .* close_task_aio .* busy~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "sanlock" + pid_br_re + ": .* renewal error .*~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "scsi_reserve: \[error\] cluster not configured for scsi reservations~"\
    "EXEC_SCAN:anomaly_points['cluster']+=1~"\
    "ANOM:CLUSTER~"\
    "\n"\
    "" + sd_re + ": checker init failed~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + sd_re + ": state = ghost~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    ""
daemon_misc_t_scan_blocks = ''
daemon_misc_t_scan_table = \
    "tldcd" + pid_br_re + ": TLD\(.*\) key = 0x.*, ascq = 0x.*, LOGICAL UNIT COMMUNICATION TIME-OUT~"\
    "ANOM:ST~"\
    "\n"\
    "tldcd" + pid_br_re + ": Daemon has terminated abnormally~"\
    "ANOM:ST~"\
    "\n"\
    "tldd" + pid_br_re + ": TLD\(" + n3_re + "\) unavailable: initialization failed: Unable to sense robotic device~"\
    "ANOM:ST~"\
    "\n"\
    ""
daemon_misc_u_scan_blocks = ''
daemon_misc_u_scan_table = \
    ""
daemon_misc_v_scan_blocks = ''
daemon_misc_v_scan_table = \
    "vxesd" + pid_br_re + ": Failed to dispatch DMP events~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "vxesd" + pid_br_re + ": vxesd: Device " + sd_re + mm_pa_re2 + " is changed.~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "vxvm:vxconfigd: V-5-1-13834 ddl_add_to_conflict_list: Could not find entry in path for .*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "vxvm:vxconfigd: WARNING V-365-1-1 This host is not entitled to run Veritas Storage Foundation/Veritas Cluster Server.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    ""
daemon_misc_w_scan_blocks = ''
daemon_misc_w_scan_table = \
    ""
daemon_misc_x_scan_blocks = ''
daemon_misc_x_scan_table = \
    "XFS: possible memory allocation deadlock in kmem_alloc \(mode:0x.*\)~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "KCS:532663~"\
    "ANOM:XFS~"\
    "\n"\
    ""
daemon_misc_y_scan_blocks = ''
daemon_misc_y_scan_table = \
    ""
daemon_misc_z_scan_blocks = ''
daemon_misc_z_scan_table = \
    ""
daemon_misc_wc_scan_blocks = ''
daemon_misc_wc_scan_table = \
    "\# :# :# :# .* " + mm_re + " .* undef faulty ,~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " .* undef faulty .*,.* running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " .* undef ghost .*,.* running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " .* \[undef\]\[faulty\] .*,.*~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " \[failed\]\[faulty\]~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " active faulty running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " failed faulty running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " failed undef running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " failed ready running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " failed undef unknown~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "" + scsi_adr_re + " " + sd_re + " " + mm_re + " active ghost running~"\
    "# multipath_-v4_-ll msg~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    ".*gmond" + pid_br_re + ": slurpfile\(\) read\(\) buffer overflow on file .*~"\
    "KCS:133753~"\
    "ANOM:CLUSTER~"\
    "\n"\
    ""
# end of daemon scan tables -------------------------------------------------------------

# start of kernel: scan tables ----------------------------------------------------------
#
# See daemon_specific_scan_tables above for instructions on how to add a new kernel_<name>_scan_table.
#
# +--------------+
#
# # <||Developer Note||>
#
# A cautionary tale: Initially "kernel: "+sd_re+... messages were part of "kernel: sd " table but due to the
# growing length of that table they were broken out into a table of their own; "kernel: "+sd_re (aka kernel_sdc).
#
# When the 'last_kernel_specific_id_str_match/scan_blocks_match' fields and associated logic was added, it broke
# messages evaluation in certain cases. Specifically where a "kernel: sd ..." message followed a "kernel: sd_re" message.
# This is due ot the fact that id string in kernel_specific_scan_tables was "sd~" which is subset of "sd ~".
# Thus the last_kernel logic would fail in the above case as only the "kernel: sd_re" message table would be searched.
# To fix this, the "kernel: sd_re" messages were moved to the kernel_misc_s table.
#
# In general terms, this means that *NONE* of the strings associated with the scan tables can be a subset of one another.
#
# +--------------+
#
#
# kernel_<name>_scan_blocks|"kernel: <str>" match check
kernel_specific_scan_tables = ""\
    "sd|sd ~"\
    "scsi|scsi~"\
    "end_request|end_request:~"\
    "buffer_io_error|buffer i/o error~"\
    "device_mapper|device-mapper:~"\
    "blk_update_request|blk_update_request:~"\
    "lpfc|lpfc~"\
    "qla|qla~"\
    "rport|rport~"\
    "ext3|ext3-fs~"\
    "ext4|ext4-fs~"\
    "xfs|xfs~"\
    "st|st~"\
    "sr|sr~"\
    "bug|bug~"\
    "be2net|be2net~"\
                              ""
# "sdc|sd~"\
check_table_data(kernel_specific_scan_tables, "kernel_specific_scan_tables")
kernel_specific_ids = kernel_specific_scan_tables.split('~')
last_kernel_specific_id_str_match = ''
last_kernel_specific_scan_blocks_match = ''

kernel_device_mapper_scan_blocks = ''
kernel_device_mapper_scan_table = \
    "kernel: device-mapper: multipath: Failing path " + mm_re + "~"\
    "ANOM:MULTIPATH~"\
    "KCS:78813:(kernel_is('LT','2.6.32.-279'))~"\
    "EXEC_SCAN:track_failing_paths(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['multipath']+=20~"\
    "INSTXT:[total_path_errors++]~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": multipath: error getting device~"\
    "# PASS:2~"\
    "ANOM:MULTIPATH~"\
    "KCS:38538~"\
    "EXEC_SCAN:device_mapper_error_getting_device(line,source)~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": multipath: unknown path selector type~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=10~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": multipath: Unrecognised multipath feature request~"\
    "ANOM:MULTIPATH~"\
    "KCS:337363~"\
    "EXEC_SCAN:anomaly_points['multipath']+=2~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": " + sd_re + " too small for target~"\
    "ANOM:MULTIPATH~"\
    "KCS:392963~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": " + sd_re_p + " too small for target~"\
    "ANOM:MULTIPATH~"\
    "KCS:392963~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: table: device " + mm_re + " too small for target~"\
    "ANOM:MULTIPATH~"\
    "KCS:392963~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: multipath: Reinstating path " + mm_re + "~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": unable to service pool target messages in READ_ONLY or FAIL mode~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": reached low water mark for metadata device: sending event.~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=1~"\
    "KCS:2136901~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": metadata operation 'dm_pool_commit_metadata' failed: error = .*~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": aborting current metadata transaxtion~"\
    "ANOM:MULTIPATH~"\
    "KCS:1521023~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": switching pool to out-of-data-space mode~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: thin: " + mm_re + ": switching pool to read-only mode~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: thin: Deletion of thin device " + n4_re + " failed~"\
    "ANOM:MULTIPATH~"\
    "ID:susceptible_to_filescanners_1~"\
    "\n"\
    "kernel: device-mapper: table: " + mm_re + ": snapshot: Snapshot cow pairing for exception table handover failed~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "kernel: device-mapper: multipath: Unrecognised multipath message received~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=5~"\
    "\n"\
    "kernel: device-mapper: table: device /dev/mapper/mpath.* too small for target~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "kernel: device-mapper: multipath: Could not failover the device: Handler .* Error " + n3_re + "~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:check_lsmod_info(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['multipath']+=10~"\
    "\n"\
    "kernel: device-mapper: raid1: All replicated volumes dead, failing I/O~"\
    "ANOM:MULTIPATH~"\
    "EXEC_SCAN:anomaly_points['multipath']+=20~"\
    "\n"\
    "kernel: device-mapper: multipath.* version .* loaded~"\
    "EXEC_SCAN:check_dm_mp_loaded(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: device-mapper: ioctl: ioctl interface mismatch: kernel(.*), user(.*), cmd(.*)~"\
    "ANOM:MULTIPATH~"\
    "KCS:78813~"\
    "\n"\
    "kernel: device-mapper: " + raid_re + ": Mirror read failed~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "kernel: device-mapper: multipath: Using scsi_dh module scsi_dh_alua for failover/failback and device management.~"\
    "ANOM:MULTIPATH~"\
    "INFO_KCS:415253~"\
    "\n"\
    ""
#
# kernel_sdc_scan_table are messages that start like this-> kernel: sda: ....
# The elements of this list were taken from kernel_sd_scan_table to keep kernel_sd_scan_table as short as possible
# due to its fairly long length..
#
# >> See "Cautionary tale:" note above.
#
# kernel_sdc_scan_blocks = ''
# kernel_sdc_scan_table =
#
# TODO: work in KCS solution 627903 which deals with limiting path failover time for SCSI devices
# Need to work out what messges to best reference the KCS article.
#
kernel_sd_scan_blocks = ''
kernel_sd_scan_table = \
    "kernel: sd " + scsi_adr_re + ":~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": reservation conflict~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Attached .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Direct-Access .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + "$~"\
    "# handled by add_scsi_info() above, here to short circuit search -- nothing but kernel: sd h:b:t:l [sdc]~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + n12_re + " 512-byte logical blocks: .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "ASC=0x.* ASCQ=0x.*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "<<vendor>> ASC=0x.* ASCQ=0x.*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Mode Sense: .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Parameters changed~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Device not ready~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Attached .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Synchronizing SCSI cache~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB: Write" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB: Write same" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " CDB: Write" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " CDB: Write same" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "KCS:2994531~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB: Read" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " CDB: Read" + pa_n2_re + ".*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB: Synchronize Cache" + pa_n2_re + ".*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " CDB: Synchronize Cache" + pa_n2_re + ".*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB: Test Unit Ready .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " CDB: Test Unit Ready .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Synchronize Cache" + pa_n2_re + " failed: Result: hostbyte=.* driverbyte=.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Unhandled error code~"\
    "KCS:1212233~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " CDB:~"\
    "# 7.1 msg CDB(nn) and '(nn) xx xx ...' data split on 2 lines ~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Unhandled error code~"\
    "KCS:1405103~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Medium access timeout failure. Offlining disk~"\
    "MATCH:CONTINUE~"\
    "KCS:1283543~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Medium access timeout failure. Offlining disk~"\
    "TEST_SCAN:(('fnic' in get_host_desc(words[2])) or ('Cisco Systems Inc VIC FCoE' in get_host_desc(words[2])))~"\
    "EXEC_SCAN:event_count['fnic']+=1~"\
    "INSTXT:Cisco fnic~"\
    "KCS:2162451~"\
    "BZ:1341298~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Warning! Received an indication that the LUN assignments on this target have changed.*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=5~"\
    "EXEC_SUMM:lun_assignment_check(scan_block,source)~"\
    "KCS:1598403~"\
    "ANOM:SD~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Warning! Received an indication that the operating parameters on this target have changed.*~"\
    "KCS:276553~"\
    "ANOM:SD~"\
    "\n"\
    "# kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x.*~"\
    "MATCH:CONTINUE~"\
    "# this happens in add_scsi_info()->exec_scan:track_scsi_error(line,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00010000~"\
    "KCS:163203~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00020008~"\
    "KCS:1202423~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00040000~"\
    "KCS:499873~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00070000~"\
    "KCS:59311~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00070002~"\
    "TEST_SCAN:word_in_list('LSI',all_hba_mfgs)~"\
    "# TEST_SCAN:word_in_list('megaraid',all_hba_mfgs)~"\
    "KCS:391023~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00070028~"\
    "TEST_SCAN:word_in_list('QLogic',all_hba_mfgs)~"\
    "KCS:122113~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x000d0000~"\
    "# TEST_SCAN:word_in_list('lpfc',all_hba_mfgs)~"\
    "KCS:26956~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x000e0000~"\
    "KCS:131533~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x000f0000~"\
    "KCS:1189483~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x00110018~"\
    "KCS:202763~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x06000000~"\
    "TEST_SCAN:rhel_is('LT','6') and word_in_list('QLogic',all_hba_mfgs)~"\
    "KCS:37946~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x070d0000~"\
    "KCS:1203313~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x08000002~"\
    "KCS:35465~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x08070002~"\
    "KCS:35465~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x08100002~"\
    "KCS:35465~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": SCSI error: return code = 0x........~"\
    "# catch all~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": alua: rtpg failed with 8000002~"\
    "INSTXT:have cust involve storage vendor & san team in troubleshooting~"\
    "ANOM:MULTIPATHCONF~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": alua: port group " + n2_re + " state .* non-preferred supports .*~"\
    "EXEC_SCAN:track_alua_states(line,source)~"\
    "INFO_KCA:362324~"\
    "# ANOM:SD~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": alua: port group " + n2_re + " state .* preferred supports .*~"\
    "EXEC_SCAN:track_alua_states(line,source)~"\
    "INFO_KCA:362324~"\
    "# ANOM:SD~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": alua: port group " + n2_re + " .*~"\
    "# if not handled by previous filters, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Hardware Error .*~"\
    "KCS:271923~"\
    "INSTXT:contact storage vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Recovered Error .*~"\
    "KCS:41612~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Recovered Error .*~"\
    "KCS:41612~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Data Protect~"\
    "MATCH:CONTINUE~"\
    "TEST_SCAN:kernel_is('LT','2.6.32-220.el6')~"\
    "KCS:78813~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Data Protect~"\
    "MATCH:CONTINUE~"\
    "TEST_SCAN:kernel_is('LT','2.6.32-220.el6')~"\
    "KCS:78813~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Data Protect.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Data Protect.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Illegal Request \[current\]~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Illegal Request .*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Illegal Request \[current\]~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Illegal Request .*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request \[current\]~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request .*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Sense Key: Unit Attention \[current\]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Discard failure~"\
    "MATCH:CONTINUE~"\
    "TEST_SCAN:kernel_is('LT','2.6.32-279.el6')~"\
    "KCS:78813~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Discard failure~"\
    "MATCH:CONTINUE~"\
    "TEST_SCAN:word_in_list('mkfs.ext4',blocked_task_names['IO'])~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Discard failure~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": timing out command, waited " + n4_re + "s~"\
    "MATCH:CONTINUE~"\
    "EXEC_SCAN:track_sd_timeouts(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": timing out command, waited " + n4_re + "s~"\
    "MATCH:CONTINUE~"\
    "EXEC_SCAN:if not Virtual_guest: anomaly_points['hardware']+=10~"\
    "TEST_SUMM:(not Virtual_guest)~"\
    "KCS:363174~"\
    "# :kcs explains how timeouts occur~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": timing out command, waited " + n4_re + "s~"\
    "MATCH:CONTINUE~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCA:46958~"\
    "# :kca explains when & why to use noop scheduler (i.e. for VMs)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": timing out command, waited " + n4_re + "s~"\
    "TEST_SCAN:(check_vmware_time_out(line,words,source))~"\
    "KCS:129773~"\
    "# :kcs explains how & why to increase low timeout values for VMs if TO < 180s~"\
    "# :routine also issues anomalies to check specific virtual disks~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": megasas: RESET -.* cmd=.* retries=.*~"\
    "KCS:1481613~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " megasas: target reset FAILED.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_OK driverbyte=DRIVER_OK~"\
    "# TEST_SCAN:word_in_list('EMC',all_hba_mfgs) or word_in_list('DGC',all_hba_mfgs)~"\
    "INSTXT:check for reservation conflicts~"\
    "KCS:357753~"\
    "KCS:539553~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK~"\
    "KCS:163203~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "FAILED Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK~"\
    "KCS:163203~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + var_spaces + "FAILED Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK~"\
    "KCS:163203~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_TIME_OUT driverbyte=DRIVER_OK~"\
    "KCS:163203~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_ERROR driverbyte=DRIVER_OK~"\
    "KCS:438403~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_TRANSPORT_FAILFAST driverbyte=DRIVER_OK~"\
    "KCS:1159213~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_OK driverbyte=DRIVER_TIMEOUT~"\
    "KCS:349353~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_OK~"\
    "KCS:2686631~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Done: SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_TIMEOUT~"\
    "KCS:349353~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE~"\
    "KCS:1256863~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_TRANSPORT_DISRUPTED driverbyte=DRIVER_OK~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " FAILED Result: hostbyte=DID_TRANSPORT_DISRUPTED driverbyte=DRIVER_OK~"\
    "KCS:507673~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " FAILED Result: hostbyte=DID_BAD_TARGET driverbyte=DRIVER_OK~"\
    "KCS:131533~"\
    "KCS:1592523~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_BAD_TARGET driverbyte=DRIVER_OK~"\
    "KCS:131533~"\
    "KCS:1592523~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Result: hostbyte=DID_REQUEUE driverbyte=DRIVER_OK~"\
    "KCS:738223~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " FAILED Result: hostbyte=DID_ERROR driverbyte=DRIVER_OK~"\
    "KCS:438403~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " FAILED Result: hostbyte=DID_ERROR driverbyte=DRIVER_OK~"\
    "KCS:438403~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Write cache: (disabled|enabled), read cache: (disabled|enabled), .*~"\
    "EXEC_SCAN:check_write_read_cache(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Write cache: disabled, read cache: enabled, doesn't support DPO or FUA~"\
    "TEST_SCAN:word_in_list('LSI',all_hba_mfgs)~"\
    "INFO_KCS:1527943~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Write cache: enabled, read cache: enabled, doesn't support DPO or FUA~"\
    "# if not handled by previous filters, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " READ CAPACITY.* failed~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Read Capacity.* failed~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Very big device. Trying to use READ CAPACITY~"\
    "INSTXT:eval 'unique device count {0}'.format(word_count(very_big_device_list))~"\
    "KCS:59606~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " SCSI Bus reset~"\
    "KCS:2127091~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " SCSI device reset on scsi.*~"\
    "INSTXT:[total_io_errors++]~"\
    "KCS:2127091~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": rejecting I/O to offline device~"\
    "INSTXT:[total_io_errors++]~"\
    "KCS:44867~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": scsi: Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Internal target failure~"\
    "KCS:58800~"\
    "INSTXT:contact storage vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + tag_re + " Add. Sense: Internal target failure~"\
    "KCS:58800~"\
    "INSTXT:contact storage vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Invalid message error~"\
    "INSTXT:contact storage/hba vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Space allocation failed write protect~"\
    "KCS:1549773~"\
    "INSTXT:contact storage vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Logical unit not supported~"\
    "KCS:907813~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Invalid field in cdb~"\
    "KCS:2994531~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + var_spaces + "Add. Sense: Invalid field in cdb~"\
    "KCS:2994531~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: No additional sense information~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Logical unit not ready, manual intervention required~"\
    "ID:lun_nr_1~"\
    "ANOM:SD~"\
    "KCS:738963~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + var_spaces + "Add. Sense: Logical unit not ready, manual intervention required~"\
    "ID:lun_nr_2~"\
    "ANOM:SD~"\
    "KCS:738963~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Logical unit not accessible, target port in standby state~"\
    "INSTXT:check for passive devices~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Add. Sense: Logical unit not accessible, target port in standby state~"\
    "INSTXT:check for passive devices~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Unrecovered read error - auto reallocate failed~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Add. Sense: Unrecovered read error - auto reallocate failed~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Add. Sense: Timeout on logical unit~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Add. Sense: Timeout on logical unit~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid command operation code~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid field in cdb~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": \[storvsc\] Add. Sense: Changed operating definition~"\
    "KCS:3220121~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Warning! Received an indication that the LUN reached a thin provisioning soft threshold~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Assuming drive cache: write through~"\
    "INFO_KCS:42752~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " task abort on host " + n2_re + ", ff.*~"\
    "INSTXT:[total_io_errors++]~"\
    "KCS:2893401:(Oracle)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Unexpected response from lun " + n4_re + " while scanning, scan aborted~"\
    "KCS:1225113:(Oracle)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Medium Error .*~"\
    "ANOM:SD~"\
    "INSTXT:likely hardware problem~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Data Protect \[current\]~"\
    "KCS:1549773~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": attempting task abort! scmd\(.*\)~"\
    "INFO_KCS:193743~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": task abort: FAILED scmd\(.*\)~"\
    "INSTXT:[total_io_errors++]~"\
    "INFO_KCS:193743~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": task abort: SUCCESS scmd\(.*\)~"\
    "INSTXT:[total_io_errors++]~"\
    "INFO_KCS:193743~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Sense Key: Aborted Command \[current\]~"\
    "KCS:58800~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Aborted Command \[current\]~"\
    "KCS:58800~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Sense Key: No Sense \[current\]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Failed to abort cmd ff.*~"\
    "KCS:2893401:(Oracle)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Failed to get completion for aborted cmd ff.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " megasas: target reset FAILED!!~"\
    "EXEC_SCAN:anomaly_points['hardware']+=5~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Unit Not Ready~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": emc: ALUA failover mode detected~"\
    "KCS:139193~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": emc: long trespass command sent~"\
    "KCS:55350~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": emc: .*~"\
    "# if not handled by previous filters, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Asymmetric access state changed~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Write Protect is on~"\
    "EXEC_SCAN:check_write_protected_msg(line,source)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Send: scmd 0x.*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + var_spaces + "Sense Key: Not Ready \[current\]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Sense Key: Not Ready \[current\]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Sense Key: Not Ready \[current\]~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Write Protect is off~"\
    "# now here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "# EXEC_SCAN:check_write_protected_msg(line,source)~"\
    "# ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Test WP failed, assume Write Enabled~"\
    "INFO_KCS:25608~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Asking for cache data failed~"\
    "INFO_KCS:25608~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Mode parameters changed~"\
    "KCS:1290893~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Using 0xffffffff as device size~"\
    "INFO_KCS:59606~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": lun" + n5_re + " has a LUN larger than allowed by the host adapter~"\
    "INFO_KCS:26017~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " killing request~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Command \(.*\) failed: transaction cancelled \(" + n4_re + ":" + n4_re + "\) flags: .* fcp_rsp: .*, resid=.*, scsi_status: .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " Command \(.*\) failed: transaction cancelled implicit \(" + n4_re + ":" + n4_re + "\) flags: .* fcp_rsp: .*, resid=.*, scsi_status: .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Command \(.*\) failed: transaction cancelled \(" + n4_re + ":" + n4_re + "\) flags: .* fcp_rsp: .*, resid=.*, scsi_status: .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": " + sd_br_re + " " + tag_re + " Command \(.*\) failed: transaction cancelled implicit \(" + n4_re + ":" + n4_re + "\) flags: .* fcp_rsp: .*, resid=.*, scsi_status: .*~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Cancelling outstanding commands.~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Successfully cancelled outstanding commands~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Aborting outstanding commands~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: sd " + scsi_adr_re + ": Abort successful~"\
    "ANOM:SD~"\
    "\n"\
    ""
kernel_st_scan_blocks = ''
kernel_st_scan_table = \
    "kernel: st " + scsi_adr_re + ":~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": reservation conflict~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: " + st_re + ": Failed to read " + n8_re + " byte block with " + n8_re + " byte transfer~"\
    "KCS:20735~"\
    "KCS:270603~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": scsi: Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Can't allocate " + n8_re + " byte tape buffer~"\
    "KCS:1376503~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": Unexpected response from lun " + n4_re + " while scanning, scan aborted~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Current: sense key: Medium Error~"\
    "PROC_SUMM:SKIP~"\
    "PROC_SCAN:DETAIL~"\
    "INSTXT:likely physical media problem~"\
    "KCS:1434623~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Current: sense Key: Hardware Error .*~"\
    "KCS:1434623~"\
    "INSTXT:contact storage vendor~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Sense Key: Medium Error \[deferred\]~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Device already in use~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Add. Sense: Write error~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st: Too many tape devices \(max. 128\)~"\
    "KCS:24699~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st: Too many tape devices \(max. 512\)~"\
    "KCS:24699~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st: Too many tape devices \(max. " + n4_re + "\)~"\
    "KCS:24699~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": rejecting I/O to offline device~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: " + st_re + ": Error " + hex5_re + " \(driver bt 0x.*, host bt 0x.*\)~"\
    "INSTXT:[total_io_errors++]~"\
    "EXEC_SCAN:st_io_error(line,source)~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: st " + scsi_adr_re + ": Mode parameters changed~"\
    "KCS:1290893~"\
    "ANOM:ST~"\
    "\n"\
    ""
kernel_sr_scan_blocks = ''
kernel_sr_scan_table = \
    "kernel: sr " + scsi_adr_re + ":~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": Send: scmd 0x.*~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": " + sr_br_re + " CDB: Read" + pa_n2_re + ".*~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": " + sr_br_re + " CDB: Write" + pa_n2_re + ".*~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": " + sr_br_re + var_spaces + "Sense Key: Medium Error .*~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": Done: SUCCESS Result: hostbyte=DID_TARGET_FAILURE driverbyte=DRIVER_OK~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": Sense Key: Illegal Request \[current\]~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr: Sense Key: Medium Error \[deferred\]~"\
    "ANOM:SR~"\
    "KCS:906563~"\
    "\n"\
    "kernel: sr: Add. Sense: Medium format corrupted~"\
    "ANOM:SR~"\
    "KCS:906563~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": Add. Sense: Invalid command operation code~"\
    "ANOM:SR~"\
    "\n"\
    "kernel: sr " + scsi_adr_re + ": " + sr_br_re + var_spaces + "Add. Sense: L-EC uncorrectable error~"\
    "ANOM:SR~"\
    "\n"\
    ""
kernel_scsi_scan_blocks = ''
kernel_scsi_scan_table = \
    "kernel: SCSI device .*~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ":~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Direct-Access .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Attached .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": rejecting I/O to offline device~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": rejecting I/O to dead device~"\
    "INSTXT:[total_io_errors++]~"\
    "KCS:69034~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi scan: device exists on " + scsi_adr_re + "~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:bld_ha_bus_tgt_lun(words[6],source)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Warning! Received an indication that the LUN assignments on this target have changed~"\
    "EXEC_SCAN:anomaly_points['hardware']+=5~"\
    "EXEC_SUMM:lun_assignment_check(scan_block,source)~"\
    "KCS:1598403~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi: On host " + n2_re + " channel " + n2_re + " id " + n2_re + " only " + n5_re + " \(max_scsi_report_luns\) of " + n5_re + " luns reported, try increasing max_scsi_report_luns~"\
    "KCS:749503~"\
    "ANOM:SCSI~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "kernel: scsi: host " + n3_re + " channel " + n3_re + " id " + n3_re + " lun.* has a LUN larger than allowed by the host adapter~"\
    "KCS:67157~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": bnx2fc: FCF not selected yet!~"\
    "TEST_SUMM:config_service['lldpad']=='on'~"\
    "INSTXT:lldap service is configured 'on'~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": hdr status = FCPIO_DATA_CNT_MISMATCH~"\
    "# TEST_SCAN:word_in_list('Cisco',all_hba_mfgs)~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=5~"\
    "KCS:1976843~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": hdr status = FCPIO_SGL_INVALID~"\
    "KCS:389763~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": hdr status = FCPIO_OUT_OF_RESOURCE~"\
    "INSTXT:check for fw update~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": libfc: Could not allocate frame~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi host" + n3_re + ": ~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_host(line,source)~"\
    "\n"\
    "kernel: scsi" + n3_re + ": ~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_host(line,source)~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": scsi: Device offlined - not ready after error recovery~"\
    "# PROC_SUMM:SKIP~"\
    "# PROC_SCAN:DETAIL~"\
    "# INSTXT:eval check_offlined_msg(line,source)~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi\(" + n1_re + "\): The edc_status node should no longer be used.~"\
    "KCS:486553~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Unexpected response from lun " + n4_re + " while scanning, scan aborted~"\
    "KCS:1225113:(Oracle)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": attempting task abort! scmd\(.*\)~"\
    "INFO_KCS:193743~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": task abort: FAILED scmd\(.*\)~"\
    "INSTXT:[total_io_errors++]~"\
    "INFO_KCS:193743~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": task abort: SUCCESS scmd\(.*\)~"\
    "INSTXT:[total_io_errors++]~"\
    "INFO_KCS:193743~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": Wrong diagnostic page; asked for " + n1_re + " got " + n1_re + "~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid command operation code~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid field in cdb~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Add. Sense: Power on, reset, or bus device reset occurred~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request \[current\]~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request .*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Sense Key: Unit Attention \[current\]~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": \[storvsc\] Sense Key: Unit Attention .*~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": alua: rtpg failed with~"\
    "INSTXT:check /etc/multipath.conf~"\
    "ANOM:MULTIPATHCONF~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": alua: port group " + n2_re + " state .* non-preferred supports .*~"\
    "EXEC_SCAN:track_alua_states(line,source)~"\
    "INFO_KCA:362324~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": alua: port group " + n2_re + " state .* preferred supports .*~"\
    "EXEC_SCAN:track_alua_states(line,source)~"\
    "INFO_KCA:362324~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": alua: .*~"\
    "# handled by add_scsi_info() above, here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: scsi " + scsi_adr_re + ": scsi scan: peripheral qualifier of " + n2_re + ", device not added~"\
    "EXEC_SCAN:check_not_added_msg(line,source)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: scsi\(" + n3_re + "\): Discard RND Frame -- .*~"\
    "KCS:65865~"\
    "ANOM:SCSI~"\
    "\n"\
    ""
#
#
#
kernel_be2net_scan_blocks = ''
kernel_be2net_scan_table = \
    "kernel: be2net " + pci_long_re + ": .*~"\
    "EXEC_SCAN:event_count['be2net']+=1~"\
    "EXEC_SCAN:anomaly_points['be2net']+=1~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": Unrecoverable Error detected in the adapter~"\
    "KCS:1229853~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": Error detected in the adapter~"\
    "KCS:1229853~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": Adapter recovery failed~"\
    "KCS:1229853~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": Please reboot server to recover~"\
    "KCS:401023~"\
    "KCS:2996101~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": UE: .*" + var_spaces + "bit set~"\
    "KCS:1229853~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": UE HIGH: .*" + var_spaces + "bit set~"\
    "KCS:1229853~"\
    "ANOM:BE2NET~"\
    "\n"\
    "kernel: be2net " + pci_long_re + ": .*~"\
    "# if we make it thru with no match, then take the event count back down one and the anomaly_points down 1~"\
    "EXEC_SCAN:event_count['be2net']-=1~"\
    "EXEC_SCAN:anomaly_points['be2net']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
#
# see https://docs.broadcom.com/docs/12356591 for reference
#
kernel_lpfc_scan_blocks = ''
kernel_lpfc_scan_table = \
    "kernel: lpfc " + pci_long_re + ": .*:" + n4_re + " .*~"\
    "EXEC_SCAN:event_count['lpfc']+=1~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=1~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .* READ_FCF_RECORD Indicates empty FCF table~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=20~"\
    "KCS:69150~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0100 FLOGI failure Status:.* TMO:x.*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:48886~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0115 Unknown ELS command x18 received from NPORT x.*~"\
    "INFO_KCS:2110501~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0115 Unknown ELS command x.* received from NPORT x.*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0127 ELS timeout Data: x.* x.* x.* x.*~"\
    "KCS:2046643~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0203 Devloss timeout on WWPN .* NPort .* Data: .*~"\
    "INFO_KCS:45774~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0205 Abort outstanding I/O on NPort x.* Data: .*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0310 Mailbox command x.* timeout Data: x.* x.* x.*~"\
    "ID:lpfc_kcs_29128_check~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0336 Rsp Ring .* error: IOCB Data: x.* x.* x.*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0338 IOCB wait timeout error - no wake response Data x.*~"\
    "KCS:356243~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0345 Resetting board due to mailbox timeout~"\
    "ID:lpfc_kcs_29128_check~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0372 iotag x.* is out off range: max iotag \(x9c0\)~"\
    "BZ:1149846~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0436 Adapter failed to init, timeout, status reg x.*, FW Data: .*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:316803~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:044[2|6] Adapter failed to init, .*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0445 Firmware initialization failed.*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:316803~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0708 Allocation request of " + n3_re + " command buffers did not succeed.  Allocated " + n3_re + " buffers~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0710 Iodone <.*/.*> cmd .*, error x.* SNS x.* Data: x.*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:38906~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0713 SCSI layer issued Device Reset~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:39590~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0714 SCSI layer issued Bus Reset~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:39590~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0716 FCP Read Underrun, expected " + n3_re + ", residual " + n3_re + " Data: .*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=1~"\
    "INFO_KCS:39338~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0727 TMF FCP_TARGET_RESET to TGT " + n2_re + " LUN " + n2_re + " failed \(.*\) iocb_flag x.*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:356243~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0730 FCP command x.* failed: x.* SNS .* Data: .*~"\
    "INFO_KCS:126383~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0748 abort handler timed out waiting for abortng I/O .* to complete~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:221043~"\
    "KCS:1993743~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0748 abort handler timed out waiting for aborting I/O .* to complete~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:221043~"\
    "KCS:1993743~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:0748 abort handler timed out waiting for abort to complete: ret .*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:221043~"\
    "KCS:356243~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1302 Invalid speed for this board:" + n2_re + " Reset link speed to auto~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1303 Link Up Event x.* received Data: x.*~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "EXEC_SCAN:event_count['lpfc']-=1~"\
    "EXEC_SCAN:anomaly_points['lpfc']-=1~"\
    "# link up & link down are 'normal', remove the event count bump given by the initial match~"\
    "ID:lpfc_link_up~"\
    "EXEC_SUMM:do_lpfc_link(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "KCS:33221~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1305 Link Down Event .* received Data: .*~"\
    "EXEC_SCAN:event_count['lpfc']-=1~"\
    "# link up & link down are 'normal', remove the event count bump given by the initial match~"\
    "ID:lpfc_link_down~"\
    "PROC_SUMM:SKIP~"\
    "KCS:33221~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1309 Link Up Event npiv not supported in loop topology~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "KCS:1268273~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1421 Failed to set up hba~"\
    "KCS:316803~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:1477 Failed to set up hba~"\
    "KCS:316803~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2530 Mailbox command x.* cannot issue Data: x.* x.*~"\
    "ID:lpfc_kcs_29128_check~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2548 FCF Table full count 0x.* tag 0x.*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2753 PLOGI failure DID:.* Status:.*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2755 ADISC failure DID:.* Status:.*~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2813 Mgmt IO is Blocked .* - mbox cmd " + n3_re + " still active~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2819 Abort outstanding I/O on NPort x.* Data: .*~"\
    "EXEC_SCAN:anomaly_points['lpfc']+=5~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2858 FLOGI failure Status:.* TMO:x.*~"\
    "KCS:48886~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:2611 FLOGI failed on FCF \(.*\), status:x.*, tmo:x.*, peform roundrobin FCF failover~"\
    "KCS:48886~"\
    "# SFDC:01639803~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:9024 FCP command x(12|a3) failed: x.* SNS .* Data: .*~"\
    "INFO_KCS:2206921~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:9024 FCP command x.* failed: x.* SNS .* Data: .*~"\
    "INFO_KCS:126383~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:9030 FCP cmd x.* failed <" + n2_re + "/" + n2_re + "> status: .* result: .* Data: .*~"\
    "INFO_KCS:126383~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:9064 BLKGRD: lpfc_scsi_prep_dma_buf_s3: Too many sg segments from dma_map_sg.  Config .*, seg_cnt .*~"\
    "KCS:234693~"\
    "KCS:2188091~"\
    "ANOM:LPFC~"\
    "\n"\
    "kernel: lpfc " + pci_long_re + ": .*:" + n4_re + " .*~"\
    "# if we make it thru with no match, then take the event count back down one and the anomaly_points down 1~"\
    "EXEC_SCAN:event_count['lpfc']-=1~"\
    "EXEC_SCAN:anomaly_points['lpfc']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
#
#
#
kernel_qla_scan_blocks = ''
kernel_qla_scan_table = \
    "kernel: qla2xxx " + pci_long_re + ":.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*:~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\): Abort command issued -- .*~"\
    "EXEC_SCAN:track_qla_aborts(line,words,line_no,source); anomaly_points['qla2xxx']+=5~"\
    "INSTXT:eval high_qla_aborts(scan_block,source)~"\
    "KCS:27624~"\
    "KCS:45099~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\) Dropped frame\(s\) detected \(.*\), firmware reported underrun~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=10~"\
    "INSTXT:check fc cabling~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\) Dropped frame\(s\) detected \(.* of .* bytes\)~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=10~"\
    "KCS:65865~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-801c:.*: Abort command issued nexus=.* -- .*~"\
    "EXEC_SCAN:track_qla_aborts(line,words,line_no,source); anomaly_points['qla2xxx']+=5~"\
    "INSTXT:eval high_qla_aborts(scan_block,source)~"\
    "KCS:27624~"\
    "KCS:45099~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx_eh_abort\(.*\): aborting sp ff.* from RISC~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=2~"\
    "# usually appears with qla2xxx <pci_adr> scsi(n:n:n): Abort command issued~"\
    "KCS:221713~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-8009:.*: DEVICE RESET ISSUED nexus=.* cmd=.*~"\
    "ID:DEVICE_RESET_ISSUED~"\
    "EXEC_SUMM:check_for_port_flap(scan_block,source)~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-800e:.*: DEVICE RESET SUCCEEDED nexus.* cmd=.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "ID:DEVICE_RESET_SUCCEEDED~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-800f:.*: DEVICE RESET FAILED: Task management failed nexus.* cmd=.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=5~"\
    "ID:DEVICE_RESET_FAILED~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-8017:.*: ADAPTER RESET SUCCEEDED nexus=.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-8018:.*: ADAPTER RESET ISSUED nexus=.*~"\
    "# EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-8802:.*: Aborting from RISC nexus=.* sp=.* cmd=.*~"\
    "KCS:1273273~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-8804:.*: Abort command mbx success cmd=.*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-287d:.*: FCPort state transitioned from ONLINE to LOST - portid=.*~"\
    "KCS:1273273~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-287d:.*: FCPort state transitioned from LOST to DEAD - portid=.*~"\
    "KCS:1342053~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-2087:.*: No loop_id's available, portid=.*~"\
    "KCS:1287923~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-5003:.*: ISP System Error - mbx.*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-00cd:.*: ISP Firmware failed checksum~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-00cf:.*: Setup chip \*\*\*\*FAILED\*\*\*\*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-00d2:.*: Init Firmware \*\*\*\* FAILED \*\*\*\*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-0034:.*: MSI-X: Unsupported ISP .* SSVID/SSDID \(0x.*,0x.*\)~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-d00b:.*: Firmware has been previously dumped .*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-00af:.*: Performing ISP error recovery - ha=.*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": Performing ISP error recovery - ha=.*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-00d6:.*: Failed to initialize adapter - Adapter flags .*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-5837:.*: Async-login failed - hdl=.* portid=.* comp=.* iop0=.* iop1=.*~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-5816:.*: Discard RND Frame -- .*~"\
    "KCS:54682~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-6006:.*: Detect abort" + var_spaces + "needed.*~"\
    "KCS:3241281~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-6007:.*: Firmware hung.*~"\
    "KCS:3241281~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-009b:.*: Device state is 0x4 = Need Reset.~"\
    "KCS:3241281~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-009d:.*: Device state is 0x4 = Need Reset.~"\
    "KCS:3241281~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\): DEVICE RESET ISSUED.*~"\
    "ID:DEVICE_RESET_ISSUED_ALT~"\
    "EXEC_SUMM:check_for_port_flap_alt(scan_block,source)~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\): DEVICE RESET SUCCEEDED.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "ID:DEVICE_RESET_SUCCEEDED_ALT~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\): DEVICE RESET FAILED: Task management failed.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=5~"\
    "ID:DEVICE_RESET_FAILED_ALT~"\
    "\n"\
    "kernel: qla2xxx (" + pci_long_re + ":|" + pci_br_long_re + "-.*:) LOOP DOWN detected .*~"\
    "ID:QLA2XXX_LOOP_DOWN_DETECTED~"\
    "EXEC_SUMM:check_for_qla_loop_up_down(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx (" + pci_long_re + ":|" + pci_br_long_re + "-.*:) LOOP UP detected .*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "ID:QLA2XXX_LOOP_UP_DETECTED~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Unable to read SFP data~"\
    "INFO_KCS:41042~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": Unable to read SFP data~"\
    "INFO_KCS:41042~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: \*\*\*\* Failed mbx\[0\]=4005, .* cmd=31 ~"\
    "INFO_KCS:436113~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": Cable is unplugged~"\
    "KCS:32767~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Cable is unplugged~"\
    "KCS:32767~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Failed to load firmware image~"\
    "KCS:224443~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: 83XX: F/W Error Reported: Check if reset required~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Heartbeat Failure encountered, chip reset required~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": \[ERROR\] Failed to load segment " + n3_re + " of firmware~"\
    "KCS:224443~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Firmware dump saved to temp buffer~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": Firmware dump saved to temp buffer~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": SNS scan failed -- assuming zero-entry result~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=5~"\
    "INSTXT:possible cabling/zoning issue~"\
    "KCS:25541~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: SNS scan failed -- assuming zero-entry result~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=5~"\
    "INSTXT:possible cabling/zoning issue~"\
    "KCS:25541~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Mailbox (cmd|command) timeout occurred~"\
    "KCS:36357~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": Mailbox (cmd|command) timeout occurred~"\
    "KCS:36357~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": vpd r/w failed.  This is likely a firmware bug on this device.  Contact the card vendor for a firmware update~"\
    "TEST_SCAN:rh_major <= 5~"\
    "KCS:633553~"\
    "MATCH:CONTINUE~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=4~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": vpd r/w failed.  This is likely a firmware bug on this device.  Contact the card vendor for a firmware update~"\
    "TEST_SCAN:rh_major >= 6~"\
    "KCS:39748~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=4~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Queue depth adjusted-up to " + n4_re + " for nexus=~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Queue depth adjusted-down to " + n4_re + " for nexus=~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": scsi\(.*\) QUEUE FULL detected~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-3820:.*: QUEUE FULL detected~"\
    "INSTXT:adjust sd device/queue_depth~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": LIP reset occurred \(.*\)~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "# KCS:443243~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": LIP occurred \(.*\)~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=1~"\
    "# KCS:443243~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ": RISC paused -- HCCR=.*, Dumping firmware!~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=9~"\
    "KCS:28144~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Thermal not supported through I2C bus, trying alternate method \(ISP access\)~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=4~"\
    "INFO_KCS:785263~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Thermal not supported through ISP~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=4~"\
    "INFO_KCS:785263~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*: Thermal not supported by this card \(ignoring further requests\)~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']+=4~"\
    "INFO_KCS:785263~"\
    "ANOM:QLA~"\
    "\n"\
    "kernel: qla2xxx " + pci_br_long_re + "-.*:~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "# MATCH:must be last in qla2xxx queue, adjust for +1 at start if no match~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: qla2xxx " + pci_long_re + ":.*~"\
    "EXEC_SCAN:anomaly_points['qla2xxx']-=1~"\
    "EXEC_SCAN:track_pci_errors(line,'--',source)~"\
    "# MATCH:must be last in qla2xxx queue, adjust for +1 at start if no match~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_rport_scan_blocks = ''
kernel_rport_scan_table = \
    "kernel: rport-.*: blocked FC remote port time out: removing rport~"\
    "ANOM:RPORT~"\
    "INFO_KCS:65596~"\
    "EXEC_SCAN:anomaly_points['rport']+=1~"\
    "\n"\
    "kernel: rport-.*: blocked FC remote port time out: removing target$~"\
    "# rhel 6,7~"\
    "ANOM:RPORT~"\
    "INFO_KCS:65596~"\
    "EXEC_SCAN:anomaly_points['rport']+=1~"\
    "\n"\
    "kernel: rport-.*: blocked FC remote port time out: saving binding~"\
    "# rhel 5~"\
    "ANOM:RPORT~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "KCS:58169~"\
    "\n"\
    "# kernel:  rport-.*: blocked FC remote port time out: saving binding~"\
    "# rhel 7 (==> in kernel_misc_wc due to double space before 'rport')~"\
    "# EXEC_SCAN:anomaly_points['rport']+=5~"\
    "# KCS:58169~"\
    "\n"\
    "kernel: rport-.*: blocked FC remote port time out: removing target and saving binding~"\
    "# rhel 6,7~"\
    "ANOM:RPORT~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "KCS:58169~"\
    "\n"\
    "kernel: rport-.*: blocked FC remote port time out: no longer a FCP target, removing starget~"\
    "ANOM:RPORT~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "KCS:58169~"\
    "\n"\
    ""
kernel_blk_update_request_scan_blocks = ''
kernel_blk_update_request_scan_table = \
    "kernel: blk_update_request: I/O error, dev " + sd_re + ", sector " + n11_re + "~"\
    "EXEC_SCAN:do_blk_update_request_io_error(line,words,source)~"\
    "INSTXT:eval summ_blk_update_request_sd_error()~"\
    "ANOM:IOERR~"\
    "\n"\
    "kernel: blk_update_request: I/O error, dev " + sd_re_p + ", sector " + n11_re + "~"\
    "EXEC_SCAN:do_blk_update_request_io_error(line,words,source)~"\
    "INSTXT:eval summ_blk_update_request_sd_error()~"\
    "ANOM:IOERR~"\
    "\n"\
    "kernel: blk_update_request: I/O error, dev " + dm_re + ", sector " + n11_re + "~"\
    "EXEC_SCAN:do_blk_update_request_io_error(line,words,source)~"\
    "INSTXT:eval summ_blk_update_request_dm_error()~"\
    "ANOM:IOERR~"\
    "\n"\
    "kernel: blk_update_request: critical target error, dev " + sd_re + ", sector *~"\
    "ANOM:IOERR~"\
    "BZ:1462594~"\
    "\n"\
    "kernel: blk_update_request: critical target error, dev " + dm_re + ", sector *~"\
    "ANOM:IOERR~"\
    "BZ:1462594~"\
    "\n"\
    "kernel: blk_update_request: critical target error, dev .*, sector *~"\
    "ANOM:IOERR~"\
    "\n"\
    "kernel: blk_update_request: .* callbacks suppressed~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: blk_update_request: I/O error, dev fd0, sector 0~"\
    "TEST_SUMM:(Virtual_guest)~"\
    "INSTXT:try to unpresent in hypervisor~"\
    "KCS:1191433~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "ANOM:FD~"\
    "\n"\
    ""
kernel_end_request_scan_blocks = ''
kernel_end_request_scan_table = \
    "kernel: end_request: I/O error, dev " + sd_re + ", sector .*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: I/O error, dev " + dm_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: I/O error, dev " + vxvm_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: I/O error, dev " + fd_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "KCS:1191433~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: critical medium error, dev " + sd_re + ", sector .*~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: critical target error, dev " + sd_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: critical target error, dev " + dm_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: critical medium error, dev " + dm_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    "kernel: end_request: critical space allocation error, dev " + sd_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "KCS:1549773~"\
    "\n"\
    "kernel: end_request: critical space allocation error, dev " + dm_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "KCS:1549773~"\
    "\n"\
    "kernel: end_request: critical nexus error, dev " + sd_re + ", sector .*~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_end_request_error(line,words,source)~"\
    "\n"\
    ""
kernel_buffer_io_error_scan_blocks = ''
kernel_buffer_io_error_scan_table = \
    "kernel: Buffer I/O error on dev " + sd_re + ", logical block " + n11_re + ", lost async page write~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on dev " + sd_re + ", logical block " + n11_re + ", async page read~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on device " + sd_re + ", logical block " + n11_re + "~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on dev " + sd_re_p + ", logical block " + n11_re + ", lost async page write~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on device " + sd_re_p + ", logical block " + n11_re + "~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on dev " + dm_re + ", logical block " + n11_re + ", lost async page write~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_sd_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on device " + dm_re + ", logical block " + n11_re + "~"\
    "ANOM:IOERR~"\
    "EXEC_SCAN:do_buffer_io_error(line,words,source)~"\
    "INSTXT:eval summ_buffer_dm_io_error()~"\
    "\n"\
    "kernel: Buffer I/O error on device sr0, logical block " + n11_re + "~"\
    "ANOM:SR~"\
    "KCS:1133893~"\
    "\n"\
    "kernel: Buffer I/O error on device .*, logical block " + n11_re + "~"\
    "\n"\
    ""
# ?? if ioerr-6 and veritas dmp devs present, check kcs 61811?
#
kernel_bug_scan_blocks = ''
kernel_bug_scan_table = \
    "kernel: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "EXEC_SCAN:track_lockup_processes(line,words,source)~"\
    "MATCH:CONTINUE~"\
    "# ANOM:LOCKUP~"\
    "EXEC_SUMM:issue_lockup_summary()~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCS:21849~"\
    "MATCH:CONTINUE~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "TEST_SUMM:not Virtual_guest~"\
    "KCA:1353303~"\
    "MATCH:CONTINUE~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! \[(lpfc_worker_|fc_dl_)~"\
    "BZ:1063699~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! \[scopeux:~"\
    "INFO_KCS:1585363~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: BUG: warning at lib/kref.c:32/kref_get()~"\
    "TEST_SUMM:(word_in_list('EMC',all_dev_mfgs) or word_in_list('DGC',all_dev_mfgs))~"\
    "INSTXT:and EMC storage present~"\
    "KCS:1376723~"\
    "# see also:kernel: WARNING: at lib/kref.c:32 kref_get()~"\
    "\n"\
    "kernel: BUG: unable to handle kernel NULL pointer dereference at .*~"\
    "# typically only found in vmcore-dmesg.txt files, use PROC_SCAN:DETAIL to print exact line~"\
    "ANOM:VMCORE~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    ""
kernel_ext3_scan_blocks = ''
kernel_ext3_scan_table = \
    "kernel: EXT3-fs .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "MATCH:CONTINUE~"\
    "PROC_SUMM:SKIP~"\
    "# <MUST BE FIRST> add 5 points to 'filesystem' for any/all matching EXT3-fs events~"\
    "\n"\
    "kernel: EXT3-fs \(.*\): warning: checktime reached, running e2fsck is recommended~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_journal_start_sb: Detected aborted journal~"\
    "ANOM:EXT3~"\
    "KCS:67975~"\
    "\n"\
    "kernel: EXT3-fs \(.*\): error: ext3_journal_start_sb: Detected aborted journal~"\
    "ANOM:EXT3~"\
    "KCS:67975~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_free_blocks_sb: bit already cleared for block .*~"\
    "ANOM:EXT3~"\
    "KCS:26049~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): htree_dirblock_to_tree: bad entry in directory .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_lookup: unlinked inode .* in dir .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_lookup: deleted inode referenced: .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_find_entry: reading directory # .* offset .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_get_inode_loc: unable to read inode block - inode=.* block=.*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): ext3_check_descriptors: Block bitmap for group .* not in group .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\): read_block_bitmap: Cannot read block bitmap .*~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\) in ext3_write_begin: IO failure~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs error \(device .*\)~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs \(.*\): error: remounting filesystem read-only~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCS:35329~"\
    "ANOM:EXT3~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: EXT3-fs \(.*\): error: remounting filesystem read-only~"\
    "KCS:54790~"\
    "ANOM:EXT3~"\
    "\n"\
    "kernel: EXT3-fs .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']-=5~"\
    "PROC_SUMM:SKIP~"\
    "# <MUST BE LAST> in case of no match in the above EXT3-fs templates, adjust down for +5 at start...~"\
    "\n"\
    ""
kernel_ext4_scan_blocks = ''
kernel_ext4_scan_table = \
    "kernel: EXT4-fs .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "PROC_SUMM:SKIP~"\
    "MATCH:CONTINUE~"\
    "# <MUST BE FIRST> add 5 points to 'filesystem' for any/all matching EXT4-fs events~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): file system corruption: inode # " + n9_re + " logical block " + n8_re + " mapped to " + n8_re + " \(size .*\)~"\
    "INSTXT:unmount and run e2fsck -f -v -y <filesystem>~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs \(.*\): previous I/O error to superblock detected~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_journal_start_sb: Detected aborted journal~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_free_blocks_sb: bit already cleared for block .*~"\
    "ANOM:EXT4~"\
    "KCS:26049~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): htree_dirblock_to_tree: bad entry in directory .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_lookup: unlinked inode .* in dir .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_lookup: deleted inode referenced: .*~"\
    "ANOM:EXT4~"\
    "KCS:1161603~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_find_entry: reading directory # .* offset .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): __ext4_get_inode_loc: unable to read inode block - inode=.* block=.*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_mb_generate_buddy: EXT4-fs: group .*: .* blocks in bitmap~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_check_descriptors: Block bitmap for group .* not in group .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): read_block_bitmap: Cannot read block bitmap .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_discard_preallocations: Error reading block bitmap .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_discard_preallocations: Error loading buddy information for .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\): ext4_put_super:.*: Couldn't clean up journal~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\) in ext4_write_begin: IO failure~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\) in ext4_reserve_inode_write: Journal aborted~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\) in ext4_reserve_inode_write:.*: Journal has aborted~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs error \(device .*\)~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs warning \(device .*\): ext4_dx_add_entry: Directory index full!~"\
    "KCS:29894~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs warning \(device .*\): .*~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs \(.*\): Remounting filesystem read-only~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCS:35329~"\
    "ANOM:EXT4~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: EXT4-fs \(.*\): Remounting filesystem read-only~"\
    "KCS:54790~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs \(.*\): Unaligned AIO/DIO on inode " + n12_re + " by .*; performance will be poor.~"\
    "KCS:62016~"\
    "ANOM:EXT4~"\
    "\n"\
    "kernel: EXT4-fs .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']-=5~"\
    "PROC_SUMM:SKIP~"\
    "# <MUST BE LAST>in case of no match in the above EXT4-fs templates, adjust down for +5 at start...~"\
    "\n"\
    ""
kernel_xfs_scan_blocks = ''
kernel_xfs_scan_table = \
    "kernel: XFS \(.*\): Corruption detected. Unmount and run xfs_repair~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=100~"\
    "KCS:1194613~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Unmount and run xfs_repair~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=100~"\
    "KCS:1194613~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): xfs_log_force: error 5 returned.~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "KCS:524323~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): xfs_log_force: error -5 returned.~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "KCS:524323~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): xfs_do_force_shutdown\(0x.*\) called from .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=40~"\
    "KCS:1326923~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): xfs_imap_to_bp: xfs_trans_read_buf\(\) returned error -5~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): metadata I/O error: block 0x.* \(\"xfs_.*\"\) error 5 numblks .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Metadata corruption detected at .*\+0x.*/0x.* \[xfs\], block 0x.*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): totally zeroed log~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=8~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): log mount finish failed~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=2~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Log I/O Error Detected.  Shutting down filesystem~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=20~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Mounting V4 Filesystem~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Mounting V5 Filesystem~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Ending clean mount~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Unmounting Filesystem~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Filesystem has duplicate UUID .* - can't mount~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=20~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): metadata I/O error: block 0x.*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=5~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS: Internal error .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=20~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): discard failed for extent \[0x.*\], error .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=10~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Starting recovery \(logdev: .*\)~"\
    "ANOM:XFS~"\
    "\n"\
    "kernel: XFS \(.*\): Ending recovery \(logdev: .*\)~"\
    "ANOM:XFS~"\
    "\n"\
    ""
# =======================================================================================

#
# Improve var/log/messages scanning performance by further subdividing the previous
# kernel_misc_scan_table into individual kernel_misc_<letter>_scan_tables.
#
# Originally kernel_misc_scan_table had all the entries found belosw in the kernel_misc_<letter>_scan_tables
# however, when a large var/log/messages file was scanned with numberous 'kernel:' messages, processing all
# miscellaneous message became expensive so they were broken out into smaller lists.
#
# There is also a wildcard list (wc) which is used to catch messages which have:
# 1) more than one space after "kernel: "
# 2) the token after "kernel: " can vary, for example "kernel: <program_name> segfault..."
#
alphabet_list = "a b c d e f g h i j k l m n o p q r s t u v w x y z wc"
alphabet_words = alphabet_list.split()

kernel_misc_a_scan_blocks = ''
kernel_misc_a_scan_table = \
    "kernel: " + ata_re + ".*: SATA link up .*~"\
    "ID:sata_link_up~"\
    "EXEC_SUMM:do_sata_link(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "KCS:293693~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + ata_re + ".*: SATA link down .*~"\
    "ID:sata_link_down~"\
    "EXEC_SUMM:do_sata_link(scan_block,source)~"\
    "PROC_SUMM:SKIP~"\
    "KCS:293693~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: ASC=0x.* ASCQ=0x.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: attempt to access beyond end of device~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SUMM:do_att_abeod(line,source)~"\
    "\n"\
    "kernel: " + ata_port_re + ": exception Emask 0x.* SErr 0x.* action 0x.* frozen~"\
    "KCS:293693~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + ata_re + ": soft resetting link~"\
    "KCS:653833~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + ata_port_re + ": soft resetting link~"\
    "KCS:653833~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + ata_re + ": hard resetting link~"\
    "ID:sata_link_hard_reset_1~"\
    "KCS:293693~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + ata_port_re + ": hard resetting link~"\
    "ID:sata_link_hard_reset_2~"\
    "KCS:293693~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: ACPI Error: SMBus or IPMI write requires Buffer of length " + n3_re + ", found length " + n3_re + " (.*/exfield-286)~"\
    "INFO_KCS:48109~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: audit: backlog limit exceeded~"\
    "KCS:293693~"\
    "ANOM:FS~"\
    "\n"\
    "kernel: ACPI: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: audit_printk.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: ACFSK-0029: Volume /dev/.* is now offline~"\
    "ANOM:ORACLE~"\
    "\n"\
    "kernel: ACFSK-0030: ASM Instance has Failed.~"\
    "ANOM:ORACLE~"\
    "\n"\
    "kernel: ADVMK-0019: Volume .* in disk group .* was taken offline, all attempts to read or write to this volume will fail.~"\
    "ANOM:ORACLE~"\
    "\n"\
    "kernel: ADVMK-0006: Volume .* in diskgroup .* disabled.~"\
    "ANOM:ORACLE~"\
    "\n"\
    "kernel: amf: disagrees about version of symbol .*~"\
    "KCS:3400841~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    ""
kernel_misc_b_scan_blocks = ''
kernel_misc_b_scan_table = \
    "kernel: bio too big device " + mdn_re + " \(" + n5_re + " > " + n5_re + "\)~"\
    "BZ:1557434~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: bio too big device " + dm_re + " \(" + n5_re + " > " + n5_re + "\)~"\
    "KCS:62245~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: bio too big device .* \(" + n5_re + " > " + n5_re + "\)~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: bdi-block not registered~"\
    "\n"\
    "kernel: broken BIOS!!~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: Brought up " + n3_re + " CPUs~"\
    "EXEC_SCAN:get_active_cpu_count(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: bio too big device " + dm_re + " \(" + n4_re + " > " + n4_re + "\)~"\
    "KCS:62245~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: blk_cloned_rq_check_limits: over max size limit~"\
    "TEST_SUMM:(word_in_list('gpfs',all_fs_types))~"\
    "INSTXT:and gpfs file systems present~"\
    "KCS:2437991~"\
    "KCS:3014361~"\
    "# SFDC:01651876~"\
    "MATCH:CONTINUE~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: blk_cloned_rq_check_limits: over max size limit~"\
    "INSTXT:, max_sectors_kb may need to be set~"\
    "KCS:145163~"\
    "KCS:2802071~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: blk_cloned_rq_check_limits: over max segments limit~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: bonding: bond" + n1_re + ": link status definitely down for interface eth" + n1_re + ", disabling it~"\
    "KCS:44475~"\
    "ANOM:FW~"\
    "\n"\
    "kernel: bonding: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: bond.*: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: BFA" + pci_br_long_re + "\[error\] BFA_AEN_PORT_DISCONNECT: Base port \(WWN = " + wwn_re + "\) lost fabric connectivity.~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "KCS:118393~"\
    "\n"\
    "kernel: BFA" + pci_br_long_re + "\[error\] BFA_AEN_RPORT_DISCONNECT: Remote port \(WWN = " + wwn_re + "\) connectivity lost for logical port \(WWN = " + wwn_re + "\)~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "KCS:118393~"\
    "\n"\
    "kernel: BFA" + pci_br_long_re + "\[error\] BFA_AEN_ITNIM_DISCONNECT: Target \(WWN = " + wwn_re + "\) connectivity lost for initiator \(WWN = " + wwn_re + "\)~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "KCS:118393~"\
    "\n"\
    "kernel: BFA" + pci_br_long_re + "\[warn\] BFA_AEN_IOC_FWMISMATCH: Running firmware version is incompatible with the driver version~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: BFA" + pci_br_long_re + "\[warn\] BFA_AEN_PORT_OFFLINE: Base port offline: WWN = .*~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: bfa " + pci_long_re + ": bfa init failed~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: bfa " + pci_long_re + ": Base port \(WWN = .*\) lost fabric connectivity~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "\n"\
    "kernel: bfa " + pci_long_re + ": Target \(WWN = .*\) connectivity lost for initiator \(WWN = .*\)~"\
    "KCS:118393~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "\n"\
    "kernel: bfa " + pci_long_re + ": Remote port \(WWN = .*\) connectivity lost for logical port \(WWN = .*\)~"\
    "KCS:118393~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:FCOE~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "\n"\
    "kernel: bnx2fc: initiate_abts: link is not ready~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: BIOS.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_c_scan_blocks = ''
kernel_misc_c_scan_table = \
    "kernel: CPU: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: cciss~"\
    "EXEC_SCAN:event_count['cciss']+=1~"\
    "PROC_SUMM:SKIP~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: cciss " + pci_long_re + ": cciss: c .* has CHECK CONDITION sense key = 0x4~"\
    "EXEC_SCAN:track_cciss_devs(words[2],'',source)~"\
    "KCS:647233~"\
    "EXEC_SCAN:anomaly_points['hardware']+=10~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: cciss: cmd .* has CHECK CONDITION sense key = 0x4~"\
    "EXEC_SCAN:track_cciss_devs(words[3],'',source)~"\
    "KCS:647233~"\
    "EXEC_SCAN:anomaly_points['hardware']+=10~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: cciss " + pci_long_re + ": cciss: c .* has CHECK CONDITION sense key = 0x3~"\
    "EXEC_SCAN:track_cciss_devs(words[2],'',source)~"\
    "KCS:2796~"\
    "EXEC_SCAN:anomaly_points['hardware']+=10~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: cciss: cmd .* has CHECK CONDITION sense key = 0x3~"\
    "EXEC_SCAN:track_cciss_devs(words[3],'',source)~"\
    "KCS:2796~"\
    "EXEC_SCAN:anomaly_points['hardware']+=10~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: CDB .*: hardware error~"\
    "KCS:304093~"\
    "\n"\
    "kernel: ch " + scsi_adr_re + ":~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "MATCH:CONTINUE~"\
    "ANOM:CH~"\
    "\n"\
    "kernel: ch " + scsi_adr_re + ": rejecting I/O to offline device~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:CH~"\
    "\n"\
    "kernel: ch " + scsi_adr_re + ": attempting task abort! scmd\(.*\)~"\
    "INFO_KCS:193743~"\
    "ANOM:CH~"\
    "\n"\
    "kernel: connection" + n3_re + ":0: detected conn error \(" + n4_re + "\)~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=5~"\
    "KCS:36141~"\
    "KCS:45167~"\
    "KCS:423473~"\
    "ANOM:ISCSI~"\
    "\n"\
    "kernel: ch " + scsi_adr_re + ": Device offlined - not ready after error recovery~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:CH~"\
    "\n"\
    "kernel: ch " + scsi_adr_re + ": scsi: Device offlined - not ready after error recovery~"\
    "EXEC_SCAN:check_offlined_msg(line,source)~"\
    "ANOM:CH~"\
    "\n"\
    "kernel: cxgb4 " + pci_long_re + ": unable to load firmware image .*~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: Call Trace:~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: CPU " + n2_re + ": Machine Check Exception: " + n2_re + " Bank " + n2_re + ": .*~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: Cannot recover from unknown opcode while ERL=0, closing iSCSI connection.~"\
    "ANOM:ISCSI~"\
    "\n"\
    ""
kernel_misc_d_scan_blocks = ''
kernel_misc_d_scan_table = \
    "kernel: dasd-eckd " + cuuu_re + ": .*~"\
    "EXEC_SCAN:check_s390_dasd(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: dasd-fba " + cuuu_re + ": .*~"\
    "EXEC_SCAN:check_s390_dasd(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: dasd-eckd " + cuuu_re + ": An error occurred in the DASD device driver, reason=.*~"\
    "ANOM:DASD~"\
    "KCS:171983~"\
    "\n"\
    "kernel: dasd-eckd " + cuuu_re + ": No operational channel path is left for the device~"\
    "ANOM:DASD~"\
    "\n"\
    "kernel: dasd-eckd " + cuuu_re + ": cqr .* timed out \(" + n4_re + "s\), " + n4_re + " retries remaining~"\
    "ANOM:DASD~"\
    "\n"\
    "kernel: dasd-eckd " + cuuu_re + ": FORMAT F - Operation Terminated~"\
    "ANOM:DASD~"\
    "\n"\
    "kernel: " + dm_re + ": rw=.*, want=.*, limit=.*~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:do_attempt_to_access_beyond_end_of_device(line,words,source)~"\
    "ANOM:MULTIPATH~"\
    "\n"\
    "kernel: DMI: ~"\
    "EXEC_SCAN:do_dmi_line(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: dracut: Found duplicate PV .*: using /dev/" + sd_re_p + " not /dev/" + sd_re_p + "~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "EXEC_SCAN:anomaly_points['lvm']+=1~"\
    "\n"\
    "kernel: dracut: Found duplicate PV .*: using /dev/" + sd_re + " not /dev/" + sd_re + "~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "EXEC_SCAN:anomaly_points['lvm']+=1~"\
    "\n"\
    "kernel: dracut: Found duplicate PV .*: using /dev/.* not /dev/.*~"\
    "ANOM:LVM~"\
    "KCS:2989~"\
    "EXEC_SCAN:anomaly_points['lvm']+=1~"\
    "\n"\
    "kernel: dracut: device-mapper: create ioctl on .* failed: Device or resource busy~"\
    "ANOM:LVM~"\
    "\n"\
    "kernel: dracut: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: do_IRQ: " + n2_re + "." + n3_re + " No irq handler for vector \(irq -1\)~"\
    "KCS:110053~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: Dev " + sd_re + ": unable to read RDB block " + n12_re + "~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: Dev .*: unable to read RDB block " + n12_re + "~"\
    "# emcpower, dm, etc.~"\
    "ANOM:SD~"\
    "\n"\
    ""
kernel_misc_e_scan_blocks = ''
kernel_misc_e_scan_table = \
    "kernel: Error:Mpx:Path Bus " + n3_re + " Tgt " + n3_re + " Lun " + n3_re + " to .* is dead~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "# TODO:get anom type and pts assigned from table entries~"\
    "KCS:120943~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: Error:Mpx:Bus " + n3_re + " to .* port .* is dead~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:120943~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: Error:Mpx:All paths to .* are dead~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:120943~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: Error:emcp:emcp_pseudo_ctl_ioctl: Invalid cmd 0x.*, proc name: scsi_id~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: eth" + n1_re + ": firmware hang detected~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:44475~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: EDAC e7xxx: error reporting device not found:vendor 8086 device 0x.* \(broken BIOS\?\)~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:43904~"\
    "ANOM:HW~"\
    "\n"\
    ""
kernel_misc_f_scan_blocks = ''
kernel_misc_f_scan_table = \
    "kernel: Free swap .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: fcoe fcf_2: FIP fcf connection time out: removing fcf~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: fioerr Fusion-io .* ioScale2 .*: request append .* failed -22~"\
    "ANOM:HW~"\
    "\n"\
    ""
kernel_misc_g_scan_blocks = ''
kernel_misc_g_scan_table = \
    "kernel: general protection fault: " + n4_re + " \[# " + n2_re + "\] .*~"\
    "# (rare, see case  as an example)~"\
    "ANOM:VMCORE~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "kernel: GFS2: fsid=.*: fatal: I/O error~"\
    "ANOM:FS~"\
    "\n"\
    "kernel: GHES: Generic hardware error source: " + n5_re + " notified via NMI is not supported!~"\
    "INFO_KCS:64818~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: GHES: Generic hardware error source: .*~"\
    "INSTXT:check with hardware vendor~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: gsch_get_file_event\(\) open\(.*\(.*\)\) failed: .*~"\
    "KCS:1376133~"\
    "\n"\
    "kernel: Got unknown iSCSI OpCode: 0x.*~"\
    "ANOM:ISCSI~"\
    "\n"\
    ""
kernel_misc_h_scan_blocks = ''
kernel_misc_h_scan_table = \
    "kernel: Hardware name: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: " + hda_re + ": drive_cmd: status=0x51 { DriveReady SeekComplete Error }~"\
    "TEST_SCAN:(rhel_is('LE','5.99'))~"\
    "KCS:19204~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + hda_re + ": cdrom_decode_status: status=0x51 { DriveReady SeekComplete Error }~"\
    "TEST_SCAN:(rhel_is('LE','5.99'))~"\
    "KCS:19204~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: " + hda_re + ": drive not ready for command~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: host" + n3_re + ": libfc: Link down on port \(.*\)~"\
    "EXEC_SCAN:anomaly_points['fcoe']+=30~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: host" + n3_re + ": ~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_host(line,source)~"\
    "\n"\
    "kernel: Hypervisor detected: ~"\
    "EXEC_SCAN:do_dmi_line(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: hpsa .*: cmd_alloc returned NULL~"\
    "EXEC_SCAN:event_count['hpsa']+=1~"\
    "KCS:392983~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: hpsa .*: Abort request on .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=5~"\
    "EXEC_SCAN:event_count['hpsa']+=1~"\
    "KCS:304093~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: hpsa .*: Controller lockup detected: 0x.*~"\
    "EXEC_SCAN:event_count['hpsa']+=10~"\
    "KCS:304093~"\
    "ANOM:HPE~"\
    "\n"\
    "kernel: hpsa " + pci_long_re + ": PCIe Bus Error: severity=Corrected, type=.*, id=.*\(.*\)~"\
    "ANOM:HPE~"\
    "KCS:56302~"\
    "\n"\
    "kernel: hv_storvsc vmbus_.*_.*: cmd 0x.* scsi status 0x.* srb status 0x.*~"\
    "ANOM:SCSI~"\
    "KCS:1985653~"\
    "\n"\
    ""
kernel_misc_i_scan_blocks = ''
kernel_misc_i_scan_table = \
    "kernel: Info fld=0x.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: INFO: task .*:" + pid_re + " blocked for more than " + n4_re + " seconds~"\
    "ANOM:HUNG~"\
    "EXEC_SCAN:anomaly_points['performance']+=10~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:process_blocked_tasks(line,words,source)~"\
    "\n"\
    "kernel: io scheduler .* registered \(default\)~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:cmdline['elevator']=words[3]~"\
    "\n"\
    "kernel: iTCO_wdt: Unexpected close, not stopping watchdog!~"\
    "URL:https://support.symantec.com/en_US/article.TECH186628.html~"\
    "\n"\
    "kernel: Intel pstate controlling: cpu " + n3_re + "~"\
    "EXEC_SCAN:do_intel_cpu(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: isci .*: isci_port_perform_hard_reset: iport = .*; hard reset failed~"\
    "ANOM:ISCSI~"\
    "\n"\
    "kernel: iSCSI Login negotiation failed.~"\
    "ANOM:ISCSI~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=10~"\
    "\n"\
    "kernel: iSCSI Login timeout on Network Portal " + ip_addr_and_port_re + "~"\
    "ANOM:ISCSI~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=10~"\
    "\n"\
    "kernel: Info:Mpx:Path Bus " + n3_re + " Tgt " + n3_re + " Lun " + n5_re + " is set to Auto standby due to Iopf.~"\
    "KCS:532893~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: Info:Mpx:Latency Threshold exceeded by Path Bus " + n3_re + " Tgt " + n4_re + " Lun " + n5_re + " Vol .* with a new high latency of " + n6_re + " msec~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: ipr " + pci_long_re + ": " + hex4_re + ": A permanent cache battery pack failure occurred~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: ip_conntrack: table full, dropping packet~"\
    "KCS:8721~"\
    "ANOM:NETWORK~"\
    "\n"\
    "kernel: ioapic: probe of " + pci_long_re + " failed with error -22~"\
    "INFO_KCS:913863~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: i8042: probe of i8042 failed with error -5~"\
    "INFO_KCS:184883~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: Illegally set Immediate Bit in iSCSI Initiator Scsi Command PDU.~"\
    "ANOM:ISCSI~"\
    "\n"\
    "kernel: IPv4: martian source " + ip_addr_re + " from " + ip_addr_re + ", on dev eth" + n1_re + "~"\
    "EXEC_SCAN:anomaly_points['configuration']+=1~"\
    "KCS:25157~"\
    "ANOM:NETWORK~"\
    "\n"\
    "kernel: IPv4: martian source " + ip_addr_re + " from " + ip_addr_re + ", on dev bond" + n1_re + "~"\
    "EXEC_SCAN:anomaly_points['configuration']+=1~"\
    "KCS:25157~"\
    "ANOM:NETWORK~"\
    "\n"\
    "kernel: IP: .*~"\
    "# typically only found in vmcore-dmesg.txt files, use PROC_SCAN:DETAIL to print exact line~"\
    "# (see case  as an example)~"\
    "ANOM:VMCORE~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    ""
kernel_misc_j_scan_blocks = ''
kernel_misc_j_scan_table = \
    "kernel: JBD2: Detected IO errors while flushing file data on .*~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=15~"\
    "INSTXT:suggest dismounting filesytem and running e2fsck to check the FS~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=2~"\
    "ANOM:FS~"\
    "\n"\
    "kernel: JBD: Spotted dirty metadata buffer \(dev = .*, blocknr = .*\). There's a risk of filesystem corruption in case of system crash~"\
    "KCS:358963~"\
    "EXEC_SCAN:anomaly_points['filesystem']+=2~"\
    "ANOM:FS~"\
    "\n"\
    ""
kernel_misc_k_scan_blocks = ''
kernel_misc_k_scan_table = \
    "kernel: kworker/" + n3_re + ":" + n3_re + ": page allocation failure: order:.*, mode:0x.*~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: kernel BUG at .*~"\
    "# typically only found in vmcore-dmesg.txt files, use PROC_SCAN:DETAIL to print exact line~"\
    "ANOM:VMCORE~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    ""
kernel_misc_l_scan_blocks = ''
kernel_misc_l_scan_table = \
    "kernel: lowmem_reserve.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: libfc: lookup request for XID = " + n5_re + ", indicates invalid CPU " + n3_re + "~"\
    "BZ:1431440~"\
    "BZ:1378320~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: lin_tape: detected device at host " + n3_re + ", channel " + n3_re + ", id " + n3_re + ", lun " + n5_re + "~"\
    "EXEC_SCAN:do_lin_tape(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: lin_tape: attached .*~"\
    "EXEC_SCAN:do_lin_tape(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: lin_tape " + scsi_adr_re + ": Unexpected response from lun " + n4_re + " while scanning, scan aborted~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "ANOM:ST~"\
    "\n"\
    "kernel: lost page write due to I/O error on rss.*~"\
    "ANOM:IOERR~"\
    "KCS:484063~"\
    "KCS:163643~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "\n"\
    "kernel: lost page write due to I/O error on .*~"\
    "ANOM:IOERR~"\
    "KCS:62032~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "\n"\
    "kernel: libfcoe: host" + n2_re + ": Missing Discovery Advertisement for fab .* count .*~"\
    "ANOM:FCOE~"\
    "\n"\
    "kernel: libfcoe: host" + n2_re + ": FIP Fibre-Channel Forwarder MAC " + mac_re + " deselected~"\
    "ANOM:FCOE~"\
    "\n"\
    ""
kernel_misc_m_scan_blocks = ''
kernel_misc_m_scan_table = \
    "kernel: Mem-Info:.*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: megasas: \[" + n4_re + "\]waiting for " + n3_re + " commands to complete for .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:1481613~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": \[" + zero_or_more_spaces + n4_re + "\]waiting for " + n3_re + " commands to complete for .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:1481613~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megasas_sas: " + pci_long_re + ": \[" + zero_or_more_spaces + n4_re + "\]waiting for " + n3_re + " commands to complete for .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:1481613~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megasas: \[" + n4_re + "\]waiting for " + n3_re + " commands to complete~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "KCS:1481613~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas: FW detected to be in fault state, restarting it~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:412643~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas: FW detected to be in faultstate, restarting it~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:412643~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megasas: Found FW in FAULT state, will reset adapter~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:412643~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megasas: FW in FAULT state!!~"\
    "EXEC_SCAN:anomaly_points['hardware']+=20~"\
    "KCS:412643~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": Firmware crash dump is not available~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "INFO_KCS:2217981~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas: resetting fusion adapter .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:412643~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/CRIT\) - Enclosure PD " + n2_re + "\(.*\) not responding~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/CRIT\) - Controller encountered a fatal error and was reset~"\
    "EXEC_SCAN:anomaly_points['hardware']+=30~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/CRIT\) - Diagnostics failed for PD .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=30~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/FATAL\) - Unrecoverable medium error during recovery on PD .* at .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=50~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/FATAL\) - VD .*/.* is now OFFLINE~"\
    "EXEC_SCAN:anomaly_points['hardware']+=50~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas " + pci_long_re + ": " + n9_re + " \(.*/FATAL\) - VD .*/.* access blocked as cached data in CacheCade\(TM\) is unavailable~"\
    "EXEC_SCAN:anomaly_points['hardware']+=50~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: megaraid_sas 0000:5e:00.0: Found FW in FAULT state, will reset adapter scsi2.~"\
    "EXEC_SCAN:anomaly_points['hardware']+=50~"\
    "INSTXT:contact vendor and open a parallel case~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: mpdt " + scsi_adr_re + ":~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "MATCH:CONTINUE~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: mpdt " + scsi_adr_re + ": attempting task abort! scmd\(.*\)~"\
    "INFO_KCS:193743~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: mptscsih: ioc[0-9]: attempting task abort!~"\
    "ANOM:SCSI~"\
    "TEST_SCAN:Virtual_guest~"\
    "KCS:108273~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: mptscsih: ioc[0-9]: attempting task abort!~"\
    "ANOM:SCSI~"\
    "# TEST_SCAN:word_in_list('LSI',all_hba_mfgs)~"\
    "KCS:912143~"\
    "\n"\
    "kernel: mpt2sas0: port enable: failed~"\
    "ANOM:SCSI~"\
    "INSTXT:possible hardware problem~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "\n"\
    "kernel: mpt2sas0: fault_state\(0x.*\)~"\
    "ANOM:SCSI~"\
    "INSTXT:possible hardware problem~"\
    "KCS:1990653~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "\n"\
    "kernel: mpt2sas0: sending diag reset !!~"\
    "ANOM:SCSI~"\
    "INSTXT:possible hardware problem~"\
    "KCS:1990653~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "\n"\
    "kernel: mpt2sas " + pci_long_re + ": invalid short VPD tag .* at offset .*~"\
    "ANOM:SCSI~"\
    "INFO_KCS:3001451~"\
    "\n"\
    "kernel: mpt3sas_cm" + n1_re + ": # " + n3_re + "scsi_status\(check condition\)\(0x" + hex2_re + "\), scsi_state\(.*\)\(0x" + hex2_re + "\)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: multipathd.*: segfault at .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=2~"\
    "ANOM:MULTIPATHD~"\
    "\n"\
    "kernel: microcode: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: md/raid:" + mdn_re + ": read error NOT corrected!! \(sector " + n12_re + " on " + sd_re_p + "\).~"\
    "ANOM:SD~"\
    "\n"\
    ""
kernel_misc_n_scan_blocks = ''
kernel_misc_n_scan_table = \
    "kernel: Node .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: NETDEV WATCHDOG: eth.* \(.*\): transmit queue " + n3_re + " timed out~"\
    "KCS:43168~"\
    "\n"\
    "kernel: nfs: server .* not responding, still trying~"\
    "EXEC_SCAN:do_nfs_not_responding(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['nfs']+=20~"\
    "KCS:28211~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: nfs: server .* not responding, timed out~"\
    "EXEC_SCAN:do_nfs_not_responding(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['nfs']+=20~"\
    "KCS:28211~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: nfsacl: server .* not responding, still trying~"\
    "EXEC_SCAN:do_nfs_not_responding(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['nfs']+=20~"\
    "KCS:28211~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: nfsacl: server .* not responding, timed out~"\
    "EXEC_SCAN:do_nfs_not_responding(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['nfs']+=20~"\
    "KCS:28211~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: NFS: nfs4_reclaim_open_state: Lock reclaim failed!~"\
    "EXEC_SCAN:anomaly_points['nfs']+=5~"\
    "KCS:2586191~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: NFS: nfs4_reclaim_open_state: unhandled error -55~"\
    "EXEC_SCAN:anomaly_points['nfs']+=5~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: NFS: nfs4_reclaim_open_state: unhandled error -10026~"\
    "EXEC_SCAN:anomaly_points['nfs']+=5~"\
    "KCS:1291523~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: NFS: nfs4_reclaim_open_state: unhandled error -10068~"\
    "EXEC_SCAN:anomaly_points['nfs']+=5~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: NFS: nfs4_reclaim_open_state: unhandled error .*~"\
    "EXEC_SCAN:anomaly_points['nfs']+=5~"\
    "ANOM:NFS~"\
    "\n"\
    "kernel: nf_conntrack: table full, dropping packet~"\
    "KCS:8721~"\
    "\n"\
    "kernel: NMI watchdog: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "EXEC_SCAN:track_lockup_processes(line,words,source)~"\
    "MATCH:CONTINUE~"\
    "# ANOM:LOCKUP~"\
    "EXEC_SUMM:issue_lockup_summary()~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: NMI watchdog: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCS:21849~"\
    "MATCH:CONTINUE~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: NMI watchdog: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! .*~"\
    "TEST_SUMM:not Virtual_guest~"\
    "KCA:1353303~"\
    "MATCH:CONTINUE~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: NMI watchdog: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! \[(lpfc_worker_|fc_dl_)~"\
    "BZ:1063699~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: NMI watchdog: BUG: soft lockup - CPU# " + n3_re + " stuck for " + n3_re + "s! \[scopeux:~"\
    "INFO_KCS:1585363~"\
    "PROC_SCAN:DETAIL~"\
    "ANOM:LOCKUP~"\
    "\n"\
    "kernel: nvme " + pci_long_re + ": PCIe Bus Error: severity=Corrected, type=.*, id=.*\(.*\)~"\
    "ANOM:PCI~"\
    "KCS:56302~"\
    "\n"\
    ""
kernel_misc_o_scan_blocks = ''
kernel_misc_o_scan_table = \
    "kernel: Out of memory: Kill process " + n5_re + " \(.*\) score " + n4_re + " or sacrifice child~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:25965~"\
    "KCS:22871~"\
    "ANOM:KERN~"\
    "\n"\
    ""
kernel_misc_p_scan_blocks = ''
kernel_misc_p_scan_table = \
    "kernel: program bma is using a deprecated SCSI ioctl, please convert it to SG_IO~"\
    "INFO_KCS:446063~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: Pid: " + pid_re + ", comm: .* Tainted: .*~"\
    "ANOM:TAINT~"\
    "\n"\
    "kernel: Pid: " + pid_re + "\(.*\) over core_pipe_limit~"\
    "ANOM:KERNEL~"\
    "KCS:2046443~"\
    "\n"\
    "kernel: pci " + pci_long_re + ": BAR " + n2_re + ": can't assign mem pref \(size 0x.*\)~"\
    "ANOM:PCI~"\
    "KCS:411113~"\
    "\n"\
    "kernel: pci " + pci_long_re + ": BAR " + n2_re + ": failed to assign \[io  size 0x.*\]~"\
    "ANOM:PCI~"\
    "KCS:2772311~"\
    "\n"\
    "kernel: pcieport " + pci_long_re + ": AER: Corrected error received: id=.*~"\
    "KCS:56302~"\
    "ANOM:PCI~"\
    "\n"\
    "kernel: pcieport " + pci_long_re + ": device [.*:.*] has invalid IRQ; check vendor BIOS~"\
    "ANOM:PCI~"\
    "KCS:1562773~"\
    "\n"\
    "kernel: pci " + pci_long_re + ": can't find IRQ for PCI INT .*; probably buggy MP table~"\
    "ANOM:PCI~"\
    "KCS:1562773~"\
    "\n"\
    "kernel: pci .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_q_scan_blocks = ''
kernel_misc_q_scan_table = \
    ""
kernel_misc_r_scan_blocks = ''
kernel_misc_r_scan_table = \
    "kernel: raid[0-9]{1,2}: " + sd_re + ": unrecoverable I/O '~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:do_unrecov_io_error(line,words,source)~"\
    "ANOM:IOERR~"\
    "\n"\
    "kernel: Remounting filesystem read-only~"\
    "TEST_SUMM:Virtual_guest~"\
    "KCS:35329~"\
    "ANOM:FS~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: Remounting filesystem read-only~"\
    "ANOM:FS~"\
    "\n"\
    "kernel: Result: hostbyte=DID_ERROR driverbyte=DRIVER_OK~"\
    "KCS:438403~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE,SUGGEST_OK~"\
    "ANOM:SCSI~"\
    "KCS:369363~"\
    "KCS:33097~"\
    "\n"\
    "kernel: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK,SUGGEST_OK~"\
    "ANOM:SCSI~"\
    "KCS:1212233~"\
    "\n"\
    "kernel: Result: hostbyte=DID_TRANSPORT_DISRUPTED driverbyte=DRIVER_OK,SUGGEST_OK~"\
    "ANOM:SCSI~"\
    "INFO_KCS:131533~"\
    "\n"\
    "kernel: Result: hostbyte=DID_TRANSPORT_DISRUPTED driverbyte=DRIVER_TIMEOUT,SUGGEST_OK~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: Read-error on swap-device \(" + mm_re + ":" + n7_re + "\)~"\
    "ANOM:KERN~"\
    "KCS:1450043~"\
    "KCS:2085473~"\
    "\n"\
    "kernel: Read" + pa_n2_re + ".*~"\
    "# 7.1 msg, preceded by kernel: sd h:b:t:l [sdcc] CDB: ~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    ""
kernel_misc_s_scan_blocks = ''
kernel_misc_s_scan_table = \
    "kernel: " + sd_re + ": " + sd_re_p + "~"\
    "ANOM:SD~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_sd_partition_info(line,source)~"\
    "\n"\
    "kernel: " + sd_re + ": " + sd_re_p + "$~"\
    "# here to short circuit search -- nothing but kernel: sdcc: sdccn~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: " + sd_re + ": Current: sense key: Data Protect~"\
    "MATCH:CONTINUE~"\
    "TEST_SCAN:kernel_is('LT','2.6.32-220.el6')~"\
    "KCS:78813~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: " + sd_re + ": Current: sense key: Medium Error~"\
    "PROC_SUMM:SKIP~"\
    "PROC_SCAN:DETAIL~"\
    "INSTXT:likely hardware problem~"\
    "KCS:35465~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: " + sd_re + ": Current: sense key: Not Ready~"\
    "KCS:431923~"\
    "\n"\
    "kernel: " + sd_re + ": rw=.*, want=.*, limit=.*~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:do_attempt_to_access_beyond_end_of_device(line,words,source)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: " + sd_re_p + ": rw=.*, want=.*, limit=.*~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:do_attempt_to_access_beyond_end_of_device(line,words,source)~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: " + sd_re + ": unknown partition table~"\
    "INFO_KCS:1611753~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: " + sd_re + ": detected capacity change from " + n12_re + " to " + n12_re + "~"\
    "KCS:436173~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: scsi_io_completion: " + n12_re + " callbacks suppressed~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: Swap cache stats: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ":~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:add_scsi_info(line,source)~"\
    "MATCH:CONTINUE~"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ": attempting task abort! scmd\(.*\)~"\
    "INFO_KCS:193743~"\
    "ANOM:SES"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request \[current\]~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SES"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ": \[storvsc\] Sense Key: Illegal Request .*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "KCS:1256863~"\
    "ANOM:SES"\
    "\n"\
    "kernel: Sense Key: Data Protect.*~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: Sense Key: Illegal Request.*~"\
    "EXEC_SCAN:global total_illegal_requests;total_illegal_requests+=1~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid command operation code~"\
    "ANOM:SES"\
    "\n"\
    "kernel: ses " + scsi_adr_re + ": \[storvsc\] Add. Sense: Invalid field in cdb~"\
    "ANOM:SES"\
    "\n"\
    "kernel: set_host_param could not find host no .*~"\
    "EXEC_SCAN:check_iscsi_host_no(line,words,source)~"\
    "EXEC_SUMM:summary_iscsi_host_no(scan_block,words,source)~"\
    "\n"\
    "kernel: systemd.*: multipathd\.service never wrote its PID file\. Failing~"\
    "ANOM:MULTIPATHD~"\
    "KCS:2857731~"\
    "\n"\
    "kernel: setup: Linux is running as a z/VM guest operating system in 64-bit mode~"\
    "EXEC_SCAN:check_virtual_status(line,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: sfc " + pci_long_re + " \(unregistered net_device\): .*~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:HW~"\
    "KCS:2912941~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "\n"\
    "kernel: sfc " + pci_long_re + " .*: MC command 0x.* inlen " + n4_re + " failed rc=.* \(raw=.*\) arg=.*~"\
    "EXEC_SCAN:track_pci_errors(line,'++',source)~"\
    "ANOM:HW~"\
    "KCS:2912941~"\
    "EXEC_SCAN:anomaly_points['hardware']+=1~"\
    "\n"\
    "kernel: sbridge: HANDLING MCE MEMORY ERROR~"\
    "ANOM:KERN~"\
    "\n"\
    "kernel: SLUB: Unable to allocate memory on node .*~"\
    "ANOM:KERN~"\
    "\n"\
    ""
kernel_misc_t_scan_blocks = ''
kernel_misc_t_scan_table = \
    "kernel: Total swap .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_u_scan_blocks = ''
kernel_misc_u_scan_table = \
    "kernel: Unable to locate Target IQN: .*:.* in Storage Node~"\
    "ANOM:ISCSI~"\
    "\n"\
    "kernel: UNSUPPORTED HARDWARE DEVICE: Intel CPU model~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "PROC_SCAN:DETAIL~"\
    "INFO_KCS:722773~"\
    "\n"\
    "kernel: UNSUPPORTED HARDWARE DEVICE: .*~"\
    "EXEC_SCAN:anomaly_points['hardware']+=100~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "kernel: unknown partition table~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: unable to read partition table~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: usb .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_v_scan_blocks = ''
kernel_misc_v_scan_table = \
    "kernel: VxVM vxdmp V-.*-.*-.* \[Error\] i/o error occurred \(errno=0x.\) on dmpnode " + n3_re + "/0x.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxdmp V-.*-.*-.* \[Warn\] disabled dmpnode " + n3_re + "/0x.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxdmp V-.*-.*-.* \[Warn\] disabled path " + n3_re + "/0x.* belonging to the dmpnode " + n3_re + "/0x.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxdmp V-.*-.*-.* \[Info\] disabled path " + n3_re + "/0x.* belonging to the dmpnode " + n3_re + "/0x.* due to admin CLI~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxdmp V-.*-.*-.* \[Info\] failover initiated for " + n3_re + "/0x.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxdmp V-.*-.*-.* memory allocation failed for size =0x.*~"\
    "INFO_KCS:632863~"\
    "KCS:1590523~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxio V-.*-.*-.* voldmp_errbuf_sio_start: Failed to flush the error buffer .* on device .* to DMP~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxio V-.*-.*-.* Subdisk .* block .*: Uncorrectable read error~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxio V-.*-.*-.* Subdisk .* block .*: Uncorrectable write error~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxio V-.*-.*-.* error on Plex .* while writing volume .* offset .* length .*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: vxfs: msgcnt " + n4_re + " mesg " + n4_re + ": V-.*-.*: vx_metaioerr - vx_bufiodone - /dev/vx/.* file system meta data write error in dev/block .*/.*~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: vx.*: disagrees about version of symbol .*~"\
    "KCS:3400841~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: vxfs: Unknown symbol .* \(err -22\)~"\
    "KCS:3400841~"\
    "INSTXT:customer should consult Veritas~"\
    "ANOM:VERITAS~"\
    "\n"\
    "kernel: VxVM vxio .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: vmur: z/VM virtual unit record device driver loaded~"\
    "EXEC_SCAN:check_virtual_status(line,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_w_scan_blocks = ''
kernel_misc_w_scan_table = \
    "kernel: WARNING: at lib/kref.c:32 kref_get()~"\
    "TEST_SUMM:(word_in_list('EMC',all_dev_mfgs) or word_in_list('DGC',all_dev_mfgs))~"\
    "INSTXT:and EMC storage present~"\
    "KCS:1376723~"\
    "# see also:kernel: BUG: warning at lib/kref.c:32/kref_get()~"\
    "ANOM:EMC~"\
    "\n"\
    "kernel: Workqueue: fc_wq_" + n2_re + " fc_starget_delete \[scsi_transport_fc\]~"\
    "ANOM:SCSI~"\
    "BZ:1384091~"\
    "\n"\
    "kernel: Workqueue: .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: Write-error on swap-device \(" + mm_re + ":" + n7_re + "\)~"\
    "ANOM:IOERR~"\
    "KCS:1450043~"\
    "KCS:2085473~"\
    "\n"\
    "kernel: Write" + pa_n2_re + ".*~"\
    "# 7.1 msg, preceded by kernel: sd h:b:t:l [sdcc] CDB: ~"\
    "INSTXT:[total_io_errors++]~"\
    "ANOM:SD~"\
    "\n"\
    ""
kernel_misc_x_scan_blocks = ''
kernel_misc_x_scan_table = \
    "kernel: Xen version: " + n1_re + "\." + n1_re + "\." + n1_re + "OVM \(preserve-AD\)~"\
    "EXEC_SCAN:check_virtual_status(line,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    ""
kernel_misc_y_scan_blocks = ''
kernel_misc_y_scan_table = \
    ""
kernel_misc_z_scan_blocks = ''
kernel_misc_z_scan_table = \
    ""
kernel_misc_wc_scan_blocks = ''
kernel_misc_wc_scan_table = \
    "kernel: .* INFO: task .*:" + pid_re + " blocked for more than " + n4_re + " seconds~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:process_blocked_tasks(line,words,source)~"\
    "\n"\
    "kernel: .*: page allocation failure. order:2, mode:.* in bnx2x.*~"\
    "ANOM:KERN~"\
    "KCS:641323~"\
    "\n"\
    "kernel: .*: page allocation failure. order:~"\
    "ANOM:KERN~"\
    "EXEC_SCAN:global page_allocation_failure_count;page_allocation_failure_count+=1~"\
    "INSTXT:check vm.min_free_kbytes (-p option)~"\
    "KCA:1360023~"\
    "\n"\
    "kernel: [Hardware Error]: Machine check events logged~"\
    "ANOM:HW~"\
    "\n"\
    "kernel: .*: module license .* taints kernel.~"\
    "ANOM:TAINT~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "kernel: .* found: kernel tainted.~"\
    "ANOM:TAINT~"\
    "PROC_SCAN:DETAIL~"\
    "\n"\
    "kernel: .*: loading out-of-tree module taints kernel~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:800133~"\
    "ANOM:TAINT~"\
    "\n"\
    "kernel: .*: module verification failed: signature and/or required key missing - tainting kernel~"\
    "PROC_SCAN:DETAIL~"\
    "KCS:800133~"\
    "ANOM:TAINT~"\
    "\n"\
    "kernel:" + var_spaces + "dasd.*:VOL1/  .*: .*~"\
    "EXEC_SCAN:check_s390_dasd(line,words,line_no,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: .*session" + n2_re + ": session recovery timed out after " + n3_re + " secs~"\
    "EXEC_SCAN:process_session_recovery_timeout(line,words,source)~"\
    "EXEC_SCAN:anomaly_points['iscsi']+=20~"\
    "ANOM:ISCSI~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] \? wake_futex+.*~"\
    "ANOM:KERN~"\
    "KCS:1386323~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] \? fanotify_handle_event+.*~"\
    "ANOM:KERN~"\
    "KCS:2838901~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] \? .* \[emcp\]~"\
    "ANOM:EMC~"\
    "INSTXT:possible EMC issue~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] \? emcp_mrf+.* \[.*\]~"\
    "ANOM:EMC~"\
    "INSTXT:probable EMC issue~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] .* \[secfs2\]~"\
    "ANOM:THIRDPARTY~"\
    "KCS:280593~"\
    "\n"\
    "kernel:" + var_spaces + "\[<ffff.*>\] .*~"\
    "# here to short circuit search~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel:" + var_spaces + "rport-.*: blocked FC remote port time out: saving binding~"\
    "ANOM:RPORT~"\
    "# rhel 7~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "KCS:58169~"\
    "\n"\
    "kernel:" + var_spaces + "rport-.*: blocked FC remote port time out: removing target and saving binding~"\
    "ANOM:RPORT~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "KCS:58169~"\
    "\n"\
    "kernel:" + var_spaces + "rport-.*: blocked FC remote port time out: removing rport~"\
    "ANOM:RPORT~"\
    "INFO_KCS:65596~"\
    "EXEC_SCAN:anomaly_points['rport']+=5~"\
    "\n"\
    "kernel:" + var_spaces + "Add. Sense: Logical unit not accessible, target port in standby state~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel:" + var_spaces + "Add. Sense: Logical unit not ready, manual intervention required~"\
    "ID:lun_nr_3~"\
    "ANOM:SCSI~"\
    "KCS:738963~"\
    "\n"\
    "kernel:" + var_spaces + "cciss/" + ccd_re + ":.*~"\
    "EXEC_SCAN:do_cciss_dev(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "\n"\
    "kernel: .*: sending ioctl 2285 to a partition!~"\
    "ANOM:ORACLE~"\
    "KCS:1326193~"\
    "\n"\
    "kernel: .*: sending ioctl .* to a partition!~"\
    "ANOM:SCSI~"\
    "INFO_KCS:2189851~"\
    "\n"\
    "kernel: .*" + pid_br_re + ": segfault at .*~"\
    "EXEC_SCAN:check_segfault_lines(line,words,source)~"\
    "PROC_SUMM:SKIP~"\
    "ANOM:SEGFAULT~"\
    "\n"\
    "kernel: .*: rw=.*, want=.*, limit=.*~"\
    "PROC_SUMM:SKIP~"\
    "EXEC_SCAN:do_attempt_to_access_beyond_end_of_device(line,words,source)~"\
    "ANOM:SCSI~"\
    "\n"\
    "kernel:" + var_spaces + sd_re + ": unknown partition table~"\
    "INFO_KCS:1611753~"\
    "ANOM:SD~"\
    "\n"\
    "kernel: .*: disagrees about version of symbol .*~"\
    "KCS:3400841~"\
    "INSTXT:customer should consult vendor~"\
    "ANOM:NOTE~"\
    "\n"\
    ""
# end of scan_tables --------------------------------------------------------------------
# =======================================================================================


# ============================#
# End of data definitions
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Start of data gathering
# In general, try to gather needed and or more reliable
# information first, then proceed to log file data;
# var/log/dmesg and var/log/messages data

# ============================#

set_scan_blocks()

debug_print(1, "starting data gathering...")

crunch_meminfo()   # crunch data in proc/meminfo

crunch_mem_info()  # set total_mem, and potentially other values

crunch_sysctl_data()  # gather kernel parameter settings (kernel., vm.)

crunch_sys_directory()  # crunch selected subdirectories and files under sys/

crunch_hostname()  # set hostname & hostname_short (if applicable)

crunch_release()  # crunch etc/release, sets rh_major/rh_minor

crunch_uname()  # Among other things, sets various kernelStr[] & kernelNum[] variables and s390

crunch_rsyslog_conf()  # set localhostname, etc.

crunch_ip_addrs()  # gather ip addresses info, create the mfg host-ip_address names

crunch_cmdline()  # Kernel command line parms

crunch_network()  # scan sos_commmands/networking/eth* files for rx/tx errors # example: case

crunch_grub()

crunch_proc_devices()  # gather major number device info

set_default_device_type_names()  # set default major number info

# scan dmesg files, set early variables if possible (actual messages scanning happens later in crunch_dmesg_files)
scan_dmesg_files()

# check syslog messages format, set messages_start_line if needed
scan_messages_files()


if kernelStr['expanded'] == '':
    kernelStr['expanded'] = kernel_normalize(kernelNum['major'], kernelNum['minor'], kernelNum['rel1'], kernelNum['rel2'])

crunch_system_startup()  # check inittab & ckconfig or systemctl (rhel 7 and beyond)

crunch_cpuinfo()

crunch_lspci()

crunch_scsi_scsi()  # slurp up scsi/scsi data

crunch_lsscsi()  # slurp up scsi/scsi data

crunch_files_for_vg_names()  # get all vg names now
crunch_ls_dev(1)
# dump_uuid_devs()

crunch_udevadm_info()

crunch_systool_info()

crunch_ps_l_info()

crunch_ps_info()

crunch_ps_slot_info()  # check proc count vs pid_max etc.

crunch_modprobe_conf()

crunch_lsmod()

crunch_lsof()

crunch_oracleasm()

crunch_dmi_data()


crunch_mcelog()

# crunch_files_for_vg_names() # get all vg names now

# crunch_scsi_scsi() # slurp up scsi/scsi data

# crunch_lsscsi() # slurp up scsi/scsi data

crunch_scsi_sg_devices()

crunch_sgmap()

crunch_hw_lshal()  # slurp up more device data

crunch_proc_partitions()  # get device & partition maj/min & size

# crunch_ls_dev(1)

crunch_md_data()

crunch_mdadm_data()

crunch_ls_sys_block()

crunch_blkid()  # provided anomalies but no real value

crunch_cluster_data()

crunch_iscsid_conf()

# TODO build etc/multipath.conf objects now that the config file is read, then evaluate
crunch_multipath_conf()


# TODO read etc/multipath/bindings
# TODO read etc/multipath/wwids

crunch_lvm_conf()

crunch_multipath_data()

crunch_lsblk_data()

crunch_dmsetup_info()

crunch_dmsetup_table(1)  # pass 1

crunch_dmsetup_tree()


crunch_dmesg_files(1)
crunch_messages_files(1)


crunch_lvs_data()

crunch_vgscan()

crunch_vgdisplay()

crunch_pvs()

crunch_dmsetup_table(2)  # pass 2 (with full vg/lv data available)

crunch_fdisk_data()

crunch_fstab(1)

crunch_df_data()

crunch_mount_data(False)  # False means not calling simply to get vg/lv names, want all fs data

crunch_proc_mounts()

crunch_fstab(2)

crunch_ls_dev(2)
# dump_uuid_devs()
crunch_parted_udev_data()

if s390:
    crunch_s390_dasd_data()

crunch_ceph_data()

crunch_gluster_data()

crunch_rpm_info()

crunch_modinfo_info()

do_scsi_stats()  # go count scsi data

check_services()

do_fs_checks()  # check for fs related issues

crunch_ls_dev(3)  # once more to get oracle devs with hba data improved

crunch_dumpe2fs_data()

crunch_sar_data()


# ============================#
# sos summary output
# ============================#

# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#
# optional summary data follows:
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#


# block_minor_cnt = Counter()         # key: block major device number, data: count of minor device numbers ||| REMOVE next 3
# block_minor_devs = Key_data()       # key: block major device number, data: unique list of minor device numbers


check_volume_groups()
if sw_vg is True:
    display_volume_groups()

if sw_fs is True:
    display_filesystems()

# CHG_MM change sw_dm to something else; sw_mm ?
# if sw_mm: display_mm_devs....
# if sw_dm is True: display_mm_devices()
display_mm_devices()  # dm_print() controls actual printing, allows anom checks to be done
if sw_dm is True:
    display_id_devices()
if sw_pci is True:
    display_pci_map()

if sw_sm is True:
    if s390:
        display_s390_devs()
    display_scsi_map()

if sw_w:
    # do_watch_words() can take time when there are many matches and more than ~20k lines in a file
    do_watch_words("var/log/dmesg", 1)

    do_watch_words("var/log/" + messages_fn, 1)

    if not file_exists_with_data("var/log/" + messages_fn):
        do_watch_words("sos_commands/general/tail_" + messages_fn, 1)


# if sw_performance   is True: chk_performance()
chk_performance()  # do peformance check regardless, only print results if sw_performance is set

if sw_configuration is True:
    chk_configuration()


# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#
# standard summary data follows:
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#

debug_print(1, "beginning summary")

print("")

display_release_and_kernel()

taint_mask = sysctl["kernel.tainted"]
tainted_desc(taint_mask, rh_major)


# hostname  = get_general_data("hostname") # done earlier now
sos_date = get_general_data("date")
if sos_date == '':
    sos_date = last_timestamp + " (best guess)"  # no dow or year, but better than nothing
uptime = get_general_data("uptime")
errorprint("hostname: {0} uname nodename: {1}".format(hostname, uname_nodename))
errorprint("sos date: {0}".format(sos_date))
errorprint("")


display_uptime()

display_mem_info()

print("")
if cpus_active == 0:
    cpus_active = cpu_count + 1  # best guess
print("DMI: {0} ({1} cpu{2}, {3} active: {4})".format(dmi_sys_data, cpu_count + 1, plural(cpu_count + 1), cpus_active, dmi_cpu_data))

display_boot_disk()

tmp = database_vendors.split()
for db in tmp:
    # if Oracle: errorprint("Oracle:{0}(~{1} procs)\n".format(Oracle,oracle_procs))
    if Virtual_guest:
        errorprint("Virtual_guest:{0}[{1}]\n".format(Virtual_guest, Virtual_type))


if cluster_status:
    errorprint("cluster status:{0}\n".format(cluster_status_line))


display_hba_mfgs()
display_stg_mfgs()

sum_scan_blocks()  # create summary based anomaly entries..

check_misc_items()

check_blocked_task_anomalies()

display_scsi_errors()

check_segfault_anomalies()

check_abort_anomalies()

check_nfs_not_responding()

check_multipath_anomalies()

check_scsi_anomalies()

check_for_oracle_sd_anomlaies()

display_anomalies()

if sw_u or uuids_to_check != '' or all_vgs_with_no_pvs != '' or all_vgs_with_missing_pvs != '':
    debug_print(3, "uuids to check '{0}'".format(uuids_to_check))
    debug_print(3, "VGs with no PVs to check '{0}'".format(all_vgs_with_no_pvs))
    debug_print(3, "VGs with missing PVs to check '{0}'".format(all_vgs_with_missing_pvs))
    if all_vgs_with_no_pvs != '':
        debug_print(3, "'{0}'".format(all_unrecognised_disk_label_devices))
    check_lvm_backup_data()
    check_lvm_backup_data()


display_anomaly_timeline()

debug_print(1, "cmdline['elevator']={0}".format(cmdline["elevator"]))
debug_print(1, "done with summary")
# debug_print(0,"lsblk mpath names:'{0}'".format(all_lsblk_mpath_names)) # REMOVE
# debug_print(0,"lsblk lvm names:'{0}'".format(all_lsblk_lvm_names)) # REMOVE
# debug_print(0,"lsblk dm names:'{0}'".format(all_lsblk_dm_names)) # REMOVE

# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#
# standard summary data finished.
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#

# run device tests, if provided, against lvm.conf and/or multipath.conf:
if lvm_device_to_test != '':
    lvm_conf_eval_rule = LVMConf["filter"]
    if lvm_conf_eval_rule == '':
        lvm_conf_eval_rule = "a/.*/"
    check_lvm_rule(lvm_device_to_test, lvm_conf_eval_rule)
    check_lvm_rule(lvm_device_to_test, lvm_conf_eval_rule)
if mpc_device_to_test != '':
    test_mpc_rule(mpc_device_to_test, mpc_rule_to_eval)
    test_mpc_rule(mpc_device_to_test, mpc_rule_to_eval)

# ============================#
# End of script
# ============================#
print("")
cleanup(0)

