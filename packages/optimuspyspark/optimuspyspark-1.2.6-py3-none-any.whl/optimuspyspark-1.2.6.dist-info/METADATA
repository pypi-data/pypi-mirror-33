Metadata-Version: 2.0
Name: optimuspyspark
Version: 1.2.6
Summary: Optimus is the missing framework for cleaning and preprocessing data in a distributed fashion with pyspark.
Home-page: https://github.com/ironmussa/Optimus/
Author: Favio Vazquez
Author-email: favio.vazquez@ironmussa.com
License: APACHE
Download-URL: https://github.com/ironmussa/Optimus/archive/1.2.6.tar.gz
Description-Content-Type: UNKNOWN
Keywords: datacleaner,apachespark,spark,pyspark,data-wrangling,data-cleansing
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Requires-Dist: pytest
Requires-Dist: findspark
Requires-Dist: pytest-spark
Requires-Dist: spark-df-profiling-optimus
Requires-Dist: pyspark
Requires-Dist: seaborn
Requires-Dist: pixiedust-optimus
Requires-Dist: deprecated
Provides-Extra: all
Requires-Dist: pytest; extra == 'all'
Requires-Dist: findspark; extra == 'all'
Requires-Dist: pytest-spark; extra == 'all'
Requires-Dist: spark-df-profiling-optimus; extra == 'all'
Requires-Dist: pyspark; extra == 'all'
Requires-Dist: seaborn; extra == 'all'
Requires-Dist: pixiedust-optimus; extra == 'all'
Requires-Dist: deprecated; extra == 'all'
Requires-Dist: pytest; extra == 'all'
Requires-Dist: mock; extra == 'all'
Requires-Dist: nose; extra == 'all'
Provides-Extra: docs
Requires-Dist: sphinx; extra == 'docs'
Requires-Dist: pytest; extra == 'docs'
Requires-Dist: mock; extra == 'docs'
Requires-Dist: nose; extra == 'docs'
Provides-Extra: lint
Requires-Dist: pep8; extra == 'lint'
Requires-Dist: pyflakes; extra == 'lint'
Provides-Extra: test
Requires-Dist: pytest; extra == 'test'
Requires-Dist: mock; extra == 'test'
Requires-Dist: nose; extra == 'test'

Optimus is the missing framework for cleaning and pre-processing data in a distributed fashion.
It uses all the power of Apache Spark (optimized via Catalyst) to do it. It implements several handy tools for data
wrangling and munging that will make your life much easier. The first obvious advantage over any other public data
cleaning library is that it will work on your laptop or your big cluster, and second, it is amazingly easy to install,
use and understand.

- Requirements:

* Apache Spark 2.2.0

* Python>=3.6

- Installation:

In your terminal just type:

$ pip install optimuspyspark

- Contributors:

* Project Manager: Argenis León.

* Original Developers: Andrea Rosales, Hugo Reyes, Alberto Bonsanto.

* Principal developer and maintainer: Favio Vázquez.

- License:

Apache 2.0 © Iron


