
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Spider Cache &#8212; Grab 0.6 documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.6',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spider Error Handling" href="error_handling.html" />
    <link rel="prev" title="Task Queue" href="task_queue.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="error_handling.html" title="Spider Error Handling"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="task_queue.html" title="Task Queue"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Grab 0.6 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="spider-cache">
<span id="id1"></span><h1>Spider Cache<a class="headerlink" href="#spider-cache" title="Permalink to this headline">¶</a></h1>
<p>There is cache built in the spider. It could be helpful on development stage.
When you need to scrape same documents for many times to check the results
and to fix bugs. Also you can crawl whole web-site, put it into cache and
then work only with cache.</p>
<p>Keep in mind that if the web-site is large, millions of web pages then working
with cache could be slower than working with live web-site. This is because of
limited disk I/O where the cache storage is hosted.</p>
<p>Also keep in mind the the spider cache is very simple:</p>
<ul class="simple">
<li>it allows to cache only GET requests</li>
<li><dl class="first docutils">
<dt>it does not allow to differentiate documents with same URL but</dt>
<dd>different cookies/headers</dd>
</dl>
</li>
<li>it does not support max-age and other cache headers</li>
</ul>
<div class="section" id="spider-cache-backends">
<span id="id2"></span><h2>Spider Cache Backends<a class="headerlink" href="#spider-cache-backends" title="Permalink to this headline">¶</a></h2>
<p>You can choose what storage to use for the cache. You can use mongodb, mysql
and postgresql.</p>
<p>MongoDB example:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">bot</span> <span class="o">=</span> <span class="n">ExampleSpider</span><span class="p">()</span>
<span class="n">bot</span><span class="o">.</span><span class="n">setup_cache</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;mongo&#39;</span><span class="p">,</span> <span class="n">database</span><span class="o">=</span><span class="s1">&#39;some-database&#39;</span><span class="p">)</span>
<span class="n">bot</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<p>In this example the spider is configured to use mongodb as cache storage.
The name of database is “some-database”. The name of collection would
be “cache”.</p>
<p>All arguments except <cite>backend</cite>, <cite>database</cite> and <cite>use_compression</cite> go to
database connection constructor. You can setup database name, host name, port,
authorization arguments and other things.</p>
<p>Example of custom host name and port for mongodb connection:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">code</span><span class="p">::</span> <span class="n">python</span>
</pre></div>
</div>
<blockquote>
<div>bot = SomeSpider()
bot.setup_cache(backend=’mongo’, port=7777, host=’mongo.localhost’)</div></blockquote>
</div>
<div class="section" id="cache-compression">
<span id="spider-cache-compression"></span><h2>Cache Compression<a class="headerlink" href="#cache-compression" title="Permalink to this headline">¶</a></h2>
<p>By default cache compression is enabled. That means that all documents placed in
the cache are compressed with gzip library. Compression decreases the disk space
required to store the cache and increases the CPU load (a bit).</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Spider Cache</a><ul>
<li><a class="reference internal" href="#spider-cache-backends">Spider Cache Backends</a></li>
<li><a class="reference internal" href="#cache-compression">Cache Compression</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="task_queue.html"
                        title="previous chapter">Task Queue</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="error_handling.html"
                        title="next chapter">Spider Error Handling</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/spider/cache.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="error_handling.html" title="Spider Error Handling"
             >next</a> |</li>
        <li class="right" >
          <a href="task_queue.html" title="Task Queue"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Grab 0.6 documentation</a> &#187;</li> 
      </ul>
    </div>
    
    <div class="footer" role="contentinfo">
        &#169; Copyright 2015, Gregory Petukhov.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
    <p style="margin-top: 0; text-align: center; font-size: 0.8em;">Developed by <a href="http://grablab.io">GrabLab</a> - web scraping and data mining services.</p>
    <p style="margin-top: 0; text-align: center; font-size: 0.8em;">He also does web scraping: <a href="https://www.imscraping.ninja">www.imscraping.ninja</a>.</p>

    <!-- Yandex.Metrika counter --> <script type="text/javascript" > (function (d, w, c) { (w[c] = w[c] || []).push(function() { try { w.yaCounter13841917 = new Ya.Metrika({ id:13841917, clickmap:true, trackLinks:true, accurateTrackBounce:true }); } catch(e) { } }); var n = d.getElementsByTagName("script")[0], s = d.createElement("script"), f = function () { n.parentNode.insertBefore(s, n); }; s.type = "text/javascript"; s.async = true; s.src = "https://mc.yandex.ru/metrika/watch.js"; if (w.opera == "[object Opera]") { d.addEventListener("DOMContentLoaded", f, false); } else { f(); } })(document, window, "yandex_metrika_callbacks"); </script> <noscript><div><img src="https://mc.yandex.ru/watch/13841917" style="position:absolute; left:-9999px;" alt="" /></div></noscript> <!-- /Yandex.Metrika counter -->


  </body>
</html>