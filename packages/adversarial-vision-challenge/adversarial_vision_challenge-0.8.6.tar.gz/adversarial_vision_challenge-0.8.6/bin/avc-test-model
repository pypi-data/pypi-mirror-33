#!/usr/bin/env python3

from __future__ import print_function

import threading
import argparse
import subprocess
import adversarial_vision_challenge
import foolbox
import numpy as np
import yaml
import time
import os
import sys
import socket
from tqdm import tqdm

def checkmark():
    print(u' \u2713')

def _get_free_port():
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(('', 0))
        return s.getsockname()[1]


def test_model(directory, no_cache, gpu):
    image_name = 'avc/model_submission'
    container_name = 'avc_test_model_submission'

    subprocess.check_call('avc-test-setup', shell=True)

    print()
    print('Building docker image of submission')
    print('-----------------------------------')

    print('Submission folder: "{}"'.format(directory))

    # build image
    if no_cache:
        print('Building image (without cache)...')
        raise AssertionError('Option does not yet exist because repo2docker does not allow us to build without cache.')
        subprocess.check_call(
            "crowdai-repo2docker --no-run --image-name {} --debug {}".format(image_name, directory),
            shell=True)
    else:
        print('Building image from cache (if exists)...', end="")
        subprocess.check_call("crowdai-repo2docker --no-run --image-name {} --debug {}".format(
            image_name, directory), shell=True)
        checkmark()

    # remove old container if exists
    if container_name in str(subprocess.check_output('docker ps -a', shell=True)):
        print('Removing existing submission container...', end="")
        subprocess.check_call("docker rm -f {cn}".format(cn=container_name), shell=True)
        checkmark()

    # start model container
    port = _get_free_port()
    cmd = "NV_GPU={gpu} nvidia-docker run --expose={port} -d -p {port}:{port} "
    cmd += "-e GPU={gpu} -e MODEL_PORT={port} --name={cn} {im} bash run.sh"
    cmd = cmd.format(port=port, gpu=gpu, cn=container_name, im=image_name)
    print('Starting container on port {} using the command \n \n {}'.format(port, cmd))
    subprocess.check_call(cmd, shell=True)

    # attach to container to print output in case of failures
    cmd = "docker attach {}".format(container_name)
    dump = subprocess.Popen(cmd, shell=True, stderr=subprocess.PIPE)

    # get IP
    form = '{{ .NetworkSettings.IPAddress }}'
    cmd = "docker inspect --format='{}' {}".format(form, container_name)
    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
    p.wait()
    ip = p.stdout.read()[:-1].decode('UTF-8')
    print('Received IP of server: ', ip)

    # wait until start of server
    print('Waiting for server to start...', end="")
    for i in range(30):
        # check if the server is up
        cmd = 'wget -qO - --tries 2 --retry-connrefused http://{}:{}'
        if subprocess.Popen(cmd.format(ip, port), shell=True).wait() == 0:
            break

        # check if the container is running
        form = "{{ .State.Running }}"
        cmd = "docker inspect --format='{}' {}".format(form, container_name)
        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        p.wait()
        running = p.stdout.read().decode('UTF-8').strip() == 'true'
        if not running:
            # print any errors in the code and exit
            print(dump.stderr.read().decode('UTF-8'))
            form = "{{ .State.ExitCode }}"
            cmd = "docker inspect --format='{}' {}".format(
                form, container_name)
            p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
            p.wait()
            return exit(int(p.stdout.read().decode('UTF-8').strip()))

    checkmark()

    # start client model
    print('Connecting to model sever...', end="")
    model = adversarial_vision_challenge.TinyImageNetBSONModel('http://{}:{}'.format(ip, port))
    checkmark()

    print('Server version', model.server_version())
    # get predictions and/or gradient for model
    print('Checking model axis and bounds...', end="")
    channel_axis = model.channel_axis()

    assert channel_axis == 3, "model channel axis should be 3, but is: %s" % channel_axis
    assert model.bounds() == (0, 255), "model bounds should be (0,255), but got: %s" % model.bounds
    checkmark()

    # test predictions
    print('Checking return value...', end="")
    image, label = np.random.uniform(size=(64, 64, 3)).astype(
        np.float32) * 255, 1

    assert isinstance(model(image), int), "prediction should be an int-value, but got: %s" % type(model(image))
    checkmark()

    # test prediction performance
    print('Testing model accuracy on test samples...')
    test_samples = adversarial_vision_challenge.utils.get_test_data()
    correct = 0

    for image, label in tqdm(test_samples):
        if model(image) == label:
            correct += 1

    print('The top-1 performance of your model is {}%.'.format(100 * correct / float(len(test_samples))))

    if correct / float(len(test_samples)) < 0.5:
        raise IOError('The performance of your model is too low (< 50%)! Please check whether your preprocessing is correctly implemented.')

    print('')
    print('All tests successful, have fun submitting!')
    print('')
    sys.exit()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "directory", help="The directory containing the Dockerfile.")
    parser.add_argument(
        "--no-cache", action='store_true',
        help="Disables the cache when building the model image.")
    parser.add_argument(
        "--gpu", type=int, default=0, help="GPU number to run container on")
    args = parser.parse_args()
    test_model(args.directory, no_cache=args.no_cache, gpu=args.gpu)
